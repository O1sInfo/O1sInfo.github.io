{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/Convolutions-on-RGB-image.png","path":"images/Convolutions-on-RGB-image.png","modified":0,"renderable":0},{"_id":"source/images/adam.PNG","path":"images/adam.PNG","modified":0,"renderable":0},{"_id":"source/images/alexnet_ilsvrc.PNG","path":"images/alexnet_ilsvrc.PNG","modified":0,"renderable":0},{"_id":"source/images/Padding.jpg","path":"images/Padding.jpg","modified":0,"renderable":0},{"_id":"source/images/Stride.jpg","path":"images/Stride.jpg","modified":0,"renderable":0},{"_id":"source/images/faster_t8.PNG","path":"images/faster_t8.PNG","modified":0,"renderable":0},{"_id":"source/images/res1.PNG","path":"images/res1.PNG","modified":0,"renderable":0},{"_id":"source/images/resnet_f2.PNG","path":"images/resnet_f2.PNG","modified":0,"renderable":0},{"_id":"source/images/resnet_f5.PNG","path":"images/resnet_f5.PNG","modified":0,"renderable":0},{"_id":"source/images/resnet_f7.PNG","path":"images/resnet_f7.PNG","modified":0,"renderable":0},{"_id":"source/images/resnet_t1.PNG","path":"images/resnet_t1.PNG","modified":0,"renderable":0},{"_id":"source/images/vgg_performance_1.PNG","path":"images/vgg_performance_1.PNG","modified":0,"renderable":0},{"_id":"source/images/vgg_performance_3.PNG","path":"images/vgg_performance_3.PNG","modified":0,"renderable":0},{"_id":"source/images/vgg_performance_2.PNG","path":"images/vgg_performance_2.PNG","modified":0,"renderable":0},{"_id":"source/images/eas.png","path":"images/eas.png","modified":0,"renderable":0},{"_id":"source/images/faster_f2.PNG","path":"images/faster_f2.PNG","modified":0,"renderable":0},{"_id":"source/images/minibatch.png","path":"images/minibatch.png","modified":0,"renderable":0},{"_id":"source/images/partition.png","path":"images/partition.png","modified":0,"renderable":0},{"_id":"source/images/my_image.jpg","path":"images/my_image.jpg","modified":0,"renderable":0},{"_id":"source/images/sgd.png","path":"images/sgd.png","modified":0,"renderable":0},{"_id":"source/images/resnet_f1.jpg","path":"images/resnet_f1.jpg","modified":0,"renderable":0},{"_id":"source/images/resnet_f3.jpg","path":"images/resnet_f3.jpg","modified":0,"renderable":0},{"_id":"source/images/alexnet_architecture.PNG","path":"images/alexnet_architecture.PNG","modified":0,"renderable":0},{"_id":"source/images/faster_f1.PNG","path":"images/faster_f1.PNG","modified":0,"renderable":0},{"_id":"source/images/momentum.png","path":"images/momentum.png","modified":0,"renderable":0},{"_id":"source/images/shuffle.png","path":"images/shuffle.png","modified":0,"renderable":0},{"_id":"source/images/vgg_architecture.PNG","path":"images/vgg_architecture.PNG","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.jpeg","path":"images/avatar.jpeg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"source/images/LlayerNN.png","path":"images/LlayerNN.png","modified":0,"renderable":0},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"source/images/faster_f3.PNG","path":"images/faster_f3.PNG","modified":0,"renderable":0},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"source/images/动态规划.jpg","path":"images/动态规划.jpg","modified":0,"renderable":0},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"source/images/dl_pic9_2.jpg","path":"images/dl_pic9_2.jpg","modified":0,"renderable":0},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"source/images/dl_pic9_8.jpg","path":"images/dl_pic9_8.jpg","modified":0,"renderable":0},{"_id":"source/images/dl_pic9_5.jpg","path":"images/dl_pic9_5.jpg","modified":0,"renderable":0},{"_id":"source/images/dl_pic9_7.jpg","path":"images/dl_pic9_7.jpg","modified":0,"renderable":0},{"_id":"source/images/lmfr_f4.PNG","path":"images/lmfr_f4.PNG","modified":0,"renderable":0},{"_id":"source/images/lmfr_f3.PNG","path":"images/lmfr_f3.PNG","modified":0,"renderable":0},{"_id":"source/images/lmfr.PNG","path":"images/lmfr.PNG","modified":0,"renderable":0}],"Cache":[{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1538117438171},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1538117438171},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1538117438171},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1538117438171},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1538117438171},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1538117438171},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1538117438171},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1538117438171},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1538117438171},{"_id":"themes/next/README.cn.md","hash":"2c766b3369ed477bce134a5450dab45bef161504","modified":1538117438171},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1538117438171},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1538117438175},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1538117438175},{"_id":"themes/next/README.md","hash":"8ce60ce578963eb4e1eb5e33e1efc2fc4779af9c","modified":1538117438171},{"_id":"themes/next/_config.yml","hash":"ba1d41370a4bab0e1c1c50c69b4847322db77a5c","modified":1538117438175},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1538117438175},{"_id":"source/_posts/BeautifulSoup.md","hash":"65aa78228bdc17d40b9673d35afaa77df7d42fdd","modified":1538117438143},{"_id":"source/_posts/CIFAR-10.md","hash":"b21b58235f64126869797d922233c5492c71a06e","modified":1537588316207},{"_id":"source/_posts/Evolutionary-Algorithms.md","hash":"5f5bcc4a5687d670ecdeb1c83cd44683f5cf4d3c","modified":1538117438143},{"_id":"source/_posts/Faster-R-CNN-Towards-Real-Time-Object-Dectection-with-Region-Proposal-Networks.md","hash":"c17751902db051b13f6fabcb6bd661ddb3e75b67","modified":1538128646495},{"_id":"source/_posts/DNN应用1-识别猫.md","hash":"f42081436a89614bfb79e594561e5266440bdcb7","modified":1538117438143},{"_id":"source/_posts/Genetic-Algorithms.md","hash":"086a849988e7669b229461e13c511910f8aea0a1","modified":1538117438143},{"_id":"source/_posts/Deep-Residual-Learning-for-Image-Recognition.md","hash":"53fc7a22116c91e2cbd763028df315574782e43c","modified":1538119716629},{"_id":"source/_posts/How-to-set-up-a-blog-with-hexo-on-github-io.md","hash":"e669c0bed01b5d76d7644e2bbff7849f81cdf41f","modified":1538117438143},{"_id":"source/_posts/Linear-Models-for-Regression.md","hash":"d0d5554eb42442a153209389c5b06acbb72db550","modified":1538076364659},{"_id":"source/_posts/Gradient-Descent-Famliy.md","hash":"3ecf4969d0bf93f93bd5ba75f37bf54429e3c0d7","modified":1538117438143},{"_id":"source/_posts/ImageNet-Classification-wih-Deep-Convolutional-Neural-Network.md","hash":"3a148b4726ef28f262e7e796f3347a7cfb38e00a","modified":1535441142186},{"_id":"source/_posts/MNIST数据集.md","hash":"3d50656e87b7715aebb35ec70f96078109df82e6","modified":1536315219495},{"_id":"source/_posts/Permutation-generate.md","hash":"376d68fa0b578eb3a4bd75a54b5bc909d66b643d","modified":1536153491624},{"_id":"source/_posts/Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recongnition.md","hash":"adc197ae2d097dbe46eb7aa5325ccad04d04fee4","modified":1535688366157},{"_id":"source/_posts/github使用手册.md","hash":"c9ff9d19b5143432ab54582247e636c755532ed2","modified":1538117438143},{"_id":"source/_posts/hello-world.md","hash":"b4f283c1f275e64526f5fc48cbe315056937d25b","modified":1534643975792},{"_id":"source/_posts/matplotlib.md","hash":"ae9c07e1e455172ee10e09cb538a733726ce1b22","modified":1538117438143},{"_id":"source/_posts/dropout.md","hash":"b3b3ddb043da635fdabeb1d0827996900fa7409b","modified":1538117438143},{"_id":"source/_posts/python内置小工具.md","hash":"45502e82e1d29877c50a7dc5733533ace2e3f371","modified":1538117438143},{"_id":"source/_posts/requests.md","hash":"ae938997d0ccd5baf88e8bd694fef3f7f1dff637","modified":1538117438143},{"_id":"source/_posts/tensorflow-graphs.md","hash":"5de9493554ce7e4f7580063b184677f1fcbe649d","modified":1536141518618},{"_id":"source/_posts/tensorflow-session.md","hash":"b43b084a9d1c3539301e18796bb1e0c6bd4fc7a7","modified":1536139560927},{"_id":"source/_posts/人生-路遥.md","hash":"b2a46722fb3cd49dc97ed01aca034217e6c2ae7c","modified":1538117438147},{"_id":"source/_posts/tensorflow-variable.md","hash":"f34e67698402e2faa161e7f959e111d4e9a9042e","modified":1536141449074},{"_id":"source/_posts/人脸识别.md","hash":"5626606b93d644538bcf4fc00faa49b76f54651b","modified":1536141721859},{"_id":"source/_posts/信息简史.md","hash":"f4b095a040a68978c3bc14c71884584b0a37c3f8","modified":1537588209092},{"_id":"source/_posts/动态规划.md","hash":"b2283cbe33716fc1cece40d60c0c2d0002784552","modified":1538117438147},{"_id":"source/_posts/十个策略故事.md","hash":"cb57164e25b665e79b0e711c1a806bb2ff7fd614","modified":1538117438147},{"_id":"source/_posts/分治策略.md","hash":"86e533028e27b9ac01a3056f3453bbf31c394629","modified":1537594109852},{"_id":"source/_posts/初始化参数.md","hash":"fcb4144cc8b11ee13dabdb15cc9ee7c0343c6987","modified":1538117438147},{"_id":"source/_posts/卷积神经网络.md","hash":"cb922c50498f59cb74d8ec93d09061dd459c10e9","modified":1535276910935},{"_id":"source/_posts/循环神经网络.md","hash":"70f368ab83aecfa37b9624a10d04e22b3963abab","modified":1535811314770},{"_id":"source/_posts/恋爱领域中普遍存在的贬低倾向.md","hash":"5534cb967ed4885d8dbf033c5cdfff6cc7e0c702","modified":1538117438147},{"_id":"source/_posts/数据的加载-预处理-可视化.md","hash":"8bf55ae0286dfa2f7f94d0767f82a3c1aa94f93a","modified":1538117438147},{"_id":"source/_posts/数据划分.md","hash":"0e72cbf733280f01fe3ecf098e9841733779b3bf","modified":1538117438147},{"_id":"source/_posts/标准化输入.md","hash":"87676031715ad9df4bb28ef30208b47122ffb068","modified":1538117438147},{"_id":"source/_posts/梯度检验.md","hash":"648ffe292e6fcdec18f1d934cfeb3a368980bd09","modified":1538117438147},{"_id":"source/_posts/梯度消失和梯度爆炸.md","hash":"54aa2dfd5b368b8f33b199509a89c249fcf98f73","modified":1538117438147},{"_id":"source/_posts/深度卷积神经网络-实例探究.md","hash":"2969f6cc6248d108ccb75a2ba125f812cf5b8540","modified":1535276918084},{"_id":"source/_posts/模型估计.md","hash":"88b61414cf27352d952673208973bc88c118a807","modified":1538117438147},{"_id":"source/_posts/正则化.md","hash":"cf62300afa07493d9de3f939db114755b72d6e69","modified":1538117438147},{"_id":"source/_posts/特征值与特征向量.md","hash":"e0149dcd7cb0d2d58efbeafe208882fcb2ab9bda","modified":1537694096165},{"_id":"source/_posts/男人的对象选择中的一种特殊类型.md","hash":"d7708665412adf7e69cfd02c80f4a6022388f6d6","modified":1538117438147},{"_id":"source/_posts/布雷默曼极限.md","hash":"8115c9623df49f5c45f4244e952841a06fc6305b","modified":1538117438147},{"_id":"source/_posts/目标检测.md","hash":"672e3d83d49ed48a507e9a932e3f6db15a801f8e","modified":1535894035997},{"_id":"source/_posts/矩阵链乘法.md","hash":"0589a9189f63c3cb54b03afaef349a7a3ae8fadc","modified":1535852326520},{"_id":"source/_posts/短诗三首.md","hash":"63b986cea72949d653a2c47596dea0ef6e5d0803","modified":1538117438147},{"_id":"source/_posts/神经风格迁移.md","hash":"121b59631be144faffd8d052cf2a53c1974ba1bb","modified":1536148296557},{"_id":"source/images/Convolutions-on-RGB-image.png","hash":"b4de22ca607e562f21ec385e5dd14d8b11a93914","modified":1531227954186},{"_id":"source/_posts/神经网络中的通用函数代码.md","hash":"e6c34446fb1af98db6b8d5822cc50ff75f8d14ea","modified":1538117438147},{"_id":"source/_posts/深度学习中的优化算法.md","hash":"438eae7c48be40b9a4cafea02fd2c0283306b199","modified":1538117438147},{"_id":"source/images/adam.PNG","hash":"f2adc403d4012046172c37175835fefb8bec932f","modified":1534643975815},{"_id":"source/images/alexnet_ilsvrc.PNG","hash":"9f57a90d68124ad1290137cf824e9f0485f33bf7","modified":1535439784780},{"_id":"source/_posts/贞洁禁忌.md","hash":"2238d7a2d3be91c106f9260231082e1dad2f6b52","modified":1538117438147},{"_id":"source/images/Padding.jpg","hash":"e53f0396b1e806eeb94effbd33ed1d0ea1977e12","modified":1531227954202},{"_id":"source/images/Stride.jpg","hash":"56c57dbb8d74628ac798fa3c23fa1ec969146576","modified":1531227954214},{"_id":"source/images/faster_t8.PNG","hash":"1f8a7dc24603b357ddb1f89810a1965d9324a11b","modified":1537986628939},{"_id":"source/images/res1.PNG","hash":"f528eca6822e71539139aa1b2795847135dc2b07","modified":1534643975825},{"_id":"source/images/resnet_f2.PNG","hash":"33951fb386d83dd7a43de4b4ee308d32214403bb","modified":1537865606266},{"_id":"source/images/resnet_f5.PNG","hash":"2a887ac9a072d6a1bcb2e57e08ce61d5feb8b898","modified":1537866026701},{"_id":"source/images/resnet_f7.PNG","hash":"2251c69f85e0e7543d59f472b93214bdb79bf96d","modified":1537866078764},{"_id":"source/images/resnet_t1.PNG","hash":"c9aa3b4398bf4934e5577723d66de7f1615cdc0a","modified":1537865992601},{"_id":"source/images/vgg_performance_1.PNG","hash":"2ecefe1a373a0662f644679281456361f08a2ba7","modified":1535686214202},{"_id":"source/images/vgg_performance_3.PNG","hash":"6f7e807fbfb6518dd4edebaeccc3e57f47a2525c","modified":1535686752411},{"_id":"source/images/vgg_performance_2.PNG","hash":"93cc3cdf6cec1db638feebef7f3ec642cdc4de7e","modified":1535686639375},{"_id":"source/categories/index.md","hash":"91f4f4c368f1d9497e9d4fe555a7163a71788bd8","modified":1538117438147},{"_id":"source/tags/index.md","hash":"444e5b5540e160c6d7203107b976ab9857b61fef","modified":1538117438167},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1538117438171},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"50d48c47162817a3810a9d9ad51104e83947419a","modified":1538117438171},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1538117438171},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1534643975933},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1538117438175},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1538117438175},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1538117438175},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1538117438175},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1538117438175},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1538117438175},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1538117438175},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1538117438175},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1538117438175},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1538117438175},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1538117438175},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1538117438175},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1538117438175},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1538117438175},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1538117438175},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1538117438175},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1538117438175},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1538117438175},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1538117438175},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1538117438175},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1538117438175},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1538117438175},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1538117438175},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1538117438175},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1538117438175},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1538117438195},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1538117438175},{"_id":"source/images/eas.png","hash":"9d12e21703b5d1dab464bd5f8f0d2f194145b43c","modified":1534643975817},{"_id":"source/images/faster_f2.PNG","hash":"7f9c725a9f51aacf6e23ff5016f3fe842474d2e9","modified":1537951406655},{"_id":"source/images/minibatch.png","hash":"1705433ef878be5688ab474c7f3461c94b224dde","modified":1534643975818},{"_id":"source/images/partition.png","hash":"1c29a499253b64f0834f8253ea85efcb716872ac","modified":1534643975824},{"_id":"source/images/my_image.jpg","hash":"931bed91b176c20eee98be0a6f0af356d37b2330","modified":1534643975822},{"_id":"source/images/sgd.png","hash":"43fac22e9aa802e1fae6e25d791d23d3f82c616f","modified":1534643975826},{"_id":"source/images/resnet_f1.jpg","hash":"bbd09f0cfe999aa96e6c559b19be8211cf37b26d","modified":1537865291615},{"_id":"source/images/resnet_f3.jpg","hash":"449852a131b1d141a5202514438b0d499fc50478","modified":1537865382542},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1538117438195},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976163},{"_id":"source/images/alexnet_architecture.PNG","hash":"b4f692d1b6e69eacbb6e21d20a1a8cb878adf2d7","modified":1535424925483},{"_id":"source/images/faster_f1.PNG","hash":"4fc96ad070c7d52ed1fab909a9ee8401312cd7fd","modified":1537986235418},{"_id":"source/images/momentum.png","hash":"97d12c75f9b2ecd40f0a6d0d47a21f83672ede97","modified":1534643975820},{"_id":"source/images/shuffle.png","hash":"e844a5da26c91ccd40f9c5186a7fd5db7fe4f2b7","modified":1534643975829},{"_id":"source/images/vgg_architecture.PNG","hash":"1af5fe2e5878957ac8d203e712cfe965ab154d3f","modified":1535682585366},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1538117438195},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1538117438175},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1538117438175},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1538117438175},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1538117438175},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1538117438175},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1538117438175},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1538117438175},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1538117438175},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1538117438175},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1538117438175},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1538117438175},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1538117438175},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1538117438175},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1538117438175},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1538117438175},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1538117438175},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1538117438175},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1538117438175},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1538117438175},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1538117438175},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1538117438175},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1538117438175},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1538117438175},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1538117438175},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1538117438175},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1538117438179},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1538117438179},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1534643976165},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1534643976166},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1538117438179},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1538117438179},{"_id":"themes/next/source/images/avatar.jpeg","hash":"f1aa09fc418f5d6f05af58e81a9ca95790a075b0","modified":1534643976167},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1538117438179},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1538117438179},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1534643976173},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1538117438179},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1538117438179},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1534643976174},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1538117438179},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1534643976176},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1534643976174},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1538117438179},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1538117438179},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1538117438175},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1538117438175},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1538117438175},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1538117438175},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1538117438175},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1538117438175},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1538117438175},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1538117438175},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1538117438175},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1538117438179},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643975983},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643975983},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976107},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976108},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976111},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976160},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976162},{"_id":"source/images/LlayerNN.png","hash":"939d9808c2d757e7097f22cbb4b4083c40f3da9c","modified":1534643975814},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1534643976178},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1538117438175},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1538117438175},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1538117438175},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1538117438175},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1538117438175},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1538117438175},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1538117438175},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1538117438175},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1538117438175},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1538117438175},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1538117438175},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1538117438175},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1538117438175},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1538117438175},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1538117438175},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1538117438175},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1538117438175},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1538117438175},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1538117438175},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1538117438175},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1538117438175},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1538117438175},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1538117438175},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1538117438175},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1538117438175},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1538117438179},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1538117438179},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1538117438179},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1538117438175},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1538117438179},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1538117438179},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1538117438179},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1538117438179},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1538117438179},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1538117438179},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1538117438179},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1538117438179},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1538117438179},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1538117438179},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1538117438175},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1538117438179},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1538117438179},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1538117438179},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1538117438179},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1538117438179},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1534643976196},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1538117438179},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1538117438183},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1538117438183},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1538117438183},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1534643976201},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1538117438183},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1538117438183},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1538117438183},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1538117438183},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1538117438183},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1538117438187},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1538117438187},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1538117438187},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1538117438187},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1538117438187},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1538117438187},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1538117438187},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1538117438187},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1534643976249},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1538117438187},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1538117438187},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1534643976249},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1534643976250},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1534643976251},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1534643976251},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1534643976252},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1534643976254},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1534643976253},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1534643976253},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1534643976255},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1534643976256},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1534643976257},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1538117438187},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1538117438187},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1534643976255},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1538117438187},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1538117438183},{"_id":"source/images/faster_f3.PNG","hash":"76204c59927d087422e278d292af9ce83339aab1","modified":1537985264725},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1538117438187},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1538117438191},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1538117438183},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1538117438191},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1538117438191},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1538117438187},{"_id":"source/images/动态规划.jpg","hash":"771e3ceb5404dcb7ef349c6aa6e7853a7d61934e","modified":1534643975833},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1538117438191},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1538117438191},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1538117438175},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1538117438175},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1538117438179},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1538117438179},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1538117438179},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1538117438179},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1538117438179},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1538117438179},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1538117438179},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1538117438179},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1538117438179},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1534643976203},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1534643976204},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1538117438183},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1534643976204},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1534643976206},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1534643976205},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1538117438183},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1534643976207},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1538117438183},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1538117438183},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1538117438183},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1538117438183},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1534643976219},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1538117438183},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1538117438187},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1538117438187},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1538117438183},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1538117438191},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1534643976237},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1534643976238},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1538117438191},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1538117438175},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1538117438191},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1538117438175},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1538117438179},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1538117438179},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1538117438179},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1534643976187},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1538117438179},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1534643976190},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1534643976189},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1534643976188},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1534643976191},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1534643976208},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1538117438183},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1538117438183},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1538117438183},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1538117438183},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1534643976228},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1534643976231},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1534643976236},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1538117438183},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1538117438183},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1538117438191},{"_id":"source/images/dl_pic9_2.jpg","hash":"1de175528c89642a2520d640861ff5237da9aefc","modified":1535080882042},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1538117438187},{"_id":"source/images/dl_pic9_8.jpg","hash":"7c99fba6503ff5a23a3d8e39278c5dc2bdd3b9ee","modified":1535082369512},{"_id":"source/images/dl_pic9_5.jpg","hash":"b1ccd9c91f99bf4bb2d0804901a11aa840283c5b","modified":1535081541240},{"_id":"source/images/dl_pic9_7.jpg","hash":"3d8b3e0b5dc8a8a76fb67cd86f23d125c896809f","modified":1535082325324},{"_id":"source/images/lmfr_f4.PNG","hash":"42cd560b5be8d25429a9113cf1345d23b0bb1c3f","modified":1538025005254},{"_id":"source/images/lmfr_f3.PNG","hash":"b72f0c00f94970d329899f21d320dbd1338f5f2a","modified":1538024956172},{"_id":"source/images/lmfr.PNG","hash":"76f60b3351029db5ee539527050818c89a8e6d2b","modified":1538022031926}],"Category":[{"name":"python包和模块","_id":"cjmk9ds150004pcvov68k4sc8"},{"name":"深度学习","_id":"cjmk9ds1l0009pcvoqkgt0l64"},{"name":"进化计算","_id":"cjmk9ds20000fpcvo40m2rklu"},{"name":"web","_id":"cjmk9ds3b0016pcvo6qfcsx5i"},{"name":"机器学习","_id":"cjmk9ds3r001dpcvozzn363hv"},{"name":"算法导论","_id":"cjmk9ds3r001npcvoxjzvoztl"},{"name":"程序员实用工具","_id":"cjmk9ds3r001vpcvojunlbyl6"},{"name":"Tensorflow","_id":"cjmk9ds4m002apcvox71sx5fb"},{"name":"文学","_id":"cjmk9ds4m002opcvo3cilj6q5"},{"name":"科普读物","_id":"cjmk9ds5h0035pcvo6vcovkpg"},{"name":"心理学","_id":"cjmk9ds5h003cpcvo3xx55dg8"},{"name":"计算机科学","_id":"cjmk9ds6c0045pcvoqrcdgpka"}],"Data":[],"Page":[{"title":"categories","date":"2018-07-18T16:23:02.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-07-19 00:23:02\ntype: \"categories\"\n---\n","updated":"2018-09-28T06:50:38.147Z","path":"categories/index.html","_id":"cjmk9ds0p0001pcvoy1af1geo","comments":1,"layout":"page","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2018-07-18T16:21:54.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-07-19 00:21:54\ntype: \"tags\"\n---\n","updated":"2018-09-28T06:50:38.167Z","path":"tags/index.html","_id":"cjmk9ds150003pcvojq6kbc6b","comments":1,"layout":"page","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"BeautifulSoup","date":"2018-08-15T03:40:51.000Z","_content":"## [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html)\n\nYou didn't write that awful page. You're just trying to get some data out of it. Beautiful Soup is here to help. Since 2004, it's been saving programmers hours or days of work on quick-turnaround screen scraping projects.\n\n## 如何使用\n\n```python\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(open('index.html'))\n```\n\n## 对象的种类\n\n### Tag\n\nTag 对象与XML或HTML原生文档中的tag相同:\n\n```python\nsoup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>')\ntag = soup.b\ntype(tag)\n# <class 'bs4.element.Tag'>\n```\n\nTag的属性：`tag.name, tag.attrs`\n\ntag的属性的操作方法与字典相同: `tag['class']`\n\n### 可以遍历的字符串\n\n字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:`tag.string`\n\n`unicode_string = unicode(tag.string)`\n\ntag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法:`tag.string.replace_with(\"No\")`\n\n### BeautifulSoup\n\nBeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.\n\n### 注释及特殊字符串\n\nComment 对象是一个特殊类型的 NavigableString 对象:\n\n```python\nmarkup = \"<b><!--Hey, buddy. Want to buy a used parser?--></b>\"\nsoup = BeautifulSoup(markup)\ncomment = soup.b.string\ntype(comment)\n# <class 'bs4.element.Comment'>\n```\n\n## 遍历文档树\n\n### 子节点\n\n一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.\n\n#### tag的名字\n\n`soup.head, soup.title, soup.body.b, soup.a, soup.find_all('a')`\n\n#### .contents和.children\n\ntag的 .contents 属性可以将tag的子节点以列表的方式输出:\n\n通过tag的 .children 生成器,可以对tag的子节点进行循环:\n\n```python\nfor child in title_tag.children:\n    print(child)\n```\ndescendants 属性可以对所有tag的子孙节点进行递归循环:\n\n```python\nfor child in title_tag.descendants:\n    print(child)\n```\n\n### .string\n\n如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点:`tag.string`\n\n如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同\n\n如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :\n\n### .strings和stripped__strings\n\n如果tag中包含多个字符串 ,可以使用 .strings 来循环获取, 输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容\n\n```python\nfor string in soup.strings:\n    print(repr(string))\n\nfor string in soup.stripped_strings:\n    ...\n```\n\n### 父节点\n\n#### .parent\n\n`tag.parent, tag.string.parent`\n\n#### .parents\n\n```python\nlink = soup.a\nfor parent in link.parents:\n    if parent is None:\n        print(parent)\n    else:\n        print(parent.name)\n```\n\n### 兄弟节点\n\n#### .next_sibling和.previous_sibling\n\n实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白.\n\n#### .next_siblings和.previous_siblings\n\n通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出\n\n```python\nfor sibling in soup.a.next_siblings:\n    print(repr(sibling))\n```\n\n### 回退和前进\n\n```html\n<html><head><title>The Dormouse's story</title></head>\n<p class=\"title\"><b>The Dormouse's story</b></p>\n```\n\nHTML解析器把这段字符串转换成一连串的事件: “打开html标签”,”打开一个head标签”,”打开一个title标签”,”添加一段字符串”,”关闭title标签”,”关闭p标签”,等等.Beautiful Soup提供了重现解析器初始化过程的方法\n\n#### .next_element和.previous_element\n\n.previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象, next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),\n\n#### .next_elements和.previous_elements\n\n通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:\n\n```python\nfor elementin a_tag.next_elements:\n    print(repr(element))\n```\n\n## 搜索文档树\n\n### 过滤器\n\n#### 字符串\n\n最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的\\<b>标签:\n\n`soup.find_all('b')`\n\n#### 正则表达式\n\n如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示\\<body>和\\<b>标签都应该被找到:\n\n```python\nimport re\nfor tag in soup.find_all(re.compile(\"^b\"):\n    print(tag.name)\n```\n\n#### 列表\n\n如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有\\<a>标签和\\<b>标签:\n\n`soup.find_all(['a', 'b'])`\n\n#### True\n\nTrue 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点\n\n```python\nfor tag in soup.find_all(True):\n    print(tag.name)\n```\n\n#### 方法\n\n如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False\n\n下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:\n\n```python\ndef has_class_but_no_id(tag):\n    return tag.has_attr('class') and not tag.has_attr('id')\n```\n\n下面代码找到所有被文字包含的节点内容\n\n```python\nfrom bs4 import NavigableString\n\ndef surrounded_by_strings(tag):\n    return (isinstance(tag.next_element, NavigableString)) and isinstance(tag.previous_element, NavigableString)\n```\n\n### find_all()\n\n`find_all(name, attrs, recursive, text, **kwargs)`\n\nfind_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件\n\n#### name参数\n\n搜索 name 参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .\n\nname 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.\n\n#### keyword参数\n\n`soup.find_all(id='link2')`\n`soup.find_all(href=re.compile('elsie'))`\n`soup.find_all(id=True)`\n`soup.find_all(attrs={'id':'link2'})`\n\n#### 按CSS搜索\n\n通过 \".class__\"_ 参数搜索有指定CSS类名的tag, \".class__\"_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True\n\n`soup.find_all('a', class_='sister')`\n\n#### text参数\n\n通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True.\n\n`soup.find_all(text=re.compile(\"Dormouse\"))`\n\n#### limit参数\n\nfind_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.\n\n`soup.find_all('a', limit=2)`\n\n#### recursive参数\n\n调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False.\n\n`soup.find_all('title', recursive=False)`\n\n### 像调用find_all()一样调用tag\n\nfind_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:\n\n`soup.find_all('a')`\n`soup('a')`\n\n### find()\n\n`find(name, attrs, recursive, text, **kwargs)`\n\n```python\nsoup.find_all('title', limit=1)\n# [<title>The Dormouse's story</title>]\n\nsoup.find('title')\n# <title>The Dormouse's story</title>\n```\n\n唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.\n\nfind_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None.\n\n### find_parents()和find_parent()\n\nfind_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同\n\n### find_next_siblings()和find_next_sibling()\n\n这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.\n\n### find_previous_siblings和find_previous_sibling()\n\nfind_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:\n\n### find_all_next()和find_next()\n\n这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:\n\n### find_all_previous()和find_previous()\n\n这2个方法通过 .previous_elements 属性对当前节点前面的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.\n\n### CSS选择器\n\n通过tag标签逐层查找 `soup.select(\"body a\")`\n\n找到某个tag标签的直接子标签 `soup.select(\"p > #link1\")`\n\n找到兄弟节点标签 `soup.select(\"#link1 + .sister\")`\n\n通过CSS类名查找 `soup.select(\".sister\"), soup.select(\"[class~=sister]\")`\n\n通过tag的id查找 `soup.select(\"#link1\")`\n\n通过是否存在某个属性查找 `soup.slect('a[href]')`\n\n通过属性的值来查找 `soup.select('a[href^=\"https:\"]', [href$='title'], [href*=\".com/\"]`\n\n## 修改文档树\n\n## 输出\n\n### 格式化输出\n\nprettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行\n\n```python\nmarkup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\nsoup = BeautifulSoup(markup)\nsoup.prettify()\n# '<html>\\n <head>\\n </head>\\n <body>\\n  <a href=\"http://example.com/\">\\n...'\n\nprint(soup.prettify())\n# <html>\n#  <head>\n#  </head>\n#  <body>\n#   <a href=\"http://example.com/\">\n#    I linked to\n#    <i>\n#     example.com\n#    </i>\n#   </a>\n#  </body>\n# </html>\n```\n\n### 压缩输出\n\n如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:\n\n`str(soup), Unicode(soup.a)`\n\n### 输出格式\n\nBeautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“\\&lquot;”:\n如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:\n\n### get_text()\n\n如果只想得到tag中包含的文本内容,那么可以用 get_text() 方法,这个方法获取到tag中包含的所有文本内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:\n\n可以通过参数指定tag的文本内容的分隔符, 还可以去除前后空白: `soup.get_text('|', strip=True)`\n\n## 指定文档解析器\n\n## 编码\n","source":"_posts/BeautifulSoup.md","raw":"---\ntitle: BeautifulSoup\ndate: 2018-08-15 11:40:51\ntags: python\ncategories: python包和模块\n---\n## [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html)\n\nYou didn't write that awful page. You're just trying to get some data out of it. Beautiful Soup is here to help. Since 2004, it's been saving programmers hours or days of work on quick-turnaround screen scraping projects.\n\n## 如何使用\n\n```python\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(open('index.html'))\n```\n\n## 对象的种类\n\n### Tag\n\nTag 对象与XML或HTML原生文档中的tag相同:\n\n```python\nsoup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>')\ntag = soup.b\ntype(tag)\n# <class 'bs4.element.Tag'>\n```\n\nTag的属性：`tag.name, tag.attrs`\n\ntag的属性的操作方法与字典相同: `tag['class']`\n\n### 可以遍历的字符串\n\n字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:`tag.string`\n\n`unicode_string = unicode(tag.string)`\n\ntag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法:`tag.string.replace_with(\"No\")`\n\n### BeautifulSoup\n\nBeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.\n\n### 注释及特殊字符串\n\nComment 对象是一个特殊类型的 NavigableString 对象:\n\n```python\nmarkup = \"<b><!--Hey, buddy. Want to buy a used parser?--></b>\"\nsoup = BeautifulSoup(markup)\ncomment = soup.b.string\ntype(comment)\n# <class 'bs4.element.Comment'>\n```\n\n## 遍历文档树\n\n### 子节点\n\n一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.\n\n#### tag的名字\n\n`soup.head, soup.title, soup.body.b, soup.a, soup.find_all('a')`\n\n#### .contents和.children\n\ntag的 .contents 属性可以将tag的子节点以列表的方式输出:\n\n通过tag的 .children 生成器,可以对tag的子节点进行循环:\n\n```python\nfor child in title_tag.children:\n    print(child)\n```\ndescendants 属性可以对所有tag的子孙节点进行递归循环:\n\n```python\nfor child in title_tag.descendants:\n    print(child)\n```\n\n### .string\n\n如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点:`tag.string`\n\n如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同\n\n如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :\n\n### .strings和stripped__strings\n\n如果tag中包含多个字符串 ,可以使用 .strings 来循环获取, 输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容\n\n```python\nfor string in soup.strings:\n    print(repr(string))\n\nfor string in soup.stripped_strings:\n    ...\n```\n\n### 父节点\n\n#### .parent\n\n`tag.parent, tag.string.parent`\n\n#### .parents\n\n```python\nlink = soup.a\nfor parent in link.parents:\n    if parent is None:\n        print(parent)\n    else:\n        print(parent.name)\n```\n\n### 兄弟节点\n\n#### .next_sibling和.previous_sibling\n\n实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白.\n\n#### .next_siblings和.previous_siblings\n\n通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出\n\n```python\nfor sibling in soup.a.next_siblings:\n    print(repr(sibling))\n```\n\n### 回退和前进\n\n```html\n<html><head><title>The Dormouse's story</title></head>\n<p class=\"title\"><b>The Dormouse's story</b></p>\n```\n\nHTML解析器把这段字符串转换成一连串的事件: “打开html标签”,”打开一个head标签”,”打开一个title标签”,”添加一段字符串”,”关闭title标签”,”关闭p标签”,等等.Beautiful Soup提供了重现解析器初始化过程的方法\n\n#### .next_element和.previous_element\n\n.previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象, next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),\n\n#### .next_elements和.previous_elements\n\n通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:\n\n```python\nfor elementin a_tag.next_elements:\n    print(repr(element))\n```\n\n## 搜索文档树\n\n### 过滤器\n\n#### 字符串\n\n最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的\\<b>标签:\n\n`soup.find_all('b')`\n\n#### 正则表达式\n\n如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示\\<body>和\\<b>标签都应该被找到:\n\n```python\nimport re\nfor tag in soup.find_all(re.compile(\"^b\"):\n    print(tag.name)\n```\n\n#### 列表\n\n如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有\\<a>标签和\\<b>标签:\n\n`soup.find_all(['a', 'b'])`\n\n#### True\n\nTrue 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点\n\n```python\nfor tag in soup.find_all(True):\n    print(tag.name)\n```\n\n#### 方法\n\n如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False\n\n下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:\n\n```python\ndef has_class_but_no_id(tag):\n    return tag.has_attr('class') and not tag.has_attr('id')\n```\n\n下面代码找到所有被文字包含的节点内容\n\n```python\nfrom bs4 import NavigableString\n\ndef surrounded_by_strings(tag):\n    return (isinstance(tag.next_element, NavigableString)) and isinstance(tag.previous_element, NavigableString)\n```\n\n### find_all()\n\n`find_all(name, attrs, recursive, text, **kwargs)`\n\nfind_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件\n\n#### name参数\n\n搜索 name 参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .\n\nname 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.\n\n#### keyword参数\n\n`soup.find_all(id='link2')`\n`soup.find_all(href=re.compile('elsie'))`\n`soup.find_all(id=True)`\n`soup.find_all(attrs={'id':'link2'})`\n\n#### 按CSS搜索\n\n通过 \".class__\"_ 参数搜索有指定CSS类名的tag, \".class__\"_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True\n\n`soup.find_all('a', class_='sister')`\n\n#### text参数\n\n通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True.\n\n`soup.find_all(text=re.compile(\"Dormouse\"))`\n\n#### limit参数\n\nfind_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.\n\n`soup.find_all('a', limit=2)`\n\n#### recursive参数\n\n调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False.\n\n`soup.find_all('title', recursive=False)`\n\n### 像调用find_all()一样调用tag\n\nfind_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:\n\n`soup.find_all('a')`\n`soup('a')`\n\n### find()\n\n`find(name, attrs, recursive, text, **kwargs)`\n\n```python\nsoup.find_all('title', limit=1)\n# [<title>The Dormouse's story</title>]\n\nsoup.find('title')\n# <title>The Dormouse's story</title>\n```\n\n唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.\n\nfind_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None.\n\n### find_parents()和find_parent()\n\nfind_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同\n\n### find_next_siblings()和find_next_sibling()\n\n这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.\n\n### find_previous_siblings和find_previous_sibling()\n\nfind_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:\n\n### find_all_next()和find_next()\n\n这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:\n\n### find_all_previous()和find_previous()\n\n这2个方法通过 .previous_elements 属性对当前节点前面的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.\n\n### CSS选择器\n\n通过tag标签逐层查找 `soup.select(\"body a\")`\n\n找到某个tag标签的直接子标签 `soup.select(\"p > #link1\")`\n\n找到兄弟节点标签 `soup.select(\"#link1 + .sister\")`\n\n通过CSS类名查找 `soup.select(\".sister\"), soup.select(\"[class~=sister]\")`\n\n通过tag的id查找 `soup.select(\"#link1\")`\n\n通过是否存在某个属性查找 `soup.slect('a[href]')`\n\n通过属性的值来查找 `soup.select('a[href^=\"https:\"]', [href$='title'], [href*=\".com/\"]`\n\n## 修改文档树\n\n## 输出\n\n### 格式化输出\n\nprettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行\n\n```python\nmarkup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\nsoup = BeautifulSoup(markup)\nsoup.prettify()\n# '<html>\\n <head>\\n </head>\\n <body>\\n  <a href=\"http://example.com/\">\\n...'\n\nprint(soup.prettify())\n# <html>\n#  <head>\n#  </head>\n#  <body>\n#   <a href=\"http://example.com/\">\n#    I linked to\n#    <i>\n#     example.com\n#    </i>\n#   </a>\n#  </body>\n# </html>\n```\n\n### 压缩输出\n\n如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:\n\n`str(soup), Unicode(soup.a)`\n\n### 输出格式\n\nBeautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“\\&lquot;”:\n如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:\n\n### get_text()\n\n如果只想得到tag中包含的文本内容,那么可以用 get_text() 方法,这个方法获取到tag中包含的所有文本内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:\n\n可以通过参数指定tag的文本内容的分隔符, 还可以去除前后空白: `soup.get_text('|', strip=True)`\n\n## 指定文档解析器\n\n## 编码\n","slug":"BeautifulSoup","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds0p0000pcvo29hsc6pb","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"BeautifulSoup\"><a href=\"#BeautifulSoup\" class=\"headerlink\" title=\"BeautifulSoup\"></a><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html\" target=\"_blank\" rel=\"noopener\">BeautifulSoup</a></h2><p>You didn’t write that awful page. You’re just trying to get some data out of it. Beautiful Soup is here to help. Since 2004, it’s been saving programmers hours or days of work on quick-turnaround screen scraping projects.</p>\n<h2 id=\"如何使用\"><a href=\"#如何使用\" class=\"headerlink\" title=\"如何使用\"></a>如何使用</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup</span><br><span class=\"line\">soup = BeautifulSoup(open(<span class=\"string\">'index.html'</span>))</span><br></pre></td></tr></table></figure>\n<h2 id=\"对象的种类\"><a href=\"#对象的种类\" class=\"headerlink\" title=\"对象的种类\"></a>对象的种类</h2><h3 id=\"Tag\"><a href=\"#Tag\" class=\"headerlink\" title=\"Tag\"></a>Tag</h3><p>Tag 对象与XML或HTML原生文档中的tag相同:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">soup = BeautifulSoup(<span class=\"string\">'&lt;b class=\"boldest\"&gt;Extremely bold&lt;/b&gt;'</span>)</span><br><span class=\"line\">tag = soup.b</span><br><span class=\"line\">type(tag)</span><br><span class=\"line\"><span class=\"comment\"># &lt;class 'bs4.element.Tag'&gt;</span></span><br></pre></td></tr></table></figure>\n<p>Tag的属性：<code>tag.name, tag.attrs</code></p>\n<p>tag的属性的操作方法与字典相同: <code>tag[&#39;class&#39;]</code></p>\n<h3 id=\"可以遍历的字符串\"><a href=\"#可以遍历的字符串\" class=\"headerlink\" title=\"可以遍历的字符串\"></a>可以遍历的字符串</h3><p>字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:<code>tag.string</code></p>\n<p><code>unicode_string = unicode(tag.string)</code></p>\n<p>tag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法:<code>tag.string.replace_with(&quot;No&quot;)</code></p>\n<h3 id=\"BeautifulSoup-1\"><a href=\"#BeautifulSoup-1\" class=\"headerlink\" title=\"BeautifulSoup\"></a>BeautifulSoup</h3><p>BeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.</p>\n<h3 id=\"注释及特殊字符串\"><a href=\"#注释及特殊字符串\" class=\"headerlink\" title=\"注释及特殊字符串\"></a>注释及特殊字符串</h3><p>Comment 对象是一个特殊类型的 NavigableString 对象:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">markup = <span class=\"string\">\"&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;\"</span></span><br><span class=\"line\">soup = BeautifulSoup(markup)</span><br><span class=\"line\">comment = soup.b.string</span><br><span class=\"line\">type(comment)</span><br><span class=\"line\"><span class=\"comment\"># &lt;class 'bs4.element.Comment'&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"遍历文档树\"><a href=\"#遍历文档树\" class=\"headerlink\" title=\"遍历文档树\"></a>遍历文档树</h2><h3 id=\"子节点\"><a href=\"#子节点\" class=\"headerlink\" title=\"子节点\"></a>子节点</h3><p>一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.</p>\n<h4 id=\"tag的名字\"><a href=\"#tag的名字\" class=\"headerlink\" title=\"tag的名字\"></a>tag的名字</h4><p><code>soup.head, soup.title, soup.body.b, soup.a, soup.find_all(&#39;a&#39;)</code></p>\n<h4 id=\"contents和-children\"><a href=\"#contents和-children\" class=\"headerlink\" title=\".contents和.children\"></a>.contents和.children</h4><p>tag的 .contents 属性可以将tag的子节点以列表的方式输出:</p>\n<p>通过tag的 .children 生成器,可以对tag的子节点进行循环:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> title_tag.children:</span><br><span class=\"line\">    print(child)</span><br></pre></td></tr></table></figure>\n<p>descendants 属性可以对所有tag的子孙节点进行递归循环:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> title_tag.descendants:</span><br><span class=\"line\">    print(child)</span><br></pre></td></tr></table></figure>\n<h3 id=\"string\"><a href=\"#string\" class=\"headerlink\" title=\".string\"></a>.string</h3><p>如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点:<code>tag.string</code></p>\n<p>如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同</p>\n<p>如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :</p>\n<h3 id=\"strings和stripped-strings\"><a href=\"#strings和stripped-strings\" class=\"headerlink\" title=\".strings和stripped__strings\"></a>.strings和stripped__strings</h3><p>如果tag中包含多个字符串 ,可以使用 .strings 来循环获取, 输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> string <span class=\"keyword\">in</span> soup.strings:</span><br><span class=\"line\">    print(repr(string))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> string <span class=\"keyword\">in</span> soup.stripped_strings:</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n<h3 id=\"父节点\"><a href=\"#父节点\" class=\"headerlink\" title=\"父节点\"></a>父节点</h3><h4 id=\"parent\"><a href=\"#parent\" class=\"headerlink\" title=\".parent\"></a>.parent</h4><p><code>tag.parent, tag.string.parent</code></p>\n<h4 id=\"parents\"><a href=\"#parents\" class=\"headerlink\" title=\".parents\"></a>.parents</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">link = soup.a</span><br><span class=\"line\"><span class=\"keyword\">for</span> parent <span class=\"keyword\">in</span> link.parents:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> parent <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        print(parent)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        print(parent.name)</span><br></pre></td></tr></table></figure>\n<h3 id=\"兄弟节点\"><a href=\"#兄弟节点\" class=\"headerlink\" title=\"兄弟节点\"></a>兄弟节点</h3><h4 id=\"next-sibling和-previous-sibling\"><a href=\"#next-sibling和-previous-sibling\" class=\"headerlink\" title=\".next_sibling和.previous_sibling\"></a>.next_sibling和.previous_sibling</h4><p>实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白.</p>\n<h4 id=\"next-siblings和-previous-siblings\"><a href=\"#next-siblings和-previous-siblings\" class=\"headerlink\" title=\".next_siblings和.previous_siblings\"></a>.next_siblings和.previous_siblings</h4><p>通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> sibling <span class=\"keyword\">in</span> soup.a.next_siblings:</span><br><span class=\"line\">    print(repr(sibling))</span><br></pre></td></tr></table></figure>\n<h3 id=\"回退和前进\"><a href=\"#回退和前进\" class=\"headerlink\" title=\"回退和前进\"></a>回退和前进</h3><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>The Dormouse's story<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">class</span>=<span class=\"string\">\"title\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">b</span>&gt;</span>The Dormouse's story<span class=\"tag\">&lt;/<span class=\"name\">b</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>HTML解析器把这段字符串转换成一连串的事件: “打开html标签”,”打开一个head标签”,”打开一个title标签”,”添加一段字符串”,”关闭title标签”,”关闭p标签”,等等.Beautiful Soup提供了重现解析器初始化过程的方法</p>\n<h4 id=\"next-element和-previous-element\"><a href=\"#next-element和-previous-element\" class=\"headerlink\" title=\".next_element和.previous_element\"></a>.next_element和.previous_element</h4><p>.previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象, next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),</p>\n<h4 id=\"next-elements和-previous-elements\"><a href=\"#next-elements和-previous-elements\" class=\"headerlink\" title=\".next_elements和.previous_elements\"></a>.next_elements和.previous_elements</h4><p>通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> elementin a_tag.next_elements:</span><br><span class=\"line\">    print(repr(element))</span><br></pre></td></tr></table></figure>\n<h2 id=\"搜索文档树\"><a href=\"#搜索文档树\" class=\"headerlink\" title=\"搜索文档树\"></a>搜索文档树</h2><h3 id=\"过滤器\"><a href=\"#过滤器\" class=\"headerlink\" title=\"过滤器\"></a>过滤器</h3><h4 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h4><p>最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的\\<b>标签:</b></p>\n<p><code>soup.find_all(&#39;b&#39;)</code></p>\n<h4 id=\"正则表达式\"><a href=\"#正则表达式\" class=\"headerlink\" title=\"正则表达式\"></a>正则表达式</h4><p>如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示\\<body>和\\<b>标签都应该被找到:</b></body></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">for</span> tag <span class=\"keyword\">in</span> soup.find_all(re.compile(<span class=\"string\">\"^b\"</span>):</span><br><span class=\"line\">    print(tag.name)</span><br></pre></td></tr></table></figure>\n<h4 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h4><p>如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有\\<a>标签和\\<b>标签:</b></a></p>\n<p><code>soup.find_all([&#39;a&#39;, &#39;b&#39;])</code></p>\n<h4 id=\"True\"><a href=\"#True\" class=\"headerlink\" title=\"True\"></a>True</h4><p>True 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> tag <span class=\"keyword\">in</span> soup.find_all(<span class=\"keyword\">True</span>):</span><br><span class=\"line\">    print(tag.name)</span><br></pre></td></tr></table></figure>\n<h4 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h4><p>如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False</p>\n<p>下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">has_class_but_no_id</span><span class=\"params\">(tag)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> tag.has_attr(<span class=\"string\">'class'</span>) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> tag.has_attr(<span class=\"string\">'id'</span>)</span><br></pre></td></tr></table></figure>\n<p>下面代码找到所有被文字包含的节点内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> NavigableString</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">surrounded_by_strings</span><span class=\"params\">(tag)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (isinstance(tag.next_element, NavigableString)) <span class=\"keyword\">and</span> isinstance(tag.previous_element, NavigableString)</span><br></pre></td></tr></table></figure>\n<h3 id=\"find-all\"><a href=\"#find-all\" class=\"headerlink\" title=\"find_all()\"></a>find_all()</h3><p><code>find_all(name, attrs, recursive, text, **kwargs)</code></p>\n<p>find_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件</p>\n<h4 id=\"name参数\"><a href=\"#name参数\" class=\"headerlink\" title=\"name参数\"></a>name参数</h4><p>搜索 name 参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .</p>\n<p>name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.</p>\n<h4 id=\"keyword参数\"><a href=\"#keyword参数\" class=\"headerlink\" title=\"keyword参数\"></a>keyword参数</h4><p><code>soup.find_all(id=&#39;link2&#39;)</code><br><code>soup.find_all(href=re.compile(&#39;elsie&#39;))</code><br><code>soup.find_all(id=True)</code><br><code>soup.find_all(attrs={&#39;id&#39;:&#39;link2&#39;})</code></p>\n<h4 id=\"按CSS搜索\"><a href=\"#按CSS搜索\" class=\"headerlink\" title=\"按CSS搜索\"></a>按CSS搜索</h4><p>通过 “.class__”_ 参数搜索有指定CSS类名的tag, “.class__”_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True</p>\n<p><code>soup.find_all(&#39;a&#39;, class_=&#39;sister&#39;)</code></p>\n<h4 id=\"text参数\"><a href=\"#text参数\" class=\"headerlink\" title=\"text参数\"></a>text参数</h4><p>通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True.</p>\n<p><code>soup.find_all(text=re.compile(&quot;Dormouse&quot;))</code></p>\n<h4 id=\"limit参数\"><a href=\"#limit参数\" class=\"headerlink\" title=\"limit参数\"></a>limit参数</h4><p>find_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.</p>\n<p><code>soup.find_all(&#39;a&#39;, limit=2)</code></p>\n<h4 id=\"recursive参数\"><a href=\"#recursive参数\" class=\"headerlink\" title=\"recursive参数\"></a>recursive参数</h4><p>调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False.</p>\n<p><code>soup.find_all(&#39;title&#39;, recursive=False)</code></p>\n<h3 id=\"像调用find-all-一样调用tag\"><a href=\"#像调用find-all-一样调用tag\" class=\"headerlink\" title=\"像调用find_all()一样调用tag\"></a>像调用find_all()一样调用tag</h3><p>find_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:</p>\n<p><code>soup.find_all(&#39;a&#39;)</code><br><code>soup(&#39;a&#39;)</code></p>\n<h3 id=\"find\"><a href=\"#find\" class=\"headerlink\" title=\"find()\"></a>find()</h3><p><code>find(name, attrs, recursive, text, **kwargs)</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">soup.find_all(<span class=\"string\">'title'</span>, limit=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></span><br><span class=\"line\"></span><br><span class=\"line\">soup.find(<span class=\"string\">'title'</span>)</span><br><span class=\"line\"><span class=\"comment\"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></span><br></pre></td></tr></table></figure>\n<p>唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.</p>\n<p>find_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None.</p>\n<h3 id=\"find-parents-和find-parent\"><a href=\"#find-parents-和find-parent\" class=\"headerlink\" title=\"find_parents()和find_parent()\"></a>find_parents()和find_parent()</h3><p>find_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同</p>\n<h3 id=\"find-next-siblings-和find-next-sibling\"><a href=\"#find-next-siblings-和find-next-sibling\" class=\"headerlink\" title=\"find_next_siblings()和find_next_sibling()\"></a>find_next_siblings()和find_next_sibling()</h3><p>这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.</p>\n<h3 id=\"find-previous-siblings和find-previous-sibling\"><a href=\"#find-previous-siblings和find-previous-sibling\" class=\"headerlink\" title=\"find_previous_siblings和find_previous_sibling()\"></a>find_previous_siblings和find_previous_sibling()</h3><p>find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:</p>\n<h3 id=\"find-all-next-和find-next\"><a href=\"#find-all-next-和find-next\" class=\"headerlink\" title=\"find_all_next()和find_next()\"></a>find_all_next()和find_next()</h3><p>这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:</p>\n<h3 id=\"find-all-previous-和find-previous\"><a href=\"#find-all-previous-和find-previous\" class=\"headerlink\" title=\"find_all_previous()和find_previous()\"></a>find_all_previous()和find_previous()</h3><p>这2个方法通过 .previous_elements 属性对当前节点前面的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.</p>\n<h3 id=\"CSS选择器\"><a href=\"#CSS选择器\" class=\"headerlink\" title=\"CSS选择器\"></a>CSS选择器</h3><p>通过tag标签逐层查找 <code>soup.select(&quot;body a&quot;)</code></p>\n<p>找到某个tag标签的直接子标签 <code>soup.select(&quot;p &gt; #link1&quot;)</code></p>\n<p>找到兄弟节点标签 <code>soup.select(&quot;#link1 + .sister&quot;)</code></p>\n<p>通过CSS类名查找 <code>soup.select(&quot;.sister&quot;), soup.select(&quot;[class~=sister]&quot;)</code></p>\n<p>通过tag的id查找 <code>soup.select(&quot;#link1&quot;)</code></p>\n<p>通过是否存在某个属性查找 <code>soup.slect(&#39;a[href]&#39;)</code></p>\n<p>通过属性的值来查找 <code>soup.select(&#39;a[href^=&quot;https:&quot;]&#39;, [href$=&#39;title&#39;], [href*=&quot;.com/&quot;]</code></p>\n<h2 id=\"修改文档树\"><a href=\"#修改文档树\" class=\"headerlink\" title=\"修改文档树\"></a>修改文档树</h2><h2 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h2><h3 id=\"格式化输出\"><a href=\"#格式化输出\" class=\"headerlink\" title=\"格式化输出\"></a>格式化输出</h3><p>prettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">markup = <span class=\"string\">'&lt;a href=\"http://example.com/\"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></span><br><span class=\"line\">soup = BeautifulSoup(markup)</span><br><span class=\"line\">soup.prettify()</span><br><span class=\"line\"><span class=\"comment\"># '&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n  &lt;a href=\"http://example.com/\"&gt;\\n...'</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(soup.prettify())</span><br><span class=\"line\"><span class=\"comment\"># &lt;html&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;head&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;/head&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;body&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#   &lt;a href=\"http://example.com/\"&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#    I linked to</span></span><br><span class=\"line\"><span class=\"comment\">#    &lt;i&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#     example.com</span></span><br><span class=\"line\"><span class=\"comment\">#    &lt;/i&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#   &lt;/a&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;/body&gt;</span></span><br><span class=\"line\"><span class=\"comment\"># &lt;/html&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"压缩输出\"><a href=\"#压缩输出\" class=\"headerlink\" title=\"压缩输出\"></a>压缩输出</h3><p>如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:</p>\n<p><code>str(soup), Unicode(soup.a)</code></p>\n<h3 id=\"输出格式\"><a href=\"#输出格式\" class=\"headerlink\" title=\"输出格式\"></a>输出格式</h3><p>Beautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“\\&lquot;”:<br>如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:</p>\n<h3 id=\"get-text\"><a href=\"#get-text\" class=\"headerlink\" title=\"get_text()\"></a>get_text()</h3><p>如果只想得到tag中包含的文本内容,那么可以用 get_text() 方法,这个方法获取到tag中包含的所有文本内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:</p>\n<p>可以通过参数指定tag的文本内容的分隔符, 还可以去除前后空白: <code>soup.get_text(&#39;|&#39;, strip=True)</code></p>\n<h2 id=\"指定文档解析器\"><a href=\"#指定文档解析器\" class=\"headerlink\" title=\"指定文档解析器\"></a>指定文档解析器</h2><h2 id=\"编码\"><a href=\"#编码\" class=\"headerlink\" title=\"编码\"></a>编码</h2>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"BeautifulSoup\"><a href=\"#BeautifulSoup\" class=\"headerlink\" title=\"BeautifulSoup\"></a><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html\" target=\"_blank\" rel=\"noopener\">BeautifulSoup</a></h2><p>You didn’t write that awful page. You’re just trying to get some data out of it. Beautiful Soup is here to help. Since 2004, it’s been saving programmers hours or days of work on quick-turnaround screen scraping projects.</p>\n<h2 id=\"如何使用\"><a href=\"#如何使用\" class=\"headerlink\" title=\"如何使用\"></a>如何使用</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup</span><br><span class=\"line\">soup = BeautifulSoup(open(<span class=\"string\">'index.html'</span>))</span><br></pre></td></tr></table></figure>\n<h2 id=\"对象的种类\"><a href=\"#对象的种类\" class=\"headerlink\" title=\"对象的种类\"></a>对象的种类</h2><h3 id=\"Tag\"><a href=\"#Tag\" class=\"headerlink\" title=\"Tag\"></a>Tag</h3><p>Tag 对象与XML或HTML原生文档中的tag相同:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">soup = BeautifulSoup(<span class=\"string\">'&lt;b class=\"boldest\"&gt;Extremely bold&lt;/b&gt;'</span>)</span><br><span class=\"line\">tag = soup.b</span><br><span class=\"line\">type(tag)</span><br><span class=\"line\"><span class=\"comment\"># &lt;class 'bs4.element.Tag'&gt;</span></span><br></pre></td></tr></table></figure>\n<p>Tag的属性：<code>tag.name, tag.attrs</code></p>\n<p>tag的属性的操作方法与字典相同: <code>tag[&#39;class&#39;]</code></p>\n<h3 id=\"可以遍历的字符串\"><a href=\"#可以遍历的字符串\" class=\"headerlink\" title=\"可以遍历的字符串\"></a>可以遍历的字符串</h3><p>字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:<code>tag.string</code></p>\n<p><code>unicode_string = unicode(tag.string)</code></p>\n<p>tag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法:<code>tag.string.replace_with(&quot;No&quot;)</code></p>\n<h3 id=\"BeautifulSoup-1\"><a href=\"#BeautifulSoup-1\" class=\"headerlink\" title=\"BeautifulSoup\"></a>BeautifulSoup</h3><p>BeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.</p>\n<h3 id=\"注释及特殊字符串\"><a href=\"#注释及特殊字符串\" class=\"headerlink\" title=\"注释及特殊字符串\"></a>注释及特殊字符串</h3><p>Comment 对象是一个特殊类型的 NavigableString 对象:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">markup = <span class=\"string\">\"&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;\"</span></span><br><span class=\"line\">soup = BeautifulSoup(markup)</span><br><span class=\"line\">comment = soup.b.string</span><br><span class=\"line\">type(comment)</span><br><span class=\"line\"><span class=\"comment\"># &lt;class 'bs4.element.Comment'&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"遍历文档树\"><a href=\"#遍历文档树\" class=\"headerlink\" title=\"遍历文档树\"></a>遍历文档树</h2><h3 id=\"子节点\"><a href=\"#子节点\" class=\"headerlink\" title=\"子节点\"></a>子节点</h3><p>一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.</p>\n<h4 id=\"tag的名字\"><a href=\"#tag的名字\" class=\"headerlink\" title=\"tag的名字\"></a>tag的名字</h4><p><code>soup.head, soup.title, soup.body.b, soup.a, soup.find_all(&#39;a&#39;)</code></p>\n<h4 id=\"contents和-children\"><a href=\"#contents和-children\" class=\"headerlink\" title=\".contents和.children\"></a>.contents和.children</h4><p>tag的 .contents 属性可以将tag的子节点以列表的方式输出:</p>\n<p>通过tag的 .children 生成器,可以对tag的子节点进行循环:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> title_tag.children:</span><br><span class=\"line\">    print(child)</span><br></pre></td></tr></table></figure>\n<p>descendants 属性可以对所有tag的子孙节点进行递归循环:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> title_tag.descendants:</span><br><span class=\"line\">    print(child)</span><br></pre></td></tr></table></figure>\n<h3 id=\"string\"><a href=\"#string\" class=\"headerlink\" title=\".string\"></a>.string</h3><p>如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点:<code>tag.string</code></p>\n<p>如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同</p>\n<p>如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :</p>\n<h3 id=\"strings和stripped-strings\"><a href=\"#strings和stripped-strings\" class=\"headerlink\" title=\".strings和stripped__strings\"></a>.strings和stripped__strings</h3><p>如果tag中包含多个字符串 ,可以使用 .strings 来循环获取, 输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> string <span class=\"keyword\">in</span> soup.strings:</span><br><span class=\"line\">    print(repr(string))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> string <span class=\"keyword\">in</span> soup.stripped_strings:</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n<h3 id=\"父节点\"><a href=\"#父节点\" class=\"headerlink\" title=\"父节点\"></a>父节点</h3><h4 id=\"parent\"><a href=\"#parent\" class=\"headerlink\" title=\".parent\"></a>.parent</h4><p><code>tag.parent, tag.string.parent</code></p>\n<h4 id=\"parents\"><a href=\"#parents\" class=\"headerlink\" title=\".parents\"></a>.parents</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">link = soup.a</span><br><span class=\"line\"><span class=\"keyword\">for</span> parent <span class=\"keyword\">in</span> link.parents:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> parent <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        print(parent)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        print(parent.name)</span><br></pre></td></tr></table></figure>\n<h3 id=\"兄弟节点\"><a href=\"#兄弟节点\" class=\"headerlink\" title=\"兄弟节点\"></a>兄弟节点</h3><h4 id=\"next-sibling和-previous-sibling\"><a href=\"#next-sibling和-previous-sibling\" class=\"headerlink\" title=\".next_sibling和.previous_sibling\"></a>.next_sibling和.previous_sibling</h4><p>实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白.</p>\n<h4 id=\"next-siblings和-previous-siblings\"><a href=\"#next-siblings和-previous-siblings\" class=\"headerlink\" title=\".next_siblings和.previous_siblings\"></a>.next_siblings和.previous_siblings</h4><p>通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> sibling <span class=\"keyword\">in</span> soup.a.next_siblings:</span><br><span class=\"line\">    print(repr(sibling))</span><br></pre></td></tr></table></figure>\n<h3 id=\"回退和前进\"><a href=\"#回退和前进\" class=\"headerlink\" title=\"回退和前进\"></a>回退和前进</h3><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>The Dormouse's story<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">class</span>=<span class=\"string\">\"title\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">b</span>&gt;</span>The Dormouse's story<span class=\"tag\">&lt;/<span class=\"name\">b</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>HTML解析器把这段字符串转换成一连串的事件: “打开html标签”,”打开一个head标签”,”打开一个title标签”,”添加一段字符串”,”关闭title标签”,”关闭p标签”,等等.Beautiful Soup提供了重现解析器初始化过程的方法</p>\n<h4 id=\"next-element和-previous-element\"><a href=\"#next-element和-previous-element\" class=\"headerlink\" title=\".next_element和.previous_element\"></a>.next_element和.previous_element</h4><p>.previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象, next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),</p>\n<h4 id=\"next-elements和-previous-elements\"><a href=\"#next-elements和-previous-elements\" class=\"headerlink\" title=\".next_elements和.previous_elements\"></a>.next_elements和.previous_elements</h4><p>通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> elementin a_tag.next_elements:</span><br><span class=\"line\">    print(repr(element))</span><br></pre></td></tr></table></figure>\n<h2 id=\"搜索文档树\"><a href=\"#搜索文档树\" class=\"headerlink\" title=\"搜索文档树\"></a>搜索文档树</h2><h3 id=\"过滤器\"><a href=\"#过滤器\" class=\"headerlink\" title=\"过滤器\"></a>过滤器</h3><h4 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h4><p>最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的\\<b>标签:</b></p>\n<p><code>soup.find_all(&#39;b&#39;)</code></p>\n<h4 id=\"正则表达式\"><a href=\"#正则表达式\" class=\"headerlink\" title=\"正则表达式\"></a>正则表达式</h4><p>如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示\\<body>和\\<b>标签都应该被找到:</b></body></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">for</span> tag <span class=\"keyword\">in</span> soup.find_all(re.compile(<span class=\"string\">\"^b\"</span>):</span><br><span class=\"line\">    print(tag.name)</span><br></pre></td></tr></table></figure>\n<h4 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h4><p>如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有\\<a>标签和\\<b>标签:</b></a></p>\n<p><code>soup.find_all([&#39;a&#39;, &#39;b&#39;])</code></p>\n<h4 id=\"True\"><a href=\"#True\" class=\"headerlink\" title=\"True\"></a>True</h4><p>True 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> tag <span class=\"keyword\">in</span> soup.find_all(<span class=\"keyword\">True</span>):</span><br><span class=\"line\">    print(tag.name)</span><br></pre></td></tr></table></figure>\n<h4 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h4><p>如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False</p>\n<p>下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">has_class_but_no_id</span><span class=\"params\">(tag)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> tag.has_attr(<span class=\"string\">'class'</span>) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> tag.has_attr(<span class=\"string\">'id'</span>)</span><br></pre></td></tr></table></figure>\n<p>下面代码找到所有被文字包含的节点内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> NavigableString</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">surrounded_by_strings</span><span class=\"params\">(tag)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (isinstance(tag.next_element, NavigableString)) <span class=\"keyword\">and</span> isinstance(tag.previous_element, NavigableString)</span><br></pre></td></tr></table></figure>\n<h3 id=\"find-all\"><a href=\"#find-all\" class=\"headerlink\" title=\"find_all()\"></a>find_all()</h3><p><code>find_all(name, attrs, recursive, text, **kwargs)</code></p>\n<p>find_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件</p>\n<h4 id=\"name参数\"><a href=\"#name参数\" class=\"headerlink\" title=\"name参数\"></a>name参数</h4><p>搜索 name 参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .</p>\n<p>name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.</p>\n<h4 id=\"keyword参数\"><a href=\"#keyword参数\" class=\"headerlink\" title=\"keyword参数\"></a>keyword参数</h4><p><code>soup.find_all(id=&#39;link2&#39;)</code><br><code>soup.find_all(href=re.compile(&#39;elsie&#39;))</code><br><code>soup.find_all(id=True)</code><br><code>soup.find_all(attrs={&#39;id&#39;:&#39;link2&#39;})</code></p>\n<h4 id=\"按CSS搜索\"><a href=\"#按CSS搜索\" class=\"headerlink\" title=\"按CSS搜索\"></a>按CSS搜索</h4><p>通过 “.class__”_ 参数搜索有指定CSS类名的tag, “.class__”_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True</p>\n<p><code>soup.find_all(&#39;a&#39;, class_=&#39;sister&#39;)</code></p>\n<h4 id=\"text参数\"><a href=\"#text参数\" class=\"headerlink\" title=\"text参数\"></a>text参数</h4><p>通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True.</p>\n<p><code>soup.find_all(text=re.compile(&quot;Dormouse&quot;))</code></p>\n<h4 id=\"limit参数\"><a href=\"#limit参数\" class=\"headerlink\" title=\"limit参数\"></a>limit参数</h4><p>find_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.</p>\n<p><code>soup.find_all(&#39;a&#39;, limit=2)</code></p>\n<h4 id=\"recursive参数\"><a href=\"#recursive参数\" class=\"headerlink\" title=\"recursive参数\"></a>recursive参数</h4><p>调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False.</p>\n<p><code>soup.find_all(&#39;title&#39;, recursive=False)</code></p>\n<h3 id=\"像调用find-all-一样调用tag\"><a href=\"#像调用find-all-一样调用tag\" class=\"headerlink\" title=\"像调用find_all()一样调用tag\"></a>像调用find_all()一样调用tag</h3><p>find_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:</p>\n<p><code>soup.find_all(&#39;a&#39;)</code><br><code>soup(&#39;a&#39;)</code></p>\n<h3 id=\"find\"><a href=\"#find\" class=\"headerlink\" title=\"find()\"></a>find()</h3><p><code>find(name, attrs, recursive, text, **kwargs)</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">soup.find_all(<span class=\"string\">'title'</span>, limit=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></span><br><span class=\"line\"></span><br><span class=\"line\">soup.find(<span class=\"string\">'title'</span>)</span><br><span class=\"line\"><span class=\"comment\"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></span><br></pre></td></tr></table></figure>\n<p>唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.</p>\n<p>find_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None.</p>\n<h3 id=\"find-parents-和find-parent\"><a href=\"#find-parents-和find-parent\" class=\"headerlink\" title=\"find_parents()和find_parent()\"></a>find_parents()和find_parent()</h3><p>find_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同</p>\n<h3 id=\"find-next-siblings-和find-next-sibling\"><a href=\"#find-next-siblings-和find-next-sibling\" class=\"headerlink\" title=\"find_next_siblings()和find_next_sibling()\"></a>find_next_siblings()和find_next_sibling()</h3><p>这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.</p>\n<h3 id=\"find-previous-siblings和find-previous-sibling\"><a href=\"#find-previous-siblings和find-previous-sibling\" class=\"headerlink\" title=\"find_previous_siblings和find_previous_sibling()\"></a>find_previous_siblings和find_previous_sibling()</h3><p>find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:</p>\n<h3 id=\"find-all-next-和find-next\"><a href=\"#find-all-next-和find-next\" class=\"headerlink\" title=\"find_all_next()和find_next()\"></a>find_all_next()和find_next()</h3><p>这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:</p>\n<h3 id=\"find-all-previous-和find-previous\"><a href=\"#find-all-previous-和find-previous\" class=\"headerlink\" title=\"find_all_previous()和find_previous()\"></a>find_all_previous()和find_previous()</h3><p>这2个方法通过 .previous_elements 属性对当前节点前面的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.</p>\n<h3 id=\"CSS选择器\"><a href=\"#CSS选择器\" class=\"headerlink\" title=\"CSS选择器\"></a>CSS选择器</h3><p>通过tag标签逐层查找 <code>soup.select(&quot;body a&quot;)</code></p>\n<p>找到某个tag标签的直接子标签 <code>soup.select(&quot;p &gt; #link1&quot;)</code></p>\n<p>找到兄弟节点标签 <code>soup.select(&quot;#link1 + .sister&quot;)</code></p>\n<p>通过CSS类名查找 <code>soup.select(&quot;.sister&quot;), soup.select(&quot;[class~=sister]&quot;)</code></p>\n<p>通过tag的id查找 <code>soup.select(&quot;#link1&quot;)</code></p>\n<p>通过是否存在某个属性查找 <code>soup.slect(&#39;a[href]&#39;)</code></p>\n<p>通过属性的值来查找 <code>soup.select(&#39;a[href^=&quot;https:&quot;]&#39;, [href$=&#39;title&#39;], [href*=&quot;.com/&quot;]</code></p>\n<h2 id=\"修改文档树\"><a href=\"#修改文档树\" class=\"headerlink\" title=\"修改文档树\"></a>修改文档树</h2><h2 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h2><h3 id=\"格式化输出\"><a href=\"#格式化输出\" class=\"headerlink\" title=\"格式化输出\"></a>格式化输出</h3><p>prettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">markup = <span class=\"string\">'&lt;a href=\"http://example.com/\"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></span><br><span class=\"line\">soup = BeautifulSoup(markup)</span><br><span class=\"line\">soup.prettify()</span><br><span class=\"line\"><span class=\"comment\"># '&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n  &lt;a href=\"http://example.com/\"&gt;\\n...'</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(soup.prettify())</span><br><span class=\"line\"><span class=\"comment\"># &lt;html&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;head&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;/head&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;body&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#   &lt;a href=\"http://example.com/\"&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#    I linked to</span></span><br><span class=\"line\"><span class=\"comment\">#    &lt;i&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#     example.com</span></span><br><span class=\"line\"><span class=\"comment\">#    &lt;/i&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#   &lt;/a&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;/body&gt;</span></span><br><span class=\"line\"><span class=\"comment\"># &lt;/html&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"压缩输出\"><a href=\"#压缩输出\" class=\"headerlink\" title=\"压缩输出\"></a>压缩输出</h3><p>如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:</p>\n<p><code>str(soup), Unicode(soup.a)</code></p>\n<h3 id=\"输出格式\"><a href=\"#输出格式\" class=\"headerlink\" title=\"输出格式\"></a>输出格式</h3><p>Beautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“\\&lquot;”:<br>如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:</p>\n<h3 id=\"get-text\"><a href=\"#get-text\" class=\"headerlink\" title=\"get_text()\"></a>get_text()</h3><p>如果只想得到tag中包含的文本内容,那么可以用 get_text() 方法,这个方法获取到tag中包含的所有文本内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:</p>\n<p>可以通过参数指定tag的文本内容的分隔符, 还可以去除前后空白: <code>soup.get_text(&#39;|&#39;, strip=True)</code></p>\n<h2 id=\"指定文档解析器\"><a href=\"#指定文档解析器\" class=\"headerlink\" title=\"指定文档解析器\"></a>指定文档解析器</h2><h2 id=\"编码\"><a href=\"#编码\" class=\"headerlink\" title=\"编码\"></a>编码</h2>"},{"title":"CIFAR-10","date":"2018-09-15T05:02:14.000Z","_content":"The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n\n## [The CIFAR-10 dataset](http://www.cs.toronto.edu/~kriz/cifar.html)\n\nThe CIFAR-10 dataset consists of **60000 32x32** colour images in **10 classes**, with 6000 images per class. There are **50000 training** images and **10000 test** images.\n\nThe dataset is divided into **five training batches** and **one test batch**, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n\n## Dataset layout (python/matlab version)\n\nThe archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object\n\n```python\ndef unpickle(file):  # python2\n    import cPickle\n    with open(file, 'rb') as fo:\n        dict = cPickle.load(fo)\n    return dict\n\ndef unpickle(file):  # python3\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n```\n\nLoaded in this way, each of the batch files contains a dictionary with the following elements:\n\n    data --\n    a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image.\n    The first 1024 entries contain the red channel values,\n    the next 1024 the green, and the final 1024 the blue.\n    The image is stored in row-major order, so that the first 32 entries of\n    the array are the red channel values of the first row of the image.\n\n    labels --\n    a list of 10000 numbers in the range 0-9.\n    The number at index i indicates the label of the ith image in the array data.\n\nThe dataset contains another file, called **batches.meta**. It too contains a Python dictionary object. It has the following entries:\n\n    label_names --\n    a 10-element list which gives meaningful names to the numeric labels in the labels array described above.\n     For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\n","source":"_posts/CIFAR-10.md","raw":"---\ntitle: CIFAR-10\ndate: 2018-09-15 13:02:14\ntags: 数据集\ncategories: 深度学习\n---\nThe CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n\n## [The CIFAR-10 dataset](http://www.cs.toronto.edu/~kriz/cifar.html)\n\nThe CIFAR-10 dataset consists of **60000 32x32** colour images in **10 classes**, with 6000 images per class. There are **50000 training** images and **10000 test** images.\n\nThe dataset is divided into **five training batches** and **one test batch**, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n\n## Dataset layout (python/matlab version)\n\nThe archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object\n\n```python\ndef unpickle(file):  # python2\n    import cPickle\n    with open(file, 'rb') as fo:\n        dict = cPickle.load(fo)\n    return dict\n\ndef unpickle(file):  # python3\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n```\n\nLoaded in this way, each of the batch files contains a dictionary with the following elements:\n\n    data --\n    a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image.\n    The first 1024 entries contain the red channel values,\n    the next 1024 the green, and the final 1024 the blue.\n    The image is stored in row-major order, so that the first 32 entries of\n    the array are the red channel values of the first row of the image.\n\n    labels --\n    a list of 10000 numbers in the range 0-9.\n    The number at index i indicates the label of the ith image in the array data.\n\nThe dataset contains another file, called **batches.meta**. It too contains a Python dictionary object. It has the following entries:\n\n    label_names --\n    a 10-element list which gives meaningful names to the numeric labels in the labels array described above.\n     For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\n","slug":"CIFAR-10","published":1,"updated":"2018-09-22T03:51:56.207Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds0p0002pcvonlykyz9o","content":"<p>The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.</p>\n<h2 id=\"The-CIFAR-10-dataset\"><a href=\"#The-CIFAR-10-dataset\" class=\"headerlink\" title=\"The CIFAR-10 dataset\"></a><a href=\"http://www.cs.toronto.edu/~kriz/cifar.html\" target=\"_blank\" rel=\"noopener\">The CIFAR-10 dataset</a></h2><p>The CIFAR-10 dataset consists of <strong>60000 32x32</strong> colour images in <strong>10 classes</strong>, with 6000 images per class. There are <strong>50000 training</strong> images and <strong>10000 test</strong> images.</p>\n<p>The dataset is divided into <strong>five training batches</strong> and <strong>one test batch</strong>, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.</p>\n<h2 id=\"Dataset-layout-python-matlab-version\"><a href=\"#Dataset-layout-python-matlab-version\" class=\"headerlink\" title=\"Dataset layout (python/matlab version)\"></a>Dataset layout (python/matlab version)</h2><p>The archive contains the files data_batch_1, data_batch_2, …, data_batch_5, as well as test_batch. Each of these files is a Python “pickled” object</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">unpickle</span><span class=\"params\">(file)</span>:</span>  <span class=\"comment\"># python2</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> cPickle</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> fo:</span><br><span class=\"line\">        dict = cPickle.load(fo)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dict</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">unpickle</span><span class=\"params\">(file)</span>:</span>  <span class=\"comment\"># python3</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> pickle</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> fo:</span><br><span class=\"line\">        dict = pickle.load(fo, encoding=<span class=\"string\">'bytes'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dict</span><br></pre></td></tr></table></figure>\n<p>Loaded in this way, each of the batch files contains a dictionary with the following elements:</p>\n<pre><code>data --\na 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image.\nThe first 1024 entries contain the red channel values,\nthe next 1024 the green, and the final 1024 the blue.\nThe image is stored in row-major order, so that the first 32 entries of\nthe array are the red channel values of the first row of the image.\n\nlabels --\na list of 10000 numbers in the range 0-9.\nThe number at index i indicates the label of the ith image in the array data.\n</code></pre><p>The dataset contains another file, called <strong>batches.meta</strong>. It too contains a Python dictionary object. It has the following entries:</p>\n<pre><code>label_names --\na 10-element list which gives meaningful names to the numeric labels in the labels array described above.\n For example, label_names[0] == &quot;airplane&quot;, label_names[1] == &quot;automobile&quot;, etc.\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.</p>\n<h2 id=\"The-CIFAR-10-dataset\"><a href=\"#The-CIFAR-10-dataset\" class=\"headerlink\" title=\"The CIFAR-10 dataset\"></a><a href=\"http://www.cs.toronto.edu/~kriz/cifar.html\" target=\"_blank\" rel=\"noopener\">The CIFAR-10 dataset</a></h2><p>The CIFAR-10 dataset consists of <strong>60000 32x32</strong> colour images in <strong>10 classes</strong>, with 6000 images per class. There are <strong>50000 training</strong> images and <strong>10000 test</strong> images.</p>\n<p>The dataset is divided into <strong>five training batches</strong> and <strong>one test batch</strong>, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.</p>\n<h2 id=\"Dataset-layout-python-matlab-version\"><a href=\"#Dataset-layout-python-matlab-version\" class=\"headerlink\" title=\"Dataset layout (python/matlab version)\"></a>Dataset layout (python/matlab version)</h2><p>The archive contains the files data_batch_1, data_batch_2, …, data_batch_5, as well as test_batch. Each of these files is a Python “pickled” object</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">unpickle</span><span class=\"params\">(file)</span>:</span>  <span class=\"comment\"># python2</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> cPickle</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> fo:</span><br><span class=\"line\">        dict = cPickle.load(fo)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dict</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">unpickle</span><span class=\"params\">(file)</span>:</span>  <span class=\"comment\"># python3</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> pickle</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> fo:</span><br><span class=\"line\">        dict = pickle.load(fo, encoding=<span class=\"string\">'bytes'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dict</span><br></pre></td></tr></table></figure>\n<p>Loaded in this way, each of the batch files contains a dictionary with the following elements:</p>\n<pre><code>data --\na 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image.\nThe first 1024 entries contain the red channel values,\nthe next 1024 the green, and the final 1024 the blue.\nThe image is stored in row-major order, so that the first 32 entries of\nthe array are the red channel values of the first row of the image.\n\nlabels --\na list of 10000 numbers in the range 0-9.\nThe number at index i indicates the label of the ith image in the array data.\n</code></pre><p>The dataset contains another file, called <strong>batches.meta</strong>. It too contains a Python dictionary object. It has the following entries:</p>\n<pre><code>label_names --\na 10-element list which gives meaningful names to the numeric labels in the labels array described above.\n For example, label_names[0] == &quot;airplane&quot;, label_names[1] == &quot;automobile&quot;, etc.\n</code></pre>"},{"title":"Evolutionary Algorithms","date":"2018-08-05T09:12:46.000Z","_content":"\n>It is not strongest of the species that survives, nor the most intelligent that survives. It is the one that is the most adaptable to change. -- Charles Darwin\n\n## Motivation of EAs\n\n1. What can EAs do for us?\n\t- Optimization\n\t- Help people understand the evolution in nature.\n\n2. What is optimizatin?\n\t- The process of searching for the optimal solution from a set of candidates to the problem of interest based on certrain **performance criteria**\n\n3. Produce maximum yields given litmited resources.\n\n## Key Concepts\n\n- Population-Based Stochastic Optimization Methods\n- Inherently Parallel\n- A Good Example of Bionics in Engineering\n- Survival of the Fittest\n- Chromosome, Crossover, Mutation\n- Metaheuristics\n- Bio-/Nature Inspired Computing\n\n## The Big Picture\n\n![](/images/eas.png)\n\n## EA Family\n\n- GA: Genetic Algorithm\n- GP: Genetic Programming\n- ES: Evolution Strategies\n- EP: Evolution Programming\n- EDA: Estimation of Distribution Algorithm\n- PSO: Particle Swarm Optimization\n- ACO: Ant Colony Optimization\n- DE: Differential Evolution\n\n## Optimization Problem Set\n\n- Portfolio Optimization\n- Travelling Salesman Problem\n- Knapsack Problem\n- Machine Learing Problems\n\n![](/images/local_optima.png)\n\nMany interesting optimization problems are not trivial.The optimal solution cannot always be found in polynomial time.\n\n## Solution: Parallel Search\n\n- Conduct searching in different areas simultaneously.\n\t- Population Based\n\t- Avoid unfortunate starting positions.\n- Employ heuristic methods to effectively explore the space.\n\t- Focus on promising areas.\n\t- Also keep an eye on other regions.\n\t- More than random restart strategies.\n\n## Publications\n\nTop Journals:\n- IEEE Transactions On Evolutionary Computation.\n- Evolutionary Compution Journal\n\nMajor Conference:\n- IEEE Congress On Evolution Computation(CEC)\n- Genetic and Evolution Computation Conference(GECCO)\n- Parallel Problem Solving from Nature(PPSN)\n\nGame:\n\t- Blondie24: Playing at the Edge of AI\n\nBook:\n\t- How to Solve It: Modern Heuristics\n","source":"_posts/Evolutionary-Algorithms.md","raw":"---\ntitle: Evolutionary Algorithms\ndate: 2018-08-05 17:12:46\ntags: 进化算法\ncategories: 进化计算\n---\n\n>It is not strongest of the species that survives, nor the most intelligent that survives. It is the one that is the most adaptable to change. -- Charles Darwin\n\n## Motivation of EAs\n\n1. What can EAs do for us?\n\t- Optimization\n\t- Help people understand the evolution in nature.\n\n2. What is optimizatin?\n\t- The process of searching for the optimal solution from a set of candidates to the problem of interest based on certrain **performance criteria**\n\n3. Produce maximum yields given litmited resources.\n\n## Key Concepts\n\n- Population-Based Stochastic Optimization Methods\n- Inherently Parallel\n- A Good Example of Bionics in Engineering\n- Survival of the Fittest\n- Chromosome, Crossover, Mutation\n- Metaheuristics\n- Bio-/Nature Inspired Computing\n\n## The Big Picture\n\n![](/images/eas.png)\n\n## EA Family\n\n- GA: Genetic Algorithm\n- GP: Genetic Programming\n- ES: Evolution Strategies\n- EP: Evolution Programming\n- EDA: Estimation of Distribution Algorithm\n- PSO: Particle Swarm Optimization\n- ACO: Ant Colony Optimization\n- DE: Differential Evolution\n\n## Optimization Problem Set\n\n- Portfolio Optimization\n- Travelling Salesman Problem\n- Knapsack Problem\n- Machine Learing Problems\n\n![](/images/local_optima.png)\n\nMany interesting optimization problems are not trivial.The optimal solution cannot always be found in polynomial time.\n\n## Solution: Parallel Search\n\n- Conduct searching in different areas simultaneously.\n\t- Population Based\n\t- Avoid unfortunate starting positions.\n- Employ heuristic methods to effectively explore the space.\n\t- Focus on promising areas.\n\t- Also keep an eye on other regions.\n\t- More than random restart strategies.\n\n## Publications\n\nTop Journals:\n- IEEE Transactions On Evolutionary Computation.\n- Evolutionary Compution Journal\n\nMajor Conference:\n- IEEE Congress On Evolution Computation(CEC)\n- Genetic and Evolution Computation Conference(GECCO)\n- Parallel Problem Solving from Nature(PPSN)\n\nGame:\n\t- Blondie24: Playing at the Edge of AI\n\nBook:\n\t- How to Solve It: Modern Heuristics\n","slug":"Evolutionary-Algorithms","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds150006pcvoiic777q3","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>It is not strongest of the species that survives, nor the most intelligent that survives. It is the one that is the most adaptable to change. – Charles Darwin</p>\n</blockquote>\n<h2 id=\"Motivation-of-EAs\"><a href=\"#Motivation-of-EAs\" class=\"headerlink\" title=\"Motivation of EAs\"></a>Motivation of EAs</h2><ol>\n<li><p>What can EAs do for us?</p>\n<ul>\n<li>Optimization</li>\n<li>Help people understand the evolution in nature.</li>\n</ul>\n</li>\n<li><p>What is optimizatin?</p>\n<ul>\n<li>The process of searching for the optimal solution from a set of candidates to the problem of interest based on certrain <strong>performance criteria</strong></li>\n</ul>\n</li>\n<li><p>Produce maximum yields given litmited resources.</p>\n</li>\n</ol>\n<h2 id=\"Key-Concepts\"><a href=\"#Key-Concepts\" class=\"headerlink\" title=\"Key Concepts\"></a>Key Concepts</h2><ul>\n<li>Population-Based Stochastic Optimization Methods</li>\n<li>Inherently Parallel</li>\n<li>A Good Example of Bionics in Engineering</li>\n<li>Survival of the Fittest</li>\n<li>Chromosome, Crossover, Mutation</li>\n<li>Metaheuristics</li>\n<li>Bio-/Nature Inspired Computing</li>\n</ul>\n<h2 id=\"The-Big-Picture\"><a href=\"#The-Big-Picture\" class=\"headerlink\" title=\"The Big Picture\"></a>The Big Picture</h2><p><img src=\"/images/eas.png\" alt=\"\"></p>\n<h2 id=\"EA-Family\"><a href=\"#EA-Family\" class=\"headerlink\" title=\"EA Family\"></a>EA Family</h2><ul>\n<li>GA: Genetic Algorithm</li>\n<li>GP: Genetic Programming</li>\n<li>ES: Evolution Strategies</li>\n<li>EP: Evolution Programming</li>\n<li>EDA: Estimation of Distribution Algorithm</li>\n<li>PSO: Particle Swarm Optimization</li>\n<li>ACO: Ant Colony Optimization</li>\n<li>DE: Differential Evolution</li>\n</ul>\n<h2 id=\"Optimization-Problem-Set\"><a href=\"#Optimization-Problem-Set\" class=\"headerlink\" title=\"Optimization Problem Set\"></a>Optimization Problem Set</h2><ul>\n<li>Portfolio Optimization</li>\n<li>Travelling Salesman Problem</li>\n<li>Knapsack Problem</li>\n<li>Machine Learing Problems</li>\n</ul>\n<p><img src=\"/images/local_optima.png\" alt=\"\"></p>\n<p>Many interesting optimization problems are not trivial.The optimal solution cannot always be found in polynomial time.</p>\n<h2 id=\"Solution-Parallel-Search\"><a href=\"#Solution-Parallel-Search\" class=\"headerlink\" title=\"Solution: Parallel Search\"></a>Solution: Parallel Search</h2><ul>\n<li>Conduct searching in different areas simultaneously.<ul>\n<li>Population Based</li>\n<li>Avoid unfortunate starting positions.</li>\n</ul>\n</li>\n<li>Employ heuristic methods to effectively explore the space.<ul>\n<li>Focus on promising areas.</li>\n<li>Also keep an eye on other regions.</li>\n<li>More than random restart strategies.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Publications\"><a href=\"#Publications\" class=\"headerlink\" title=\"Publications\"></a>Publications</h2><p>Top Journals:</p>\n<ul>\n<li>IEEE Transactions On Evolutionary Computation.</li>\n<li>Evolutionary Compution Journal</li>\n</ul>\n<p>Major Conference:</p>\n<ul>\n<li>IEEE Congress On Evolution Computation(CEC)</li>\n<li>Genetic and Evolution Computation Conference(GECCO)</li>\n<li>Parallel Problem Solving from Nature(PPSN)</li>\n</ul>\n<p>Game:</p>\n<pre><code>- Blondie24: Playing at the Edge of AI\n</code></pre><p>Book:</p>\n<pre><code>- How to Solve It: Modern Heuristics\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>It is not strongest of the species that survives, nor the most intelligent that survives. It is the one that is the most adaptable to change. – Charles Darwin</p>\n</blockquote>\n<h2 id=\"Motivation-of-EAs\"><a href=\"#Motivation-of-EAs\" class=\"headerlink\" title=\"Motivation of EAs\"></a>Motivation of EAs</h2><ol>\n<li><p>What can EAs do for us?</p>\n<ul>\n<li>Optimization</li>\n<li>Help people understand the evolution in nature.</li>\n</ul>\n</li>\n<li><p>What is optimizatin?</p>\n<ul>\n<li>The process of searching for the optimal solution from a set of candidates to the problem of interest based on certrain <strong>performance criteria</strong></li>\n</ul>\n</li>\n<li><p>Produce maximum yields given litmited resources.</p>\n</li>\n</ol>\n<h2 id=\"Key-Concepts\"><a href=\"#Key-Concepts\" class=\"headerlink\" title=\"Key Concepts\"></a>Key Concepts</h2><ul>\n<li>Population-Based Stochastic Optimization Methods</li>\n<li>Inherently Parallel</li>\n<li>A Good Example of Bionics in Engineering</li>\n<li>Survival of the Fittest</li>\n<li>Chromosome, Crossover, Mutation</li>\n<li>Metaheuristics</li>\n<li>Bio-/Nature Inspired Computing</li>\n</ul>\n<h2 id=\"The-Big-Picture\"><a href=\"#The-Big-Picture\" class=\"headerlink\" title=\"The Big Picture\"></a>The Big Picture</h2><p><img src=\"/images/eas.png\" alt=\"\"></p>\n<h2 id=\"EA-Family\"><a href=\"#EA-Family\" class=\"headerlink\" title=\"EA Family\"></a>EA Family</h2><ul>\n<li>GA: Genetic Algorithm</li>\n<li>GP: Genetic Programming</li>\n<li>ES: Evolution Strategies</li>\n<li>EP: Evolution Programming</li>\n<li>EDA: Estimation of Distribution Algorithm</li>\n<li>PSO: Particle Swarm Optimization</li>\n<li>ACO: Ant Colony Optimization</li>\n<li>DE: Differential Evolution</li>\n</ul>\n<h2 id=\"Optimization-Problem-Set\"><a href=\"#Optimization-Problem-Set\" class=\"headerlink\" title=\"Optimization Problem Set\"></a>Optimization Problem Set</h2><ul>\n<li>Portfolio Optimization</li>\n<li>Travelling Salesman Problem</li>\n<li>Knapsack Problem</li>\n<li>Machine Learing Problems</li>\n</ul>\n<p><img src=\"/images/local_optima.png\" alt=\"\"></p>\n<p>Many interesting optimization problems are not trivial.The optimal solution cannot always be found in polynomial time.</p>\n<h2 id=\"Solution-Parallel-Search\"><a href=\"#Solution-Parallel-Search\" class=\"headerlink\" title=\"Solution: Parallel Search\"></a>Solution: Parallel Search</h2><ul>\n<li>Conduct searching in different areas simultaneously.<ul>\n<li>Population Based</li>\n<li>Avoid unfortunate starting positions.</li>\n</ul>\n</li>\n<li>Employ heuristic methods to effectively explore the space.<ul>\n<li>Focus on promising areas.</li>\n<li>Also keep an eye on other regions.</li>\n<li>More than random restart strategies.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Publications\"><a href=\"#Publications\" class=\"headerlink\" title=\"Publications\"></a>Publications</h2><p>Top Journals:</p>\n<ul>\n<li>IEEE Transactions On Evolutionary Computation.</li>\n<li>Evolutionary Compution Journal</li>\n</ul>\n<p>Major Conference:</p>\n<ul>\n<li>IEEE Congress On Evolution Computation(CEC)</li>\n<li>Genetic and Evolution Computation Conference(GECCO)</li>\n<li>Parallel Problem Solving from Nature(PPSN)</li>\n</ul>\n<p>Game:</p>\n<pre><code>- Blondie24: Playing at the Edge of AI\n</code></pre><p>Book:</p>\n<pre><code>- How to Solve It: Modern Heuristics\n</code></pre>"},{"title":"Faster R-CNN:Towards Real-Time Object Dectection with Region Proposal Networks","date":"2018-09-26T08:13:20.000Z","mathjax":true,"_content":"## 摘要\n\n最先进的目标检测网络依赖region proposal算法来假设目标的位置。SPPnet[1]和Fast R-CNN[2]等研究已经减少了这些检测网络的运行时间，同时暴露出region proposal计算成为一个瓶颈。在这项工作中，我们引入了一个 **region proposal network(RPN)**，**该网络与检测网络共享全图像的卷积特征**，从而使近乎零成本的region proposal成为可能。**RPN是一个全卷积网络，可以同时在每个位置预测目标边界和目标的得分**。RPN经过端到端的训练来生成高质量的region proposal，进而由Fast R-CNN进行检测。我们 **将RPN和Fast R-CNN通过共享卷积特征进一步合并为一个单一的网络** ——使用最近流行的具有“注意力”机制的神经网络术语，RPN组件告诉统一的网络在哪里寻找。对于非常深的VGG-16模型[3]，我们的检测系统在GPU上的帧率为5fps（包括所有步骤），同时在PASCAL VOC 2007，2012和MS COCO数据集上实现了目前最优的目标检测精度，每个图像只有300个proposals。在ILSVRC和COCO 2015竞赛中，Faster R-CNN和RPN是多个比赛中获得第一名的基础。代码可公开获得。\n\n索引词--对象检测，region proposal, 卷积神经网络\n\n## 简介\n\nregion proposal 方法[4]和基于区域的卷积神经网络(R-CNNs)[5]的成功给目标检测带来了最新的进展。尽管在[5]中最初开发的基于区域的CNN计算成本很高，但是由于在各种proposal中共享卷积，其成本已经大大降低了[1]，[2]。忽略花费在region proposal上的时间，最新版本Fast R-CNN[2]利用非常深的网络[3]实现了接近实时的速率(当忽略region proposal的时间花费)。现在，proposals是最新的检测系统中测试时间的计算瓶颈。\n\nregion proposal方法通常依赖廉价的特征和经济的推断方案。选择性搜索(Selective Search)[4]是最流行的方法之一，它贪婪地合并基于工程的低级特征的超像素。然而，与有效的检测网络[2]相比，选择性搜索速度慢了一个数量级，在CPU实现中每张图像的时间为2秒。EdgeBoxes[6]目前提供了在proposal质量和速度之间的最佳权衡，每张图像0.2秒。尽管如此，region proposal步骤仍然像检测网络那样消耗同样多的运行时间。\n\n有人可能会注意到，基于区域的快速CNN利用GPU，而在研究中使用的region proposal方法在CPU上实现，使得运行时间的比较不公平。加速region proposal计算的一个显而易见的方法是将其在GPU上重新实现。这可能是一个有效的工程解决方案，但重新实现忽略了下游检测网络，因此错过了共享计算的重要机会。\n\n在本文中，我们对算法做了一点改变——用深度卷积神经网络计算proposals——带来了一个优雅而且有效的解决方案，其中在给定检测网络计算的情况下proposal计算几乎零成本。为此，我们引入了新的RPNs，它们共享最先进的目标检测网络的卷积层[1]，[2]。通过在测试时共享卷积，计算region proposal的边际成本很小（例如，每张图像10ms）。\n\n我们的观察到基于区域的检测器所使用的卷积特征映射，如Fast R-CNN，也可以用于生成region proposal。在这些卷积特征之上，我们通过添加一些额外的卷积层来构建RPN，这些卷积层同时在规则网格上的每个位置上regress区域边界和目标分数。因此RPN是一种全卷积网络（FCN）[7]，可以针对生成检测区域推荐的任务进行端到端的训练。\n\n![](/images/faster_f1.PNG)\n\n**RPN旨在有效预测具有广泛尺度和长宽比的region proposal**。与使用图像金字塔（图1，a）或滤波器金字塔（图1，b）的流行方法[8]，[9]，[1]相比，我们引入新的“**anchor**”盒作为多种尺度和长宽比的参考。我们的方案可以被认为是回归参考金字塔（图1，c），它避免了枚举多种尺度或长宽比的图像或滤波器。这个模型在使用单尺度图像进行训练和测试时表现很好，从而有利于运行速度的提高。\n\n为了将RPN与Fast R-CNN [2]目标检测网络相结合，我们提出了一种训练方案，**在微调region proposal任务和微调目标检测之间进行交替，同时保持the proposals的固定**。该方案快速收敛，并产生两个任务之间共享卷积特征的统一网络。\n\n我们在PASCAL VOC检测基准数据集上[11]综合评估了我们的方法，其中具有Fast R-CNN的RPN产生的检测精度优于使用强基准选择性搜索的Fast R-CNN。同时，我们的方法在测试时几乎免除了选择性搜索的所有计算负担——proposal的有效运行时间仅为10毫秒。使用昂贵的非常深的模型[3]，我们的检测方法在GPU上仍然具有5fps的帧率（包括所有步骤），因此在速度和准确性方面是实用的目标检测系统。我们还报告了在MS COCO数据集上[12]的结果，并使用COCO数据研究了在PASCAL VOC上的改进。代码可公开获得https://github.com/shaoqingren/faster_rcnn（MATLAB）和https://github.com/rbgirshick/py-faster-rcnn（Python）。\n\n这个手稿的初步版本是以前发表的[10]。从那时起，RPN和Faster R-CNN的框架已经被采用并推广到其他方法，如3D目标检测[13]，基于部件的检测[14]，实例分割[15]和图像标题[16]。我们快速和有效的目标检测系统也已经在Pinterest[17]的商业系统中建立了，并报告了用户参与度的提高。\n\n在ILSVRC和COCO 2015竞赛中，Faster R-CNN和RPN是ImageNet检测，ImageNet定位，COCO检测和COCO分割中几个第一名参赛者[18]的基础。RPN完全从数据中学习提议区域，因此可以从更深入和更具表达性的特征（例如[18]中采用的101层残差网络）中轻松获益。Faster R-CNN和RPN也被这些比赛中的其他几个主要参赛者所使用。这些结果表明，我们的方法不仅是一个实用合算的解决方案，而且是一个提高目标检测精度的有效方法。\n\n## 相关工作\n\n**Object Proposal**。Object Proposal方法方面有大量的文献。目标提议方法的综合调查和比较可以在[19]，[20]，[21]中找到。广泛使用的目标提议方法包括基于超像素分组（例如，选择性搜索[4]，CPMC[22]，MCG[23]）和那些基于滑动窗口的方法（例如窗口中的目标[24]，EdgeBoxes[6]）。目标提议方法被采用为独立于检测器（例如，选择性搜索[4]目标检测器，R-CNN[5]和Fast R-CNN[2]）的外部模块。\n\n**Deep Network for Object Dection**。R-CNN方法[5]端到端地对CNN进行训练，将提议区域分类为目标类别或背景。R-CNN主要作为分类器，它不预测目标边界（除了通过边界框回归进行细化）。其准确度取决于区域提议模块的性能（参见[20]中的比较）。一些论文提出了使用深度网络来预测目标边界框的方法[25]，[9]，[26]，[27]。在OverFeat方法[9]中，训练一个全连接层来预测单个目标定位任务的边界框坐标。然后将全连接层变成卷积层，用于检测多个类别的目标。MultiBox方法[26]，[27]从网络中生成区域提议，该网络最后的全连接层同时预测多个类别不可知的边界框，并推广到OverFeat的“single-box”方式。这些类别不可知的边界框被用作R-CNN的提议区域[5]。与我们的全卷积方案相比，MultiBox提议网络适用于单张裁剪图像或多张大型裁剪图像（例如224×224）。MultiBox在提议区域和检测网络之间不共享特征。稍后在我们的方法上下文中会讨论OverFeat和MultiBox。与我们的工作同时进行的，DeepMask方法[28]是为学习分割提议区域而开发的。\n\n卷积[9]，[1]，[29]，[7]，[2]的共享计算已经越来越受到人们的关注，因为它可以有效而准确地进行视觉识别。OverFeat论文[9]计算图像金字塔的卷积特征用于分类，定位和检测。共享卷积特征映射的自适应大小池化（SPP）[1]被开发用于有效的基于区域的目标检测[1]，[30]和语义分割[29]。Fast R-CNN[2]能够对共享卷积特征进行端到端的检测器训练，并显示出令人叹服的准确性和速度。\n\n## FASTER R-CNN\n\n我们的目标检测系统，称为 **Faster R-CNN** ，由两个模块组成。第一个模块是 **proposal regions的深度全卷积网络**，第二个模块是 **使用提议区域的Fast R-CNN检测器**[2]。整个系统是一个单个的，统一的目标检测网络（图2）。使用最近流行的“注意力”[31]机制的神经网络术语，**RPN模块告诉Fast R-CNN模块在哪里寻找**。在第3.1节中，我们介绍了区域提议网络的设计和属性。在第3.2节中，我们开发了用于训练具有共享特征模块的算法。\n\n![](/images/faster_f2.PNG)\n\n### Region Proposal Networks\n\n区域提议网络（RPN）**以任意大小的图像作为输入，输出一组矩形的目标提议，每个提议都有一个目标得分**。我们用全卷积网络[7]对这个过程进行建模，我们将在本节进行描述。因为我们的最终目标是与Fast R-CNN目标检测网络[2]共享计算，所以我们假设两个网络共享一组共同的卷积层。在我们的实验中，我们研究了具有5个共享卷积层的Zeiler和Fergus模型[32]（ZF）和具有13个共享卷积层的Simonyan和Zisserman模型[3]（VGG-16）。\n\n为了生成区域提议，我们 **在最后的共享卷积层输出的卷积特征映射上滑动一个小网络**。这个小网络将输入卷积特征映射的 $n×n$ 空间窗口作为输入。每个滑动窗口映射到一个低维特征（ZF为256维，VGG为512维，后面是ReLU[33]）。**这个特征被输入到两个子全连接层——一个边界框回归层（reg）和一个边界框分类层（cls）**。在本文中，我们使用n=3，注意输入图像上的有效接受域是大的（ZF和VGG分别为171和228个像素）。图3（左）显示了这个小型网络的一个位置。请注意，因为小网络以滑动窗口方式运行，所有空间位置共享全连接层。这种架构通过一个 $n×n$ 卷积层，后面是两个子1×1卷积层（分别用于reg和cls）自然地实现。\n\n#### Anchors\n\n在每个滑动窗口位置，我们同时预测多个区域提议，其中每个位置可能提议的最大数目定义为k。因此，reg层具有4k个输出，分别编码k个边界框的坐标，cls层输出2k个分数，估计每个提议是目标或不是目标的概率。相对于我们称之为Anchors的k个参考边界框，k是参数化的。**锚点位于滑动窗口的中心，并与一个尺度和长宽比相关**（图3左）。默认情况下，我们使用3个尺度和3个长宽比，在每个滑动位置产生k=9个锚点。对于大小为W×H（通常约为2400）的卷积特征映射，总共有WHk个锚点。\n\n![](/images/faster_f3.PNG)\n\n#### Translation-Invariant Anchors\n\n我们的方法的一个重要特性是它是平移不变的，无论是在锚点还是计算相对于锚点的区域提议的函数。如果在图像中平移目标，提议应该平移，并且同样的函数应该能够在任一位置预测提议。平移不变特性是由我们的方法保证的。作为比较，MultiBox方法[27]使用k-means生成800个锚点，这不是平移不变的。所以如果平移目标，MultiBox不保证会生成相同的提议。\n\n**平移不变特性也减小了模型的大小**。MultiBox有(4+1)×800维的全连接输出层，而我们的方法在k=9个锚点的情况下有(4+2)×9维的卷积输出层。因此，我们的输出层具有 $2.8×10^4$ 个参数（512×(4+2)×9 对于VGG-16），比MultiBox输出层的 $6.1×10^6$ 个参数少了两个数量级（对于MultiBox [27]中的GoogleNet[34]为1536×(4+1)×800）。如果考虑到特征投影层，我们的提议层参数仍然比MultiBox少一个数量级。我们期望我们的方法在PASCAL VOC等小数据集上有更小的过拟合风险。\n\n#### Multi-Scale Anchors as Regression References\n\n我们的锚点设计提出了一个新的方案来解决多尺度（和长宽比）。如图1所示，多尺度预测有两种流行的方法。第一种方法是基于图像/特征金字塔，例如DPM[8]和基于CNN的方法[9]，[1]，[2]中。图像在多个尺度上进行缩放，并且针对每个尺度（图1（a））计算特征映射（HOG[8]或深卷积特征[9]，[1]，[2]）。这种方法通常是有用的，但是非常耗时。第二种方法是在特征映射上使用多尺度（和/或长宽比）的滑动窗口。例如，在DPM[8]中，使用不同的滤波器大小（例如5×7和7×5）分别对不同长宽比的模型进行训练。如果用这种方法来解决多尺度问题，可以把它看作是一个“滤波器金字塔”（图1（b））。第二种方法通常与第一种方法联合采用[8]。\n\n作为比较，**我们的基于锚点方法建立在锚点金字塔上**，这是更具成本效益的。我们的方法 **参照多尺度和长宽比的锚盒来分类和回归边界框**。它只依赖单一尺度的图像和特征映射，并使用单一尺寸的滤波器（特征映射上的滑动窗口）。我们通过实验来展示这个方案解决多尺度和尺寸的效果（表8）。\n\n![](/images/faster_t8.PNG)\n\n由于这种基于锚点的多尺度设计，我们可以简单地使用在单尺度图像上计算的卷积特征，Fast R-CNN检测器也是这样做的[2]。多尺度锚点设计是共享特征的关键组件，不需要额外的成本来处理尺度。\n\n#### Loss Function\n\n为了训练RPN，我们 **为每个锚点分配一个二值类别标签（是目标或不是目标）**。我们给两种锚点分配一个正标签：（i）具有与实际边界框的重叠最高交并比（IoU）的锚点，（ii）具有与实际边界框的重叠超过0.7 IoU的锚点。注意，单个真实边界框可以为多个锚点分配正标签。通常第二个条件足以确定正样本；但我们仍然采用第一个条件，因为在一些极少数情况下，第二个条件可能找不到正样本。对于所有的真实边界框，如果一个锚点的IoU比率低于0.3，我们给这样的锚点分配一个负标签。其他的就分配为非正也非负标签，这样的锚点不会有助于训练目标函数。\n\n根据这些定义，我们对目标函数Fast R-CNN[2]中的多任务损失进行最小化。我们对图像的损失函数定义为：\n\n$$L(\\{p_i\\},\\{t_i\\}) = \\frac{1}{N_{cls}}\\sum_{i}L_{cls}(p_i, p_i^\\star) + \\lambda \\frac{1}{N_{reg}}\\sum_i p_i^\\star L_{reg}(t_i, t_i^\\star) \\tag{1}$$\n\n其中，$i$ 是一个小批量数据中锚点的索引，$p_i$ 是锚点 $i$ 作为目标的预测概率。如果锚点为正，真实标签 $p_i^\\star$ 为1，如果锚点为负，则为0。$t_i$ 是表示预测边界框4个参数化坐标的向量，而 $t_i^\\star$ 是与正锚点相关的真实边界框的向量。分类损失 $L_{cls}$ 是两个类别上（目标或不是目标）的对数损失。对于回归损失，我们使用 $L_{reg}(t_i,t_i^\\star) = R(t_i−t_i^\\star)$，其中 $R$ 是在[2]中定义的鲁棒损失函数（平滑L1）。项 $p_i^\\star L_{reg}$ 表示回归损失仅对于正锚点激活。cls和reg层的输出分别由 $\\{p_i\\}$ 和 $\\{t_i\\}$ 组成。\n\n这两个项用 $N_{cls}$ 和$N_{reg}$ 进行归一化，并由一个平衡参数 $\\lambda$ 加权。在我们目前的实现中（如在发布的代码中），方程（1）中的cls项通过小批量数据（即 $N_{cls}=256$）进行归一化，reg项根据锚点位置的数量（即 $N_{reg} ~= 24000$）进行归一化。默认情况下，我们设置 $\\lambda =10$，因此cls和reg项的权重大致相等。我们通过实验显示，结果对宽范围的 $\\lambda$ 值不敏感(表9)。我们还注意到，上面的归一化不是必需的，可以简化。\n\n对于边界框回归，我们采用[5]中的4个坐标参数化：\n\n$$t_x = \\frac{(x−x_a)}{w_a}, t_y = \\frac{(y − y_a)}{h_a},\\\\ t_w = log(\\frac{w}{w_a}),t_h = log(\\frac{h}{h_a}),\\\\ t_x^\\star =\\frac{(x^\\star − x_a)}{w_a},t_y^\\star = \\frac{(y^\\star − y_a)}{h_a},\\\\ t_w^\\star = log(\\frac{w^\\star}{w_a}), t_h^\\star = log(\\frac{h^\\star}{h_a}),\\tag{2} $$\n\n其中，x，y，w和h表示边界框的中心坐标及其宽和高。变量$x$，$x_a$ 和 $x^\\star$ 分别表示预测边界框，锚盒和实际边界框（类似于y,w,h）。这可以被认为是从锚盒到邻近的实际边界框的回归。\n\n然而，我们的方法通过与之前的基于RoI（感兴趣区域）方法[1]，[2]不同的方式来实现边界框回归。在[1]，[2]中，对任意大小的RoI池化的特征执行边界框回归，并且回归权重由所有区域共享。在我们的公式中，用于回归的特征在特征映射上具有相同的空间大小（3×3）。为了考虑不同的大小，学习一组k个边界框回归器。每个回归器负责一个尺度和一个长宽比，而k个回归器不共享权重。因此，由于锚点的设计，即使特征具有固定的尺度/比例，仍然可以预测各种尺寸的边界框。\n\n#### Training RPNs\n\nRPN可以通过反向传播和随机梯度下降（SGD）进行端对端训练[35]。我们遵循[2]的 **“以图像为中心”的采样策略来训练这个网络**。每个小批量数据都从包含许多正面和负面示例锚点的单张图像中产生。对所有锚点的损失函数进行优化是可能的，但是这样会偏向于负样本，因为它们是占主导地位的。取而代之的是，我们在图像中随机采样256个锚点，计算一个小批量数据的损失函数，其中采样的正锚点和负锚点的比率为1:1。如果图像中的正样本少于128个，我们使用负样本填充小批量数据。\n\n我们通过从标准方差为0.01的零均值高斯分布中提取权重来随机初始化所有新层。所有其他层（即共享卷积层）通过预训练的ImageNet分类模型[36]来初始化，如同标准实践[5]。我们调整ZF网络的所有层，以及VGG网络的conv3_1及其之上的层以节省内存[2]。对于60k的小批量数据，我们使用0.001的学习率，对于PASCAL VOC数据集中的下一个20k小批量数据，使用0.0001。我们使用0.9的动量和0.0005的权重衰减[37]。我们的实现使用Caffe[38]。\n\n### SharingFeatures for RPN and Faster R-CNN\n\n到目前为止，我们已经描述了如何训练用于区域提议生成的网络，没有考虑将利用这些提议来进行目标检测的CNN。对于检测网络，我们采用Fast R-CNN[2]。接下来我们介绍一些算法，学习由RPN和Fast R-CNN组成的具有共享卷积层的统一网络（图2）。\n\n独立训练的RPN和Fast R-CNN将以不同的方式修改它们的卷积层。因此，我们需要开发一种允许在两个网络之间共享卷积层的技术，而不是学习两个独立的网络。我们讨论三个方法来训练具有共享特征的网络：\n\n（一）**交替训练(Alternating training)**。在这个解决方案中，我们首先训练RPN，并使用这些提议来训练Fast R-CNN。由Fast R-CNN微调的网络然后被用于初始化RPN，并且重复这个过程。这是本文所有实验中使用的解决方案。\n\n（二）**近似联合训练(Approximate joint training)**。在这个解决方案中，RPN和Fast R-CNN网络在训练期间合并成一个网络，如图2所示。在每次SGD迭代中，前向传递生成区域提议，在训练Fast R-CNN检测器将这看作是固定的、预计算的提议。反向传播像往常一样进行，其中对于共享层，组合来自RPN损失和Fast R-CNN损失的反向传播信号。这个解决方案很容易实现。但是这个解决方案忽略了关于提议边界框的坐标（也是网络响应）的导数，因此是近似的。在我们的实验中，我们实验发现这个求解器产生了接近的结果，与交替训练相比，训练时间减少了大约25−50%。这个求解器包含在我们发布的Python代码中。\n\n（三）**非近似的联合训练(Non-approximate joint training)**。如上所述，由RPN预测的边界框也是输入的函数。Fast R-CNN中的RoI池化层[2]接受卷积特征以及预测的边界框作为输入，所以理论上有效的反向传播求解器也应该包括关于边界框坐标的梯度。在上述近似联合训练中，这些梯度被忽略。在一个非近似的联合训练解决方案中，我们需要一个关于边界框坐标可微分的RoI池化层。这是一个重要的问题，可以通过[15]中提出的“RoI wraping”层给出解决方案，这超出了本文的范围。\n\n**四步交替训练(4-Step Alternating Training)**。在本文中，我们采用实用的四步训练算法，通过交替优化学习共享特征。在第一步中，我们按照3.1.3节的描述训练RPN。该网络使用ImageNet的预训练模型进行初始化，并针对区域提议任务进行了端到端的微调。在第二步中，我们使用由第一步RPN生成的提议，由Fast R-CNN训练单独的检测网络。该检测网络也由ImageNet的预训练模型进行初始化。此时两个网络不共享卷积层。在第三步中，我们使用检测器网络来初始化RPN训练，但是我们固定共享的卷积层，并且只对RPN特有的层进行微调。现在这两个网络共享卷积层。最后，保持共享卷积层的固定，我们对Fast R-CNN的独有层进行微调。因此，两个网络共享相同的卷积层并形成统一的网络。类似的交替训练可以迭代更多次，但是我们只观察到微小的改进。\n\n### Implementation Details\n\n我们在单尺度图像上训练和测试区域提议和目标检测网络[1]，[2]。我们重新缩放图像，使得它们的短边是s=600像素[2]。多尺度特征提取（使用图像金字塔）可能会提高精度，但不会表现出速度与精度的良好折衷[2]。在重新缩放的图像上，最后卷积层上的ZF和VGG网络的总步长为16个像素，因此在调整大小（〜500×375）之前，典型的PASCAL图像上的总步长为〜10个像素。即使如此大的步长也能提供良好的效果，尽管步幅更小，精度可能会进一步提高。\n\n对于锚点，我们使用了3个尺度，边界框面积分别为 $128^2$，$256^2$ 和 $512^2$ 个像素，以及$1:1$，$1:2$和$2:1$的长宽比。这些超参数不是针对特定数据集仔细选择的，我们将在下一节中提供有关其作用的消融实验。如上所述，我们的解决方案不需要图像金字塔或滤波器金字塔来预测多个尺度的区域，节省了大量的运行时间。图3（右）显示了我们的方法在广泛的尺度和长宽比方面的能力。表1显示了使用ZF网络的每个锚点学习到的平均提议大小。我们注意到，我们的算法允许预测比潜在接受域更大的区域。这样的预测不是不可能的——如果只有目标的中间部分是可见的，那么仍然可以粗略地推断出目标的范围。\n\n![](/images/faster_t1.PNG)\n\n跨越图像边界的锚盒需要小心处理。在训练过程中，我们忽略了所有的跨界锚点，所以不会造成损失。对于一个典型的1000×600的图片，总共将会有大约20000（≈60×40×9）个锚点。跨界锚点被忽略，每张图像约有6000个锚点用于训练。如果跨界异常值在训练中不被忽略，则会在目标函数中引入大的，难以纠正的误差项，且训练不会收敛。但在测试过程中，我们仍然将全卷积RPN应用于整张图像。这可能会产生跨边界的提议边界框，我们剪切到图像边界。\n\n一些RPN提议互相之间高度重叠。为了减少冗余，我们在提议区域根据他们的cls分数采取非极大值抑制（NMS）。我们将NMS的IoU阈值固定为0.7，这就给每张图像留下了大约2000个提议区域。正如我们将要展示的那样，NMS不会损害最终的检测准确性，但会大大减少提议的数量。在NMS之后，我们使用前N个提议区域来进行检测。接下来，我们使用2000个RPN提议对Fast R-CNN进行训练，但在测试时评估不同数量的提议。\n","source":"_posts/Faster-R-CNN-Towards-Real-Time-Object-Dectection-with-Region-Proposal-Networks.md","raw":"---\ntitle: Faster R-CNN:Towards Real-Time Object Dectection with Region Proposal Networks\ndate: 2018-09-26 16:13:20\ntags: FasterR-CNN\ncategories: 深度学习\nmathjax: true\n---\n## 摘要\n\n最先进的目标检测网络依赖region proposal算法来假设目标的位置。SPPnet[1]和Fast R-CNN[2]等研究已经减少了这些检测网络的运行时间，同时暴露出region proposal计算成为一个瓶颈。在这项工作中，我们引入了一个 **region proposal network(RPN)**，**该网络与检测网络共享全图像的卷积特征**，从而使近乎零成本的region proposal成为可能。**RPN是一个全卷积网络，可以同时在每个位置预测目标边界和目标的得分**。RPN经过端到端的训练来生成高质量的region proposal，进而由Fast R-CNN进行检测。我们 **将RPN和Fast R-CNN通过共享卷积特征进一步合并为一个单一的网络** ——使用最近流行的具有“注意力”机制的神经网络术语，RPN组件告诉统一的网络在哪里寻找。对于非常深的VGG-16模型[3]，我们的检测系统在GPU上的帧率为5fps（包括所有步骤），同时在PASCAL VOC 2007，2012和MS COCO数据集上实现了目前最优的目标检测精度，每个图像只有300个proposals。在ILSVRC和COCO 2015竞赛中，Faster R-CNN和RPN是多个比赛中获得第一名的基础。代码可公开获得。\n\n索引词--对象检测，region proposal, 卷积神经网络\n\n## 简介\n\nregion proposal 方法[4]和基于区域的卷积神经网络(R-CNNs)[5]的成功给目标检测带来了最新的进展。尽管在[5]中最初开发的基于区域的CNN计算成本很高，但是由于在各种proposal中共享卷积，其成本已经大大降低了[1]，[2]。忽略花费在region proposal上的时间，最新版本Fast R-CNN[2]利用非常深的网络[3]实现了接近实时的速率(当忽略region proposal的时间花费)。现在，proposals是最新的检测系统中测试时间的计算瓶颈。\n\nregion proposal方法通常依赖廉价的特征和经济的推断方案。选择性搜索(Selective Search)[4]是最流行的方法之一，它贪婪地合并基于工程的低级特征的超像素。然而，与有效的检测网络[2]相比，选择性搜索速度慢了一个数量级，在CPU实现中每张图像的时间为2秒。EdgeBoxes[6]目前提供了在proposal质量和速度之间的最佳权衡，每张图像0.2秒。尽管如此，region proposal步骤仍然像检测网络那样消耗同样多的运行时间。\n\n有人可能会注意到，基于区域的快速CNN利用GPU，而在研究中使用的region proposal方法在CPU上实现，使得运行时间的比较不公平。加速region proposal计算的一个显而易见的方法是将其在GPU上重新实现。这可能是一个有效的工程解决方案，但重新实现忽略了下游检测网络，因此错过了共享计算的重要机会。\n\n在本文中，我们对算法做了一点改变——用深度卷积神经网络计算proposals——带来了一个优雅而且有效的解决方案，其中在给定检测网络计算的情况下proposal计算几乎零成本。为此，我们引入了新的RPNs，它们共享最先进的目标检测网络的卷积层[1]，[2]。通过在测试时共享卷积，计算region proposal的边际成本很小（例如，每张图像10ms）。\n\n我们的观察到基于区域的检测器所使用的卷积特征映射，如Fast R-CNN，也可以用于生成region proposal。在这些卷积特征之上，我们通过添加一些额外的卷积层来构建RPN，这些卷积层同时在规则网格上的每个位置上regress区域边界和目标分数。因此RPN是一种全卷积网络（FCN）[7]，可以针对生成检测区域推荐的任务进行端到端的训练。\n\n![](/images/faster_f1.PNG)\n\n**RPN旨在有效预测具有广泛尺度和长宽比的region proposal**。与使用图像金字塔（图1，a）或滤波器金字塔（图1，b）的流行方法[8]，[9]，[1]相比，我们引入新的“**anchor**”盒作为多种尺度和长宽比的参考。我们的方案可以被认为是回归参考金字塔（图1，c），它避免了枚举多种尺度或长宽比的图像或滤波器。这个模型在使用单尺度图像进行训练和测试时表现很好，从而有利于运行速度的提高。\n\n为了将RPN与Fast R-CNN [2]目标检测网络相结合，我们提出了一种训练方案，**在微调region proposal任务和微调目标检测之间进行交替，同时保持the proposals的固定**。该方案快速收敛，并产生两个任务之间共享卷积特征的统一网络。\n\n我们在PASCAL VOC检测基准数据集上[11]综合评估了我们的方法，其中具有Fast R-CNN的RPN产生的检测精度优于使用强基准选择性搜索的Fast R-CNN。同时，我们的方法在测试时几乎免除了选择性搜索的所有计算负担——proposal的有效运行时间仅为10毫秒。使用昂贵的非常深的模型[3]，我们的检测方法在GPU上仍然具有5fps的帧率（包括所有步骤），因此在速度和准确性方面是实用的目标检测系统。我们还报告了在MS COCO数据集上[12]的结果，并使用COCO数据研究了在PASCAL VOC上的改进。代码可公开获得https://github.com/shaoqingren/faster_rcnn（MATLAB）和https://github.com/rbgirshick/py-faster-rcnn（Python）。\n\n这个手稿的初步版本是以前发表的[10]。从那时起，RPN和Faster R-CNN的框架已经被采用并推广到其他方法，如3D目标检测[13]，基于部件的检测[14]，实例分割[15]和图像标题[16]。我们快速和有效的目标检测系统也已经在Pinterest[17]的商业系统中建立了，并报告了用户参与度的提高。\n\n在ILSVRC和COCO 2015竞赛中，Faster R-CNN和RPN是ImageNet检测，ImageNet定位，COCO检测和COCO分割中几个第一名参赛者[18]的基础。RPN完全从数据中学习提议区域，因此可以从更深入和更具表达性的特征（例如[18]中采用的101层残差网络）中轻松获益。Faster R-CNN和RPN也被这些比赛中的其他几个主要参赛者所使用。这些结果表明，我们的方法不仅是一个实用合算的解决方案，而且是一个提高目标检测精度的有效方法。\n\n## 相关工作\n\n**Object Proposal**。Object Proposal方法方面有大量的文献。目标提议方法的综合调查和比较可以在[19]，[20]，[21]中找到。广泛使用的目标提议方法包括基于超像素分组（例如，选择性搜索[4]，CPMC[22]，MCG[23]）和那些基于滑动窗口的方法（例如窗口中的目标[24]，EdgeBoxes[6]）。目标提议方法被采用为独立于检测器（例如，选择性搜索[4]目标检测器，R-CNN[5]和Fast R-CNN[2]）的外部模块。\n\n**Deep Network for Object Dection**。R-CNN方法[5]端到端地对CNN进行训练，将提议区域分类为目标类别或背景。R-CNN主要作为分类器，它不预测目标边界（除了通过边界框回归进行细化）。其准确度取决于区域提议模块的性能（参见[20]中的比较）。一些论文提出了使用深度网络来预测目标边界框的方法[25]，[9]，[26]，[27]。在OverFeat方法[9]中，训练一个全连接层来预测单个目标定位任务的边界框坐标。然后将全连接层变成卷积层，用于检测多个类别的目标。MultiBox方法[26]，[27]从网络中生成区域提议，该网络最后的全连接层同时预测多个类别不可知的边界框，并推广到OverFeat的“single-box”方式。这些类别不可知的边界框被用作R-CNN的提议区域[5]。与我们的全卷积方案相比，MultiBox提议网络适用于单张裁剪图像或多张大型裁剪图像（例如224×224）。MultiBox在提议区域和检测网络之间不共享特征。稍后在我们的方法上下文中会讨论OverFeat和MultiBox。与我们的工作同时进行的，DeepMask方法[28]是为学习分割提议区域而开发的。\n\n卷积[9]，[1]，[29]，[7]，[2]的共享计算已经越来越受到人们的关注，因为它可以有效而准确地进行视觉识别。OverFeat论文[9]计算图像金字塔的卷积特征用于分类，定位和检测。共享卷积特征映射的自适应大小池化（SPP）[1]被开发用于有效的基于区域的目标检测[1]，[30]和语义分割[29]。Fast R-CNN[2]能够对共享卷积特征进行端到端的检测器训练，并显示出令人叹服的准确性和速度。\n\n## FASTER R-CNN\n\n我们的目标检测系统，称为 **Faster R-CNN** ，由两个模块组成。第一个模块是 **proposal regions的深度全卷积网络**，第二个模块是 **使用提议区域的Fast R-CNN检测器**[2]。整个系统是一个单个的，统一的目标检测网络（图2）。使用最近流行的“注意力”[31]机制的神经网络术语，**RPN模块告诉Fast R-CNN模块在哪里寻找**。在第3.1节中，我们介绍了区域提议网络的设计和属性。在第3.2节中，我们开发了用于训练具有共享特征模块的算法。\n\n![](/images/faster_f2.PNG)\n\n### Region Proposal Networks\n\n区域提议网络（RPN）**以任意大小的图像作为输入，输出一组矩形的目标提议，每个提议都有一个目标得分**。我们用全卷积网络[7]对这个过程进行建模，我们将在本节进行描述。因为我们的最终目标是与Fast R-CNN目标检测网络[2]共享计算，所以我们假设两个网络共享一组共同的卷积层。在我们的实验中，我们研究了具有5个共享卷积层的Zeiler和Fergus模型[32]（ZF）和具有13个共享卷积层的Simonyan和Zisserman模型[3]（VGG-16）。\n\n为了生成区域提议，我们 **在最后的共享卷积层输出的卷积特征映射上滑动一个小网络**。这个小网络将输入卷积特征映射的 $n×n$ 空间窗口作为输入。每个滑动窗口映射到一个低维特征（ZF为256维，VGG为512维，后面是ReLU[33]）。**这个特征被输入到两个子全连接层——一个边界框回归层（reg）和一个边界框分类层（cls）**。在本文中，我们使用n=3，注意输入图像上的有效接受域是大的（ZF和VGG分别为171和228个像素）。图3（左）显示了这个小型网络的一个位置。请注意，因为小网络以滑动窗口方式运行，所有空间位置共享全连接层。这种架构通过一个 $n×n$ 卷积层，后面是两个子1×1卷积层（分别用于reg和cls）自然地实现。\n\n#### Anchors\n\n在每个滑动窗口位置，我们同时预测多个区域提议，其中每个位置可能提议的最大数目定义为k。因此，reg层具有4k个输出，分别编码k个边界框的坐标，cls层输出2k个分数，估计每个提议是目标或不是目标的概率。相对于我们称之为Anchors的k个参考边界框，k是参数化的。**锚点位于滑动窗口的中心，并与一个尺度和长宽比相关**（图3左）。默认情况下，我们使用3个尺度和3个长宽比，在每个滑动位置产生k=9个锚点。对于大小为W×H（通常约为2400）的卷积特征映射，总共有WHk个锚点。\n\n![](/images/faster_f3.PNG)\n\n#### Translation-Invariant Anchors\n\n我们的方法的一个重要特性是它是平移不变的，无论是在锚点还是计算相对于锚点的区域提议的函数。如果在图像中平移目标，提议应该平移，并且同样的函数应该能够在任一位置预测提议。平移不变特性是由我们的方法保证的。作为比较，MultiBox方法[27]使用k-means生成800个锚点，这不是平移不变的。所以如果平移目标，MultiBox不保证会生成相同的提议。\n\n**平移不变特性也减小了模型的大小**。MultiBox有(4+1)×800维的全连接输出层，而我们的方法在k=9个锚点的情况下有(4+2)×9维的卷积输出层。因此，我们的输出层具有 $2.8×10^4$ 个参数（512×(4+2)×9 对于VGG-16），比MultiBox输出层的 $6.1×10^6$ 个参数少了两个数量级（对于MultiBox [27]中的GoogleNet[34]为1536×(4+1)×800）。如果考虑到特征投影层，我们的提议层参数仍然比MultiBox少一个数量级。我们期望我们的方法在PASCAL VOC等小数据集上有更小的过拟合风险。\n\n#### Multi-Scale Anchors as Regression References\n\n我们的锚点设计提出了一个新的方案来解决多尺度（和长宽比）。如图1所示，多尺度预测有两种流行的方法。第一种方法是基于图像/特征金字塔，例如DPM[8]和基于CNN的方法[9]，[1]，[2]中。图像在多个尺度上进行缩放，并且针对每个尺度（图1（a））计算特征映射（HOG[8]或深卷积特征[9]，[1]，[2]）。这种方法通常是有用的，但是非常耗时。第二种方法是在特征映射上使用多尺度（和/或长宽比）的滑动窗口。例如，在DPM[8]中，使用不同的滤波器大小（例如5×7和7×5）分别对不同长宽比的模型进行训练。如果用这种方法来解决多尺度问题，可以把它看作是一个“滤波器金字塔”（图1（b））。第二种方法通常与第一种方法联合采用[8]。\n\n作为比较，**我们的基于锚点方法建立在锚点金字塔上**，这是更具成本效益的。我们的方法 **参照多尺度和长宽比的锚盒来分类和回归边界框**。它只依赖单一尺度的图像和特征映射，并使用单一尺寸的滤波器（特征映射上的滑动窗口）。我们通过实验来展示这个方案解决多尺度和尺寸的效果（表8）。\n\n![](/images/faster_t8.PNG)\n\n由于这种基于锚点的多尺度设计，我们可以简单地使用在单尺度图像上计算的卷积特征，Fast R-CNN检测器也是这样做的[2]。多尺度锚点设计是共享特征的关键组件，不需要额外的成本来处理尺度。\n\n#### Loss Function\n\n为了训练RPN，我们 **为每个锚点分配一个二值类别标签（是目标或不是目标）**。我们给两种锚点分配一个正标签：（i）具有与实际边界框的重叠最高交并比（IoU）的锚点，（ii）具有与实际边界框的重叠超过0.7 IoU的锚点。注意，单个真实边界框可以为多个锚点分配正标签。通常第二个条件足以确定正样本；但我们仍然采用第一个条件，因为在一些极少数情况下，第二个条件可能找不到正样本。对于所有的真实边界框，如果一个锚点的IoU比率低于0.3，我们给这样的锚点分配一个负标签。其他的就分配为非正也非负标签，这样的锚点不会有助于训练目标函数。\n\n根据这些定义，我们对目标函数Fast R-CNN[2]中的多任务损失进行最小化。我们对图像的损失函数定义为：\n\n$$L(\\{p_i\\},\\{t_i\\}) = \\frac{1}{N_{cls}}\\sum_{i}L_{cls}(p_i, p_i^\\star) + \\lambda \\frac{1}{N_{reg}}\\sum_i p_i^\\star L_{reg}(t_i, t_i^\\star) \\tag{1}$$\n\n其中，$i$ 是一个小批量数据中锚点的索引，$p_i$ 是锚点 $i$ 作为目标的预测概率。如果锚点为正，真实标签 $p_i^\\star$ 为1，如果锚点为负，则为0。$t_i$ 是表示预测边界框4个参数化坐标的向量，而 $t_i^\\star$ 是与正锚点相关的真实边界框的向量。分类损失 $L_{cls}$ 是两个类别上（目标或不是目标）的对数损失。对于回归损失，我们使用 $L_{reg}(t_i,t_i^\\star) = R(t_i−t_i^\\star)$，其中 $R$ 是在[2]中定义的鲁棒损失函数（平滑L1）。项 $p_i^\\star L_{reg}$ 表示回归损失仅对于正锚点激活。cls和reg层的输出分别由 $\\{p_i\\}$ 和 $\\{t_i\\}$ 组成。\n\n这两个项用 $N_{cls}$ 和$N_{reg}$ 进行归一化，并由一个平衡参数 $\\lambda$ 加权。在我们目前的实现中（如在发布的代码中），方程（1）中的cls项通过小批量数据（即 $N_{cls}=256$）进行归一化，reg项根据锚点位置的数量（即 $N_{reg} ~= 24000$）进行归一化。默认情况下，我们设置 $\\lambda =10$，因此cls和reg项的权重大致相等。我们通过实验显示，结果对宽范围的 $\\lambda$ 值不敏感(表9)。我们还注意到，上面的归一化不是必需的，可以简化。\n\n对于边界框回归，我们采用[5]中的4个坐标参数化：\n\n$$t_x = \\frac{(x−x_a)}{w_a}, t_y = \\frac{(y − y_a)}{h_a},\\\\ t_w = log(\\frac{w}{w_a}),t_h = log(\\frac{h}{h_a}),\\\\ t_x^\\star =\\frac{(x^\\star − x_a)}{w_a},t_y^\\star = \\frac{(y^\\star − y_a)}{h_a},\\\\ t_w^\\star = log(\\frac{w^\\star}{w_a}), t_h^\\star = log(\\frac{h^\\star}{h_a}),\\tag{2} $$\n\n其中，x，y，w和h表示边界框的中心坐标及其宽和高。变量$x$，$x_a$ 和 $x^\\star$ 分别表示预测边界框，锚盒和实际边界框（类似于y,w,h）。这可以被认为是从锚盒到邻近的实际边界框的回归。\n\n然而，我们的方法通过与之前的基于RoI（感兴趣区域）方法[1]，[2]不同的方式来实现边界框回归。在[1]，[2]中，对任意大小的RoI池化的特征执行边界框回归，并且回归权重由所有区域共享。在我们的公式中，用于回归的特征在特征映射上具有相同的空间大小（3×3）。为了考虑不同的大小，学习一组k个边界框回归器。每个回归器负责一个尺度和一个长宽比，而k个回归器不共享权重。因此，由于锚点的设计，即使特征具有固定的尺度/比例，仍然可以预测各种尺寸的边界框。\n\n#### Training RPNs\n\nRPN可以通过反向传播和随机梯度下降（SGD）进行端对端训练[35]。我们遵循[2]的 **“以图像为中心”的采样策略来训练这个网络**。每个小批量数据都从包含许多正面和负面示例锚点的单张图像中产生。对所有锚点的损失函数进行优化是可能的，但是这样会偏向于负样本，因为它们是占主导地位的。取而代之的是，我们在图像中随机采样256个锚点，计算一个小批量数据的损失函数，其中采样的正锚点和负锚点的比率为1:1。如果图像中的正样本少于128个，我们使用负样本填充小批量数据。\n\n我们通过从标准方差为0.01的零均值高斯分布中提取权重来随机初始化所有新层。所有其他层（即共享卷积层）通过预训练的ImageNet分类模型[36]来初始化，如同标准实践[5]。我们调整ZF网络的所有层，以及VGG网络的conv3_1及其之上的层以节省内存[2]。对于60k的小批量数据，我们使用0.001的学习率，对于PASCAL VOC数据集中的下一个20k小批量数据，使用0.0001。我们使用0.9的动量和0.0005的权重衰减[37]。我们的实现使用Caffe[38]。\n\n### SharingFeatures for RPN and Faster R-CNN\n\n到目前为止，我们已经描述了如何训练用于区域提议生成的网络，没有考虑将利用这些提议来进行目标检测的CNN。对于检测网络，我们采用Fast R-CNN[2]。接下来我们介绍一些算法，学习由RPN和Fast R-CNN组成的具有共享卷积层的统一网络（图2）。\n\n独立训练的RPN和Fast R-CNN将以不同的方式修改它们的卷积层。因此，我们需要开发一种允许在两个网络之间共享卷积层的技术，而不是学习两个独立的网络。我们讨论三个方法来训练具有共享特征的网络：\n\n（一）**交替训练(Alternating training)**。在这个解决方案中，我们首先训练RPN，并使用这些提议来训练Fast R-CNN。由Fast R-CNN微调的网络然后被用于初始化RPN，并且重复这个过程。这是本文所有实验中使用的解决方案。\n\n（二）**近似联合训练(Approximate joint training)**。在这个解决方案中，RPN和Fast R-CNN网络在训练期间合并成一个网络，如图2所示。在每次SGD迭代中，前向传递生成区域提议，在训练Fast R-CNN检测器将这看作是固定的、预计算的提议。反向传播像往常一样进行，其中对于共享层，组合来自RPN损失和Fast R-CNN损失的反向传播信号。这个解决方案很容易实现。但是这个解决方案忽略了关于提议边界框的坐标（也是网络响应）的导数，因此是近似的。在我们的实验中，我们实验发现这个求解器产生了接近的结果，与交替训练相比，训练时间减少了大约25−50%。这个求解器包含在我们发布的Python代码中。\n\n（三）**非近似的联合训练(Non-approximate joint training)**。如上所述，由RPN预测的边界框也是输入的函数。Fast R-CNN中的RoI池化层[2]接受卷积特征以及预测的边界框作为输入，所以理论上有效的反向传播求解器也应该包括关于边界框坐标的梯度。在上述近似联合训练中，这些梯度被忽略。在一个非近似的联合训练解决方案中，我们需要一个关于边界框坐标可微分的RoI池化层。这是一个重要的问题，可以通过[15]中提出的“RoI wraping”层给出解决方案，这超出了本文的范围。\n\n**四步交替训练(4-Step Alternating Training)**。在本文中，我们采用实用的四步训练算法，通过交替优化学习共享特征。在第一步中，我们按照3.1.3节的描述训练RPN。该网络使用ImageNet的预训练模型进行初始化，并针对区域提议任务进行了端到端的微调。在第二步中，我们使用由第一步RPN生成的提议，由Fast R-CNN训练单独的检测网络。该检测网络也由ImageNet的预训练模型进行初始化。此时两个网络不共享卷积层。在第三步中，我们使用检测器网络来初始化RPN训练，但是我们固定共享的卷积层，并且只对RPN特有的层进行微调。现在这两个网络共享卷积层。最后，保持共享卷积层的固定，我们对Fast R-CNN的独有层进行微调。因此，两个网络共享相同的卷积层并形成统一的网络。类似的交替训练可以迭代更多次，但是我们只观察到微小的改进。\n\n### Implementation Details\n\n我们在单尺度图像上训练和测试区域提议和目标检测网络[1]，[2]。我们重新缩放图像，使得它们的短边是s=600像素[2]。多尺度特征提取（使用图像金字塔）可能会提高精度，但不会表现出速度与精度的良好折衷[2]。在重新缩放的图像上，最后卷积层上的ZF和VGG网络的总步长为16个像素，因此在调整大小（〜500×375）之前，典型的PASCAL图像上的总步长为〜10个像素。即使如此大的步长也能提供良好的效果，尽管步幅更小，精度可能会进一步提高。\n\n对于锚点，我们使用了3个尺度，边界框面积分别为 $128^2$，$256^2$ 和 $512^2$ 个像素，以及$1:1$，$1:2$和$2:1$的长宽比。这些超参数不是针对特定数据集仔细选择的，我们将在下一节中提供有关其作用的消融实验。如上所述，我们的解决方案不需要图像金字塔或滤波器金字塔来预测多个尺度的区域，节省了大量的运行时间。图3（右）显示了我们的方法在广泛的尺度和长宽比方面的能力。表1显示了使用ZF网络的每个锚点学习到的平均提议大小。我们注意到，我们的算法允许预测比潜在接受域更大的区域。这样的预测不是不可能的——如果只有目标的中间部分是可见的，那么仍然可以粗略地推断出目标的范围。\n\n![](/images/faster_t1.PNG)\n\n跨越图像边界的锚盒需要小心处理。在训练过程中，我们忽略了所有的跨界锚点，所以不会造成损失。对于一个典型的1000×600的图片，总共将会有大约20000（≈60×40×9）个锚点。跨界锚点被忽略，每张图像约有6000个锚点用于训练。如果跨界异常值在训练中不被忽略，则会在目标函数中引入大的，难以纠正的误差项，且训练不会收敛。但在测试过程中，我们仍然将全卷积RPN应用于整张图像。这可能会产生跨边界的提议边界框，我们剪切到图像边界。\n\n一些RPN提议互相之间高度重叠。为了减少冗余，我们在提议区域根据他们的cls分数采取非极大值抑制（NMS）。我们将NMS的IoU阈值固定为0.7，这就给每张图像留下了大约2000个提议区域。正如我们将要展示的那样，NMS不会损害最终的检测准确性，但会大大减少提议的数量。在NMS之后，我们使用前N个提议区域来进行检测。接下来，我们使用2000个RPN提议对Fast R-CNN进行训练，但在测试时评估不同数量的提议。\n","slug":"Faster-R-CNN-Towards-Real-Time-Object-Dectection-with-Region-Proposal-Networks","published":1,"updated":"2018-09-28T09:57:26.495Z","_id":"cjmk9ds1l0007pcvoyxj1g1d4","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><p>最先进的目标检测网络依赖region proposal算法来假设目标的位置。SPPnet[1]和Fast R-CNN[2]等研究已经减少了这些检测网络的运行时间，同时暴露出region proposal计算成为一个瓶颈。在这项工作中，我们引入了一个 <strong>region proposal network(RPN)</strong>，<strong>该网络与检测网络共享全图像的卷积特征</strong>，从而使近乎零成本的region proposal成为可能。<strong>RPN是一个全卷积网络，可以同时在每个位置预测目标边界和目标的得分</strong>。RPN经过端到端的训练来生成高质量的region proposal，进而由Fast R-CNN进行检测。我们 <strong>将RPN和Fast R-CNN通过共享卷积特征进一步合并为一个单一的网络</strong> ——使用最近流行的具有“注意力”机制的神经网络术语，RPN组件告诉统一的网络在哪里寻找。对于非常深的VGG-16模型[3]，我们的检测系统在GPU上的帧率为5fps（包括所有步骤），同时在PASCAL VOC 2007，2012和MS COCO数据集上实现了目前最优的目标检测精度，每个图像只有300个proposals。在ILSVRC和COCO 2015竞赛中，Faster R-CNN和RPN是多个比赛中获得第一名的基础。代码可公开获得。</p>\n<p>索引词–对象检测，region proposal, 卷积神经网络</p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>region proposal 方法[4]和基于区域的卷积神经网络(R-CNNs)[5]的成功给目标检测带来了最新的进展。尽管在[5]中最初开发的基于区域的CNN计算成本很高，但是由于在各种proposal中共享卷积，其成本已经大大降低了[1]，[2]。忽略花费在region proposal上的时间，最新版本Fast R-CNN[2]利用非常深的网络[3]实现了接近实时的速率(当忽略region proposal的时间花费)。现在，proposals是最新的检测系统中测试时间的计算瓶颈。</p>\n<p>region proposal方法通常依赖廉价的特征和经济的推断方案。选择性搜索(Selective Search)[4]是最流行的方法之一，它贪婪地合并基于工程的低级特征的超像素。然而，与有效的检测网络[2]相比，选择性搜索速度慢了一个数量级，在CPU实现中每张图像的时间为2秒。EdgeBoxes[6]目前提供了在proposal质量和速度之间的最佳权衡，每张图像0.2秒。尽管如此，region proposal步骤仍然像检测网络那样消耗同样多的运行时间。</p>\n<p>有人可能会注意到，基于区域的快速CNN利用GPU，而在研究中使用的region proposal方法在CPU上实现，使得运行时间的比较不公平。加速region proposal计算的一个显而易见的方法是将其在GPU上重新实现。这可能是一个有效的工程解决方案，但重新实现忽略了下游检测网络，因此错过了共享计算的重要机会。</p>\n<p>在本文中，我们对算法做了一点改变——用深度卷积神经网络计算proposals——带来了一个优雅而且有效的解决方案，其中在给定检测网络计算的情况下proposal计算几乎零成本。为此，我们引入了新的RPNs，它们共享最先进的目标检测网络的卷积层[1]，[2]。通过在测试时共享卷积，计算region proposal的边际成本很小（例如，每张图像10ms）。</p>\n<p>我们的观察到基于区域的检测器所使用的卷积特征映射，如Fast R-CNN，也可以用于生成region proposal。在这些卷积特征之上，我们通过添加一些额外的卷积层来构建RPN，这些卷积层同时在规则网格上的每个位置上regress区域边界和目标分数。因此RPN是一种全卷积网络（FCN）[7]，可以针对生成检测区域推荐的任务进行端到端的训练。</p>\n<p><img src=\"/images/faster_f1.PNG\" alt=\"\"></p>\n<p><strong>RPN旨在有效预测具有广泛尺度和长宽比的region proposal</strong>。与使用图像金字塔（图1，a）或滤波器金字塔（图1，b）的流行方法[8]，[9]，[1]相比，我们引入新的“<strong>anchor</strong>”盒作为多种尺度和长宽比的参考。我们的方案可以被认为是回归参考金字塔（图1，c），它避免了枚举多种尺度或长宽比的图像或滤波器。这个模型在使用单尺度图像进行训练和测试时表现很好，从而有利于运行速度的提高。</p>\n<p>为了将RPN与Fast R-CNN [2]目标检测网络相结合，我们提出了一种训练方案，<strong>在微调region proposal任务和微调目标检测之间进行交替，同时保持the proposals的固定</strong>。该方案快速收敛，并产生两个任务之间共享卷积特征的统一网络。</p>\n<p>我们在PASCAL VOC检测基准数据集上[11]综合评估了我们的方法，其中具有Fast R-CNN的RPN产生的检测精度优于使用强基准选择性搜索的Fast R-CNN。同时，我们的方法在测试时几乎免除了选择性搜索的所有计算负担——proposal的有效运行时间仅为10毫秒。使用昂贵的非常深的模型[3]，我们的检测方法在GPU上仍然具有5fps的帧率（包括所有步骤），因此在速度和准确性方面是实用的目标检测系统。我们还报告了在MS COCO数据集上[12]的结果，并使用COCO数据研究了在PASCAL VOC上的改进。代码可公开获得<a href=\"https://github.com/shaoqingren/faster_rcnn（MATLAB）和https://github.com/rbgirshick/py-faster-rcnn（Python）。\" target=\"_blank\" rel=\"noopener\">https://github.com/shaoqingren/faster_rcnn（MATLAB）和https://github.com/rbgirshick/py-faster-rcnn（Python）。</a></p>\n<p>这个手稿的初步版本是以前发表的[10]。从那时起，RPN和Faster R-CNN的框架已经被采用并推广到其他方法，如3D目标检测[13]，基于部件的检测[14]，实例分割[15]和图像标题[16]。我们快速和有效的目标检测系统也已经在Pinterest[17]的商业系统中建立了，并报告了用户参与度的提高。</p>\n<p>在ILSVRC和COCO 2015竞赛中，Faster R-CNN和RPN是ImageNet检测，ImageNet定位，COCO检测和COCO分割中几个第一名参赛者[18]的基础。RPN完全从数据中学习提议区域，因此可以从更深入和更具表达性的特征（例如[18]中采用的101层残差网络）中轻松获益。Faster R-CNN和RPN也被这些比赛中的其他几个主要参赛者所使用。这些结果表明，我们的方法不仅是一个实用合算的解决方案，而且是一个提高目标检测精度的有效方法。</p>\n<h2 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h2><p><strong>Object Proposal</strong>。Object Proposal方法方面有大量的文献。目标提议方法的综合调查和比较可以在[19]，[20]，[21]中找到。广泛使用的目标提议方法包括基于超像素分组（例如，选择性搜索[4]，CPMC[22]，MCG[23]）和那些基于滑动窗口的方法（例如窗口中的目标[24]，EdgeBoxes[6]）。目标提议方法被采用为独立于检测器（例如，选择性搜索[4]目标检测器，R-CNN[5]和Fast R-CNN[2]）的外部模块。</p>\n<p><strong>Deep Network for Object Dection</strong>。R-CNN方法[5]端到端地对CNN进行训练，将提议区域分类为目标类别或背景。R-CNN主要作为分类器，它不预测目标边界（除了通过边界框回归进行细化）。其准确度取决于区域提议模块的性能（参见[20]中的比较）。一些论文提出了使用深度网络来预测目标边界框的方法[25]，[9]，[26]，[27]。在OverFeat方法[9]中，训练一个全连接层来预测单个目标定位任务的边界框坐标。然后将全连接层变成卷积层，用于检测多个类别的目标。MultiBox方法[26]，[27]从网络中生成区域提议，该网络最后的全连接层同时预测多个类别不可知的边界框，并推广到OverFeat的“single-box”方式。这些类别不可知的边界框被用作R-CNN的提议区域[5]。与我们的全卷积方案相比，MultiBox提议网络适用于单张裁剪图像或多张大型裁剪图像（例如224×224）。MultiBox在提议区域和检测网络之间不共享特征。稍后在我们的方法上下文中会讨论OverFeat和MultiBox。与我们的工作同时进行的，DeepMask方法[28]是为学习分割提议区域而开发的。</p>\n<p>卷积[9]，[1]，[29]，[7]，[2]的共享计算已经越来越受到人们的关注，因为它可以有效而准确地进行视觉识别。OverFeat论文[9]计算图像金字塔的卷积特征用于分类，定位和检测。共享卷积特征映射的自适应大小池化（SPP）[1]被开发用于有效的基于区域的目标检测[1]，[30]和语义分割[29]。Fast R-CNN[2]能够对共享卷积特征进行端到端的检测器训练，并显示出令人叹服的准确性和速度。</p>\n<h2 id=\"FASTER-R-CNN\"><a href=\"#FASTER-R-CNN\" class=\"headerlink\" title=\"FASTER R-CNN\"></a>FASTER R-CNN</h2><p>我们的目标检测系统，称为 <strong>Faster R-CNN</strong> ，由两个模块组成。第一个模块是 <strong>proposal regions的深度全卷积网络</strong>，第二个模块是 <strong>使用提议区域的Fast R-CNN检测器</strong>[2]。整个系统是一个单个的，统一的目标检测网络（图2）。使用最近流行的“注意力”[31]机制的神经网络术语，<strong>RPN模块告诉Fast R-CNN模块在哪里寻找</strong>。在第3.1节中，我们介绍了区域提议网络的设计和属性。在第3.2节中，我们开发了用于训练具有共享特征模块的算法。</p>\n<p><img src=\"/images/faster_f2.PNG\" alt=\"\"></p>\n<h3 id=\"Region-Proposal-Networks\"><a href=\"#Region-Proposal-Networks\" class=\"headerlink\" title=\"Region Proposal Networks\"></a>Region Proposal Networks</h3><p>区域提议网络（RPN）<strong>以任意大小的图像作为输入，输出一组矩形的目标提议，每个提议都有一个目标得分</strong>。我们用全卷积网络[7]对这个过程进行建模，我们将在本节进行描述。因为我们的最终目标是与Fast R-CNN目标检测网络[2]共享计算，所以我们假设两个网络共享一组共同的卷积层。在我们的实验中，我们研究了具有5个共享卷积层的Zeiler和Fergus模型[32]（ZF）和具有13个共享卷积层的Simonyan和Zisserman模型[3]（VGG-16）。</p>\n<p>为了生成区域提议，我们 <strong>在最后的共享卷积层输出的卷积特征映射上滑动一个小网络</strong>。这个小网络将输入卷积特征映射的 $n×n$ 空间窗口作为输入。每个滑动窗口映射到一个低维特征（ZF为256维，VGG为512维，后面是ReLU[33]）。<strong>这个特征被输入到两个子全连接层——一个边界框回归层（reg）和一个边界框分类层（cls）</strong>。在本文中，我们使用n=3，注意输入图像上的有效接受域是大的（ZF和VGG分别为171和228个像素）。图3（左）显示了这个小型网络的一个位置。请注意，因为小网络以滑动窗口方式运行，所有空间位置共享全连接层。这种架构通过一个 $n×n$ 卷积层，后面是两个子1×1卷积层（分别用于reg和cls）自然地实现。</p>\n<h4 id=\"Anchors\"><a href=\"#Anchors\" class=\"headerlink\" title=\"Anchors\"></a>Anchors</h4><p>在每个滑动窗口位置，我们同时预测多个区域提议，其中每个位置可能提议的最大数目定义为k。因此，reg层具有4k个输出，分别编码k个边界框的坐标，cls层输出2k个分数，估计每个提议是目标或不是目标的概率。相对于我们称之为Anchors的k个参考边界框，k是参数化的。<strong>锚点位于滑动窗口的中心，并与一个尺度和长宽比相关</strong>（图3左）。默认情况下，我们使用3个尺度和3个长宽比，在每个滑动位置产生k=9个锚点。对于大小为W×H（通常约为2400）的卷积特征映射，总共有WHk个锚点。</p>\n<p><img src=\"/images/faster_f3.PNG\" alt=\"\"></p>\n<h4 id=\"Translation-Invariant-Anchors\"><a href=\"#Translation-Invariant-Anchors\" class=\"headerlink\" title=\"Translation-Invariant Anchors\"></a>Translation-Invariant Anchors</h4><p>我们的方法的一个重要特性是它是平移不变的，无论是在锚点还是计算相对于锚点的区域提议的函数。如果在图像中平移目标，提议应该平移，并且同样的函数应该能够在任一位置预测提议。平移不变特性是由我们的方法保证的。作为比较，MultiBox方法[27]使用k-means生成800个锚点，这不是平移不变的。所以如果平移目标，MultiBox不保证会生成相同的提议。</p>\n<p><strong>平移不变特性也减小了模型的大小</strong>。MultiBox有(4+1)×800维的全连接输出层，而我们的方法在k=9个锚点的情况下有(4+2)×9维的卷积输出层。因此，我们的输出层具有 $2.8×10^4$ 个参数（512×(4+2)×9 对于VGG-16），比MultiBox输出层的 $6.1×10^6$ 个参数少了两个数量级（对于MultiBox [27]中的GoogleNet[34]为1536×(4+1)×800）。如果考虑到特征投影层，我们的提议层参数仍然比MultiBox少一个数量级。我们期望我们的方法在PASCAL VOC等小数据集上有更小的过拟合风险。</p>\n<h4 id=\"Multi-Scale-Anchors-as-Regression-References\"><a href=\"#Multi-Scale-Anchors-as-Regression-References\" class=\"headerlink\" title=\"Multi-Scale Anchors as Regression References\"></a>Multi-Scale Anchors as Regression References</h4><p>我们的锚点设计提出了一个新的方案来解决多尺度（和长宽比）。如图1所示，多尺度预测有两种流行的方法。第一种方法是基于图像/特征金字塔，例如DPM[8]和基于CNN的方法[9]，[1]，[2]中。图像在多个尺度上进行缩放，并且针对每个尺度（图1（a））计算特征映射（HOG[8]或深卷积特征[9]，[1]，[2]）。这种方法通常是有用的，但是非常耗时。第二种方法是在特征映射上使用多尺度（和/或长宽比）的滑动窗口。例如，在DPM[8]中，使用不同的滤波器大小（例如5×7和7×5）分别对不同长宽比的模型进行训练。如果用这种方法来解决多尺度问题，可以把它看作是一个“滤波器金字塔”（图1（b））。第二种方法通常与第一种方法联合采用[8]。</p>\n<p>作为比较，<strong>我们的基于锚点方法建立在锚点金字塔上</strong>，这是更具成本效益的。我们的方法 <strong>参照多尺度和长宽比的锚盒来分类和回归边界框</strong>。它只依赖单一尺度的图像和特征映射，并使用单一尺寸的滤波器（特征映射上的滑动窗口）。我们通过实验来展示这个方案解决多尺度和尺寸的效果（表8）。</p>\n<p><img src=\"/images/faster_t8.PNG\" alt=\"\"></p>\n<p>由于这种基于锚点的多尺度设计，我们可以简单地使用在单尺度图像上计算的卷积特征，Fast R-CNN检测器也是这样做的[2]。多尺度锚点设计是共享特征的关键组件，不需要额外的成本来处理尺度。</p>\n<h4 id=\"Loss-Function\"><a href=\"#Loss-Function\" class=\"headerlink\" title=\"Loss Function\"></a>Loss Function</h4><p>为了训练RPN，我们 <strong>为每个锚点分配一个二值类别标签（是目标或不是目标）</strong>。我们给两种锚点分配一个正标签：（i）具有与实际边界框的重叠最高交并比（IoU）的锚点，（ii）具有与实际边界框的重叠超过0.7 IoU的锚点。注意，单个真实边界框可以为多个锚点分配正标签。通常第二个条件足以确定正样本；但我们仍然采用第一个条件，因为在一些极少数情况下，第二个条件可能找不到正样本。对于所有的真实边界框，如果一个锚点的IoU比率低于0.3，我们给这样的锚点分配一个负标签。其他的就分配为非正也非负标签，这样的锚点不会有助于训练目标函数。</p>\n<p>根据这些定义，我们对目标函数Fast R-CNN[2]中的多任务损失进行最小化。我们对图像的损失函数定义为：</p>\n<p>$$L({p_i},{t_i}) = \\frac{1}{N_{cls}}\\sum_{i}L_{cls}(p_i, p_i^\\star) + \\lambda \\frac{1}{N_{reg}}\\sum_i p_i^\\star L_{reg}(t_i, t_i^\\star) \\tag{1}$$</p>\n<p>其中，$i$ 是一个小批量数据中锚点的索引，$p_i$ 是锚点 $i$ 作为目标的预测概率。如果锚点为正，真实标签 $p_i^\\star$ 为1，如果锚点为负，则为0。$t_i$ 是表示预测边界框4个参数化坐标的向量，而 $t_i^\\star$ 是与正锚点相关的真实边界框的向量。分类损失 $L_{cls}$ 是两个类别上（目标或不是目标）的对数损失。对于回归损失，我们使用 $L_{reg}(t_i,t_i^\\star) = R(t_i−t_i^\\star)$，其中 $R$ 是在[2]中定义的鲁棒损失函数（平滑L1）。项 $p_i^\\star L_{reg}$ 表示回归损失仅对于正锚点激活。cls和reg层的输出分别由 ${p_i}$ 和 ${t_i}$ 组成。</p>\n<p>这两个项用 $N_{cls}$ 和$N_{reg}$ 进行归一化，并由一个平衡参数 $\\lambda$ 加权。在我们目前的实现中（如在发布的代码中），方程（1）中的cls项通过小批量数据（即 $N_{cls}=256$）进行归一化，reg项根据锚点位置的数量（即 $N_{reg} ~= 24000$）进行归一化。默认情况下，我们设置 $\\lambda =10$，因此cls和reg项的权重大致相等。我们通过实验显示，结果对宽范围的 $\\lambda$ 值不敏感(表9)。我们还注意到，上面的归一化不是必需的，可以简化。</p>\n<p>对于边界框回归，我们采用[5]中的4个坐标参数化：</p>\n<p>$$t_x = \\frac{(x−x_a)}{w_a}, t_y = \\frac{(y − y_a)}{h_a},\\ t_w = log(\\frac{w}{w_a}),t_h = log(\\frac{h}{h_a}),\\ t_x^\\star =\\frac{(x^\\star − x_a)}{w_a},t_y^\\star = \\frac{(y^\\star − y_a)}{h_a},\\ t_w^\\star = log(\\frac{w^\\star}{w_a}), t_h^\\star = log(\\frac{h^\\star}{h_a}),\\tag{2} $$</p>\n<p>其中，x，y，w和h表示边界框的中心坐标及其宽和高。变量$x$，$x_a$ 和 $x^\\star$ 分别表示预测边界框，锚盒和实际边界框（类似于y,w,h）。这可以被认为是从锚盒到邻近的实际边界框的回归。</p>\n<p>然而，我们的方法通过与之前的基于RoI（感兴趣区域）方法[1]，[2]不同的方式来实现边界框回归。在[1]，[2]中，对任意大小的RoI池化的特征执行边界框回归，并且回归权重由所有区域共享。在我们的公式中，用于回归的特征在特征映射上具有相同的空间大小（3×3）。为了考虑不同的大小，学习一组k个边界框回归器。每个回归器负责一个尺度和一个长宽比，而k个回归器不共享权重。因此，由于锚点的设计，即使特征具有固定的尺度/比例，仍然可以预测各种尺寸的边界框。</p>\n<h4 id=\"Training-RPNs\"><a href=\"#Training-RPNs\" class=\"headerlink\" title=\"Training RPNs\"></a>Training RPNs</h4><p>RPN可以通过反向传播和随机梯度下降（SGD）进行端对端训练[35]。我们遵循[2]的 <strong>“以图像为中心”的采样策略来训练这个网络</strong>。每个小批量数据都从包含许多正面和负面示例锚点的单张图像中产生。对所有锚点的损失函数进行优化是可能的，但是这样会偏向于负样本，因为它们是占主导地位的。取而代之的是，我们在图像中随机采样256个锚点，计算一个小批量数据的损失函数，其中采样的正锚点和负锚点的比率为1:1。如果图像中的正样本少于128个，我们使用负样本填充小批量数据。</p>\n<p>我们通过从标准方差为0.01的零均值高斯分布中提取权重来随机初始化所有新层。所有其他层（即共享卷积层）通过预训练的ImageNet分类模型[36]来初始化，如同标准实践[5]。我们调整ZF网络的所有层，以及VGG网络的conv3_1及其之上的层以节省内存[2]。对于60k的小批量数据，我们使用0.001的学习率，对于PASCAL VOC数据集中的下一个20k小批量数据，使用0.0001。我们使用0.9的动量和0.0005的权重衰减[37]。我们的实现使用Caffe[38]。</p>\n<h3 id=\"SharingFeatures-for-RPN-and-Faster-R-CNN\"><a href=\"#SharingFeatures-for-RPN-and-Faster-R-CNN\" class=\"headerlink\" title=\"SharingFeatures for RPN and Faster R-CNN\"></a>SharingFeatures for RPN and Faster R-CNN</h3><p>到目前为止，我们已经描述了如何训练用于区域提议生成的网络，没有考虑将利用这些提议来进行目标检测的CNN。对于检测网络，我们采用Fast R-CNN[2]。接下来我们介绍一些算法，学习由RPN和Fast R-CNN组成的具有共享卷积层的统一网络（图2）。</p>\n<p>独立训练的RPN和Fast R-CNN将以不同的方式修改它们的卷积层。因此，我们需要开发一种允许在两个网络之间共享卷积层的技术，而不是学习两个独立的网络。我们讨论三个方法来训练具有共享特征的网络：</p>\n<p>（一）<strong>交替训练(Alternating training)</strong>。在这个解决方案中，我们首先训练RPN，并使用这些提议来训练Fast R-CNN。由Fast R-CNN微调的网络然后被用于初始化RPN，并且重复这个过程。这是本文所有实验中使用的解决方案。</p>\n<p>（二）<strong>近似联合训练(Approximate joint training)</strong>。在这个解决方案中，RPN和Fast R-CNN网络在训练期间合并成一个网络，如图2所示。在每次SGD迭代中，前向传递生成区域提议，在训练Fast R-CNN检测器将这看作是固定的、预计算的提议。反向传播像往常一样进行，其中对于共享层，组合来自RPN损失和Fast R-CNN损失的反向传播信号。这个解决方案很容易实现。但是这个解决方案忽略了关于提议边界框的坐标（也是网络响应）的导数，因此是近似的。在我们的实验中，我们实验发现这个求解器产生了接近的结果，与交替训练相比，训练时间减少了大约25−50%。这个求解器包含在我们发布的Python代码中。</p>\n<p>（三）<strong>非近似的联合训练(Non-approximate joint training)</strong>。如上所述，由RPN预测的边界框也是输入的函数。Fast R-CNN中的RoI池化层[2]接受卷积特征以及预测的边界框作为输入，所以理论上有效的反向传播求解器也应该包括关于边界框坐标的梯度。在上述近似联合训练中，这些梯度被忽略。在一个非近似的联合训练解决方案中，我们需要一个关于边界框坐标可微分的RoI池化层。这是一个重要的问题，可以通过[15]中提出的“RoI wraping”层给出解决方案，这超出了本文的范围。</p>\n<p><strong>四步交替训练(4-Step Alternating Training)</strong>。在本文中，我们采用实用的四步训练算法，通过交替优化学习共享特征。在第一步中，我们按照3.1.3节的描述训练RPN。该网络使用ImageNet的预训练模型进行初始化，并针对区域提议任务进行了端到端的微调。在第二步中，我们使用由第一步RPN生成的提议，由Fast R-CNN训练单独的检测网络。该检测网络也由ImageNet的预训练模型进行初始化。此时两个网络不共享卷积层。在第三步中，我们使用检测器网络来初始化RPN训练，但是我们固定共享的卷积层，并且只对RPN特有的层进行微调。现在这两个网络共享卷积层。最后，保持共享卷积层的固定，我们对Fast R-CNN的独有层进行微调。因此，两个网络共享相同的卷积层并形成统一的网络。类似的交替训练可以迭代更多次，但是我们只观察到微小的改进。</p>\n<h3 id=\"Implementation-Details\"><a href=\"#Implementation-Details\" class=\"headerlink\" title=\"Implementation Details\"></a>Implementation Details</h3><p>我们在单尺度图像上训练和测试区域提议和目标检测网络[1]，[2]。我们重新缩放图像，使得它们的短边是s=600像素[2]。多尺度特征提取（使用图像金字塔）可能会提高精度，但不会表现出速度与精度的良好折衷[2]。在重新缩放的图像上，最后卷积层上的ZF和VGG网络的总步长为16个像素，因此在调整大小（〜500×375）之前，典型的PASCAL图像上的总步长为〜10个像素。即使如此大的步长也能提供良好的效果，尽管步幅更小，精度可能会进一步提高。</p>\n<p>对于锚点，我们使用了3个尺度，边界框面积分别为 $128^2$，$256^2$ 和 $512^2$ 个像素，以及$1:1$，$1:2$和$2:1$的长宽比。这些超参数不是针对特定数据集仔细选择的，我们将在下一节中提供有关其作用的消融实验。如上所述，我们的解决方案不需要图像金字塔或滤波器金字塔来预测多个尺度的区域，节省了大量的运行时间。图3（右）显示了我们的方法在广泛的尺度和长宽比方面的能力。表1显示了使用ZF网络的每个锚点学习到的平均提议大小。我们注意到，我们的算法允许预测比潜在接受域更大的区域。这样的预测不是不可能的——如果只有目标的中间部分是可见的，那么仍然可以粗略地推断出目标的范围。</p>\n<p><img src=\"/images/faster_t1.PNG\" alt=\"\"></p>\n<p>跨越图像边界的锚盒需要小心处理。在训练过程中，我们忽略了所有的跨界锚点，所以不会造成损失。对于一个典型的1000×600的图片，总共将会有大约20000（≈60×40×9）个锚点。跨界锚点被忽略，每张图像约有6000个锚点用于训练。如果跨界异常值在训练中不被忽略，则会在目标函数中引入大的，难以纠正的误差项，且训练不会收敛。但在测试过程中，我们仍然将全卷积RPN应用于整张图像。这可能会产生跨边界的提议边界框，我们剪切到图像边界。</p>\n<p>一些RPN提议互相之间高度重叠。为了减少冗余，我们在提议区域根据他们的cls分数采取非极大值抑制（NMS）。我们将NMS的IoU阈值固定为0.7，这就给每张图像留下了大约2000个提议区域。正如我们将要展示的那样，NMS不会损害最终的检测准确性，但会大大减少提议的数量。在NMS之后，我们使用前N个提议区域来进行检测。接下来，我们使用2000个RPN提议对Fast R-CNN进行训练，但在测试时评估不同数量的提议。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><p>最先进的目标检测网络依赖region proposal算法来假设目标的位置。SPPnet[1]和Fast R-CNN[2]等研究已经减少了这些检测网络的运行时间，同时暴露出region proposal计算成为一个瓶颈。在这项工作中，我们引入了一个 <strong>region proposal network(RPN)</strong>，<strong>该网络与检测网络共享全图像的卷积特征</strong>，从而使近乎零成本的region proposal成为可能。<strong>RPN是一个全卷积网络，可以同时在每个位置预测目标边界和目标的得分</strong>。RPN经过端到端的训练来生成高质量的region proposal，进而由Fast R-CNN进行检测。我们 <strong>将RPN和Fast R-CNN通过共享卷积特征进一步合并为一个单一的网络</strong> ——使用最近流行的具有“注意力”机制的神经网络术语，RPN组件告诉统一的网络在哪里寻找。对于非常深的VGG-16模型[3]，我们的检测系统在GPU上的帧率为5fps（包括所有步骤），同时在PASCAL VOC 2007，2012和MS COCO数据集上实现了目前最优的目标检测精度，每个图像只有300个proposals。在ILSVRC和COCO 2015竞赛中，Faster R-CNN和RPN是多个比赛中获得第一名的基础。代码可公开获得。</p>\n<p>索引词–对象检测，region proposal, 卷积神经网络</p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>region proposal 方法[4]和基于区域的卷积神经网络(R-CNNs)[5]的成功给目标检测带来了最新的进展。尽管在[5]中最初开发的基于区域的CNN计算成本很高，但是由于在各种proposal中共享卷积，其成本已经大大降低了[1]，[2]。忽略花费在region proposal上的时间，最新版本Fast R-CNN[2]利用非常深的网络[3]实现了接近实时的速率(当忽略region proposal的时间花费)。现在，proposals是最新的检测系统中测试时间的计算瓶颈。</p>\n<p>region proposal方法通常依赖廉价的特征和经济的推断方案。选择性搜索(Selective Search)[4]是最流行的方法之一，它贪婪地合并基于工程的低级特征的超像素。然而，与有效的检测网络[2]相比，选择性搜索速度慢了一个数量级，在CPU实现中每张图像的时间为2秒。EdgeBoxes[6]目前提供了在proposal质量和速度之间的最佳权衡，每张图像0.2秒。尽管如此，region proposal步骤仍然像检测网络那样消耗同样多的运行时间。</p>\n<p>有人可能会注意到，基于区域的快速CNN利用GPU，而在研究中使用的region proposal方法在CPU上实现，使得运行时间的比较不公平。加速region proposal计算的一个显而易见的方法是将其在GPU上重新实现。这可能是一个有效的工程解决方案，但重新实现忽略了下游检测网络，因此错过了共享计算的重要机会。</p>\n<p>在本文中，我们对算法做了一点改变——用深度卷积神经网络计算proposals——带来了一个优雅而且有效的解决方案，其中在给定检测网络计算的情况下proposal计算几乎零成本。为此，我们引入了新的RPNs，它们共享最先进的目标检测网络的卷积层[1]，[2]。通过在测试时共享卷积，计算region proposal的边际成本很小（例如，每张图像10ms）。</p>\n<p>我们的观察到基于区域的检测器所使用的卷积特征映射，如Fast R-CNN，也可以用于生成region proposal。在这些卷积特征之上，我们通过添加一些额外的卷积层来构建RPN，这些卷积层同时在规则网格上的每个位置上regress区域边界和目标分数。因此RPN是一种全卷积网络（FCN）[7]，可以针对生成检测区域推荐的任务进行端到端的训练。</p>\n<p><img src=\"/images/faster_f1.PNG\" alt=\"\"></p>\n<p><strong>RPN旨在有效预测具有广泛尺度和长宽比的region proposal</strong>。与使用图像金字塔（图1，a）或滤波器金字塔（图1，b）的流行方法[8]，[9]，[1]相比，我们引入新的“<strong>anchor</strong>”盒作为多种尺度和长宽比的参考。我们的方案可以被认为是回归参考金字塔（图1，c），它避免了枚举多种尺度或长宽比的图像或滤波器。这个模型在使用单尺度图像进行训练和测试时表现很好，从而有利于运行速度的提高。</p>\n<p>为了将RPN与Fast R-CNN [2]目标检测网络相结合，我们提出了一种训练方案，<strong>在微调region proposal任务和微调目标检测之间进行交替，同时保持the proposals的固定</strong>。该方案快速收敛，并产生两个任务之间共享卷积特征的统一网络。</p>\n<p>我们在PASCAL VOC检测基准数据集上[11]综合评估了我们的方法，其中具有Fast R-CNN的RPN产生的检测精度优于使用强基准选择性搜索的Fast R-CNN。同时，我们的方法在测试时几乎免除了选择性搜索的所有计算负担——proposal的有效运行时间仅为10毫秒。使用昂贵的非常深的模型[3]，我们的检测方法在GPU上仍然具有5fps的帧率（包括所有步骤），因此在速度和准确性方面是实用的目标检测系统。我们还报告了在MS COCO数据集上[12]的结果，并使用COCO数据研究了在PASCAL VOC上的改进。代码可公开获得<a href=\"https://github.com/shaoqingren/faster_rcnn（MATLAB）和https://github.com/rbgirshick/py-faster-rcnn（Python）。\" target=\"_blank\" rel=\"noopener\">https://github.com/shaoqingren/faster_rcnn（MATLAB）和https://github.com/rbgirshick/py-faster-rcnn（Python）。</a></p>\n<p>这个手稿的初步版本是以前发表的[10]。从那时起，RPN和Faster R-CNN的框架已经被采用并推广到其他方法，如3D目标检测[13]，基于部件的检测[14]，实例分割[15]和图像标题[16]。我们快速和有效的目标检测系统也已经在Pinterest[17]的商业系统中建立了，并报告了用户参与度的提高。</p>\n<p>在ILSVRC和COCO 2015竞赛中，Faster R-CNN和RPN是ImageNet检测，ImageNet定位，COCO检测和COCO分割中几个第一名参赛者[18]的基础。RPN完全从数据中学习提议区域，因此可以从更深入和更具表达性的特征（例如[18]中采用的101层残差网络）中轻松获益。Faster R-CNN和RPN也被这些比赛中的其他几个主要参赛者所使用。这些结果表明，我们的方法不仅是一个实用合算的解决方案，而且是一个提高目标检测精度的有效方法。</p>\n<h2 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h2><p><strong>Object Proposal</strong>。Object Proposal方法方面有大量的文献。目标提议方法的综合调查和比较可以在[19]，[20]，[21]中找到。广泛使用的目标提议方法包括基于超像素分组（例如，选择性搜索[4]，CPMC[22]，MCG[23]）和那些基于滑动窗口的方法（例如窗口中的目标[24]，EdgeBoxes[6]）。目标提议方法被采用为独立于检测器（例如，选择性搜索[4]目标检测器，R-CNN[5]和Fast R-CNN[2]）的外部模块。</p>\n<p><strong>Deep Network for Object Dection</strong>。R-CNN方法[5]端到端地对CNN进行训练，将提议区域分类为目标类别或背景。R-CNN主要作为分类器，它不预测目标边界（除了通过边界框回归进行细化）。其准确度取决于区域提议模块的性能（参见[20]中的比较）。一些论文提出了使用深度网络来预测目标边界框的方法[25]，[9]，[26]，[27]。在OverFeat方法[9]中，训练一个全连接层来预测单个目标定位任务的边界框坐标。然后将全连接层变成卷积层，用于检测多个类别的目标。MultiBox方法[26]，[27]从网络中生成区域提议，该网络最后的全连接层同时预测多个类别不可知的边界框，并推广到OverFeat的“single-box”方式。这些类别不可知的边界框被用作R-CNN的提议区域[5]。与我们的全卷积方案相比，MultiBox提议网络适用于单张裁剪图像或多张大型裁剪图像（例如224×224）。MultiBox在提议区域和检测网络之间不共享特征。稍后在我们的方法上下文中会讨论OverFeat和MultiBox。与我们的工作同时进行的，DeepMask方法[28]是为学习分割提议区域而开发的。</p>\n<p>卷积[9]，[1]，[29]，[7]，[2]的共享计算已经越来越受到人们的关注，因为它可以有效而准确地进行视觉识别。OverFeat论文[9]计算图像金字塔的卷积特征用于分类，定位和检测。共享卷积特征映射的自适应大小池化（SPP）[1]被开发用于有效的基于区域的目标检测[1]，[30]和语义分割[29]。Fast R-CNN[2]能够对共享卷积特征进行端到端的检测器训练，并显示出令人叹服的准确性和速度。</p>\n<h2 id=\"FASTER-R-CNN\"><a href=\"#FASTER-R-CNN\" class=\"headerlink\" title=\"FASTER R-CNN\"></a>FASTER R-CNN</h2><p>我们的目标检测系统，称为 <strong>Faster R-CNN</strong> ，由两个模块组成。第一个模块是 <strong>proposal regions的深度全卷积网络</strong>，第二个模块是 <strong>使用提议区域的Fast R-CNN检测器</strong>[2]。整个系统是一个单个的，统一的目标检测网络（图2）。使用最近流行的“注意力”[31]机制的神经网络术语，<strong>RPN模块告诉Fast R-CNN模块在哪里寻找</strong>。在第3.1节中，我们介绍了区域提议网络的设计和属性。在第3.2节中，我们开发了用于训练具有共享特征模块的算法。</p>\n<p><img src=\"/images/faster_f2.PNG\" alt=\"\"></p>\n<h3 id=\"Region-Proposal-Networks\"><a href=\"#Region-Proposal-Networks\" class=\"headerlink\" title=\"Region Proposal Networks\"></a>Region Proposal Networks</h3><p>区域提议网络（RPN）<strong>以任意大小的图像作为输入，输出一组矩形的目标提议，每个提议都有一个目标得分</strong>。我们用全卷积网络[7]对这个过程进行建模，我们将在本节进行描述。因为我们的最终目标是与Fast R-CNN目标检测网络[2]共享计算，所以我们假设两个网络共享一组共同的卷积层。在我们的实验中，我们研究了具有5个共享卷积层的Zeiler和Fergus模型[32]（ZF）和具有13个共享卷积层的Simonyan和Zisserman模型[3]（VGG-16）。</p>\n<p>为了生成区域提议，我们 <strong>在最后的共享卷积层输出的卷积特征映射上滑动一个小网络</strong>。这个小网络将输入卷积特征映射的 $n×n$ 空间窗口作为输入。每个滑动窗口映射到一个低维特征（ZF为256维，VGG为512维，后面是ReLU[33]）。<strong>这个特征被输入到两个子全连接层——一个边界框回归层（reg）和一个边界框分类层（cls）</strong>。在本文中，我们使用n=3，注意输入图像上的有效接受域是大的（ZF和VGG分别为171和228个像素）。图3（左）显示了这个小型网络的一个位置。请注意，因为小网络以滑动窗口方式运行，所有空间位置共享全连接层。这种架构通过一个 $n×n$ 卷积层，后面是两个子1×1卷积层（分别用于reg和cls）自然地实现。</p>\n<h4 id=\"Anchors\"><a href=\"#Anchors\" class=\"headerlink\" title=\"Anchors\"></a>Anchors</h4><p>在每个滑动窗口位置，我们同时预测多个区域提议，其中每个位置可能提议的最大数目定义为k。因此，reg层具有4k个输出，分别编码k个边界框的坐标，cls层输出2k个分数，估计每个提议是目标或不是目标的概率。相对于我们称之为Anchors的k个参考边界框，k是参数化的。<strong>锚点位于滑动窗口的中心，并与一个尺度和长宽比相关</strong>（图3左）。默认情况下，我们使用3个尺度和3个长宽比，在每个滑动位置产生k=9个锚点。对于大小为W×H（通常约为2400）的卷积特征映射，总共有WHk个锚点。</p>\n<p><img src=\"/images/faster_f3.PNG\" alt=\"\"></p>\n<h4 id=\"Translation-Invariant-Anchors\"><a href=\"#Translation-Invariant-Anchors\" class=\"headerlink\" title=\"Translation-Invariant Anchors\"></a>Translation-Invariant Anchors</h4><p>我们的方法的一个重要特性是它是平移不变的，无论是在锚点还是计算相对于锚点的区域提议的函数。如果在图像中平移目标，提议应该平移，并且同样的函数应该能够在任一位置预测提议。平移不变特性是由我们的方法保证的。作为比较，MultiBox方法[27]使用k-means生成800个锚点，这不是平移不变的。所以如果平移目标，MultiBox不保证会生成相同的提议。</p>\n<p><strong>平移不变特性也减小了模型的大小</strong>。MultiBox有(4+1)×800维的全连接输出层，而我们的方法在k=9个锚点的情况下有(4+2)×9维的卷积输出层。因此，我们的输出层具有 $2.8×10^4$ 个参数（512×(4+2)×9 对于VGG-16），比MultiBox输出层的 $6.1×10^6$ 个参数少了两个数量级（对于MultiBox [27]中的GoogleNet[34]为1536×(4+1)×800）。如果考虑到特征投影层，我们的提议层参数仍然比MultiBox少一个数量级。我们期望我们的方法在PASCAL VOC等小数据集上有更小的过拟合风险。</p>\n<h4 id=\"Multi-Scale-Anchors-as-Regression-References\"><a href=\"#Multi-Scale-Anchors-as-Regression-References\" class=\"headerlink\" title=\"Multi-Scale Anchors as Regression References\"></a>Multi-Scale Anchors as Regression References</h4><p>我们的锚点设计提出了一个新的方案来解决多尺度（和长宽比）。如图1所示，多尺度预测有两种流行的方法。第一种方法是基于图像/特征金字塔，例如DPM[8]和基于CNN的方法[9]，[1]，[2]中。图像在多个尺度上进行缩放，并且针对每个尺度（图1（a））计算特征映射（HOG[8]或深卷积特征[9]，[1]，[2]）。这种方法通常是有用的，但是非常耗时。第二种方法是在特征映射上使用多尺度（和/或长宽比）的滑动窗口。例如，在DPM[8]中，使用不同的滤波器大小（例如5×7和7×5）分别对不同长宽比的模型进行训练。如果用这种方法来解决多尺度问题，可以把它看作是一个“滤波器金字塔”（图1（b））。第二种方法通常与第一种方法联合采用[8]。</p>\n<p>作为比较，<strong>我们的基于锚点方法建立在锚点金字塔上</strong>，这是更具成本效益的。我们的方法 <strong>参照多尺度和长宽比的锚盒来分类和回归边界框</strong>。它只依赖单一尺度的图像和特征映射，并使用单一尺寸的滤波器（特征映射上的滑动窗口）。我们通过实验来展示这个方案解决多尺度和尺寸的效果（表8）。</p>\n<p><img src=\"/images/faster_t8.PNG\" alt=\"\"></p>\n<p>由于这种基于锚点的多尺度设计，我们可以简单地使用在单尺度图像上计算的卷积特征，Fast R-CNN检测器也是这样做的[2]。多尺度锚点设计是共享特征的关键组件，不需要额外的成本来处理尺度。</p>\n<h4 id=\"Loss-Function\"><a href=\"#Loss-Function\" class=\"headerlink\" title=\"Loss Function\"></a>Loss Function</h4><p>为了训练RPN，我们 <strong>为每个锚点分配一个二值类别标签（是目标或不是目标）</strong>。我们给两种锚点分配一个正标签：（i）具有与实际边界框的重叠最高交并比（IoU）的锚点，（ii）具有与实际边界框的重叠超过0.7 IoU的锚点。注意，单个真实边界框可以为多个锚点分配正标签。通常第二个条件足以确定正样本；但我们仍然采用第一个条件，因为在一些极少数情况下，第二个条件可能找不到正样本。对于所有的真实边界框，如果一个锚点的IoU比率低于0.3，我们给这样的锚点分配一个负标签。其他的就分配为非正也非负标签，这样的锚点不会有助于训练目标函数。</p>\n<p>根据这些定义，我们对目标函数Fast R-CNN[2]中的多任务损失进行最小化。我们对图像的损失函数定义为：</p>\n<p>$$L({p_i},{t_i}) = \\frac{1}{N_{cls}}\\sum_{i}L_{cls}(p_i, p_i^\\star) + \\lambda \\frac{1}{N_{reg}}\\sum_i p_i^\\star L_{reg}(t_i, t_i^\\star) \\tag{1}$$</p>\n<p>其中，$i$ 是一个小批量数据中锚点的索引，$p_i$ 是锚点 $i$ 作为目标的预测概率。如果锚点为正，真实标签 $p_i^\\star$ 为1，如果锚点为负，则为0。$t_i$ 是表示预测边界框4个参数化坐标的向量，而 $t_i^\\star$ 是与正锚点相关的真实边界框的向量。分类损失 $L_{cls}$ 是两个类别上（目标或不是目标）的对数损失。对于回归损失，我们使用 $L_{reg}(t_i,t_i^\\star) = R(t_i−t_i^\\star)$，其中 $R$ 是在[2]中定义的鲁棒损失函数（平滑L1）。项 $p_i^\\star L_{reg}$ 表示回归损失仅对于正锚点激活。cls和reg层的输出分别由 ${p_i}$ 和 ${t_i}$ 组成。</p>\n<p>这两个项用 $N_{cls}$ 和$N_{reg}$ 进行归一化，并由一个平衡参数 $\\lambda$ 加权。在我们目前的实现中（如在发布的代码中），方程（1）中的cls项通过小批量数据（即 $N_{cls}=256$）进行归一化，reg项根据锚点位置的数量（即 $N_{reg} ~= 24000$）进行归一化。默认情况下，我们设置 $\\lambda =10$，因此cls和reg项的权重大致相等。我们通过实验显示，结果对宽范围的 $\\lambda$ 值不敏感(表9)。我们还注意到，上面的归一化不是必需的，可以简化。</p>\n<p>对于边界框回归，我们采用[5]中的4个坐标参数化：</p>\n<p>$$t_x = \\frac{(x−x_a)}{w_a}, t_y = \\frac{(y − y_a)}{h_a},\\ t_w = log(\\frac{w}{w_a}),t_h = log(\\frac{h}{h_a}),\\ t_x^\\star =\\frac{(x^\\star − x_a)}{w_a},t_y^\\star = \\frac{(y^\\star − y_a)}{h_a},\\ t_w^\\star = log(\\frac{w^\\star}{w_a}), t_h^\\star = log(\\frac{h^\\star}{h_a}),\\tag{2} $$</p>\n<p>其中，x，y，w和h表示边界框的中心坐标及其宽和高。变量$x$，$x_a$ 和 $x^\\star$ 分别表示预测边界框，锚盒和实际边界框（类似于y,w,h）。这可以被认为是从锚盒到邻近的实际边界框的回归。</p>\n<p>然而，我们的方法通过与之前的基于RoI（感兴趣区域）方法[1]，[2]不同的方式来实现边界框回归。在[1]，[2]中，对任意大小的RoI池化的特征执行边界框回归，并且回归权重由所有区域共享。在我们的公式中，用于回归的特征在特征映射上具有相同的空间大小（3×3）。为了考虑不同的大小，学习一组k个边界框回归器。每个回归器负责一个尺度和一个长宽比，而k个回归器不共享权重。因此，由于锚点的设计，即使特征具有固定的尺度/比例，仍然可以预测各种尺寸的边界框。</p>\n<h4 id=\"Training-RPNs\"><a href=\"#Training-RPNs\" class=\"headerlink\" title=\"Training RPNs\"></a>Training RPNs</h4><p>RPN可以通过反向传播和随机梯度下降（SGD）进行端对端训练[35]。我们遵循[2]的 <strong>“以图像为中心”的采样策略来训练这个网络</strong>。每个小批量数据都从包含许多正面和负面示例锚点的单张图像中产生。对所有锚点的损失函数进行优化是可能的，但是这样会偏向于负样本，因为它们是占主导地位的。取而代之的是，我们在图像中随机采样256个锚点，计算一个小批量数据的损失函数，其中采样的正锚点和负锚点的比率为1:1。如果图像中的正样本少于128个，我们使用负样本填充小批量数据。</p>\n<p>我们通过从标准方差为0.01的零均值高斯分布中提取权重来随机初始化所有新层。所有其他层（即共享卷积层）通过预训练的ImageNet分类模型[36]来初始化，如同标准实践[5]。我们调整ZF网络的所有层，以及VGG网络的conv3_1及其之上的层以节省内存[2]。对于60k的小批量数据，我们使用0.001的学习率，对于PASCAL VOC数据集中的下一个20k小批量数据，使用0.0001。我们使用0.9的动量和0.0005的权重衰减[37]。我们的实现使用Caffe[38]。</p>\n<h3 id=\"SharingFeatures-for-RPN-and-Faster-R-CNN\"><a href=\"#SharingFeatures-for-RPN-and-Faster-R-CNN\" class=\"headerlink\" title=\"SharingFeatures for RPN and Faster R-CNN\"></a>SharingFeatures for RPN and Faster R-CNN</h3><p>到目前为止，我们已经描述了如何训练用于区域提议生成的网络，没有考虑将利用这些提议来进行目标检测的CNN。对于检测网络，我们采用Fast R-CNN[2]。接下来我们介绍一些算法，学习由RPN和Fast R-CNN组成的具有共享卷积层的统一网络（图2）。</p>\n<p>独立训练的RPN和Fast R-CNN将以不同的方式修改它们的卷积层。因此，我们需要开发一种允许在两个网络之间共享卷积层的技术，而不是学习两个独立的网络。我们讨论三个方法来训练具有共享特征的网络：</p>\n<p>（一）<strong>交替训练(Alternating training)</strong>。在这个解决方案中，我们首先训练RPN，并使用这些提议来训练Fast R-CNN。由Fast R-CNN微调的网络然后被用于初始化RPN，并且重复这个过程。这是本文所有实验中使用的解决方案。</p>\n<p>（二）<strong>近似联合训练(Approximate joint training)</strong>。在这个解决方案中，RPN和Fast R-CNN网络在训练期间合并成一个网络，如图2所示。在每次SGD迭代中，前向传递生成区域提议，在训练Fast R-CNN检测器将这看作是固定的、预计算的提议。反向传播像往常一样进行，其中对于共享层，组合来自RPN损失和Fast R-CNN损失的反向传播信号。这个解决方案很容易实现。但是这个解决方案忽略了关于提议边界框的坐标（也是网络响应）的导数，因此是近似的。在我们的实验中，我们实验发现这个求解器产生了接近的结果，与交替训练相比，训练时间减少了大约25−50%。这个求解器包含在我们发布的Python代码中。</p>\n<p>（三）<strong>非近似的联合训练(Non-approximate joint training)</strong>。如上所述，由RPN预测的边界框也是输入的函数。Fast R-CNN中的RoI池化层[2]接受卷积特征以及预测的边界框作为输入，所以理论上有效的反向传播求解器也应该包括关于边界框坐标的梯度。在上述近似联合训练中，这些梯度被忽略。在一个非近似的联合训练解决方案中，我们需要一个关于边界框坐标可微分的RoI池化层。这是一个重要的问题，可以通过[15]中提出的“RoI wraping”层给出解决方案，这超出了本文的范围。</p>\n<p><strong>四步交替训练(4-Step Alternating Training)</strong>。在本文中，我们采用实用的四步训练算法，通过交替优化学习共享特征。在第一步中，我们按照3.1.3节的描述训练RPN。该网络使用ImageNet的预训练模型进行初始化，并针对区域提议任务进行了端到端的微调。在第二步中，我们使用由第一步RPN生成的提议，由Fast R-CNN训练单独的检测网络。该检测网络也由ImageNet的预训练模型进行初始化。此时两个网络不共享卷积层。在第三步中，我们使用检测器网络来初始化RPN训练，但是我们固定共享的卷积层，并且只对RPN特有的层进行微调。现在这两个网络共享卷积层。最后，保持共享卷积层的固定，我们对Fast R-CNN的独有层进行微调。因此，两个网络共享相同的卷积层并形成统一的网络。类似的交替训练可以迭代更多次，但是我们只观察到微小的改进。</p>\n<h3 id=\"Implementation-Details\"><a href=\"#Implementation-Details\" class=\"headerlink\" title=\"Implementation Details\"></a>Implementation Details</h3><p>我们在单尺度图像上训练和测试区域提议和目标检测网络[1]，[2]。我们重新缩放图像，使得它们的短边是s=600像素[2]。多尺度特征提取（使用图像金字塔）可能会提高精度，但不会表现出速度与精度的良好折衷[2]。在重新缩放的图像上，最后卷积层上的ZF和VGG网络的总步长为16个像素，因此在调整大小（〜500×375）之前，典型的PASCAL图像上的总步长为〜10个像素。即使如此大的步长也能提供良好的效果，尽管步幅更小，精度可能会进一步提高。</p>\n<p>对于锚点，我们使用了3个尺度，边界框面积分别为 $128^2$，$256^2$ 和 $512^2$ 个像素，以及$1:1$，$1:2$和$2:1$的长宽比。这些超参数不是针对特定数据集仔细选择的，我们将在下一节中提供有关其作用的消融实验。如上所述，我们的解决方案不需要图像金字塔或滤波器金字塔来预测多个尺度的区域，节省了大量的运行时间。图3（右）显示了我们的方法在广泛的尺度和长宽比方面的能力。表1显示了使用ZF网络的每个锚点学习到的平均提议大小。我们注意到，我们的算法允许预测比潜在接受域更大的区域。这样的预测不是不可能的——如果只有目标的中间部分是可见的，那么仍然可以粗略地推断出目标的范围。</p>\n<p><img src=\"/images/faster_t1.PNG\" alt=\"\"></p>\n<p>跨越图像边界的锚盒需要小心处理。在训练过程中，我们忽略了所有的跨界锚点，所以不会造成损失。对于一个典型的1000×600的图片，总共将会有大约20000（≈60×40×9）个锚点。跨界锚点被忽略，每张图像约有6000个锚点用于训练。如果跨界异常值在训练中不被忽略，则会在目标函数中引入大的，难以纠正的误差项，且训练不会收敛。但在测试过程中，我们仍然将全卷积RPN应用于整张图像。这可能会产生跨边界的提议边界框，我们剪切到图像边界。</p>\n<p>一些RPN提议互相之间高度重叠。为了减少冗余，我们在提议区域根据他们的cls分数采取非极大值抑制（NMS）。我们将NMS的IoU阈值固定为0.7，这就给每张图像留下了大约2000个提议区域。正如我们将要展示的那样，NMS不会损害最终的检测准确性，但会大大减少提议的数量。在NMS之后，我们使用前N个提议区域来进行检测。接下来，我们使用2000个RPN提议对Fast R-CNN进行训练，但在测试时评估不同数量的提议。</p>\n"},{"title":"DNN应用1--识别猫","date":"2018-08-03T00:52:05.000Z","_content":"## 实验目的\n\n使用深层全连接神经网络识别一副图片是否为猫，并将网络层数及每层单元数设为超参数。\n\n## 实验方案\n\n- 使用python自行编码各运算单元，主要借助numpy库的数据结构和运算函数。\n- 各个隐藏层采用Relu激活函数，输出层采用Sigmod激活函数，隐藏层使用dropout处理\n- 损失函数采用交叉熵，并使用L2正则化\n- 网络架构\n ![](/images/LlayerNN.png)\n\n## 详细设计\n\n### 数据预处理\n\n#### 加载数据\n\n```python\nimport numpy as np\nimport h5py\n\ndef load_data():\n    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])  # your train set features\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])  # your train set labels\n\n    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])  # your test set features\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])  # your test set labels\n\n    classes = np.array(test_dataset[\"list_classes\"][:])  # the list of classes\n    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n```\n\n```python\ntrain_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n```\n\n#### 数据集形状\n\n>Number of training examples: 209\nNumber of testing examples: 50\nEach image is of size: (64, 64, 3)\ntrain_x_orig shape: (209, 64, 64, 3)\ntrain_y shape: (1, 209)\ntest_x_orig shape: (50, 64, 64, 3)\ntest_y shape: (1, 50)\n\n#### 展示数据图片\n\n```python\nimport matplotlib.pyplot as plt\n\nindex = 7\nplt.imshow(train_x_orig[index])\nprint (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")\nplt.show()\n```\n\n#### 图像矩阵向量化\n\n```python\n# Reshape the training and test examples\ntrain_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\ntest_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n\n# Standardize data to have feature values between 0 and 1.\ntrain_x = train_x_flatten/255.\ntest_x = test_x_flatten/255.\n```\n\n#### 数据集最终形状\n\n>train_x's shape: (12288, 209)\ntest_x's shape: (12288, 50)\n\n### 网络设计\n\n1. 初始化参数 / 定义超参数\n2. 迭代循环:\n    a. 前向传播\n    b. 计算代价函数\n    c. 反向传播\n    d. 更新参数\n3. 使用训练的参数去预测新的数据标签\n\n网络主框架代码，其他细节函数参见“神经网络中的通用函数代码”\n\n```python\ndef L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False):  # lr was 0.009\n    \"\"\"\n    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n\n    Arguments:\n    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    costs = []                         # keep track of cost\n    # Parameters initialization.\n    parameters = initialize_parameters_deep(layers_dims)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n        AL, caches = L_model_forward(X, parameters)\n        # Compute cost.\n        cost = compute_cost(AL, Y)\n        # Backward propagation.\n        grads = L_model_backward(AL, Y, caches)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads, learning_rate=0.0075)\n        # Print the cost every 100 training example\n        if print_cost and i % 100 == 0:\n            print(\"Cost after iteration %i: %f\" % (i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)\n    # plot the cost\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Learning rate =\" + str(learning_rate))\n    plt.show()\n    return parameters\n```\n\n## 实验结果\n\n### 训练集结果\n\n```python\nlayers_dims = [12288, 20, 7, 5, 1] #  5-layer model\nparameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)\n```\n\n![](/images/res1.PNG)\n\n```python\npred_train = predict(train_x, train_y, parameters)\n```\n\n>Accuracy: 0.9856459330143539\n\n### 测试集结果\n\n```python\npred_test = predict(test_x, test_y, parameters)\n```\n\n>Accuracy: 0.8\n\n### 数据集外结果\n\n```python\nfrom scipy import ndimage\nimport scipy.misc\n\nmy_image = \"my_image.jpg\"\nmy_label_y = [0]\nfname = \"images/\" + my_image\nimage = np.array(ndimage.imread(fname, flatten=False))\nmy_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((num_px * num_px * 3, 1))\nmy_predicted_image = predict(my_image, my_label_y, parameters)\nplt.imshow(image)\nprint(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)), ].decode(\"utf-8\") + \"\\\" picture.\")\n```\n\n>Accuracy: 1.0\n>y = 1.0, your L-layer model predicts a \"cat\" picture.\n\n![](/images/my_image.jpg)\n","source":"_posts/DNN应用1-识别猫.md","raw":"---\ntitle: DNN应用1--识别猫\ndate: 2018-08-03 08:52:05\ntags: DNN\ncategories: 深度学习\n---\n## 实验目的\n\n使用深层全连接神经网络识别一副图片是否为猫，并将网络层数及每层单元数设为超参数。\n\n## 实验方案\n\n- 使用python自行编码各运算单元，主要借助numpy库的数据结构和运算函数。\n- 各个隐藏层采用Relu激活函数，输出层采用Sigmod激活函数，隐藏层使用dropout处理\n- 损失函数采用交叉熵，并使用L2正则化\n- 网络架构\n ![](/images/LlayerNN.png)\n\n## 详细设计\n\n### 数据预处理\n\n#### 加载数据\n\n```python\nimport numpy as np\nimport h5py\n\ndef load_data():\n    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])  # your train set features\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])  # your train set labels\n\n    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])  # your test set features\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])  # your test set labels\n\n    classes = np.array(test_dataset[\"list_classes\"][:])  # the list of classes\n    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n```\n\n```python\ntrain_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n```\n\n#### 数据集形状\n\n>Number of training examples: 209\nNumber of testing examples: 50\nEach image is of size: (64, 64, 3)\ntrain_x_orig shape: (209, 64, 64, 3)\ntrain_y shape: (1, 209)\ntest_x_orig shape: (50, 64, 64, 3)\ntest_y shape: (1, 50)\n\n#### 展示数据图片\n\n```python\nimport matplotlib.pyplot as plt\n\nindex = 7\nplt.imshow(train_x_orig[index])\nprint (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")\nplt.show()\n```\n\n#### 图像矩阵向量化\n\n```python\n# Reshape the training and test examples\ntrain_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\ntest_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n\n# Standardize data to have feature values between 0 and 1.\ntrain_x = train_x_flatten/255.\ntest_x = test_x_flatten/255.\n```\n\n#### 数据集最终形状\n\n>train_x's shape: (12288, 209)\ntest_x's shape: (12288, 50)\n\n### 网络设计\n\n1. 初始化参数 / 定义超参数\n2. 迭代循环:\n    a. 前向传播\n    b. 计算代价函数\n    c. 反向传播\n    d. 更新参数\n3. 使用训练的参数去预测新的数据标签\n\n网络主框架代码，其他细节函数参见“神经网络中的通用函数代码”\n\n```python\ndef L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False):  # lr was 0.009\n    \"\"\"\n    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n\n    Arguments:\n    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    costs = []                         # keep track of cost\n    # Parameters initialization.\n    parameters = initialize_parameters_deep(layers_dims)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n        AL, caches = L_model_forward(X, parameters)\n        # Compute cost.\n        cost = compute_cost(AL, Y)\n        # Backward propagation.\n        grads = L_model_backward(AL, Y, caches)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads, learning_rate=0.0075)\n        # Print the cost every 100 training example\n        if print_cost and i % 100 == 0:\n            print(\"Cost after iteration %i: %f\" % (i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)\n    # plot the cost\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Learning rate =\" + str(learning_rate))\n    plt.show()\n    return parameters\n```\n\n## 实验结果\n\n### 训练集结果\n\n```python\nlayers_dims = [12288, 20, 7, 5, 1] #  5-layer model\nparameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)\n```\n\n![](/images/res1.PNG)\n\n```python\npred_train = predict(train_x, train_y, parameters)\n```\n\n>Accuracy: 0.9856459330143539\n\n### 测试集结果\n\n```python\npred_test = predict(test_x, test_y, parameters)\n```\n\n>Accuracy: 0.8\n\n### 数据集外结果\n\n```python\nfrom scipy import ndimage\nimport scipy.misc\n\nmy_image = \"my_image.jpg\"\nmy_label_y = [0]\nfname = \"images/\" + my_image\nimage = np.array(ndimage.imread(fname, flatten=False))\nmy_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((num_px * num_px * 3, 1))\nmy_predicted_image = predict(my_image, my_label_y, parameters)\nplt.imshow(image)\nprint(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)), ].decode(\"utf-8\") + \"\\\" picture.\")\n```\n\n>Accuracy: 1.0\n>y = 1.0, your L-layer model predicts a \"cat\" picture.\n\n![](/images/my_image.jpg)\n","slug":"DNN应用1-识别猫","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds1l0008pcvobv37uzqh","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"实验目的\"><a href=\"#实验目的\" class=\"headerlink\" title=\"实验目的\"></a>实验目的</h2><p>使用深层全连接神经网络识别一副图片是否为猫，并将网络层数及每层单元数设为超参数。</p>\n<h2 id=\"实验方案\"><a href=\"#实验方案\" class=\"headerlink\" title=\"实验方案\"></a>实验方案</h2><ul>\n<li>使用python自行编码各运算单元，主要借助numpy库的数据结构和运算函数。</li>\n<li>各个隐藏层采用Relu激活函数，输出层采用Sigmod激活函数，隐藏层使用dropout处理</li>\n<li>损失函数采用交叉熵，并使用L2正则化</li>\n<li>网络架构<br><img src=\"/images/LlayerNN.png\" alt=\"\"></li>\n</ul>\n<h2 id=\"详细设计\"><a href=\"#详细设计\" class=\"headerlink\" title=\"详细设计\"></a>详细设计</h2><h3 id=\"数据预处理\"><a href=\"#数据预处理\" class=\"headerlink\" title=\"数据预处理\"></a>数据预处理</h3><h4 id=\"加载数据\"><a href=\"#加载数据\" class=\"headerlink\" title=\"加载数据\"></a>加载数据</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> h5py</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_data</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    train_dataset = h5py.File(<span class=\"string\">'datasets/train_catvnoncat.h5'</span>, <span class=\"string\">\"r\"</span>)</span><br><span class=\"line\">    train_set_x_orig = np.array(train_dataset[<span class=\"string\">\"train_set_x\"</span>][:])  <span class=\"comment\"># your train set features</span></span><br><span class=\"line\">    train_set_y_orig = np.array(train_dataset[<span class=\"string\">\"train_set_y\"</span>][:])  <span class=\"comment\"># your train set labels</span></span><br><span class=\"line\"></span><br><span class=\"line\">    test_dataset = h5py.File(<span class=\"string\">'datasets/test_catvnoncat.h5'</span>, <span class=\"string\">\"r\"</span>)</span><br><span class=\"line\">    test_set_x_orig = np.array(test_dataset[<span class=\"string\">\"test_set_x\"</span>][:])  <span class=\"comment\"># your test set features</span></span><br><span class=\"line\">    test_set_y_orig = np.array(test_dataset[<span class=\"string\">\"test_set_y\"</span>][:])  <span class=\"comment\"># your test set labels</span></span><br><span class=\"line\"></span><br><span class=\"line\">    classes = np.array(test_dataset[<span class=\"string\">\"list_classes\"</span>][:])  <span class=\"comment\"># the list of classes</span></span><br><span class=\"line\">    train_set_y_orig = train_set_y_orig.reshape((<span class=\"number\">1</span>, train_set_y_orig.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">    test_set_y_orig = test_set_y_orig.reshape((<span class=\"number\">1</span>, test_set_y_orig.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_x_orig, train_y, test_x_orig, test_y, classes = load_data()</span><br></pre></td></tr></table></figure>\n<h4 id=\"数据集形状\"><a href=\"#数据集形状\" class=\"headerlink\" title=\"数据集形状\"></a>数据集形状</h4><blockquote>\n<p>Number of training examples: 209<br>Number of testing examples: 50<br>Each image is of size: (64, 64, 3)<br>train_x_orig shape: (209, 64, 64, 3)<br>train_y shape: (1, 209)<br>test_x_orig shape: (50, 64, 64, 3)<br>test_y shape: (1, 50)</p>\n</blockquote>\n<h4 id=\"展示数据图片\"><a href=\"#展示数据图片\" class=\"headerlink\" title=\"展示数据图片\"></a>展示数据图片</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">index = <span class=\"number\">7</span></span><br><span class=\"line\">plt.imshow(train_x_orig[index])</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"y = \"</span> + str(train_y[<span class=\"number\">0</span>,index]) + <span class=\"string\">\". It's a \"</span> + classes[train_y[<span class=\"number\">0</span>,index]].decode(<span class=\"string\">\"utf-8\"</span>) +  <span class=\"string\">\" picture.\"</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h4 id=\"图像矩阵向量化\"><a href=\"#图像矩阵向量化\" class=\"headerlink\" title=\"图像矩阵向量化\"></a>图像矩阵向量化</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Reshape the training and test examples</span></span><br><span class=\"line\">train_x_flatten = train_x_orig.reshape(train_x_orig.shape[<span class=\"number\">0</span>], <span class=\"number\">-1</span>).T   <span class=\"comment\"># The \"-1\" makes reshape flatten the remaining dimensions</span></span><br><span class=\"line\">test_x_flatten = test_x_orig.reshape(test_x_orig.shape[<span class=\"number\">0</span>], <span class=\"number\">-1</span>).T</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Standardize data to have feature values between 0 and 1.</span></span><br><span class=\"line\">train_x = train_x_flatten/<span class=\"number\">255.</span></span><br><span class=\"line\">test_x = test_x_flatten/<span class=\"number\">255.</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"数据集最终形状\"><a href=\"#数据集最终形状\" class=\"headerlink\" title=\"数据集最终形状\"></a>数据集最终形状</h4><blockquote>\n<p>train_x’s shape: (12288, 209)<br>test_x’s shape: (12288, 50)</p>\n</blockquote>\n<h3 id=\"网络设计\"><a href=\"#网络设计\" class=\"headerlink\" title=\"网络设计\"></a>网络设计</h3><ol>\n<li>初始化参数 / 定义超参数</li>\n<li>迭代循环:<br> a. 前向传播<br> b. 计算代价函数<br> c. 反向传播<br> d. 更新参数</li>\n<li>使用训练的参数去预测新的数据标签</li>\n</ol>\n<p>网络主框架代码，其他细节函数参见“神经网络中的通用函数代码”</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L_layer_model</span><span class=\"params\">(X, Y, layers_dims, learning_rate=<span class=\"number\">0.0075</span>, num_iterations=<span class=\"number\">3000</span>, print_cost=False)</span>:</span>  <span class=\"comment\"># lr was 0.009</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implements a L-layer neural network: [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- learning rate of the gradient descent update rule</span></span><br><span class=\"line\"><span class=\"string\">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class=\"line\"><span class=\"string\">    print_cost -- if True, it prints the cost every 100 steps</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    costs = []                         <span class=\"comment\"># keep track of cost</span></span><br><span class=\"line\">    <span class=\"comment\"># Parameters initialization.</span></span><br><span class=\"line\">    parameters = initialize_parameters_deep(layers_dims)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Loop (gradient descent)</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_iterations):</span><br><span class=\"line\">        <span class=\"comment\"># Forward propagation: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class=\"line\">        AL, caches = L_model_forward(X, parameters)</span><br><span class=\"line\">        <span class=\"comment\"># Compute cost.</span></span><br><span class=\"line\">        cost = compute_cost(AL, Y)</span><br><span class=\"line\">        <span class=\"comment\"># Backward propagation.</span></span><br><span class=\"line\">        grads = L_model_backward(AL, Y, caches)</span><br><span class=\"line\">        <span class=\"comment\"># Update parameters.</span></span><br><span class=\"line\">        parameters = update_parameters(parameters, grads, learning_rate=<span class=\"number\">0.0075</span>)</span><br><span class=\"line\">        <span class=\"comment\"># Print the cost every 100 training example</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            print(<span class=\"string\">\"Cost after iteration %i: %f\"</span> % (i, cost))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            costs.append(cost)</span><br><span class=\"line\">    <span class=\"comment\"># plot the cost</span></span><br><span class=\"line\">    plt.plot(np.squeeze(costs))</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">'cost'</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">'iterations (per tens)'</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">\"Learning rate =\"</span> + str(learning_rate))</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br></pre></td></tr></table></figure>\n<h2 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h2><h3 id=\"训练集结果\"><a href=\"#训练集结果\" class=\"headerlink\" title=\"训练集结果\"></a>训练集结果</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">layers_dims = [<span class=\"number\">12288</span>, <span class=\"number\">20</span>, <span class=\"number\">7</span>, <span class=\"number\">5</span>, <span class=\"number\">1</span>] <span class=\"comment\">#  5-layer model</span></span><br><span class=\"line\">parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = <span class=\"number\">2500</span>, print_cost = <span class=\"keyword\">True</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/images/res1.PNG\" alt=\"\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pred_train = predict(train_x, train_y, parameters)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Accuracy: 0.9856459330143539</p>\n</blockquote>\n<h3 id=\"测试集结果\"><a href=\"#测试集结果\" class=\"headerlink\" title=\"测试集结果\"></a>测试集结果</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pred_test = predict(test_x, test_y, parameters)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Accuracy: 0.8</p>\n</blockquote>\n<h3 id=\"数据集外结果\"><a href=\"#数据集外结果\" class=\"headerlink\" title=\"数据集外结果\"></a>数据集外结果</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scipy <span class=\"keyword\">import</span> ndimage</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy.misc</span><br><span class=\"line\"></span><br><span class=\"line\">my_image = <span class=\"string\">\"my_image.jpg\"</span></span><br><span class=\"line\">my_label_y = [<span class=\"number\">0</span>]</span><br><span class=\"line\">fname = <span class=\"string\">\"images/\"</span> + my_image</span><br><span class=\"line\">image = np.array(ndimage.imread(fname, flatten=<span class=\"keyword\">False</span>))</span><br><span class=\"line\">my_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((num_px * num_px * <span class=\"number\">3</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">my_predicted_image = predict(my_image, my_label_y, parameters)</span><br><span class=\"line\">plt.imshow(image)</span><br><span class=\"line\">print(<span class=\"string\">\"y = \"</span> + str(np.squeeze(my_predicted_image)) + <span class=\"string\">\", your L-layer model predicts a \\\"\"</span> + classes[int(np.squeeze(my_predicted_image)), ].decode(<span class=\"string\">\"utf-8\"</span>) + <span class=\"string\">\"\\\" picture.\"</span>)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Accuracy: 1.0<br>y = 1.0, your L-layer model predicts a “cat” picture.</p>\n</blockquote>\n<p><img src=\"/images/my_image.jpg\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"实验目的\"><a href=\"#实验目的\" class=\"headerlink\" title=\"实验目的\"></a>实验目的</h2><p>使用深层全连接神经网络识别一副图片是否为猫，并将网络层数及每层单元数设为超参数。</p>\n<h2 id=\"实验方案\"><a href=\"#实验方案\" class=\"headerlink\" title=\"实验方案\"></a>实验方案</h2><ul>\n<li>使用python自行编码各运算单元，主要借助numpy库的数据结构和运算函数。</li>\n<li>各个隐藏层采用Relu激活函数，输出层采用Sigmod激活函数，隐藏层使用dropout处理</li>\n<li>损失函数采用交叉熵，并使用L2正则化</li>\n<li>网络架构<br><img src=\"/images/LlayerNN.png\" alt=\"\"></li>\n</ul>\n<h2 id=\"详细设计\"><a href=\"#详细设计\" class=\"headerlink\" title=\"详细设计\"></a>详细设计</h2><h3 id=\"数据预处理\"><a href=\"#数据预处理\" class=\"headerlink\" title=\"数据预处理\"></a>数据预处理</h3><h4 id=\"加载数据\"><a href=\"#加载数据\" class=\"headerlink\" title=\"加载数据\"></a>加载数据</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> h5py</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_data</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    train_dataset = h5py.File(<span class=\"string\">'datasets/train_catvnoncat.h5'</span>, <span class=\"string\">\"r\"</span>)</span><br><span class=\"line\">    train_set_x_orig = np.array(train_dataset[<span class=\"string\">\"train_set_x\"</span>][:])  <span class=\"comment\"># your train set features</span></span><br><span class=\"line\">    train_set_y_orig = np.array(train_dataset[<span class=\"string\">\"train_set_y\"</span>][:])  <span class=\"comment\"># your train set labels</span></span><br><span class=\"line\"></span><br><span class=\"line\">    test_dataset = h5py.File(<span class=\"string\">'datasets/test_catvnoncat.h5'</span>, <span class=\"string\">\"r\"</span>)</span><br><span class=\"line\">    test_set_x_orig = np.array(test_dataset[<span class=\"string\">\"test_set_x\"</span>][:])  <span class=\"comment\"># your test set features</span></span><br><span class=\"line\">    test_set_y_orig = np.array(test_dataset[<span class=\"string\">\"test_set_y\"</span>][:])  <span class=\"comment\"># your test set labels</span></span><br><span class=\"line\"></span><br><span class=\"line\">    classes = np.array(test_dataset[<span class=\"string\">\"list_classes\"</span>][:])  <span class=\"comment\"># the list of classes</span></span><br><span class=\"line\">    train_set_y_orig = train_set_y_orig.reshape((<span class=\"number\">1</span>, train_set_y_orig.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">    test_set_y_orig = test_set_y_orig.reshape((<span class=\"number\">1</span>, test_set_y_orig.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_x_orig, train_y, test_x_orig, test_y, classes = load_data()</span><br></pre></td></tr></table></figure>\n<h4 id=\"数据集形状\"><a href=\"#数据集形状\" class=\"headerlink\" title=\"数据集形状\"></a>数据集形状</h4><blockquote>\n<p>Number of training examples: 209<br>Number of testing examples: 50<br>Each image is of size: (64, 64, 3)<br>train_x_orig shape: (209, 64, 64, 3)<br>train_y shape: (1, 209)<br>test_x_orig shape: (50, 64, 64, 3)<br>test_y shape: (1, 50)</p>\n</blockquote>\n<h4 id=\"展示数据图片\"><a href=\"#展示数据图片\" class=\"headerlink\" title=\"展示数据图片\"></a>展示数据图片</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">index = <span class=\"number\">7</span></span><br><span class=\"line\">plt.imshow(train_x_orig[index])</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"y = \"</span> + str(train_y[<span class=\"number\">0</span>,index]) + <span class=\"string\">\". It's a \"</span> + classes[train_y[<span class=\"number\">0</span>,index]].decode(<span class=\"string\">\"utf-8\"</span>) +  <span class=\"string\">\" picture.\"</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h4 id=\"图像矩阵向量化\"><a href=\"#图像矩阵向量化\" class=\"headerlink\" title=\"图像矩阵向量化\"></a>图像矩阵向量化</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Reshape the training and test examples</span></span><br><span class=\"line\">train_x_flatten = train_x_orig.reshape(train_x_orig.shape[<span class=\"number\">0</span>], <span class=\"number\">-1</span>).T   <span class=\"comment\"># The \"-1\" makes reshape flatten the remaining dimensions</span></span><br><span class=\"line\">test_x_flatten = test_x_orig.reshape(test_x_orig.shape[<span class=\"number\">0</span>], <span class=\"number\">-1</span>).T</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Standardize data to have feature values between 0 and 1.</span></span><br><span class=\"line\">train_x = train_x_flatten/<span class=\"number\">255.</span></span><br><span class=\"line\">test_x = test_x_flatten/<span class=\"number\">255.</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"数据集最终形状\"><a href=\"#数据集最终形状\" class=\"headerlink\" title=\"数据集最终形状\"></a>数据集最终形状</h4><blockquote>\n<p>train_x’s shape: (12288, 209)<br>test_x’s shape: (12288, 50)</p>\n</blockquote>\n<h3 id=\"网络设计\"><a href=\"#网络设计\" class=\"headerlink\" title=\"网络设计\"></a>网络设计</h3><ol>\n<li>初始化参数 / 定义超参数</li>\n<li>迭代循环:<br> a. 前向传播<br> b. 计算代价函数<br> c. 反向传播<br> d. 更新参数</li>\n<li>使用训练的参数去预测新的数据标签</li>\n</ol>\n<p>网络主框架代码，其他细节函数参见“神经网络中的通用函数代码”</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L_layer_model</span><span class=\"params\">(X, Y, layers_dims, learning_rate=<span class=\"number\">0.0075</span>, num_iterations=<span class=\"number\">3000</span>, print_cost=False)</span>:</span>  <span class=\"comment\"># lr was 0.009</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implements a L-layer neural network: [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- learning rate of the gradient descent update rule</span></span><br><span class=\"line\"><span class=\"string\">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class=\"line\"><span class=\"string\">    print_cost -- if True, it prints the cost every 100 steps</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    costs = []                         <span class=\"comment\"># keep track of cost</span></span><br><span class=\"line\">    <span class=\"comment\"># Parameters initialization.</span></span><br><span class=\"line\">    parameters = initialize_parameters_deep(layers_dims)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Loop (gradient descent)</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_iterations):</span><br><span class=\"line\">        <span class=\"comment\"># Forward propagation: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class=\"line\">        AL, caches = L_model_forward(X, parameters)</span><br><span class=\"line\">        <span class=\"comment\"># Compute cost.</span></span><br><span class=\"line\">        cost = compute_cost(AL, Y)</span><br><span class=\"line\">        <span class=\"comment\"># Backward propagation.</span></span><br><span class=\"line\">        grads = L_model_backward(AL, Y, caches)</span><br><span class=\"line\">        <span class=\"comment\"># Update parameters.</span></span><br><span class=\"line\">        parameters = update_parameters(parameters, grads, learning_rate=<span class=\"number\">0.0075</span>)</span><br><span class=\"line\">        <span class=\"comment\"># Print the cost every 100 training example</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            print(<span class=\"string\">\"Cost after iteration %i: %f\"</span> % (i, cost))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            costs.append(cost)</span><br><span class=\"line\">    <span class=\"comment\"># plot the cost</span></span><br><span class=\"line\">    plt.plot(np.squeeze(costs))</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">'cost'</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">'iterations (per tens)'</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">\"Learning rate =\"</span> + str(learning_rate))</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br></pre></td></tr></table></figure>\n<h2 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h2><h3 id=\"训练集结果\"><a href=\"#训练集结果\" class=\"headerlink\" title=\"训练集结果\"></a>训练集结果</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">layers_dims = [<span class=\"number\">12288</span>, <span class=\"number\">20</span>, <span class=\"number\">7</span>, <span class=\"number\">5</span>, <span class=\"number\">1</span>] <span class=\"comment\">#  5-layer model</span></span><br><span class=\"line\">parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = <span class=\"number\">2500</span>, print_cost = <span class=\"keyword\">True</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/images/res1.PNG\" alt=\"\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pred_train = predict(train_x, train_y, parameters)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Accuracy: 0.9856459330143539</p>\n</blockquote>\n<h3 id=\"测试集结果\"><a href=\"#测试集结果\" class=\"headerlink\" title=\"测试集结果\"></a>测试集结果</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pred_test = predict(test_x, test_y, parameters)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Accuracy: 0.8</p>\n</blockquote>\n<h3 id=\"数据集外结果\"><a href=\"#数据集外结果\" class=\"headerlink\" title=\"数据集外结果\"></a>数据集外结果</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scipy <span class=\"keyword\">import</span> ndimage</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy.misc</span><br><span class=\"line\"></span><br><span class=\"line\">my_image = <span class=\"string\">\"my_image.jpg\"</span></span><br><span class=\"line\">my_label_y = [<span class=\"number\">0</span>]</span><br><span class=\"line\">fname = <span class=\"string\">\"images/\"</span> + my_image</span><br><span class=\"line\">image = np.array(ndimage.imread(fname, flatten=<span class=\"keyword\">False</span>))</span><br><span class=\"line\">my_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((num_px * num_px * <span class=\"number\">3</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">my_predicted_image = predict(my_image, my_label_y, parameters)</span><br><span class=\"line\">plt.imshow(image)</span><br><span class=\"line\">print(<span class=\"string\">\"y = \"</span> + str(np.squeeze(my_predicted_image)) + <span class=\"string\">\", your L-layer model predicts a \\\"\"</span> + classes[int(np.squeeze(my_predicted_image)), ].decode(<span class=\"string\">\"utf-8\"</span>) + <span class=\"string\">\"\\\" picture.\"</span>)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Accuracy: 1.0<br>y = 1.0, your L-layer model predicts a “cat” picture.</p>\n</blockquote>\n<p><img src=\"/images/my_image.jpg\" alt=\"\"></p>\n"},{"title":"Genetic Algorithms","date":"2018-08-05T14:14:07.000Z","_content":"\n## Biology Background\n\n- Gene: A working subunit of DNA\n- Gene Trait(性状基因): For example colour of eyes\n- Allele(等位基因): Possible settings for a trait\n- Genotype(基因型): The actual genes carried by an individual\n- Phenotype(性状型): The physical characteristics into which genes are translated\n\n## Genetic Algorithms\n\nBy John Holland: \"Adaptation in Natural and Artificial Systems\"\n\n### Inspired by and (loosely) based on Darwin's Theory\n\n- Chromosome(染色体)\n- Crossover(交叉)\n- Mutation(变异)\n- Selection(Survival of the Fittest)\n\n### Basic Ideas\n\n- Each solution to the problem is represented as a chromosome.\n- The initial solutions may be randomly generated.\n- Solution are evolved during generations.\n- Improved gradually based on the principle of natural evolution.\n\n### Basic Components\n\n#### Representation\n\n- How to encode the parameters of the problem?\n- Binary Problems\n- Continuous Problems\n\n1. Individual(Chromosome)\n\nA vector that represents a specific solution to the problem.Each element on the vector corresponds to a certain variable/parameter.\n\n2. Population\n\nA set of individuals, GAs maintain and evolve a population of individuals, Parallel Search to get Global Optimization.\n\n3. Offspring\n\nNew individuals generated via genetic operators. Hopefully contain better solutions.\n\n4. Encoding\n\nBinary vs. Gray. How to encode TSP problems?\n\n#### Genetic Operators\n\n1. Crossover:\n\tExchange genetic materials between two chromosomes.\n\t- One Point Crossover\n\t- Two Point Crossover\n\t- Uniform Crossover\n \n2. Mutation:\n\tRandomly modify gene values at selected locations.Mutation is mainly used to maintain the genetiv divesity.Loss of genetic diversity will result in Permature Convergence.\n\n#### Selection Strategy\n\n- Which chromosomes should be involved in reproduction?\n- Which offspring should be able to survive?\n\n1. Roulette Wheel Selection: 根据适应度的高低按比例选择\n2. Rank Selection： 根据排名按固定比例选择\n3. Tournament Selection: 两两及以上互相竞争\n4. Elitism: 精英保留直接拷贝到下一代\n5. Offspring Selection: 子代直接进入下一代还是与父代一起竞争\n\n### Selection vs. Crossover vs. Mutation\n\n- Selection:\n\t- Bias the search effort towards promising individuals.\n\t- Loss of genetic diversity\n\n- Cossover:\n\t- Create better individuals by combining genes from good individuals\n\t- Building Block Hypothesis\n\t- Major search power of GAs\n\t- No effect on genetic diversity\n\n- Mutation:\n\t- Increase genetic diversity\n\t- Force the algorithm to search areas other than the current focus.\n\n**It is a trade off about Exploration vs. Exploitation**\n\n## GA Framework\n\n1. Intialization: Generate a random population P of M individuals\n2. Evaluation: Evaluate the fitness f(x) of each individual\n3. Repeat until the stopping criteria are met:\n\t1. Reproduction: Repeat the following steps until all offspring are generated\n\t\t1. Paraent Selection: Select two parents from P\n\t\t2. Crossover: Apply crossover on the parents with probability P_c\n\t\t3. Mutation: Apply mutation on offspring with probability P_m\n\t\t4. Evaluation: Evaluate the newly generated offspring\n\t2. Offspring Selection: Create a new population from oddspring and P\n\t3. Output: Return the best individual found\n\n## Parameters\n\n- Population Size:\n\tToo big: Slow convergence rate. Too small: Premature convergence\n\n- Crossover Rate:\n\tRecommended value: 0.8\n\n- Mutation Rate:\n\tRecommeded value: 1/L. Too big: Disrupt the evolution process. Too small: Not enough to maintain diversity.\n\n- Selection Strategy:\n\tTournament Selection. Truncation Selection(Select top T individuals). Need to be careful about the selection pressure.\n","source":"_posts/Genetic-Algorithms.md","raw":"---\ntitle: Genetic Algorithms\ndate: 2018-08-05 22:14:07\ntags: 遗传算法\ncategories: 进化计算\n---\n\n## Biology Background\n\n- Gene: A working subunit of DNA\n- Gene Trait(性状基因): For example colour of eyes\n- Allele(等位基因): Possible settings for a trait\n- Genotype(基因型): The actual genes carried by an individual\n- Phenotype(性状型): The physical characteristics into which genes are translated\n\n## Genetic Algorithms\n\nBy John Holland: \"Adaptation in Natural and Artificial Systems\"\n\n### Inspired by and (loosely) based on Darwin's Theory\n\n- Chromosome(染色体)\n- Crossover(交叉)\n- Mutation(变异)\n- Selection(Survival of the Fittest)\n\n### Basic Ideas\n\n- Each solution to the problem is represented as a chromosome.\n- The initial solutions may be randomly generated.\n- Solution are evolved during generations.\n- Improved gradually based on the principle of natural evolution.\n\n### Basic Components\n\n#### Representation\n\n- How to encode the parameters of the problem?\n- Binary Problems\n- Continuous Problems\n\n1. Individual(Chromosome)\n\nA vector that represents a specific solution to the problem.Each element on the vector corresponds to a certain variable/parameter.\n\n2. Population\n\nA set of individuals, GAs maintain and evolve a population of individuals, Parallel Search to get Global Optimization.\n\n3. Offspring\n\nNew individuals generated via genetic operators. Hopefully contain better solutions.\n\n4. Encoding\n\nBinary vs. Gray. How to encode TSP problems?\n\n#### Genetic Operators\n\n1. Crossover:\n\tExchange genetic materials between two chromosomes.\n\t- One Point Crossover\n\t- Two Point Crossover\n\t- Uniform Crossover\n \n2. Mutation:\n\tRandomly modify gene values at selected locations.Mutation is mainly used to maintain the genetiv divesity.Loss of genetic diversity will result in Permature Convergence.\n\n#### Selection Strategy\n\n- Which chromosomes should be involved in reproduction?\n- Which offspring should be able to survive?\n\n1. Roulette Wheel Selection: 根据适应度的高低按比例选择\n2. Rank Selection： 根据排名按固定比例选择\n3. Tournament Selection: 两两及以上互相竞争\n4. Elitism: 精英保留直接拷贝到下一代\n5. Offspring Selection: 子代直接进入下一代还是与父代一起竞争\n\n### Selection vs. Crossover vs. Mutation\n\n- Selection:\n\t- Bias the search effort towards promising individuals.\n\t- Loss of genetic diversity\n\n- Cossover:\n\t- Create better individuals by combining genes from good individuals\n\t- Building Block Hypothesis\n\t- Major search power of GAs\n\t- No effect on genetic diversity\n\n- Mutation:\n\t- Increase genetic diversity\n\t- Force the algorithm to search areas other than the current focus.\n\n**It is a trade off about Exploration vs. Exploitation**\n\n## GA Framework\n\n1. Intialization: Generate a random population P of M individuals\n2. Evaluation: Evaluate the fitness f(x) of each individual\n3. Repeat until the stopping criteria are met:\n\t1. Reproduction: Repeat the following steps until all offspring are generated\n\t\t1. Paraent Selection: Select two parents from P\n\t\t2. Crossover: Apply crossover on the parents with probability P_c\n\t\t3. Mutation: Apply mutation on offspring with probability P_m\n\t\t4. Evaluation: Evaluate the newly generated offspring\n\t2. Offspring Selection: Create a new population from oddspring and P\n\t3. Output: Return the best individual found\n\n## Parameters\n\n- Population Size:\n\tToo big: Slow convergence rate. Too small: Premature convergence\n\n- Crossover Rate:\n\tRecommended value: 0.8\n\n- Mutation Rate:\n\tRecommeded value: 1/L. Too big: Disrupt the evolution process. Too small: Not enough to maintain diversity.\n\n- Selection Strategy:\n\tTournament Selection. Truncation Selection(Select top T individuals). Need to be careful about the selection pressure.\n","slug":"Genetic-Algorithms","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds1l000cpcvo52u7grpb","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Biology-Background\"><a href=\"#Biology-Background\" class=\"headerlink\" title=\"Biology Background\"></a>Biology Background</h2><ul>\n<li>Gene: A working subunit of DNA</li>\n<li>Gene Trait(性状基因): For example colour of eyes</li>\n<li>Allele(等位基因): Possible settings for a trait</li>\n<li>Genotype(基因型): The actual genes carried by an individual</li>\n<li>Phenotype(性状型): The physical characteristics into which genes are translated</li>\n</ul>\n<h2 id=\"Genetic-Algorithms\"><a href=\"#Genetic-Algorithms\" class=\"headerlink\" title=\"Genetic Algorithms\"></a>Genetic Algorithms</h2><p>By John Holland: “Adaptation in Natural and Artificial Systems”</p>\n<h3 id=\"Inspired-by-and-loosely-based-on-Darwin’s-Theory\"><a href=\"#Inspired-by-and-loosely-based-on-Darwin’s-Theory\" class=\"headerlink\" title=\"Inspired by and (loosely) based on Darwin’s Theory\"></a>Inspired by and (loosely) based on Darwin’s Theory</h3><ul>\n<li>Chromosome(染色体)</li>\n<li>Crossover(交叉)</li>\n<li>Mutation(变异)</li>\n<li>Selection(Survival of the Fittest)</li>\n</ul>\n<h3 id=\"Basic-Ideas\"><a href=\"#Basic-Ideas\" class=\"headerlink\" title=\"Basic Ideas\"></a>Basic Ideas</h3><ul>\n<li>Each solution to the problem is represented as a chromosome.</li>\n<li>The initial solutions may be randomly generated.</li>\n<li>Solution are evolved during generations.</li>\n<li>Improved gradually based on the principle of natural evolution.</li>\n</ul>\n<h3 id=\"Basic-Components\"><a href=\"#Basic-Components\" class=\"headerlink\" title=\"Basic Components\"></a>Basic Components</h3><h4 id=\"Representation\"><a href=\"#Representation\" class=\"headerlink\" title=\"Representation\"></a>Representation</h4><ul>\n<li>How to encode the parameters of the problem?</li>\n<li>Binary Problems</li>\n<li>Continuous Problems</li>\n</ul>\n<ol>\n<li>Individual(Chromosome)</li>\n</ol>\n<p>A vector that represents a specific solution to the problem.Each element on the vector corresponds to a certain variable/parameter.</p>\n<ol start=\"2\">\n<li>Population</li>\n</ol>\n<p>A set of individuals, GAs maintain and evolve a population of individuals, Parallel Search to get Global Optimization.</p>\n<ol start=\"3\">\n<li>Offspring</li>\n</ol>\n<p>New individuals generated via genetic operators. Hopefully contain better solutions.</p>\n<ol start=\"4\">\n<li>Encoding</li>\n</ol>\n<p>Binary vs. Gray. How to encode TSP problems?</p>\n<h4 id=\"Genetic-Operators\"><a href=\"#Genetic-Operators\" class=\"headerlink\" title=\"Genetic Operators\"></a>Genetic Operators</h4><ol>\n<li><p>Crossover:<br> Exchange genetic materials between two chromosomes.</p>\n<ul>\n<li>One Point Crossover</li>\n<li>Two Point Crossover</li>\n<li>Uniform Crossover</li>\n</ul>\n</li>\n<li><p>Mutation:<br> Randomly modify gene values at selected locations.Mutation is mainly used to maintain the genetiv divesity.Loss of genetic diversity will result in Permature Convergence.</p>\n</li>\n</ol>\n<h4 id=\"Selection-Strategy\"><a href=\"#Selection-Strategy\" class=\"headerlink\" title=\"Selection Strategy\"></a>Selection Strategy</h4><ul>\n<li>Which chromosomes should be involved in reproduction?</li>\n<li>Which offspring should be able to survive?</li>\n</ul>\n<ol>\n<li>Roulette Wheel Selection: 根据适应度的高低按比例选择</li>\n<li>Rank Selection： 根据排名按固定比例选择</li>\n<li>Tournament Selection: 两两及以上互相竞争</li>\n<li>Elitism: 精英保留直接拷贝到下一代</li>\n<li>Offspring Selection: 子代直接进入下一代还是与父代一起竞争</li>\n</ol>\n<h3 id=\"Selection-vs-Crossover-vs-Mutation\"><a href=\"#Selection-vs-Crossover-vs-Mutation\" class=\"headerlink\" title=\"Selection vs. Crossover vs. Mutation\"></a>Selection vs. Crossover vs. Mutation</h3><ul>\n<li><p>Selection:</p>\n<ul>\n<li>Bias the search effort towards promising individuals.</li>\n<li>Loss of genetic diversity</li>\n</ul>\n</li>\n<li><p>Cossover:</p>\n<ul>\n<li>Create better individuals by combining genes from good individuals</li>\n<li>Building Block Hypothesis</li>\n<li>Major search power of GAs</li>\n<li>No effect on genetic diversity</li>\n</ul>\n</li>\n<li><p>Mutation:</p>\n<ul>\n<li>Increase genetic diversity</li>\n<li>Force the algorithm to search areas other than the current focus.</li>\n</ul>\n</li>\n</ul>\n<p><strong>It is a trade off about Exploration vs. Exploitation</strong></p>\n<h2 id=\"GA-Framework\"><a href=\"#GA-Framework\" class=\"headerlink\" title=\"GA Framework\"></a>GA Framework</h2><ol>\n<li>Intialization: Generate a random population P of M individuals</li>\n<li>Evaluation: Evaluate the fitness f(x) of each individual</li>\n<li>Repeat until the stopping criteria are met:<ol>\n<li>Reproduction: Repeat the following steps until all offspring are generated<ol>\n<li>Paraent Selection: Select two parents from P</li>\n<li>Crossover: Apply crossover on the parents with probability P_c</li>\n<li>Mutation: Apply mutation on offspring with probability P_m</li>\n<li>Evaluation: Evaluate the newly generated offspring</li>\n</ol>\n</li>\n<li>Offspring Selection: Create a new population from oddspring and P</li>\n<li>Output: Return the best individual found</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"Parameters\"><a href=\"#Parameters\" class=\"headerlink\" title=\"Parameters\"></a>Parameters</h2><ul>\n<li><p>Population Size:<br>  Too big: Slow convergence rate. Too small: Premature convergence</p>\n</li>\n<li><p>Crossover Rate:<br>  Recommended value: 0.8</p>\n</li>\n<li><p>Mutation Rate:<br>  Recommeded value: 1/L. Too big: Disrupt the evolution process. Too small: Not enough to maintain diversity.</p>\n</li>\n<li><p>Selection Strategy:<br>  Tournament Selection. Truncation Selection(Select top T individuals). Need to be careful about the selection pressure.</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Biology-Background\"><a href=\"#Biology-Background\" class=\"headerlink\" title=\"Biology Background\"></a>Biology Background</h2><ul>\n<li>Gene: A working subunit of DNA</li>\n<li>Gene Trait(性状基因): For example colour of eyes</li>\n<li>Allele(等位基因): Possible settings for a trait</li>\n<li>Genotype(基因型): The actual genes carried by an individual</li>\n<li>Phenotype(性状型): The physical characteristics into which genes are translated</li>\n</ul>\n<h2 id=\"Genetic-Algorithms\"><a href=\"#Genetic-Algorithms\" class=\"headerlink\" title=\"Genetic Algorithms\"></a>Genetic Algorithms</h2><p>By John Holland: “Adaptation in Natural and Artificial Systems”</p>\n<h3 id=\"Inspired-by-and-loosely-based-on-Darwin’s-Theory\"><a href=\"#Inspired-by-and-loosely-based-on-Darwin’s-Theory\" class=\"headerlink\" title=\"Inspired by and (loosely) based on Darwin’s Theory\"></a>Inspired by and (loosely) based on Darwin’s Theory</h3><ul>\n<li>Chromosome(染色体)</li>\n<li>Crossover(交叉)</li>\n<li>Mutation(变异)</li>\n<li>Selection(Survival of the Fittest)</li>\n</ul>\n<h3 id=\"Basic-Ideas\"><a href=\"#Basic-Ideas\" class=\"headerlink\" title=\"Basic Ideas\"></a>Basic Ideas</h3><ul>\n<li>Each solution to the problem is represented as a chromosome.</li>\n<li>The initial solutions may be randomly generated.</li>\n<li>Solution are evolved during generations.</li>\n<li>Improved gradually based on the principle of natural evolution.</li>\n</ul>\n<h3 id=\"Basic-Components\"><a href=\"#Basic-Components\" class=\"headerlink\" title=\"Basic Components\"></a>Basic Components</h3><h4 id=\"Representation\"><a href=\"#Representation\" class=\"headerlink\" title=\"Representation\"></a>Representation</h4><ul>\n<li>How to encode the parameters of the problem?</li>\n<li>Binary Problems</li>\n<li>Continuous Problems</li>\n</ul>\n<ol>\n<li>Individual(Chromosome)</li>\n</ol>\n<p>A vector that represents a specific solution to the problem.Each element on the vector corresponds to a certain variable/parameter.</p>\n<ol start=\"2\">\n<li>Population</li>\n</ol>\n<p>A set of individuals, GAs maintain and evolve a population of individuals, Parallel Search to get Global Optimization.</p>\n<ol start=\"3\">\n<li>Offspring</li>\n</ol>\n<p>New individuals generated via genetic operators. Hopefully contain better solutions.</p>\n<ol start=\"4\">\n<li>Encoding</li>\n</ol>\n<p>Binary vs. Gray. How to encode TSP problems?</p>\n<h4 id=\"Genetic-Operators\"><a href=\"#Genetic-Operators\" class=\"headerlink\" title=\"Genetic Operators\"></a>Genetic Operators</h4><ol>\n<li><p>Crossover:<br> Exchange genetic materials between two chromosomes.</p>\n<ul>\n<li>One Point Crossover</li>\n<li>Two Point Crossover</li>\n<li>Uniform Crossover</li>\n</ul>\n</li>\n<li><p>Mutation:<br> Randomly modify gene values at selected locations.Mutation is mainly used to maintain the genetiv divesity.Loss of genetic diversity will result in Permature Convergence.</p>\n</li>\n</ol>\n<h4 id=\"Selection-Strategy\"><a href=\"#Selection-Strategy\" class=\"headerlink\" title=\"Selection Strategy\"></a>Selection Strategy</h4><ul>\n<li>Which chromosomes should be involved in reproduction?</li>\n<li>Which offspring should be able to survive?</li>\n</ul>\n<ol>\n<li>Roulette Wheel Selection: 根据适应度的高低按比例选择</li>\n<li>Rank Selection： 根据排名按固定比例选择</li>\n<li>Tournament Selection: 两两及以上互相竞争</li>\n<li>Elitism: 精英保留直接拷贝到下一代</li>\n<li>Offspring Selection: 子代直接进入下一代还是与父代一起竞争</li>\n</ol>\n<h3 id=\"Selection-vs-Crossover-vs-Mutation\"><a href=\"#Selection-vs-Crossover-vs-Mutation\" class=\"headerlink\" title=\"Selection vs. Crossover vs. Mutation\"></a>Selection vs. Crossover vs. Mutation</h3><ul>\n<li><p>Selection:</p>\n<ul>\n<li>Bias the search effort towards promising individuals.</li>\n<li>Loss of genetic diversity</li>\n</ul>\n</li>\n<li><p>Cossover:</p>\n<ul>\n<li>Create better individuals by combining genes from good individuals</li>\n<li>Building Block Hypothesis</li>\n<li>Major search power of GAs</li>\n<li>No effect on genetic diversity</li>\n</ul>\n</li>\n<li><p>Mutation:</p>\n<ul>\n<li>Increase genetic diversity</li>\n<li>Force the algorithm to search areas other than the current focus.</li>\n</ul>\n</li>\n</ul>\n<p><strong>It is a trade off about Exploration vs. Exploitation</strong></p>\n<h2 id=\"GA-Framework\"><a href=\"#GA-Framework\" class=\"headerlink\" title=\"GA Framework\"></a>GA Framework</h2><ol>\n<li>Intialization: Generate a random population P of M individuals</li>\n<li>Evaluation: Evaluate the fitness f(x) of each individual</li>\n<li>Repeat until the stopping criteria are met:<ol>\n<li>Reproduction: Repeat the following steps until all offspring are generated<ol>\n<li>Paraent Selection: Select two parents from P</li>\n<li>Crossover: Apply crossover on the parents with probability P_c</li>\n<li>Mutation: Apply mutation on offspring with probability P_m</li>\n<li>Evaluation: Evaluate the newly generated offspring</li>\n</ol>\n</li>\n<li>Offspring Selection: Create a new population from oddspring and P</li>\n<li>Output: Return the best individual found</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"Parameters\"><a href=\"#Parameters\" class=\"headerlink\" title=\"Parameters\"></a>Parameters</h2><ul>\n<li><p>Population Size:<br>  Too big: Slow convergence rate. Too small: Premature convergence</p>\n</li>\n<li><p>Crossover Rate:<br>  Recommended value: 0.8</p>\n</li>\n<li><p>Mutation Rate:<br>  Recommeded value: 1/L. Too big: Disrupt the evolution process. Too small: Not enough to maintain diversity.</p>\n</li>\n<li><p>Selection Strategy:<br>  Tournament Selection. Truncation Selection(Select top T individuals). Need to be careful about the selection pressure.</p>\n</li>\n</ul>\n"},{"title":"Deep Residual Learning for Image Recognition","date":"2018-09-25T07:02:35.000Z","mathjax":true,"_content":"## 摘要\n\n更深的神经网络往往更难以训练，我们提出一个 **残差学习框架**，使训练比以往更深的网络变得更加轻松。我们明确地将这些层重新规划为 **学习与层的输入有关的残差函数**，而不是学习不相关的函数。我们提供了非常全面的实验数据来证明，残差网络更容易优化，并且可以在深度增加的情况下让精度也增加。在ImageNet的数据集上我们评测了一个深度152层（是VGG的8倍）的残差网络，但依旧拥有比VGG更低的复杂度。这些残差网络在ImageNet测试集达到了3.57%的错误率，这个结果获得了ILSVRC2015的分类任务第一名，我们还用CIFAR-10数据集分析了100层和1000层的网络。\n\n对于很多视觉识别任务来说，**表示的深度** 是至关重要的。我们极深的网络让我们在COCO的目标检测数据集上得到了28%的相对提升。同时，深度残差网络也是提交参加ILSVRC和COCO2015比赛的基础。我们还赢得了ImageNet目标检测、ImageNet目标定位、COCO目标检测和COCO图像分割等任务的第一名。\n\n## 简介\n\n深度卷积神经网络给图像分类问题上的研究带来了很多突破，深层网络自然地将 **低/中/高级的特征和分类器集成到端到端的多层方式中**，而特征的“层次”可以通过叠加层(深度)的数量来丰富。最近的证据表明，网络深度是至关重要的，而具有挑战性的ImageNet数据集的主要结果都利用了“非常深”的模型，深度为16到30。其他一些计算机视觉的问题也受益于非常深的网络模型。\n\n受到深度的重要性的驱动，出现了这样一个问题：**学习更好的网络就像堆叠更多的层一样容易吗?** 这个问题的一大障碍就是臭名昭著的梯度消失/爆炸问题，它从网络结构的一开始就阻碍收敛。然而这个问题，很大程度上可以通过 **归一化的初始化** 和 **中间层的归一化** 解决，这个方法确保几十层的网络能够在使用 **随机梯度下降（SGD）** 的后向传播过程中收敛。\n\n当更深的网络能够开始收敛时，一个 **退化问题** 就暴露出来了: **随着网络深度的增加，准确度就会饱和(这可能不足为奇)，然后就会迅速下降。出人意料的，退化问题并不是过拟合导致的，并且增加更多的层反而会导致更大的训练误差**，就像文章[11,42]中说的那样，通过我们的实验也得到证实。图1展示了一个典型的例子。\n\n![](/images/resnet_f1.jpg)\n\n训练精度的退化表明，不是所有的系统都同样容易优化。让我们考虑一个浅层网络和与之对应的增加了更多层的深层网络。有一个方法来构建该深层网络：**额外添加的层都是 恒等映射，其他层则是从训练好的浅层网络复制过来**。这种构造解的存在性表明，更深的网络应该不会比浅层网络产生更高的训练误差。但实验结果表明，我们手头上有的方案都找不到更好或者同样好的解（或者是无法在可接受的时间里做完）。\n\n在本文中，我们通过引入一个 **深度残差学习** 框架解决这个退化问题。我们 **不期望每几个叠加的层直接拟合一个映射，而是明确的让这些层去拟合 残差映射**。更正式的说法是，这里用 $H(X)$ 来表示 **想要得到的潜在映射**，但我们让堆叠的非线性层去拟合另一个映射 $F(X):=H(X)-X$，此时原潜在映射 $H(X)$ 就可以改写成 $F(X)+X$，我们 **假设残差映射跟原映射相比更容易被优化**。现在我们考虑极端情况，如果恒等映射是最优解，那么可以 **相对于用堆叠的非线性层去拟合恒等映射将残差置0更容易些**。\n\n$F(X)+X$ 的公式可以通过在前馈网络中做一个“**快捷连接**”来实现（如图2）。快捷连接跳过一个或多个层。在我们的例子中，快捷连接简单的执行恒等映射，它们的输出被添加到堆叠层的输出中。恒等映射快捷连接既不会增加额外的参数也不会增加计算复杂度。整个网络依然可以通过SGD和反向传播进行端到端训练，并且可以用常见的深度学习库来实现（比如Caffe）无需修改求解器。\n\n![](/images/resnet_f2.PNG)\n\n我们目前用ImageNet的数据集做了很多综合实验，来证实退化问题和评估我们的方法。我们发现：1）我们极深的残差网络易于优化，但当深度增加时，对应的“简单”网络（简单堆叠层）表现出更高的训练误差。2）我们的深度残差网络可以从增加的深度中轻松提高准确性，生成的结果实质上比以前的网络更好。\n\n类似的现象在CIFAR-10数据集的实验中也一样，这表明了优化的困难以及我们的方法不是仅对特定的数据集起作用。我们在这个数据集上应用了成功训练的超过100层的模型，并探索了超过1000层的模型。\n\n在ImageNet对象分类数据集上，我们用深度残差网络获得了很棒的结果，我们152层的残差网络是ImageNet的参赛网络中最深的，然而却拥有比VGG更低的复杂度。我们的模型集合在ImageNet测试集上有3.57% top-5的错误率，并在ILSVRC 2015分类比赛中获得了第一名。**极深的表示在其它识别任务中也有极好的泛化性能**，使我们进一步赢得了多个比赛的第一名包括ILSVRC & COCO 2015竞赛中的ImageNet检测，ImageNet目标定位，COCO目标检测和COCO图像分割，坚实的证据表明残差学习准则是通用的，并且我们期望它适用于其它的视觉和非视觉问题。\n\n## 相关工作\n\n**残差表示**。VLAD是一种通过关于字典的残差向量进行编码的表示形式。**Fisher矢量** 可以认为是VLAD的概率版本。它们都是图像检索和图像分类中强大的浅层表示。对于矢量量化，**编码残差矢量被证明比编码原始矢量更有效**。\n\n在低级视觉和计算机图形学中，为了求解偏微分方程（PDE），广泛使用的 **Multigrid方法** 将系统重构为在多个尺度上的子问题，其中每个子问题负责较粗尺度和较细尺度的残差解。Multigrid的替代方法是 **层次化基础预处理**，它依赖于表示两个尺度之间残差向量的变量。[3,45,46]已经证明比起不知道解的残差性质的标准求解器，这些求解器收敛得更快。这些方法表明好的重构或预处理可以简化优化过程。\n\n**快捷连接**。快捷连接的实践和理论已经被研究了很长时间。训练多层感知机（MLPs）的早期实践是添加一个线性层来连接网络的输入和输出。在[44,24]中，一些中间层直接连接到辅助分类器，用于解决梯度消失/爆炸问题。论文[39,38,31,47]提出了通过快捷连接实现层间响应，梯度和传播误差的方法。在[44]中，一个“inception”层由一个快捷分支和一些更深的分支组成。\n\n和我们同时进行的工作，高速路网络提出了门控函数的快捷连接。这些门依赖数据且有参数，与我们没有参数的恒等快捷连接相反。当门控快捷连接“关闭”（接近零）时，高速路网络中的层表示非残差函数。相反，我们的公式总是学习残差函数；我们的恒等快捷连接永远不会关闭，所有的信息总是通过，还有额外的残差函数要学习。此外，高速路网络还没有证实极度增加的深度（例如，超过100个层）能够提高准确性。\n\n## 深度残差学习\n\n### 残差学习\n\n我们考虑 $H(x)$ 作为几个堆叠层（不必是整个网络）要拟合的潜在映射，$x$ 表示这些层中第一层的输入。假设多个非线性层可以渐近地近似复杂函数，它等价于假设它们可以渐近地近似残差函数，即 $H(x)−x$ (假设输入输出维度相同)。因此，我们明确让这些层近似残差函数 $F(x):= H(x)−x$，而不是期望堆叠层近似 $H(x)$。因此原始函数变为 $F(x)+x$。尽管两种形式应该都能渐近地近似要求的函数（如假设），但学习的难易程度可能是不同的。\n\n这种重构是受到了反直觉的退化问题的激发（图1左）。正如我们在第一部分介绍中讨论的那样，如果添加的层可以被构建为恒等映射，更深模型的训练误差应该不大于它对应的更浅版本。**退化问题表明求解器通过多个非线性层来近似恒等映射可能存在困难**。通过残差学习的重构，如果恒等映射是最优解，求解器可能简单地将多个非线性层的权重置零使其得到恒等映射。\n\n在实际情况下，恒等映射不太可能是最优解，但是我们的重构可能有助于对问题进行预处理。**如果最优函数比零映射更接近于恒等映射，则求解器应该更容易找到关于恒等映射的扰动，而不是将该函数作为新函数来学习**。我们通过实验（图7）显示学习的残差函数通常有更小的响应，表明恒等映射提供了合理的预处理。\n\n![](/images/resnet_f7.PNG)\n\n### 快捷恒等映射\n\n我们每隔几个堆叠层采用残差学习。一个构建块如图2所示。在本文中我们考虑构建块正式定义为：\n\n$y=F(x, \\{W_i\\})+x \\tag{1}$\n\n$x$和$y$是考虑的层的输入和输出向量。函数 $F(x,\\{W_i\\})$ 表示要学习的残差映射。对于图2中的有两层的例子来说，$F = W_2 \\sigma (W_1x)$，其中 $\\sigma$ 表示ReLU，为了简化表达忽略偏置项。$F+x$ 操作通过快捷连接和各个元素相加来执行。在相加之后我们采取了第二个非线性 $\\sigma(y)$（图2）。\n\n方程(1)中的快捷连接既没有引入额外参数又没有增加计算复杂度。这不仅在实践中有吸引力，而且在简单网络和残差网络的比较中也很重要。我们可以公平地比较同时具有相同数量的参数，相同深度，宽度和计算成本的简单/残差网络（除了不可忽略的元素加法之外）。\n\n方程(1)中$x$和$F$的维度必须是相等的。如果不是这种情况（例如，当更改输入/输出通道时），我们可以通过快捷连接执行线性投影$W_s$来匹配维度：\n\n$y=F(x, \\{W_i\\})+W_sx \\tag{2}$\n\n我们也可以在方程(1)中使用方阵$W_s$。但是我们将通过实验表明，恒等映射足以解决退化问题，并且是合算的，因此$W_s$仅在匹配维度时使用。\n\n残差函数$F$的形式是可变的。本文中的实验包括有两层或三层（图5）的函数$F$，也可以有更多的层。但如果$F$只有一层，方程(1)类似于线性层：$y=W_1x+x$，这就没有优势了。\n\n![](/images/resnet_f5.PNG)\n\n我们还注意到尽管上述表达式是关于全连接层的，但它们同样适用于卷积层。函数 $F(x，W_i)$ 可以表示多个卷积层。元素加法在两个特征图上逐通道进行。\n\n### 网络架构\n\n我们测试了各种简单/残差网络，并观察到了一致的现象。为了给讨论举例，我们描述ImageNet的两个模型如下。\n\n![](/images/resnet_f3.jpg)\n\n简单网络。 我们简单网络的基准（图3，中间）主要受到VGG网络（图3，左图）的设计哲学启发。卷积层主要有3×3的滤波器，并遵循两个简单的设计规则：（i）对于相同的输出特征图尺寸，层具有相同数量的滤波器；（ii）如果特征图尺寸减半，则滤波器数量加倍，以便保持每层的时间复杂度。我们通过步长为2的卷积层直接执行下采样。网络以全局平均池化层和具有softmax的1000维全连接层结束。图3（中间）的权重层总数为34。\n\n值得注意的是我们的模型与VGG网络（图3左）相比，有更少的滤波器和更低的复杂度。我们的34层基准有36亿FLOP(乘加)，仅是VGG-19（196亿FLOP）的18%。\n\n残差网络。基于上述的简单网络，我们插入快捷连接（图3，右），将网络转换为其对应的残差版本。当输入和输出具有相同的维度时（图3中的实线快捷连接）时，可以直接使用恒等快捷连接（方程（1））。当维度增加（图3中的虚线快捷连接）时，我们考虑两个选项：（A）快捷连接仍然执行恒等映射，额外填充零输入以增加维度。此选项不会引入额外的参数；（B）方程（2）中的投影快捷连接用于匹配维度（由1×1卷积完成）。对于这两个选项，当快捷连接跨越两种尺寸的特征图时，它们执行时步长为2。\n\n![](/images/resnet_t1.PNG)\n### 实现\n\nImageNet中我们的实现遵循[21，41]的实践。调整图像大小，其较短的边在[256,480]之间进行随机采样，用于尺度增强。使用224×224裁剪从图像或其水平翻转中随机采样，并逐像素减去均值。使用了论文[21]中的标准颜色增强。在每个卷积之后和激活之前，我们采用批量归一化（BN）[16]。我们按照[13]的方法初始化权重，从零开始训练所有的简单/残差网络。我们使用批大小为256的SGD方法。学习速度从0.1开始，当误差稳定时学习率除以10，并且模型训练高达$60×10^4$次迭代。我们使用的权重衰减为0.0001，动量为0.9。根据[16]的实践，我们不使用dropout算法。\n\n在测试阶段，为了比较研究，我们采用标准的10-crop测试[21]。对于最好的结果，我们采用如[41, 13]中的全卷积形式，并在多尺度上对分数进行平均（对图像尺寸缩放，使短边范围在{224, 256, 384, 480, 640}中）。\n","source":"_posts/Deep-Residual-Learning-for-Image-Recognition.md","raw":"---\ntitle: Deep Residual Learning for Image Recognition\ndate: 2018-09-25 15:02:35\ntags: ResNet\ncategories: 深度学习\nmathjax: true\n---\n## 摘要\n\n更深的神经网络往往更难以训练，我们提出一个 **残差学习框架**，使训练比以往更深的网络变得更加轻松。我们明确地将这些层重新规划为 **学习与层的输入有关的残差函数**，而不是学习不相关的函数。我们提供了非常全面的实验数据来证明，残差网络更容易优化，并且可以在深度增加的情况下让精度也增加。在ImageNet的数据集上我们评测了一个深度152层（是VGG的8倍）的残差网络，但依旧拥有比VGG更低的复杂度。这些残差网络在ImageNet测试集达到了3.57%的错误率，这个结果获得了ILSVRC2015的分类任务第一名，我们还用CIFAR-10数据集分析了100层和1000层的网络。\n\n对于很多视觉识别任务来说，**表示的深度** 是至关重要的。我们极深的网络让我们在COCO的目标检测数据集上得到了28%的相对提升。同时，深度残差网络也是提交参加ILSVRC和COCO2015比赛的基础。我们还赢得了ImageNet目标检测、ImageNet目标定位、COCO目标检测和COCO图像分割等任务的第一名。\n\n## 简介\n\n深度卷积神经网络给图像分类问题上的研究带来了很多突破，深层网络自然地将 **低/中/高级的特征和分类器集成到端到端的多层方式中**，而特征的“层次”可以通过叠加层(深度)的数量来丰富。最近的证据表明，网络深度是至关重要的，而具有挑战性的ImageNet数据集的主要结果都利用了“非常深”的模型，深度为16到30。其他一些计算机视觉的问题也受益于非常深的网络模型。\n\n受到深度的重要性的驱动，出现了这样一个问题：**学习更好的网络就像堆叠更多的层一样容易吗?** 这个问题的一大障碍就是臭名昭著的梯度消失/爆炸问题，它从网络结构的一开始就阻碍收敛。然而这个问题，很大程度上可以通过 **归一化的初始化** 和 **中间层的归一化** 解决，这个方法确保几十层的网络能够在使用 **随机梯度下降（SGD）** 的后向传播过程中收敛。\n\n当更深的网络能够开始收敛时，一个 **退化问题** 就暴露出来了: **随着网络深度的增加，准确度就会饱和(这可能不足为奇)，然后就会迅速下降。出人意料的，退化问题并不是过拟合导致的，并且增加更多的层反而会导致更大的训练误差**，就像文章[11,42]中说的那样，通过我们的实验也得到证实。图1展示了一个典型的例子。\n\n![](/images/resnet_f1.jpg)\n\n训练精度的退化表明，不是所有的系统都同样容易优化。让我们考虑一个浅层网络和与之对应的增加了更多层的深层网络。有一个方法来构建该深层网络：**额外添加的层都是 恒等映射，其他层则是从训练好的浅层网络复制过来**。这种构造解的存在性表明，更深的网络应该不会比浅层网络产生更高的训练误差。但实验结果表明，我们手头上有的方案都找不到更好或者同样好的解（或者是无法在可接受的时间里做完）。\n\n在本文中，我们通过引入一个 **深度残差学习** 框架解决这个退化问题。我们 **不期望每几个叠加的层直接拟合一个映射，而是明确的让这些层去拟合 残差映射**。更正式的说法是，这里用 $H(X)$ 来表示 **想要得到的潜在映射**，但我们让堆叠的非线性层去拟合另一个映射 $F(X):=H(X)-X$，此时原潜在映射 $H(X)$ 就可以改写成 $F(X)+X$，我们 **假设残差映射跟原映射相比更容易被优化**。现在我们考虑极端情况，如果恒等映射是最优解，那么可以 **相对于用堆叠的非线性层去拟合恒等映射将残差置0更容易些**。\n\n$F(X)+X$ 的公式可以通过在前馈网络中做一个“**快捷连接**”来实现（如图2）。快捷连接跳过一个或多个层。在我们的例子中，快捷连接简单的执行恒等映射，它们的输出被添加到堆叠层的输出中。恒等映射快捷连接既不会增加额外的参数也不会增加计算复杂度。整个网络依然可以通过SGD和反向传播进行端到端训练，并且可以用常见的深度学习库来实现（比如Caffe）无需修改求解器。\n\n![](/images/resnet_f2.PNG)\n\n我们目前用ImageNet的数据集做了很多综合实验，来证实退化问题和评估我们的方法。我们发现：1）我们极深的残差网络易于优化，但当深度增加时，对应的“简单”网络（简单堆叠层）表现出更高的训练误差。2）我们的深度残差网络可以从增加的深度中轻松提高准确性，生成的结果实质上比以前的网络更好。\n\n类似的现象在CIFAR-10数据集的实验中也一样，这表明了优化的困难以及我们的方法不是仅对特定的数据集起作用。我们在这个数据集上应用了成功训练的超过100层的模型，并探索了超过1000层的模型。\n\n在ImageNet对象分类数据集上，我们用深度残差网络获得了很棒的结果，我们152层的残差网络是ImageNet的参赛网络中最深的，然而却拥有比VGG更低的复杂度。我们的模型集合在ImageNet测试集上有3.57% top-5的错误率，并在ILSVRC 2015分类比赛中获得了第一名。**极深的表示在其它识别任务中也有极好的泛化性能**，使我们进一步赢得了多个比赛的第一名包括ILSVRC & COCO 2015竞赛中的ImageNet检测，ImageNet目标定位，COCO目标检测和COCO图像分割，坚实的证据表明残差学习准则是通用的，并且我们期望它适用于其它的视觉和非视觉问题。\n\n## 相关工作\n\n**残差表示**。VLAD是一种通过关于字典的残差向量进行编码的表示形式。**Fisher矢量** 可以认为是VLAD的概率版本。它们都是图像检索和图像分类中强大的浅层表示。对于矢量量化，**编码残差矢量被证明比编码原始矢量更有效**。\n\n在低级视觉和计算机图形学中，为了求解偏微分方程（PDE），广泛使用的 **Multigrid方法** 将系统重构为在多个尺度上的子问题，其中每个子问题负责较粗尺度和较细尺度的残差解。Multigrid的替代方法是 **层次化基础预处理**，它依赖于表示两个尺度之间残差向量的变量。[3,45,46]已经证明比起不知道解的残差性质的标准求解器，这些求解器收敛得更快。这些方法表明好的重构或预处理可以简化优化过程。\n\n**快捷连接**。快捷连接的实践和理论已经被研究了很长时间。训练多层感知机（MLPs）的早期实践是添加一个线性层来连接网络的输入和输出。在[44,24]中，一些中间层直接连接到辅助分类器，用于解决梯度消失/爆炸问题。论文[39,38,31,47]提出了通过快捷连接实现层间响应，梯度和传播误差的方法。在[44]中，一个“inception”层由一个快捷分支和一些更深的分支组成。\n\n和我们同时进行的工作，高速路网络提出了门控函数的快捷连接。这些门依赖数据且有参数，与我们没有参数的恒等快捷连接相反。当门控快捷连接“关闭”（接近零）时，高速路网络中的层表示非残差函数。相反，我们的公式总是学习残差函数；我们的恒等快捷连接永远不会关闭，所有的信息总是通过，还有额外的残差函数要学习。此外，高速路网络还没有证实极度增加的深度（例如，超过100个层）能够提高准确性。\n\n## 深度残差学习\n\n### 残差学习\n\n我们考虑 $H(x)$ 作为几个堆叠层（不必是整个网络）要拟合的潜在映射，$x$ 表示这些层中第一层的输入。假设多个非线性层可以渐近地近似复杂函数，它等价于假设它们可以渐近地近似残差函数，即 $H(x)−x$ (假设输入输出维度相同)。因此，我们明确让这些层近似残差函数 $F(x):= H(x)−x$，而不是期望堆叠层近似 $H(x)$。因此原始函数变为 $F(x)+x$。尽管两种形式应该都能渐近地近似要求的函数（如假设），但学习的难易程度可能是不同的。\n\n这种重构是受到了反直觉的退化问题的激发（图1左）。正如我们在第一部分介绍中讨论的那样，如果添加的层可以被构建为恒等映射，更深模型的训练误差应该不大于它对应的更浅版本。**退化问题表明求解器通过多个非线性层来近似恒等映射可能存在困难**。通过残差学习的重构，如果恒等映射是最优解，求解器可能简单地将多个非线性层的权重置零使其得到恒等映射。\n\n在实际情况下，恒等映射不太可能是最优解，但是我们的重构可能有助于对问题进行预处理。**如果最优函数比零映射更接近于恒等映射，则求解器应该更容易找到关于恒等映射的扰动，而不是将该函数作为新函数来学习**。我们通过实验（图7）显示学习的残差函数通常有更小的响应，表明恒等映射提供了合理的预处理。\n\n![](/images/resnet_f7.PNG)\n\n### 快捷恒等映射\n\n我们每隔几个堆叠层采用残差学习。一个构建块如图2所示。在本文中我们考虑构建块正式定义为：\n\n$y=F(x, \\{W_i\\})+x \\tag{1}$\n\n$x$和$y$是考虑的层的输入和输出向量。函数 $F(x,\\{W_i\\})$ 表示要学习的残差映射。对于图2中的有两层的例子来说，$F = W_2 \\sigma (W_1x)$，其中 $\\sigma$ 表示ReLU，为了简化表达忽略偏置项。$F+x$ 操作通过快捷连接和各个元素相加来执行。在相加之后我们采取了第二个非线性 $\\sigma(y)$（图2）。\n\n方程(1)中的快捷连接既没有引入额外参数又没有增加计算复杂度。这不仅在实践中有吸引力，而且在简单网络和残差网络的比较中也很重要。我们可以公平地比较同时具有相同数量的参数，相同深度，宽度和计算成本的简单/残差网络（除了不可忽略的元素加法之外）。\n\n方程(1)中$x$和$F$的维度必须是相等的。如果不是这种情况（例如，当更改输入/输出通道时），我们可以通过快捷连接执行线性投影$W_s$来匹配维度：\n\n$y=F(x, \\{W_i\\})+W_sx \\tag{2}$\n\n我们也可以在方程(1)中使用方阵$W_s$。但是我们将通过实验表明，恒等映射足以解决退化问题，并且是合算的，因此$W_s$仅在匹配维度时使用。\n\n残差函数$F$的形式是可变的。本文中的实验包括有两层或三层（图5）的函数$F$，也可以有更多的层。但如果$F$只有一层，方程(1)类似于线性层：$y=W_1x+x$，这就没有优势了。\n\n![](/images/resnet_f5.PNG)\n\n我们还注意到尽管上述表达式是关于全连接层的，但它们同样适用于卷积层。函数 $F(x，W_i)$ 可以表示多个卷积层。元素加法在两个特征图上逐通道进行。\n\n### 网络架构\n\n我们测试了各种简单/残差网络，并观察到了一致的现象。为了给讨论举例，我们描述ImageNet的两个模型如下。\n\n![](/images/resnet_f3.jpg)\n\n简单网络。 我们简单网络的基准（图3，中间）主要受到VGG网络（图3，左图）的设计哲学启发。卷积层主要有3×3的滤波器，并遵循两个简单的设计规则：（i）对于相同的输出特征图尺寸，层具有相同数量的滤波器；（ii）如果特征图尺寸减半，则滤波器数量加倍，以便保持每层的时间复杂度。我们通过步长为2的卷积层直接执行下采样。网络以全局平均池化层和具有softmax的1000维全连接层结束。图3（中间）的权重层总数为34。\n\n值得注意的是我们的模型与VGG网络（图3左）相比，有更少的滤波器和更低的复杂度。我们的34层基准有36亿FLOP(乘加)，仅是VGG-19（196亿FLOP）的18%。\n\n残差网络。基于上述的简单网络，我们插入快捷连接（图3，右），将网络转换为其对应的残差版本。当输入和输出具有相同的维度时（图3中的实线快捷连接）时，可以直接使用恒等快捷连接（方程（1））。当维度增加（图3中的虚线快捷连接）时，我们考虑两个选项：（A）快捷连接仍然执行恒等映射，额外填充零输入以增加维度。此选项不会引入额外的参数；（B）方程（2）中的投影快捷连接用于匹配维度（由1×1卷积完成）。对于这两个选项，当快捷连接跨越两种尺寸的特征图时，它们执行时步长为2。\n\n![](/images/resnet_t1.PNG)\n### 实现\n\nImageNet中我们的实现遵循[21，41]的实践。调整图像大小，其较短的边在[256,480]之间进行随机采样，用于尺度增强。使用224×224裁剪从图像或其水平翻转中随机采样，并逐像素减去均值。使用了论文[21]中的标准颜色增强。在每个卷积之后和激活之前，我们采用批量归一化（BN）[16]。我们按照[13]的方法初始化权重，从零开始训练所有的简单/残差网络。我们使用批大小为256的SGD方法。学习速度从0.1开始，当误差稳定时学习率除以10，并且模型训练高达$60×10^4$次迭代。我们使用的权重衰减为0.0001，动量为0.9。根据[16]的实践，我们不使用dropout算法。\n\n在测试阶段，为了比较研究，我们采用标准的10-crop测试[21]。对于最好的结果，我们采用如[41, 13]中的全卷积形式，并在多尺度上对分数进行平均（对图像尺寸缩放，使短边范围在{224, 256, 384, 480, 640}中）。\n","slug":"Deep-Residual-Learning-for-Image-Recognition","published":1,"updated":"2018-09-28T07:28:36.629Z","_id":"cjmk9ds20000dpcvoi43q13lg","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><p>更深的神经网络往往更难以训练，我们提出一个 <strong>残差学习框架</strong>，使训练比以往更深的网络变得更加轻松。我们明确地将这些层重新规划为 <strong>学习与层的输入有关的残差函数</strong>，而不是学习不相关的函数。我们提供了非常全面的实验数据来证明，残差网络更容易优化，并且可以在深度增加的情况下让精度也增加。在ImageNet的数据集上我们评测了一个深度152层（是VGG的8倍）的残差网络，但依旧拥有比VGG更低的复杂度。这些残差网络在ImageNet测试集达到了3.57%的错误率，这个结果获得了ILSVRC2015的分类任务第一名，我们还用CIFAR-10数据集分析了100层和1000层的网络。</p>\n<p>对于很多视觉识别任务来说，<strong>表示的深度</strong> 是至关重要的。我们极深的网络让我们在COCO的目标检测数据集上得到了28%的相对提升。同时，深度残差网络也是提交参加ILSVRC和COCO2015比赛的基础。我们还赢得了ImageNet目标检测、ImageNet目标定位、COCO目标检测和COCO图像分割等任务的第一名。</p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>深度卷积神经网络给图像分类问题上的研究带来了很多突破，深层网络自然地将 <strong>低/中/高级的特征和分类器集成到端到端的多层方式中</strong>，而特征的“层次”可以通过叠加层(深度)的数量来丰富。最近的证据表明，网络深度是至关重要的，而具有挑战性的ImageNet数据集的主要结果都利用了“非常深”的模型，深度为16到30。其他一些计算机视觉的问题也受益于非常深的网络模型。</p>\n<p>受到深度的重要性的驱动，出现了这样一个问题：<strong>学习更好的网络就像堆叠更多的层一样容易吗?</strong> 这个问题的一大障碍就是臭名昭著的梯度消失/爆炸问题，它从网络结构的一开始就阻碍收敛。然而这个问题，很大程度上可以通过 <strong>归一化的初始化</strong> 和 <strong>中间层的归一化</strong> 解决，这个方法确保几十层的网络能够在使用 <strong>随机梯度下降（SGD）</strong> 的后向传播过程中收敛。</p>\n<p>当更深的网络能够开始收敛时，一个 <strong>退化问题</strong> 就暴露出来了: <strong>随着网络深度的增加，准确度就会饱和(这可能不足为奇)，然后就会迅速下降。出人意料的，退化问题并不是过拟合导致的，并且增加更多的层反而会导致更大的训练误差</strong>，就像文章[11,42]中说的那样，通过我们的实验也得到证实。图1展示了一个典型的例子。</p>\n<p><img src=\"/images/resnet_f1.jpg\" alt=\"\"></p>\n<p>训练精度的退化表明，不是所有的系统都同样容易优化。让我们考虑一个浅层网络和与之对应的增加了更多层的深层网络。有一个方法来构建该深层网络：<strong>额外添加的层都是 恒等映射，其他层则是从训练好的浅层网络复制过来</strong>。这种构造解的存在性表明，更深的网络应该不会比浅层网络产生更高的训练误差。但实验结果表明，我们手头上有的方案都找不到更好或者同样好的解（或者是无法在可接受的时间里做完）。</p>\n<p>在本文中，我们通过引入一个 <strong>深度残差学习</strong> 框架解决这个退化问题。我们 <strong>不期望每几个叠加的层直接拟合一个映射，而是明确的让这些层去拟合 残差映射</strong>。更正式的说法是，这里用 $H(X)$ 来表示 <strong>想要得到的潜在映射</strong>，但我们让堆叠的非线性层去拟合另一个映射 $F(X):=H(X)-X$，此时原潜在映射 $H(X)$ 就可以改写成 $F(X)+X$，我们 <strong>假设残差映射跟原映射相比更容易被优化</strong>。现在我们考虑极端情况，如果恒等映射是最优解，那么可以 <strong>相对于用堆叠的非线性层去拟合恒等映射将残差置0更容易些</strong>。</p>\n<p>$F(X)+X$ 的公式可以通过在前馈网络中做一个“<strong>快捷连接</strong>”来实现（如图2）。快捷连接跳过一个或多个层。在我们的例子中，快捷连接简单的执行恒等映射，它们的输出被添加到堆叠层的输出中。恒等映射快捷连接既不会增加额外的参数也不会增加计算复杂度。整个网络依然可以通过SGD和反向传播进行端到端训练，并且可以用常见的深度学习库来实现（比如Caffe）无需修改求解器。</p>\n<p><img src=\"/images/resnet_f2.PNG\" alt=\"\"></p>\n<p>我们目前用ImageNet的数据集做了很多综合实验，来证实退化问题和评估我们的方法。我们发现：1）我们极深的残差网络易于优化，但当深度增加时，对应的“简单”网络（简单堆叠层）表现出更高的训练误差。2）我们的深度残差网络可以从增加的深度中轻松提高准确性，生成的结果实质上比以前的网络更好。</p>\n<p>类似的现象在CIFAR-10数据集的实验中也一样，这表明了优化的困难以及我们的方法不是仅对特定的数据集起作用。我们在这个数据集上应用了成功训练的超过100层的模型，并探索了超过1000层的模型。</p>\n<p>在ImageNet对象分类数据集上，我们用深度残差网络获得了很棒的结果，我们152层的残差网络是ImageNet的参赛网络中最深的，然而却拥有比VGG更低的复杂度。我们的模型集合在ImageNet测试集上有3.57% top-5的错误率，并在ILSVRC 2015分类比赛中获得了第一名。<strong>极深的表示在其它识别任务中也有极好的泛化性能</strong>，使我们进一步赢得了多个比赛的第一名包括ILSVRC &amp; COCO 2015竞赛中的ImageNet检测，ImageNet目标定位，COCO目标检测和COCO图像分割，坚实的证据表明残差学习准则是通用的，并且我们期望它适用于其它的视觉和非视觉问题。</p>\n<h2 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h2><p><strong>残差表示</strong>。VLAD是一种通过关于字典的残差向量进行编码的表示形式。<strong>Fisher矢量</strong> 可以认为是VLAD的概率版本。它们都是图像检索和图像分类中强大的浅层表示。对于矢量量化，<strong>编码残差矢量被证明比编码原始矢量更有效</strong>。</p>\n<p>在低级视觉和计算机图形学中，为了求解偏微分方程（PDE），广泛使用的 <strong>Multigrid方法</strong> 将系统重构为在多个尺度上的子问题，其中每个子问题负责较粗尺度和较细尺度的残差解。Multigrid的替代方法是 <strong>层次化基础预处理</strong>，它依赖于表示两个尺度之间残差向量的变量。[3,45,46]已经证明比起不知道解的残差性质的标准求解器，这些求解器收敛得更快。这些方法表明好的重构或预处理可以简化优化过程。</p>\n<p><strong>快捷连接</strong>。快捷连接的实践和理论已经被研究了很长时间。训练多层感知机（MLPs）的早期实践是添加一个线性层来连接网络的输入和输出。在[44,24]中，一些中间层直接连接到辅助分类器，用于解决梯度消失/爆炸问题。论文[39,38,31,47]提出了通过快捷连接实现层间响应，梯度和传播误差的方法。在[44]中，一个“inception”层由一个快捷分支和一些更深的分支组成。</p>\n<p>和我们同时进行的工作，高速路网络提出了门控函数的快捷连接。这些门依赖数据且有参数，与我们没有参数的恒等快捷连接相反。当门控快捷连接“关闭”（接近零）时，高速路网络中的层表示非残差函数。相反，我们的公式总是学习残差函数；我们的恒等快捷连接永远不会关闭，所有的信息总是通过，还有额外的残差函数要学习。此外，高速路网络还没有证实极度增加的深度（例如，超过100个层）能够提高准确性。</p>\n<h2 id=\"深度残差学习\"><a href=\"#深度残差学习\" class=\"headerlink\" title=\"深度残差学习\"></a>深度残差学习</h2><h3 id=\"残差学习\"><a href=\"#残差学习\" class=\"headerlink\" title=\"残差学习\"></a>残差学习</h3><p>我们考虑 $H(x)$ 作为几个堆叠层（不必是整个网络）要拟合的潜在映射，$x$ 表示这些层中第一层的输入。假设多个非线性层可以渐近地近似复杂函数，它等价于假设它们可以渐近地近似残差函数，即 $H(x)−x$ (假设输入输出维度相同)。因此，我们明确让这些层近似残差函数 $F(x):= H(x)−x$，而不是期望堆叠层近似 $H(x)$。因此原始函数变为 $F(x)+x$。尽管两种形式应该都能渐近地近似要求的函数（如假设），但学习的难易程度可能是不同的。</p>\n<p>这种重构是受到了反直觉的退化问题的激发（图1左）。正如我们在第一部分介绍中讨论的那样，如果添加的层可以被构建为恒等映射，更深模型的训练误差应该不大于它对应的更浅版本。<strong>退化问题表明求解器通过多个非线性层来近似恒等映射可能存在困难</strong>。通过残差学习的重构，如果恒等映射是最优解，求解器可能简单地将多个非线性层的权重置零使其得到恒等映射。</p>\n<p>在实际情况下，恒等映射不太可能是最优解，但是我们的重构可能有助于对问题进行预处理。<strong>如果最优函数比零映射更接近于恒等映射，则求解器应该更容易找到关于恒等映射的扰动，而不是将该函数作为新函数来学习</strong>。我们通过实验（图7）显示学习的残差函数通常有更小的响应，表明恒等映射提供了合理的预处理。</p>\n<p><img src=\"/images/resnet_f7.PNG\" alt=\"\"></p>\n<h3 id=\"快捷恒等映射\"><a href=\"#快捷恒等映射\" class=\"headerlink\" title=\"快捷恒等映射\"></a>快捷恒等映射</h3><p>我们每隔几个堆叠层采用残差学习。一个构建块如图2所示。在本文中我们考虑构建块正式定义为：</p>\n<p>$y=F(x, {W_i})+x \\tag{1}$</p>\n<p>$x$和$y$是考虑的层的输入和输出向量。函数 $F(x,{W_i})$ 表示要学习的残差映射。对于图2中的有两层的例子来说，$F = W_2 \\sigma (W_1x)$，其中 $\\sigma$ 表示ReLU，为了简化表达忽略偏置项。$F+x$ 操作通过快捷连接和各个元素相加来执行。在相加之后我们采取了第二个非线性 $\\sigma(y)$（图2）。</p>\n<p>方程(1)中的快捷连接既没有引入额外参数又没有增加计算复杂度。这不仅在实践中有吸引力，而且在简单网络和残差网络的比较中也很重要。我们可以公平地比较同时具有相同数量的参数，相同深度，宽度和计算成本的简单/残差网络（除了不可忽略的元素加法之外）。</p>\n<p>方程(1)中$x$和$F$的维度必须是相等的。如果不是这种情况（例如，当更改输入/输出通道时），我们可以通过快捷连接执行线性投影$W_s$来匹配维度：</p>\n<p>$y=F(x, {W_i})+W_sx \\tag{2}$</p>\n<p>我们也可以在方程(1)中使用方阵$W_s$。但是我们将通过实验表明，恒等映射足以解决退化问题，并且是合算的，因此$W_s$仅在匹配维度时使用。</p>\n<p>残差函数$F$的形式是可变的。本文中的实验包括有两层或三层（图5）的函数$F$，也可以有更多的层。但如果$F$只有一层，方程(1)类似于线性层：$y=W_1x+x$，这就没有优势了。</p>\n<p><img src=\"/images/resnet_f5.PNG\" alt=\"\"></p>\n<p>我们还注意到尽管上述表达式是关于全连接层的，但它们同样适用于卷积层。函数 $F(x，W_i)$ 可以表示多个卷积层。元素加法在两个特征图上逐通道进行。</p>\n<h3 id=\"网络架构\"><a href=\"#网络架构\" class=\"headerlink\" title=\"网络架构\"></a>网络架构</h3><p>我们测试了各种简单/残差网络，并观察到了一致的现象。为了给讨论举例，我们描述ImageNet的两个模型如下。</p>\n<p><img src=\"/images/resnet_f3.jpg\" alt=\"\"></p>\n<p>简单网络。 我们简单网络的基准（图3，中间）主要受到VGG网络（图3，左图）的设计哲学启发。卷积层主要有3×3的滤波器，并遵循两个简单的设计规则：（i）对于相同的输出特征图尺寸，层具有相同数量的滤波器；（ii）如果特征图尺寸减半，则滤波器数量加倍，以便保持每层的时间复杂度。我们通过步长为2的卷积层直接执行下采样。网络以全局平均池化层和具有softmax的1000维全连接层结束。图3（中间）的权重层总数为34。</p>\n<p>值得注意的是我们的模型与VGG网络（图3左）相比，有更少的滤波器和更低的复杂度。我们的34层基准有36亿FLOP(乘加)，仅是VGG-19（196亿FLOP）的18%。</p>\n<p>残差网络。基于上述的简单网络，我们插入快捷连接（图3，右），将网络转换为其对应的残差版本。当输入和输出具有相同的维度时（图3中的实线快捷连接）时，可以直接使用恒等快捷连接（方程（1））。当维度增加（图3中的虚线快捷连接）时，我们考虑两个选项：（A）快捷连接仍然执行恒等映射，额外填充零输入以增加维度。此选项不会引入额外的参数；（B）方程（2）中的投影快捷连接用于匹配维度（由1×1卷积完成）。对于这两个选项，当快捷连接跨越两种尺寸的特征图时，它们执行时步长为2。</p>\n<p><img src=\"/images/resnet_t1.PNG\" alt=\"\"></p>\n<h3 id=\"实现\"><a href=\"#实现\" class=\"headerlink\" title=\"实现\"></a>实现</h3><p>ImageNet中我们的实现遵循[21，41]的实践。调整图像大小，其较短的边在[256,480]之间进行随机采样，用于尺度增强。使用224×224裁剪从图像或其水平翻转中随机采样，并逐像素减去均值。使用了论文[21]中的标准颜色增强。在每个卷积之后和激活之前，我们采用批量归一化（BN）[16]。我们按照[13]的方法初始化权重，从零开始训练所有的简单/残差网络。我们使用批大小为256的SGD方法。学习速度从0.1开始，当误差稳定时学习率除以10，并且模型训练高达$60×10^4$次迭代。我们使用的权重衰减为0.0001，动量为0.9。根据[16]的实践，我们不使用dropout算法。</p>\n<p>在测试阶段，为了比较研究，我们采用标准的10-crop测试[21]。对于最好的结果，我们采用如[41, 13]中的全卷积形式，并在多尺度上对分数进行平均（对图像尺寸缩放，使短边范围在{224, 256, 384, 480, 640}中）。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><p>更深的神经网络往往更难以训练，我们提出一个 <strong>残差学习框架</strong>，使训练比以往更深的网络变得更加轻松。我们明确地将这些层重新规划为 <strong>学习与层的输入有关的残差函数</strong>，而不是学习不相关的函数。我们提供了非常全面的实验数据来证明，残差网络更容易优化，并且可以在深度增加的情况下让精度也增加。在ImageNet的数据集上我们评测了一个深度152层（是VGG的8倍）的残差网络，但依旧拥有比VGG更低的复杂度。这些残差网络在ImageNet测试集达到了3.57%的错误率，这个结果获得了ILSVRC2015的分类任务第一名，我们还用CIFAR-10数据集分析了100层和1000层的网络。</p>\n<p>对于很多视觉识别任务来说，<strong>表示的深度</strong> 是至关重要的。我们极深的网络让我们在COCO的目标检测数据集上得到了28%的相对提升。同时，深度残差网络也是提交参加ILSVRC和COCO2015比赛的基础。我们还赢得了ImageNet目标检测、ImageNet目标定位、COCO目标检测和COCO图像分割等任务的第一名。</p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>深度卷积神经网络给图像分类问题上的研究带来了很多突破，深层网络自然地将 <strong>低/中/高级的特征和分类器集成到端到端的多层方式中</strong>，而特征的“层次”可以通过叠加层(深度)的数量来丰富。最近的证据表明，网络深度是至关重要的，而具有挑战性的ImageNet数据集的主要结果都利用了“非常深”的模型，深度为16到30。其他一些计算机视觉的问题也受益于非常深的网络模型。</p>\n<p>受到深度的重要性的驱动，出现了这样一个问题：<strong>学习更好的网络就像堆叠更多的层一样容易吗?</strong> 这个问题的一大障碍就是臭名昭著的梯度消失/爆炸问题，它从网络结构的一开始就阻碍收敛。然而这个问题，很大程度上可以通过 <strong>归一化的初始化</strong> 和 <strong>中间层的归一化</strong> 解决，这个方法确保几十层的网络能够在使用 <strong>随机梯度下降（SGD）</strong> 的后向传播过程中收敛。</p>\n<p>当更深的网络能够开始收敛时，一个 <strong>退化问题</strong> 就暴露出来了: <strong>随着网络深度的增加，准确度就会饱和(这可能不足为奇)，然后就会迅速下降。出人意料的，退化问题并不是过拟合导致的，并且增加更多的层反而会导致更大的训练误差</strong>，就像文章[11,42]中说的那样，通过我们的实验也得到证实。图1展示了一个典型的例子。</p>\n<p><img src=\"/images/resnet_f1.jpg\" alt=\"\"></p>\n<p>训练精度的退化表明，不是所有的系统都同样容易优化。让我们考虑一个浅层网络和与之对应的增加了更多层的深层网络。有一个方法来构建该深层网络：<strong>额外添加的层都是 恒等映射，其他层则是从训练好的浅层网络复制过来</strong>。这种构造解的存在性表明，更深的网络应该不会比浅层网络产生更高的训练误差。但实验结果表明，我们手头上有的方案都找不到更好或者同样好的解（或者是无法在可接受的时间里做完）。</p>\n<p>在本文中，我们通过引入一个 <strong>深度残差学习</strong> 框架解决这个退化问题。我们 <strong>不期望每几个叠加的层直接拟合一个映射，而是明确的让这些层去拟合 残差映射</strong>。更正式的说法是，这里用 $H(X)$ 来表示 <strong>想要得到的潜在映射</strong>，但我们让堆叠的非线性层去拟合另一个映射 $F(X):=H(X)-X$，此时原潜在映射 $H(X)$ 就可以改写成 $F(X)+X$，我们 <strong>假设残差映射跟原映射相比更容易被优化</strong>。现在我们考虑极端情况，如果恒等映射是最优解，那么可以 <strong>相对于用堆叠的非线性层去拟合恒等映射将残差置0更容易些</strong>。</p>\n<p>$F(X)+X$ 的公式可以通过在前馈网络中做一个“<strong>快捷连接</strong>”来实现（如图2）。快捷连接跳过一个或多个层。在我们的例子中，快捷连接简单的执行恒等映射，它们的输出被添加到堆叠层的输出中。恒等映射快捷连接既不会增加额外的参数也不会增加计算复杂度。整个网络依然可以通过SGD和反向传播进行端到端训练，并且可以用常见的深度学习库来实现（比如Caffe）无需修改求解器。</p>\n<p><img src=\"/images/resnet_f2.PNG\" alt=\"\"></p>\n<p>我们目前用ImageNet的数据集做了很多综合实验，来证实退化问题和评估我们的方法。我们发现：1）我们极深的残差网络易于优化，但当深度增加时，对应的“简单”网络（简单堆叠层）表现出更高的训练误差。2）我们的深度残差网络可以从增加的深度中轻松提高准确性，生成的结果实质上比以前的网络更好。</p>\n<p>类似的现象在CIFAR-10数据集的实验中也一样，这表明了优化的困难以及我们的方法不是仅对特定的数据集起作用。我们在这个数据集上应用了成功训练的超过100层的模型，并探索了超过1000层的模型。</p>\n<p>在ImageNet对象分类数据集上，我们用深度残差网络获得了很棒的结果，我们152层的残差网络是ImageNet的参赛网络中最深的，然而却拥有比VGG更低的复杂度。我们的模型集合在ImageNet测试集上有3.57% top-5的错误率，并在ILSVRC 2015分类比赛中获得了第一名。<strong>极深的表示在其它识别任务中也有极好的泛化性能</strong>，使我们进一步赢得了多个比赛的第一名包括ILSVRC &amp; COCO 2015竞赛中的ImageNet检测，ImageNet目标定位，COCO目标检测和COCO图像分割，坚实的证据表明残差学习准则是通用的，并且我们期望它适用于其它的视觉和非视觉问题。</p>\n<h2 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h2><p><strong>残差表示</strong>。VLAD是一种通过关于字典的残差向量进行编码的表示形式。<strong>Fisher矢量</strong> 可以认为是VLAD的概率版本。它们都是图像检索和图像分类中强大的浅层表示。对于矢量量化，<strong>编码残差矢量被证明比编码原始矢量更有效</strong>。</p>\n<p>在低级视觉和计算机图形学中，为了求解偏微分方程（PDE），广泛使用的 <strong>Multigrid方法</strong> 将系统重构为在多个尺度上的子问题，其中每个子问题负责较粗尺度和较细尺度的残差解。Multigrid的替代方法是 <strong>层次化基础预处理</strong>，它依赖于表示两个尺度之间残差向量的变量。[3,45,46]已经证明比起不知道解的残差性质的标准求解器，这些求解器收敛得更快。这些方法表明好的重构或预处理可以简化优化过程。</p>\n<p><strong>快捷连接</strong>。快捷连接的实践和理论已经被研究了很长时间。训练多层感知机（MLPs）的早期实践是添加一个线性层来连接网络的输入和输出。在[44,24]中，一些中间层直接连接到辅助分类器，用于解决梯度消失/爆炸问题。论文[39,38,31,47]提出了通过快捷连接实现层间响应，梯度和传播误差的方法。在[44]中，一个“inception”层由一个快捷分支和一些更深的分支组成。</p>\n<p>和我们同时进行的工作，高速路网络提出了门控函数的快捷连接。这些门依赖数据且有参数，与我们没有参数的恒等快捷连接相反。当门控快捷连接“关闭”（接近零）时，高速路网络中的层表示非残差函数。相反，我们的公式总是学习残差函数；我们的恒等快捷连接永远不会关闭，所有的信息总是通过，还有额外的残差函数要学习。此外，高速路网络还没有证实极度增加的深度（例如，超过100个层）能够提高准确性。</p>\n<h2 id=\"深度残差学习\"><a href=\"#深度残差学习\" class=\"headerlink\" title=\"深度残差学习\"></a>深度残差学习</h2><h3 id=\"残差学习\"><a href=\"#残差学习\" class=\"headerlink\" title=\"残差学习\"></a>残差学习</h3><p>我们考虑 $H(x)$ 作为几个堆叠层（不必是整个网络）要拟合的潜在映射，$x$ 表示这些层中第一层的输入。假设多个非线性层可以渐近地近似复杂函数，它等价于假设它们可以渐近地近似残差函数，即 $H(x)−x$ (假设输入输出维度相同)。因此，我们明确让这些层近似残差函数 $F(x):= H(x)−x$，而不是期望堆叠层近似 $H(x)$。因此原始函数变为 $F(x)+x$。尽管两种形式应该都能渐近地近似要求的函数（如假设），但学习的难易程度可能是不同的。</p>\n<p>这种重构是受到了反直觉的退化问题的激发（图1左）。正如我们在第一部分介绍中讨论的那样，如果添加的层可以被构建为恒等映射，更深模型的训练误差应该不大于它对应的更浅版本。<strong>退化问题表明求解器通过多个非线性层来近似恒等映射可能存在困难</strong>。通过残差学习的重构，如果恒等映射是最优解，求解器可能简单地将多个非线性层的权重置零使其得到恒等映射。</p>\n<p>在实际情况下，恒等映射不太可能是最优解，但是我们的重构可能有助于对问题进行预处理。<strong>如果最优函数比零映射更接近于恒等映射，则求解器应该更容易找到关于恒等映射的扰动，而不是将该函数作为新函数来学习</strong>。我们通过实验（图7）显示学习的残差函数通常有更小的响应，表明恒等映射提供了合理的预处理。</p>\n<p><img src=\"/images/resnet_f7.PNG\" alt=\"\"></p>\n<h3 id=\"快捷恒等映射\"><a href=\"#快捷恒等映射\" class=\"headerlink\" title=\"快捷恒等映射\"></a>快捷恒等映射</h3><p>我们每隔几个堆叠层采用残差学习。一个构建块如图2所示。在本文中我们考虑构建块正式定义为：</p>\n<p>$y=F(x, {W_i})+x \\tag{1}$</p>\n<p>$x$和$y$是考虑的层的输入和输出向量。函数 $F(x,{W_i})$ 表示要学习的残差映射。对于图2中的有两层的例子来说，$F = W_2 \\sigma (W_1x)$，其中 $\\sigma$ 表示ReLU，为了简化表达忽略偏置项。$F+x$ 操作通过快捷连接和各个元素相加来执行。在相加之后我们采取了第二个非线性 $\\sigma(y)$（图2）。</p>\n<p>方程(1)中的快捷连接既没有引入额外参数又没有增加计算复杂度。这不仅在实践中有吸引力，而且在简单网络和残差网络的比较中也很重要。我们可以公平地比较同时具有相同数量的参数，相同深度，宽度和计算成本的简单/残差网络（除了不可忽略的元素加法之外）。</p>\n<p>方程(1)中$x$和$F$的维度必须是相等的。如果不是这种情况（例如，当更改输入/输出通道时），我们可以通过快捷连接执行线性投影$W_s$来匹配维度：</p>\n<p>$y=F(x, {W_i})+W_sx \\tag{2}$</p>\n<p>我们也可以在方程(1)中使用方阵$W_s$。但是我们将通过实验表明，恒等映射足以解决退化问题，并且是合算的，因此$W_s$仅在匹配维度时使用。</p>\n<p>残差函数$F$的形式是可变的。本文中的实验包括有两层或三层（图5）的函数$F$，也可以有更多的层。但如果$F$只有一层，方程(1)类似于线性层：$y=W_1x+x$，这就没有优势了。</p>\n<p><img src=\"/images/resnet_f5.PNG\" alt=\"\"></p>\n<p>我们还注意到尽管上述表达式是关于全连接层的，但它们同样适用于卷积层。函数 $F(x，W_i)$ 可以表示多个卷积层。元素加法在两个特征图上逐通道进行。</p>\n<h3 id=\"网络架构\"><a href=\"#网络架构\" class=\"headerlink\" title=\"网络架构\"></a>网络架构</h3><p>我们测试了各种简单/残差网络，并观察到了一致的现象。为了给讨论举例，我们描述ImageNet的两个模型如下。</p>\n<p><img src=\"/images/resnet_f3.jpg\" alt=\"\"></p>\n<p>简单网络。 我们简单网络的基准（图3，中间）主要受到VGG网络（图3，左图）的设计哲学启发。卷积层主要有3×3的滤波器，并遵循两个简单的设计规则：（i）对于相同的输出特征图尺寸，层具有相同数量的滤波器；（ii）如果特征图尺寸减半，则滤波器数量加倍，以便保持每层的时间复杂度。我们通过步长为2的卷积层直接执行下采样。网络以全局平均池化层和具有softmax的1000维全连接层结束。图3（中间）的权重层总数为34。</p>\n<p>值得注意的是我们的模型与VGG网络（图3左）相比，有更少的滤波器和更低的复杂度。我们的34层基准有36亿FLOP(乘加)，仅是VGG-19（196亿FLOP）的18%。</p>\n<p>残差网络。基于上述的简单网络，我们插入快捷连接（图3，右），将网络转换为其对应的残差版本。当输入和输出具有相同的维度时（图3中的实线快捷连接）时，可以直接使用恒等快捷连接（方程（1））。当维度增加（图3中的虚线快捷连接）时，我们考虑两个选项：（A）快捷连接仍然执行恒等映射，额外填充零输入以增加维度。此选项不会引入额外的参数；（B）方程（2）中的投影快捷连接用于匹配维度（由1×1卷积完成）。对于这两个选项，当快捷连接跨越两种尺寸的特征图时，它们执行时步长为2。</p>\n<p><img src=\"/images/resnet_t1.PNG\" alt=\"\"></p>\n<h3 id=\"实现\"><a href=\"#实现\" class=\"headerlink\" title=\"实现\"></a>实现</h3><p>ImageNet中我们的实现遵循[21，41]的实践。调整图像大小，其较短的边在[256,480]之间进行随机采样，用于尺度增强。使用224×224裁剪从图像或其水平翻转中随机采样，并逐像素减去均值。使用了论文[21]中的标准颜色增强。在每个卷积之后和激活之前，我们采用批量归一化（BN）[16]。我们按照[13]的方法初始化权重，从零开始训练所有的简单/残差网络。我们使用批大小为256的SGD方法。学习速度从0.1开始，当误差稳定时学习率除以10，并且模型训练高达$60×10^4$次迭代。我们使用的权重衰减为0.0001，动量为0.9。根据[16]的实践，我们不使用dropout算法。</p>\n<p>在测试阶段，为了比较研究，我们采用标准的10-crop测试[21]。对于最好的结果，我们采用如[41, 13]中的全卷积形式，并在多尺度上对分数进行平均（对图像尺寸缩放，使短边范围在{224, 256, 384, 480, 640}中）。</p>\n"},{"title":"How to set up a blog with hexo on github.io","date":"2018-07-18T10:17:31.000Z","_content":"### Install Git (https://git-scm.com/)\n\n* If you have a git, you can check it by `git -v`\n\n### Install node.js envornment \n\n* Download from [https://nodejs.org/en/](https://nodejs.org/en/)\n* Install as the default(make sure the envorment path is collected)\n* When you finsh, you can check it by `node -v`\n\n###  Make a new repository named \"<your_username>.github.io\"\n\n### Install Hexo\n\n* `npm install hexo-cli -g`\n* `hexo init blog`(that folder you wanted to store your webpage)\n* `cd blog`\n* `npm install`\n* `hexo server`\n\n### Connect hexo with github\n\n* `cd blog`\n* `git config --global user.name \"<your_username>\"`\n* `git config --global user.email \"<your_email>\"`\n\nCheck if you have a ssh keygen. If not you can do as following\n\n* `cd ~/.ssh`\n* generate key: `ssh-kengen -t rsa -C \"<your_email>\"` (choice default setting)\n* add key to ssh-agent: `eval \"$(ssh-agent -s)\"`\n* `ssh-add ~/.ssh/id_rsa`\n\n### Sign in the github, in settings, add a new ssh key, copy the `id_rsa.pub` to key options. check if it's ok by `ssh -T git@github.com`. If you get a hi message, it is ok.\n\n### In your blog folder, edit the _config.yml file like this.\n\n```\n(in the end)\ndeploy:\n    type: git\n    repository: git@github.com:<your_username>/<your_username>.github.io.git\n    branch: master\n```\n\n### Before deploy the blog website, you should install a plug\n\n* `cd blog`\n* `npm install hexo-deployer-git --save`\n\n### Run it online.\n\n* `hexo clean`\n* `hexo g`\n* `hexo d`\n\n","source":"_posts/How-to-set-up-a-blog-with-hexo-on-github-io.md","raw":"---\ntitle: How to set up a blog with hexo on github.io\ndate: 2018-07-18 18:17:31\ntags: hexo\ncategories: web\n---\n### Install Git (https://git-scm.com/)\n\n* If you have a git, you can check it by `git -v`\n\n### Install node.js envornment \n\n* Download from [https://nodejs.org/en/](https://nodejs.org/en/)\n* Install as the default(make sure the envorment path is collected)\n* When you finsh, you can check it by `node -v`\n\n###  Make a new repository named \"<your_username>.github.io\"\n\n### Install Hexo\n\n* `npm install hexo-cli -g`\n* `hexo init blog`(that folder you wanted to store your webpage)\n* `cd blog`\n* `npm install`\n* `hexo server`\n\n### Connect hexo with github\n\n* `cd blog`\n* `git config --global user.name \"<your_username>\"`\n* `git config --global user.email \"<your_email>\"`\n\nCheck if you have a ssh keygen. If not you can do as following\n\n* `cd ~/.ssh`\n* generate key: `ssh-kengen -t rsa -C \"<your_email>\"` (choice default setting)\n* add key to ssh-agent: `eval \"$(ssh-agent -s)\"`\n* `ssh-add ~/.ssh/id_rsa`\n\n### Sign in the github, in settings, add a new ssh key, copy the `id_rsa.pub` to key options. check if it's ok by `ssh -T git@github.com`. If you get a hi message, it is ok.\n\n### In your blog folder, edit the _config.yml file like this.\n\n```\n(in the end)\ndeploy:\n    type: git\n    repository: git@github.com:<your_username>/<your_username>.github.io.git\n    branch: master\n```\n\n### Before deploy the blog website, you should install a plug\n\n* `cd blog`\n* `npm install hexo-deployer-git --save`\n\n### Run it online.\n\n* `hexo clean`\n* `hexo g`\n* `hexo d`\n\n","slug":"How-to-set-up-a-blog-with-hexo-on-github-io","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds20000hpcvoat2clcwj","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Install-Git-https-git-scm-com\"><a href=\"#Install-Git-https-git-scm-com\" class=\"headerlink\" title=\"Install Git (https://git-scm.com/)\"></a>Install Git (<a href=\"https://git-scm.com/\" target=\"_blank\" rel=\"noopener\">https://git-scm.com/</a>)</h3><ul>\n<li>If you have a git, you can check it by <code>git -v</code></li>\n</ul>\n<h3 id=\"Install-node-js-envornment\"><a href=\"#Install-node-js-envornment\" class=\"headerlink\" title=\"Install node.js envornment\"></a>Install node.js envornment</h3><ul>\n<li>Download from <a href=\"https://nodejs.org/en/\" target=\"_blank\" rel=\"noopener\">https://nodejs.org/en/</a></li>\n<li>Install as the default(make sure the envorment path is collected)</li>\n<li>When you finsh, you can check it by <code>node -v</code></li>\n</ul>\n<h3 id=\"Make-a-new-repository-named-“-lt-your-username-gt-github-io”\"><a href=\"#Make-a-new-repository-named-“-lt-your-username-gt-github-io”\" class=\"headerlink\" title=\"Make a new repository named “&lt;your_username&gt;.github.io”\"></a>Make a new repository named “&lt;your_username&gt;.github.io”</h3><h3 id=\"Install-Hexo\"><a href=\"#Install-Hexo\" class=\"headerlink\" title=\"Install Hexo\"></a>Install Hexo</h3><ul>\n<li><code>npm install hexo-cli -g</code></li>\n<li><code>hexo init blog</code>(that folder you wanted to store your webpage)</li>\n<li><code>cd blog</code></li>\n<li><code>npm install</code></li>\n<li><code>hexo server</code></li>\n</ul>\n<h3 id=\"Connect-hexo-with-github\"><a href=\"#Connect-hexo-with-github\" class=\"headerlink\" title=\"Connect hexo with github\"></a>Connect hexo with github</h3><ul>\n<li><code>cd blog</code></li>\n<li><code>git config --global user.name &quot;&lt;your_username&gt;&quot;</code></li>\n<li><code>git config --global user.email &quot;&lt;your_email&gt;&quot;</code></li>\n</ul>\n<p>Check if you have a ssh keygen. If not you can do as following</p>\n<ul>\n<li><code>cd ~/.ssh</code></li>\n<li>generate key: <code>ssh-kengen -t rsa -C &quot;&lt;your_email&gt;&quot;</code> (choice default setting)</li>\n<li>add key to ssh-agent: <code>eval &quot;$(ssh-agent -s)&quot;</code></li>\n<li><code>ssh-add ~/.ssh/id_rsa</code></li>\n</ul>\n<h3 id=\"Sign-in-the-github-in-settings-add-a-new-ssh-key-copy-the-id-rsa-pub-to-key-options-check-if-it’s-ok-by-ssh-T-git-github-com-If-you-get-a-hi-message-it-is-ok\"><a href=\"#Sign-in-the-github-in-settings-add-a-new-ssh-key-copy-the-id-rsa-pub-to-key-options-check-if-it’s-ok-by-ssh-T-git-github-com-If-you-get-a-hi-message-it-is-ok\" class=\"headerlink\" title=\"Sign in the github, in settings, add a new ssh key, copy the id_rsa.pub to key options. check if it’s ok by ssh -T git@github.com. If you get a hi message, it is ok.\"></a>Sign in the github, in settings, add a new ssh key, copy the <code>id_rsa.pub</code> to key options. check if it’s ok by <code>ssh -T git@github.com</code>. If you get a hi message, it is ok.</h3><h3 id=\"In-your-blog-folder-edit-the-config-yml-file-like-this\"><a href=\"#In-your-blog-folder-edit-the-config-yml-file-like-this\" class=\"headerlink\" title=\"In your blog folder, edit the _config.yml file like this.\"></a>In your blog folder, edit the _config.yml file like this.</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(in the end)</span><br><span class=\"line\">deploy:</span><br><span class=\"line\">    type: git</span><br><span class=\"line\">    repository: git@github.com:&lt;your_username&gt;/&lt;your_username&gt;.github.io.git</span><br><span class=\"line\">    branch: master</span><br></pre></td></tr></table></figure>\n<h3 id=\"Before-deploy-the-blog-website-you-should-install-a-plug\"><a href=\"#Before-deploy-the-blog-website-you-should-install-a-plug\" class=\"headerlink\" title=\"Before deploy the blog website, you should install a plug\"></a>Before deploy the blog website, you should install a plug</h3><ul>\n<li><code>cd blog</code></li>\n<li><code>npm install hexo-deployer-git --save</code></li>\n</ul>\n<h3 id=\"Run-it-online\"><a href=\"#Run-it-online\" class=\"headerlink\" title=\"Run it online.\"></a>Run it online.</h3><ul>\n<li><code>hexo clean</code></li>\n<li><code>hexo g</code></li>\n<li><code>hexo d</code></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Install-Git-https-git-scm-com\"><a href=\"#Install-Git-https-git-scm-com\" class=\"headerlink\" title=\"Install Git (https://git-scm.com/)\"></a>Install Git (<a href=\"https://git-scm.com/\" target=\"_blank\" rel=\"noopener\">https://git-scm.com/</a>)</h3><ul>\n<li>If you have a git, you can check it by <code>git -v</code></li>\n</ul>\n<h3 id=\"Install-node-js-envornment\"><a href=\"#Install-node-js-envornment\" class=\"headerlink\" title=\"Install node.js envornment\"></a>Install node.js envornment</h3><ul>\n<li>Download from <a href=\"https://nodejs.org/en/\" target=\"_blank\" rel=\"noopener\">https://nodejs.org/en/</a></li>\n<li>Install as the default(make sure the envorment path is collected)</li>\n<li>When you finsh, you can check it by <code>node -v</code></li>\n</ul>\n<h3 id=\"Make-a-new-repository-named-“-lt-your-username-gt-github-io”\"><a href=\"#Make-a-new-repository-named-“-lt-your-username-gt-github-io”\" class=\"headerlink\" title=\"Make a new repository named “&lt;your_username&gt;.github.io”\"></a>Make a new repository named “&lt;your_username&gt;.github.io”</h3><h3 id=\"Install-Hexo\"><a href=\"#Install-Hexo\" class=\"headerlink\" title=\"Install Hexo\"></a>Install Hexo</h3><ul>\n<li><code>npm install hexo-cli -g</code></li>\n<li><code>hexo init blog</code>(that folder you wanted to store your webpage)</li>\n<li><code>cd blog</code></li>\n<li><code>npm install</code></li>\n<li><code>hexo server</code></li>\n</ul>\n<h3 id=\"Connect-hexo-with-github\"><a href=\"#Connect-hexo-with-github\" class=\"headerlink\" title=\"Connect hexo with github\"></a>Connect hexo with github</h3><ul>\n<li><code>cd blog</code></li>\n<li><code>git config --global user.name &quot;&lt;your_username&gt;&quot;</code></li>\n<li><code>git config --global user.email &quot;&lt;your_email&gt;&quot;</code></li>\n</ul>\n<p>Check if you have a ssh keygen. If not you can do as following</p>\n<ul>\n<li><code>cd ~/.ssh</code></li>\n<li>generate key: <code>ssh-kengen -t rsa -C &quot;&lt;your_email&gt;&quot;</code> (choice default setting)</li>\n<li>add key to ssh-agent: <code>eval &quot;$(ssh-agent -s)&quot;</code></li>\n<li><code>ssh-add ~/.ssh/id_rsa</code></li>\n</ul>\n<h3 id=\"Sign-in-the-github-in-settings-add-a-new-ssh-key-copy-the-id-rsa-pub-to-key-options-check-if-it’s-ok-by-ssh-T-git-github-com-If-you-get-a-hi-message-it-is-ok\"><a href=\"#Sign-in-the-github-in-settings-add-a-new-ssh-key-copy-the-id-rsa-pub-to-key-options-check-if-it’s-ok-by-ssh-T-git-github-com-If-you-get-a-hi-message-it-is-ok\" class=\"headerlink\" title=\"Sign in the github, in settings, add a new ssh key, copy the id_rsa.pub to key options. check if it’s ok by ssh -T git@github.com. If you get a hi message, it is ok.\"></a>Sign in the github, in settings, add a new ssh key, copy the <code>id_rsa.pub</code> to key options. check if it’s ok by <code>ssh -T git@github.com</code>. If you get a hi message, it is ok.</h3><h3 id=\"In-your-blog-folder-edit-the-config-yml-file-like-this\"><a href=\"#In-your-blog-folder-edit-the-config-yml-file-like-this\" class=\"headerlink\" title=\"In your blog folder, edit the _config.yml file like this.\"></a>In your blog folder, edit the _config.yml file like this.</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(in the end)</span><br><span class=\"line\">deploy:</span><br><span class=\"line\">    type: git</span><br><span class=\"line\">    repository: git@github.com:&lt;your_username&gt;/&lt;your_username&gt;.github.io.git</span><br><span class=\"line\">    branch: master</span><br></pre></td></tr></table></figure>\n<h3 id=\"Before-deploy-the-blog-website-you-should-install-a-plug\"><a href=\"#Before-deploy-the-blog-website-you-should-install-a-plug\" class=\"headerlink\" title=\"Before deploy the blog website, you should install a plug\"></a>Before deploy the blog website, you should install a plug</h3><ul>\n<li><code>cd blog</code></li>\n<li><code>npm install hexo-deployer-git --save</code></li>\n</ul>\n<h3 id=\"Run-it-online\"><a href=\"#Run-it-online\" class=\"headerlink\" title=\"Run it online.\"></a>Run it online.</h3><ul>\n<li><code>hexo clean</code></li>\n<li><code>hexo g</code></li>\n<li><code>hexo d</code></li>\n</ul>\n"},{"title":"Linear Models for Regression","date":"2018-09-21T12:10:45.000Z","mathjax":true,"_content":"## Linear Basis Function Models\n\n对于回归任务最简单的线性模型是：输入变量的线性组合。\n\n$$y(\\vec x, \\vec w) = w_0+ w_1x_1 + ... + w_Dx_D \\tag{3.1}$$\n\n这就是我们所说的线性回归。\n\n这个模型既是参数的线性函数也是输入的线性函数，然而这会带来很多限制。因此我们对输入变量进行一个非线性处理。\n\n$$y(\\vec x, \\vec w) = w_0 + \\sum_{j=1}^{M-1}w_j\\phi_j(\\vec x) = \\sum_{j=0}^{M-1}w_j\\phi_j(\\vec x) = \\vec w^T \\phi(\\vec x) \\tag{3.2}$$\n\n这里的 $\\phi_j(\\vec x)$ 就是所说 **基函数（basis function）** , 其中 $\\phi_0(\\vec x) = 1$, 注意 $\\vec w, \\vec \\phi$ 均为列向量。\n\n在许多模式识别的实际应⽤中，我们会对原始的数据变量进⾏某种固定形式的预处理或者特征抽取。如果原始变量由向量 x 组成，那么特征可以⽤基函数 $\\{\\phi_j(\\vec x)\\}$ 来表示。\n\n基函数的选择有很多种形式，比如：\n\n$$\\phi_j(x) = exp\\{-\\frac{(x - \\mu_j)^2}{2s^2}\\} \\tag{3.3}$$\n\n$\\mu_j$ 决定了基函数在输入空间的位置，$s$决定了空间的范围. 但这些参数都不是重要的，因为它们还要乘以一个自适应的系数 $w_j$.\n\n$$\\phi_j = \\sigma(\\frac{x- \\mu_j}{s}) \\tag{3.4}\\\\ \\sigma(a) = \\frac{1}{1 + exp(-a)}$$\n\n除此之外还有傅里叶基函数，比如对sin函数的扩展。每一个基函数表示一个具体的频率，并且在空间上是无限的。相对地，被限定在有限的输入空间上的基函数由多个频率组合而成。在信号处理领域，考虑在空间和频率上都是有限的基函数是很有用的，它们被称为 **小波(waveles)**。\n\n### Maximum likelihood and least squares\n\n我们假设目标变量t由下式得到\n\n$$t = y(\\vec x, \\vec w) + \\epsilon \\tag{3.5}$$\n\n$\\epsilon$ 是一个零均值的高斯随机变量，其精度为 $\\beta = \\frac{1}{\\sigma ^2}$\n因此\n\n$$p(t|\\vec x, \\vec w, \\beta) = \\mathcal N(t|y(\\vec x, \\vec w), \\beta^{-1}) \\tag{3.6}$$\n\n如果我们的损失函数是平方损失，那么最优的预测就是目标变量的条件期望。在（3.6）式的高斯条件分布下，它的条件期望为\n\n$$\\mathbb E[t|\\vec x] = \\int tp(t|\\vec x)dt = y(\\vec x, \\vec w) \\tag{3.7}$$\n\n注意，高斯噪声这样的假设暗示着给定x下t的条件期望是单峰的，这可能在一些应用上不适用。\n\n现在假设我们由N个观察到的输入数据 $\\mathbf X = \\{\\vec x_1, ..., \\vec x_N\\}$ 相对应的目标值是 $t_1, ..., t_N$. 这里把（3.6）写成矩阵形式得到的似然函数为：\n\n$$p(t|\\mathbf x, \\vec w, \\beta) = \\prod_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1}) \\tag{3.8}$$\n\n注意在监督学习问题中（分类和回归），我们并不要求对输入变量的分布建模。因此x可能不会出现在条件变量上。例如 $p(t|\\vec w, \\beta)$\n\n对式（3.8）取对数有：\n\n$$\\ln p(t|w, \\beta) = \\sum_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1})\\\\ = \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln(2\\pi) - \\beta E_D(\\vec w) \\tag{3.9}$$\n\n这里平方和误差为\n\n$$E_D(\\vec w) = \\frac{1}{2} \\sum_{n=1}^{N} \\{t_n - \\vec w^T \\phi(\\vec x_n)\\}^2 \\tag{3.10}$$\n\n最大化似然函数可通过对似然函数求导：\n\n$$\\frac{\\partial \\ln p(\\vec t |\\vec w, \\beta)}{\\partial \\vec w} = \\sum_{n=1}^{N} \\{t_n - \\vec w^T \\phi(\\vec x_n)\\} \\phi(\\vec x_n)^T \\tag{3.11}$$\n\n令导数为0得到：\n\n$$\\vec w_{ML} = (\\Phi ^T \\Phi)^{-1} \\Phi ^T \\vec t \\tag{3.12}$$\n\n这个方程被称为 **正则方程(normal equations)** .\n\n$$\\Phi = \\left [ \\begin{matrix} \\phi_0(\\vec x_1) & \\phi_1(\\vec x_1) ... \\phi_{M-1}(\\vec x_1)\\\\ \\phi_0(\\vec x_2) & \\phi_1(\\vec x_2) ... \\phi_{M-1}(\\vec x_2)\\\\ ... & ...\\\\ \\phi_0(\\vec x_N) & \\phi_1(\\vec x_N) ... \\phi_{M-1}(\\vec x_N\\end{matrix}\\right] \\tag{3.13}$$\n\n$\\Phi ^+ = ((\\Phi ^T \\Phi)^{-1} \\Phi ^T)$ 被称为矩阵 $\\Phi$ 的 **Moor-Penrose pseudo-inverse**\n\n同样我们也能得到 $\\beta$ 的最大似然估计量。\n$$\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}\\{t_n - \\vec w_{ML}^T \\phi(\\vec x_n)\\}^2$$\n\n### Geometry of least squares\n\n考虑这样一个N维空间，其以$t_n$为坐标轴，因此 $\\vec t = (t_1, ..., t_N)^T$ 是该空间的一个向量。在N个数据上的每一个基函数 $\\phi_j(\\vec x_n)$ 也能表示为相同空间中的向量。我们定义 $\\vec y$ 是一个N维向量，它的第n个元素是 $y(\\vec x_n, \\vec w)$. 由于 $\\vec y$ 是 $\\phi_j(\\vec x_n)$ 在M维空间的任意线性组合。误差平方和等价于 $\\vec y$和 $t$ 之间的欧几里得距离。 因此最小二乘解就是选择在子空间中最接近 $\\vec t$的 $\\vec y$.\n\n![](/images/lmfr.PNG)\n\n### Sequential learning\n\n批处理技术使得可以一次处理很大的训练数据集。如果数据集是足够大，此时使用序列算法可能更有用，序列算法也被称作 **在线（on-line）算法**。这种算法在每一次表示后都更新模型的参数。序列学习适用于一些观察数据是连续产生的实时应用，这些应用必须利用目前所有观测到的数据来预测。\n\n我们能应用随机梯度下降技术来获得序列学习算法。\n\n$$w^{\\tau + 1} = w^\\tau - \\eta \\nabla E_n \\tag{3.22}$$\n\n这里 $\\tau$ 是迭代的次数，$\\eta$ 是学习率。对于（3.10）那样的平方和误差函数，上式可写为：\n\n$$w^{\\tau + 1} = w^\\tau + \\eta (t_n - w^{(\\tau)T}\\Phi_n)\\Phi_n \\tag{3.23}$$\n\n$\\Phi_n = \\Phi(x_n)$ 这就是 **least-mean-squares(LMS)** 算法。\n\n### Regularized learst squares\n\n我们给误差函数增加一个正则项来控制模型的过拟合。新的误差函数为。\n\n$$E_D(W) + \\lambda E_w(w) \\tag{3.24}$$\n\n$\\lambda$ 是正则系数用来控制由数据决定的误差和由正则项引入的误差的相对重要程度。一个最简单的正则形式为权重向量的平方和：\n\n$$E_w(\\vec w) = \\frac{1}{2}\\vec w^T \\vec w \\tag{3.25}$$\n\n如果我们考虑平方和误差函数，那么总的误差为：\n\n$$\\frac{1}{2}\\sum_{n=1}^{N}\\{t_n - \\vec w^T \\Phi(\\vec x_n)\\}^2 + \\frac{\\lambda}{2}\\vec w^T \\vec w \\tag{3.27}$$\n\n在机器学习文献中正则的一个解释是 **权重衰减**，因为在序列学习中，它鼓励权重向朝着0的方向变化。\n在统计学中它提供一种参数收缩的方法。它的优点是误差函数保持为w的二次型，因此可以得到精确的最小化解。\n\n$$\\vec w = (\\lambda \\mathbf I + \\Phi^T\\Phi)^{-1}\\Phi^T \\vec t \\tag{3.28}$$\n\n有时也会使用更一般的正则化形式如：\n\n$$\\frac{1}{2}\\sum_{n=1}^{N}\\{t_n - \\vec w^T \\Phi(\\vec x_n)\\}^2 + \\frac{\\lambda}{2}\\sum_{j=1}^M |w_j|^q \\tag{3.29}$$\n\n$q=1$ 时为统计学中所说的lasso。它有这样的特点：如果 $\\lambda$ 足够大，一些系数就被学习为0，与之对应的基函数就没有起作用。这学得一个稀疏的模型。\n\n![](/images/lmfr_f3.PNG)\n\n正则化允许在大小有限的数据集上训练复杂的模型而不导致严重的过拟合，这实质上是通过限制有效的模型复杂度来实现的。然而，决定最优模型复杂度的问题从寻找合适基函数的数量转变为决定一个合适的正则化系数 $\\lambda$。\n\n![](/images/lmfr_f4.PNG)\n\n### Multiple outputs\n\n到目前为止我们已经考虑了单个目标变量的例子，在某些应用中我们可能希望预测多个目标变量，我们将它们定义为一个目标向量 $\\vec t$。这可能通过分别对每一个目标变量定义一组基函数，依照单变量回归那样做。然而一个更合适更常用的方法是，使用同样的一组基函数来对所有的目标变量建模。\n\n$$y(\\vec x, \\vec w) = \\mathbf W^T \\phi(\\vec x) \\tag{3.31}$$\n\n这里 $\\vec y$ 是一个K维的列向量，$\\mathbf W$ 是一个$M \\times K$的参数矩阵。$\\phi(\\vec x)$ 是一个M维的列向量其中 $\\phi_0(\\vec x) = 0$.假设目标向量的条件分布是一个各向同性的高斯分布。\n\n$$p(\\vec t|\\vec x, \\mathbf W, \\beta) = \\mathcal N(\\vec t|\\mathbf W^T \\phi(\\vec x),\\beta^{-1}\\mathbf I) \\tag{3.32}$$\n\n如果我们有一组观察集 $\\vec t_1, ..., \\vec t_N$, 把它们组合进一个大小 $N\\times K$ 的矩阵$T$. 则对数似然函数为：\n\n$$\\ln p(\\mathbf T|\\mathbf X, \\mathbf W, \\beta) = \\sum_{n=1}^{N}\\mathcal N(\\vec t_n|\\mathbf W^T \\phi(\\vec x_n), \\beta^{-1}\\mathbf I)\\\\ = \\frac{NK}{2}\\ln(\\frac{\\beta}{2\\pi}) - \\frac{\\beta}{2}\\sum_{n=1}^{N}||\\vec t_n - \\mathbf W^T\\phi(\\vec x_n)||^2 \\tag{3.33}$$\n\n我们最大化该似然函数得到：\n\n$$\\mathbf W_{ML} = (\\Phi^T\\Phi)^{-1}\\Phi^T \\mathbf T \\tag{3.34}$$\n\n如果我们测试每一个目标的结果我们有：\n\n$$\\vec w_k = (\\Phi^T\\Phi)^{-1}\\Phi^T \\vec t_k$$\n\n$\\vec t_k$ 是一个N维的列向量。\n\n## The Bias-Variance Decomposition\n\n在我们目前考虑的线性回归模型中，我们假定了基函数的数量和形式都是固定的。如果使⽤有限规模的数据集来训练复杂的模型，那么使⽤最⼤似然⽅法（或最⼩平⽅⽅法），会导致严重的过拟合问题。然⽽，通过限制基函数的数量来避免过拟合问题有⼀个负作⽤，即限制了模型描述数据中有趣且重要的规律的灵活性。虽然引⼊正则化项可以控制具有多个参数的模型的过拟合问题，但是这就产⽣了⼀个问题：如何确定正则化系数 $\\lambda$ 的合适的值。同时关于权值 $w$ 和正则化系数 $\\lambda$ 来最小化正则化的误差函数显然不是⼀个正确的⽅法，因为这样做会使得 $\\lambda = 0$ ，从⽽产⽣非正则化的解。\n\n从频率学家的观点考虑⼀下模型的复杂度问题被称为 **偏置-⽅差折中（ bias-variance trade-off ）**\n\n当我们讨论回归问题的决策论时，我们考虑了不同的损失函数。⼀旦我们知道了\n条件概率分布 $p(t | x)$ ，每⼀种损失函数都能够给出对应的最优预测结果。使⽤最多的⼀个选择是平方损失函数，此时最优的预测由条件期望给出，即：\n\n$$h(\\vec x) = \\mathbb E[t | \\vec x] = \\int tp(t|\\vec x)dt \\tag{3.36}$$\n\n现在，有必要区分决策论中出现的平⽅损失函数以及模型参数的最⼤似然估计中出现的平⽅和误差函数。我们可以使⽤⽐最⼩平⽅更复杂的⽅法，例如正则化或者纯粹的贝叶斯⽅法，来确定条件概率分布 $p(t | x)$ 。为了进⾏预测，这些⽅法都可以与平⽅损失函数相结合。\n\n平方损失函数的期望可以写成：\n\n$$\\mathbb E[L] = \\int\\{y(\\vec x) - h(\\vec x)\\}^2p(\\vec x)d\\vec x + \\int \\int \\{h(\\vec x - t)\\}^2p(\\vec x, t)d\\vec x dt \\tag{3.37}$$\n\n回忆⼀下，与 y(x) ⽆关的第⼆项，是由数据本⾝的噪声造成的，表⽰期望损失能够达到的最⼩值。第⼀项与我们对函数 y(x) 的选择有关，我们要找⼀个 y(x) 的解，使得这⼀项最⼩。由于它是⾮负的，因此我们希望能够让这⼀项的最⼩值等于零。如果我们有⽆限多的数据（以及⽆限多的计算资源），那么原则上我们能够以任意的精度寻找回归函数 h(x) ，这会给出 y(x) 的最优解。然⽽，在实际应⽤中，我们的数据集 D 只有有限的 N 个数据点，从⽽我们不能够精确地知道回归函数 h(x) 。\n\n如果我们使⽤由参数向量 w 控制的函数 y(x,w) 对 h(x) 建模，那么从贝叶斯的观点来看我们模型的不确定性是通过 w 的后验概率分布来表⽰的。但是，频率学家的⽅法涉及到根据数据集 D 对 w 进⾏点估计，然后试着通过下⾯的思想实验来表⽰估计的不确定性。假设我们有许多数据集，每个数据集的⼤⼩为 N ，并且每个数据集都独⽴地从分布 p(t,x) 中抽取。对于任意给定的数据集 D ，我们可以运⾏我们的学习算法，得到⼀个预测函数 y(x;D) 。不同的数据集给出不同的函数，从⽽给出不同的平⽅损失的值。这样，特定的学习算法的表现就可以通过取各个数据集上的表现的平均值来进⾏评估。\n\n考虑公式（3.37）的第⼀项的被积函数，对于⼀个特定的数据集 D ，它的形式为\n\n$${y(\\vec x;D) − h(\\vec x)}^2 \\tag{3.38}$$\n\n由于这个量与特定的数据集 D 相关，因此我们对所有的数据集取平均.我们有:\n\n$$\\{y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)] + \\mathbb E_D[y(\\vec x;D)] − h(x)\\}^2 \\\\ = \\{y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)]\\}^2 + \\{\\mathbb E_D[y(\\vec x;D)] − h(x)\\}^2 + \\\\ 2\\{y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)]\\}\\{\\mathbb E_D[y(\\vec x;D)] − h(\\vec x)\\} \\tag{3.39}$$\n\n关于D求期望得到, 注意最后一项为0：\n\n$$\\mathbb E_D[\\{y(\\vec x; D) - h(\\vec x)\\}^2] \\\\ = \\{\\mathbb E_D[y(\\vec x; D)] - h(\\vec x)\\}^2 + \\mathbb E_D[\\{y(\\vec x; D) - \\mathbb E_D[y(\\vec x; D)]\\}^2] \\tag{3.40}$$\n\n$y(x;D)$ 与回归函数 $h(x)$ 的差的平⽅的期望可以表⽰为两项的和。第⼀项，被称为平⽅偏置（ **bias** ），表⽰所有数据集的平均预测与预期的回归函数之间的差异。第⼆项，被称为⽅差（ **variance** ），度量了对于单独的数据集，模型所给出的解在平均值附近波动的情况，此也就度量了函数 $y(x;D)$ 对于特定的数据集的选择的敏感程度。\n\n如果我们把这个展开式带回到公式（3.37）中，那么我们就得到了下⾯的对于期望平⽅损失的分解\n\n$$expected = (bias)^2 + variance + noise \\tag{3.41}$$\n\n$$ (bias)^2 = \\int \\{\\mathbb E_D[y(x;D)] − h(x)\\}^2p(x)dx \\\\\n    variance = \\int \\mathbb E_D[\\{y(\\vec x; D) - \\mathbb E_D[y(\\vec x; D)]\\}^2] p(x)dx \\\\\n    noise = \\int \\{h(x) - t\\}^2p(x,t)dxdt\n$$\n\n现在，偏置和⽅差指的是积分后的量。我们的⽬标是最⼩化期望损失，它可以分解为（平⽅）偏置、⽅差和⼀个常数噪声项的和。正如我们将看到的那样，在偏置和⽅差之间有⼀个折中。对于⾮常灵活的模型来说，偏置较⼩，⽅差较⼤。对于相对固定的模型来说，偏置较⼤，⽅差较⼩。有着最优预测能⼒的模型时在偏置和⽅差之间取得最优的平衡的模型。\n\n将多个解加权平均是贝叶斯⽅法的核⼼，虽然这种求平均针对的是参数的后验分布，⽽不是针对多个数据集。\n","source":"_posts/Linear-Models-for-Regression.md","raw":"---\ntitle: Linear Models for Regression\ndate: 2018-09-21 20:10:45\ntags: 回归\ncategories: 机器学习\nmathjax: true\n---\n## Linear Basis Function Models\n\n对于回归任务最简单的线性模型是：输入变量的线性组合。\n\n$$y(\\vec x, \\vec w) = w_0+ w_1x_1 + ... + w_Dx_D \\tag{3.1}$$\n\n这就是我们所说的线性回归。\n\n这个模型既是参数的线性函数也是输入的线性函数，然而这会带来很多限制。因此我们对输入变量进行一个非线性处理。\n\n$$y(\\vec x, \\vec w) = w_0 + \\sum_{j=1}^{M-1}w_j\\phi_j(\\vec x) = \\sum_{j=0}^{M-1}w_j\\phi_j(\\vec x) = \\vec w^T \\phi(\\vec x) \\tag{3.2}$$\n\n这里的 $\\phi_j(\\vec x)$ 就是所说 **基函数（basis function）** , 其中 $\\phi_0(\\vec x) = 1$, 注意 $\\vec w, \\vec \\phi$ 均为列向量。\n\n在许多模式识别的实际应⽤中，我们会对原始的数据变量进⾏某种固定形式的预处理或者特征抽取。如果原始变量由向量 x 组成，那么特征可以⽤基函数 $\\{\\phi_j(\\vec x)\\}$ 来表示。\n\n基函数的选择有很多种形式，比如：\n\n$$\\phi_j(x) = exp\\{-\\frac{(x - \\mu_j)^2}{2s^2}\\} \\tag{3.3}$$\n\n$\\mu_j$ 决定了基函数在输入空间的位置，$s$决定了空间的范围. 但这些参数都不是重要的，因为它们还要乘以一个自适应的系数 $w_j$.\n\n$$\\phi_j = \\sigma(\\frac{x- \\mu_j}{s}) \\tag{3.4}\\\\ \\sigma(a) = \\frac{1}{1 + exp(-a)}$$\n\n除此之外还有傅里叶基函数，比如对sin函数的扩展。每一个基函数表示一个具体的频率，并且在空间上是无限的。相对地，被限定在有限的输入空间上的基函数由多个频率组合而成。在信号处理领域，考虑在空间和频率上都是有限的基函数是很有用的，它们被称为 **小波(waveles)**。\n\n### Maximum likelihood and least squares\n\n我们假设目标变量t由下式得到\n\n$$t = y(\\vec x, \\vec w) + \\epsilon \\tag{3.5}$$\n\n$\\epsilon$ 是一个零均值的高斯随机变量，其精度为 $\\beta = \\frac{1}{\\sigma ^2}$\n因此\n\n$$p(t|\\vec x, \\vec w, \\beta) = \\mathcal N(t|y(\\vec x, \\vec w), \\beta^{-1}) \\tag{3.6}$$\n\n如果我们的损失函数是平方损失，那么最优的预测就是目标变量的条件期望。在（3.6）式的高斯条件分布下，它的条件期望为\n\n$$\\mathbb E[t|\\vec x] = \\int tp(t|\\vec x)dt = y(\\vec x, \\vec w) \\tag{3.7}$$\n\n注意，高斯噪声这样的假设暗示着给定x下t的条件期望是单峰的，这可能在一些应用上不适用。\n\n现在假设我们由N个观察到的输入数据 $\\mathbf X = \\{\\vec x_1, ..., \\vec x_N\\}$ 相对应的目标值是 $t_1, ..., t_N$. 这里把（3.6）写成矩阵形式得到的似然函数为：\n\n$$p(t|\\mathbf x, \\vec w, \\beta) = \\prod_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1}) \\tag{3.8}$$\n\n注意在监督学习问题中（分类和回归），我们并不要求对输入变量的分布建模。因此x可能不会出现在条件变量上。例如 $p(t|\\vec w, \\beta)$\n\n对式（3.8）取对数有：\n\n$$\\ln p(t|w, \\beta) = \\sum_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1})\\\\ = \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln(2\\pi) - \\beta E_D(\\vec w) \\tag{3.9}$$\n\n这里平方和误差为\n\n$$E_D(\\vec w) = \\frac{1}{2} \\sum_{n=1}^{N} \\{t_n - \\vec w^T \\phi(\\vec x_n)\\}^2 \\tag{3.10}$$\n\n最大化似然函数可通过对似然函数求导：\n\n$$\\frac{\\partial \\ln p(\\vec t |\\vec w, \\beta)}{\\partial \\vec w} = \\sum_{n=1}^{N} \\{t_n - \\vec w^T \\phi(\\vec x_n)\\} \\phi(\\vec x_n)^T \\tag{3.11}$$\n\n令导数为0得到：\n\n$$\\vec w_{ML} = (\\Phi ^T \\Phi)^{-1} \\Phi ^T \\vec t \\tag{3.12}$$\n\n这个方程被称为 **正则方程(normal equations)** .\n\n$$\\Phi = \\left [ \\begin{matrix} \\phi_0(\\vec x_1) & \\phi_1(\\vec x_1) ... \\phi_{M-1}(\\vec x_1)\\\\ \\phi_0(\\vec x_2) & \\phi_1(\\vec x_2) ... \\phi_{M-1}(\\vec x_2)\\\\ ... & ...\\\\ \\phi_0(\\vec x_N) & \\phi_1(\\vec x_N) ... \\phi_{M-1}(\\vec x_N\\end{matrix}\\right] \\tag{3.13}$$\n\n$\\Phi ^+ = ((\\Phi ^T \\Phi)^{-1} \\Phi ^T)$ 被称为矩阵 $\\Phi$ 的 **Moor-Penrose pseudo-inverse**\n\n同样我们也能得到 $\\beta$ 的最大似然估计量。\n$$\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}\\{t_n - \\vec w_{ML}^T \\phi(\\vec x_n)\\}^2$$\n\n### Geometry of least squares\n\n考虑这样一个N维空间，其以$t_n$为坐标轴，因此 $\\vec t = (t_1, ..., t_N)^T$ 是该空间的一个向量。在N个数据上的每一个基函数 $\\phi_j(\\vec x_n)$ 也能表示为相同空间中的向量。我们定义 $\\vec y$ 是一个N维向量，它的第n个元素是 $y(\\vec x_n, \\vec w)$. 由于 $\\vec y$ 是 $\\phi_j(\\vec x_n)$ 在M维空间的任意线性组合。误差平方和等价于 $\\vec y$和 $t$ 之间的欧几里得距离。 因此最小二乘解就是选择在子空间中最接近 $\\vec t$的 $\\vec y$.\n\n![](/images/lmfr.PNG)\n\n### Sequential learning\n\n批处理技术使得可以一次处理很大的训练数据集。如果数据集是足够大，此时使用序列算法可能更有用，序列算法也被称作 **在线（on-line）算法**。这种算法在每一次表示后都更新模型的参数。序列学习适用于一些观察数据是连续产生的实时应用，这些应用必须利用目前所有观测到的数据来预测。\n\n我们能应用随机梯度下降技术来获得序列学习算法。\n\n$$w^{\\tau + 1} = w^\\tau - \\eta \\nabla E_n \\tag{3.22}$$\n\n这里 $\\tau$ 是迭代的次数，$\\eta$ 是学习率。对于（3.10）那样的平方和误差函数，上式可写为：\n\n$$w^{\\tau + 1} = w^\\tau + \\eta (t_n - w^{(\\tau)T}\\Phi_n)\\Phi_n \\tag{3.23}$$\n\n$\\Phi_n = \\Phi(x_n)$ 这就是 **least-mean-squares(LMS)** 算法。\n\n### Regularized learst squares\n\n我们给误差函数增加一个正则项来控制模型的过拟合。新的误差函数为。\n\n$$E_D(W) + \\lambda E_w(w) \\tag{3.24}$$\n\n$\\lambda$ 是正则系数用来控制由数据决定的误差和由正则项引入的误差的相对重要程度。一个最简单的正则形式为权重向量的平方和：\n\n$$E_w(\\vec w) = \\frac{1}{2}\\vec w^T \\vec w \\tag{3.25}$$\n\n如果我们考虑平方和误差函数，那么总的误差为：\n\n$$\\frac{1}{2}\\sum_{n=1}^{N}\\{t_n - \\vec w^T \\Phi(\\vec x_n)\\}^2 + \\frac{\\lambda}{2}\\vec w^T \\vec w \\tag{3.27}$$\n\n在机器学习文献中正则的一个解释是 **权重衰减**，因为在序列学习中，它鼓励权重向朝着0的方向变化。\n在统计学中它提供一种参数收缩的方法。它的优点是误差函数保持为w的二次型，因此可以得到精确的最小化解。\n\n$$\\vec w = (\\lambda \\mathbf I + \\Phi^T\\Phi)^{-1}\\Phi^T \\vec t \\tag{3.28}$$\n\n有时也会使用更一般的正则化形式如：\n\n$$\\frac{1}{2}\\sum_{n=1}^{N}\\{t_n - \\vec w^T \\Phi(\\vec x_n)\\}^2 + \\frac{\\lambda}{2}\\sum_{j=1}^M |w_j|^q \\tag{3.29}$$\n\n$q=1$ 时为统计学中所说的lasso。它有这样的特点：如果 $\\lambda$ 足够大，一些系数就被学习为0，与之对应的基函数就没有起作用。这学得一个稀疏的模型。\n\n![](/images/lmfr_f3.PNG)\n\n正则化允许在大小有限的数据集上训练复杂的模型而不导致严重的过拟合，这实质上是通过限制有效的模型复杂度来实现的。然而，决定最优模型复杂度的问题从寻找合适基函数的数量转变为决定一个合适的正则化系数 $\\lambda$。\n\n![](/images/lmfr_f4.PNG)\n\n### Multiple outputs\n\n到目前为止我们已经考虑了单个目标变量的例子，在某些应用中我们可能希望预测多个目标变量，我们将它们定义为一个目标向量 $\\vec t$。这可能通过分别对每一个目标变量定义一组基函数，依照单变量回归那样做。然而一个更合适更常用的方法是，使用同样的一组基函数来对所有的目标变量建模。\n\n$$y(\\vec x, \\vec w) = \\mathbf W^T \\phi(\\vec x) \\tag{3.31}$$\n\n这里 $\\vec y$ 是一个K维的列向量，$\\mathbf W$ 是一个$M \\times K$的参数矩阵。$\\phi(\\vec x)$ 是一个M维的列向量其中 $\\phi_0(\\vec x) = 0$.假设目标向量的条件分布是一个各向同性的高斯分布。\n\n$$p(\\vec t|\\vec x, \\mathbf W, \\beta) = \\mathcal N(\\vec t|\\mathbf W^T \\phi(\\vec x),\\beta^{-1}\\mathbf I) \\tag{3.32}$$\n\n如果我们有一组观察集 $\\vec t_1, ..., \\vec t_N$, 把它们组合进一个大小 $N\\times K$ 的矩阵$T$. 则对数似然函数为：\n\n$$\\ln p(\\mathbf T|\\mathbf X, \\mathbf W, \\beta) = \\sum_{n=1}^{N}\\mathcal N(\\vec t_n|\\mathbf W^T \\phi(\\vec x_n), \\beta^{-1}\\mathbf I)\\\\ = \\frac{NK}{2}\\ln(\\frac{\\beta}{2\\pi}) - \\frac{\\beta}{2}\\sum_{n=1}^{N}||\\vec t_n - \\mathbf W^T\\phi(\\vec x_n)||^2 \\tag{3.33}$$\n\n我们最大化该似然函数得到：\n\n$$\\mathbf W_{ML} = (\\Phi^T\\Phi)^{-1}\\Phi^T \\mathbf T \\tag{3.34}$$\n\n如果我们测试每一个目标的结果我们有：\n\n$$\\vec w_k = (\\Phi^T\\Phi)^{-1}\\Phi^T \\vec t_k$$\n\n$\\vec t_k$ 是一个N维的列向量。\n\n## The Bias-Variance Decomposition\n\n在我们目前考虑的线性回归模型中，我们假定了基函数的数量和形式都是固定的。如果使⽤有限规模的数据集来训练复杂的模型，那么使⽤最⼤似然⽅法（或最⼩平⽅⽅法），会导致严重的过拟合问题。然⽽，通过限制基函数的数量来避免过拟合问题有⼀个负作⽤，即限制了模型描述数据中有趣且重要的规律的灵活性。虽然引⼊正则化项可以控制具有多个参数的模型的过拟合问题，但是这就产⽣了⼀个问题：如何确定正则化系数 $\\lambda$ 的合适的值。同时关于权值 $w$ 和正则化系数 $\\lambda$ 来最小化正则化的误差函数显然不是⼀个正确的⽅法，因为这样做会使得 $\\lambda = 0$ ，从⽽产⽣非正则化的解。\n\n从频率学家的观点考虑⼀下模型的复杂度问题被称为 **偏置-⽅差折中（ bias-variance trade-off ）**\n\n当我们讨论回归问题的决策论时，我们考虑了不同的损失函数。⼀旦我们知道了\n条件概率分布 $p(t | x)$ ，每⼀种损失函数都能够给出对应的最优预测结果。使⽤最多的⼀个选择是平方损失函数，此时最优的预测由条件期望给出，即：\n\n$$h(\\vec x) = \\mathbb E[t | \\vec x] = \\int tp(t|\\vec x)dt \\tag{3.36}$$\n\n现在，有必要区分决策论中出现的平⽅损失函数以及模型参数的最⼤似然估计中出现的平⽅和误差函数。我们可以使⽤⽐最⼩平⽅更复杂的⽅法，例如正则化或者纯粹的贝叶斯⽅法，来确定条件概率分布 $p(t | x)$ 。为了进⾏预测，这些⽅法都可以与平⽅损失函数相结合。\n\n平方损失函数的期望可以写成：\n\n$$\\mathbb E[L] = \\int\\{y(\\vec x) - h(\\vec x)\\}^2p(\\vec x)d\\vec x + \\int \\int \\{h(\\vec x - t)\\}^2p(\\vec x, t)d\\vec x dt \\tag{3.37}$$\n\n回忆⼀下，与 y(x) ⽆关的第⼆项，是由数据本⾝的噪声造成的，表⽰期望损失能够达到的最⼩值。第⼀项与我们对函数 y(x) 的选择有关，我们要找⼀个 y(x) 的解，使得这⼀项最⼩。由于它是⾮负的，因此我们希望能够让这⼀项的最⼩值等于零。如果我们有⽆限多的数据（以及⽆限多的计算资源），那么原则上我们能够以任意的精度寻找回归函数 h(x) ，这会给出 y(x) 的最优解。然⽽，在实际应⽤中，我们的数据集 D 只有有限的 N 个数据点，从⽽我们不能够精确地知道回归函数 h(x) 。\n\n如果我们使⽤由参数向量 w 控制的函数 y(x,w) 对 h(x) 建模，那么从贝叶斯的观点来看我们模型的不确定性是通过 w 的后验概率分布来表⽰的。但是，频率学家的⽅法涉及到根据数据集 D 对 w 进⾏点估计，然后试着通过下⾯的思想实验来表⽰估计的不确定性。假设我们有许多数据集，每个数据集的⼤⼩为 N ，并且每个数据集都独⽴地从分布 p(t,x) 中抽取。对于任意给定的数据集 D ，我们可以运⾏我们的学习算法，得到⼀个预测函数 y(x;D) 。不同的数据集给出不同的函数，从⽽给出不同的平⽅损失的值。这样，特定的学习算法的表现就可以通过取各个数据集上的表现的平均值来进⾏评估。\n\n考虑公式（3.37）的第⼀项的被积函数，对于⼀个特定的数据集 D ，它的形式为\n\n$${y(\\vec x;D) − h(\\vec x)}^2 \\tag{3.38}$$\n\n由于这个量与特定的数据集 D 相关，因此我们对所有的数据集取平均.我们有:\n\n$$\\{y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)] + \\mathbb E_D[y(\\vec x;D)] − h(x)\\}^2 \\\\ = \\{y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)]\\}^2 + \\{\\mathbb E_D[y(\\vec x;D)] − h(x)\\}^2 + \\\\ 2\\{y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)]\\}\\{\\mathbb E_D[y(\\vec x;D)] − h(\\vec x)\\} \\tag{3.39}$$\n\n关于D求期望得到, 注意最后一项为0：\n\n$$\\mathbb E_D[\\{y(\\vec x; D) - h(\\vec x)\\}^2] \\\\ = \\{\\mathbb E_D[y(\\vec x; D)] - h(\\vec x)\\}^2 + \\mathbb E_D[\\{y(\\vec x; D) - \\mathbb E_D[y(\\vec x; D)]\\}^2] \\tag{3.40}$$\n\n$y(x;D)$ 与回归函数 $h(x)$ 的差的平⽅的期望可以表⽰为两项的和。第⼀项，被称为平⽅偏置（ **bias** ），表⽰所有数据集的平均预测与预期的回归函数之间的差异。第⼆项，被称为⽅差（ **variance** ），度量了对于单独的数据集，模型所给出的解在平均值附近波动的情况，此也就度量了函数 $y(x;D)$ 对于特定的数据集的选择的敏感程度。\n\n如果我们把这个展开式带回到公式（3.37）中，那么我们就得到了下⾯的对于期望平⽅损失的分解\n\n$$expected = (bias)^2 + variance + noise \\tag{3.41}$$\n\n$$ (bias)^2 = \\int \\{\\mathbb E_D[y(x;D)] − h(x)\\}^2p(x)dx \\\\\n    variance = \\int \\mathbb E_D[\\{y(\\vec x; D) - \\mathbb E_D[y(\\vec x; D)]\\}^2] p(x)dx \\\\\n    noise = \\int \\{h(x) - t\\}^2p(x,t)dxdt\n$$\n\n现在，偏置和⽅差指的是积分后的量。我们的⽬标是最⼩化期望损失，它可以分解为（平⽅）偏置、⽅差和⼀个常数噪声项的和。正如我们将看到的那样，在偏置和⽅差之间有⼀个折中。对于⾮常灵活的模型来说，偏置较⼩，⽅差较⼤。对于相对固定的模型来说，偏置较⼤，⽅差较⼩。有着最优预测能⼒的模型时在偏置和⽅差之间取得最优的平衡的模型。\n\n将多个解加权平均是贝叶斯⽅法的核⼼，虽然这种求平均针对的是参数的后验分布，⽽不是针对多个数据集。\n","slug":"Linear-Models-for-Regression","published":1,"updated":"2018-09-27T19:26:04.659Z","_id":"cjmk9ds20000jpcvom2it3i2u","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Linear-Basis-Function-Models\"><a href=\"#Linear-Basis-Function-Models\" class=\"headerlink\" title=\"Linear Basis Function Models\"></a>Linear Basis Function Models</h2><p>对于回归任务最简单的线性模型是：输入变量的线性组合。</p>\n<p>$$y(\\vec x, \\vec w) = w_0+ w_1x_1 + … + w_Dx_D \\tag{3.1}$$</p>\n<p>这就是我们所说的线性回归。</p>\n<p>这个模型既是参数的线性函数也是输入的线性函数，然而这会带来很多限制。因此我们对输入变量进行一个非线性处理。</p>\n<p>$$y(\\vec x, \\vec w) = w_0 + \\sum_{j=1}^{M-1}w_j\\phi_j(\\vec x) = \\sum_{j=0}^{M-1}w_j\\phi_j(\\vec x) = \\vec w^T \\phi(\\vec x) \\tag{3.2}$$</p>\n<p>这里的 $\\phi_j(\\vec x)$ 就是所说 <strong>基函数（basis function）</strong> , 其中 $\\phi_0(\\vec x) = 1$, 注意 $\\vec w, \\vec \\phi$ 均为列向量。</p>\n<p>在许多模式识别的实际应⽤中，我们会对原始的数据变量进⾏某种固定形式的预处理或者特征抽取。如果原始变量由向量 x 组成，那么特征可以⽤基函数 ${\\phi_j(\\vec x)}$ 来表示。</p>\n<p>基函数的选择有很多种形式，比如：</p>\n<p>$$\\phi_j(x) = exp{-\\frac{(x - \\mu_j)^2}{2s^2}} \\tag{3.3}$$</p>\n<p>$\\mu_j$ 决定了基函数在输入空间的位置，$s$决定了空间的范围. 但这些参数都不是重要的，因为它们还要乘以一个自适应的系数 $w_j$.</p>\n<p>$$\\phi_j = \\sigma(\\frac{x- \\mu_j}{s}) \\tag{3.4}\\ \\sigma(a) = \\frac{1}{1 + exp(-a)}$$</p>\n<p>除此之外还有傅里叶基函数，比如对sin函数的扩展。每一个基函数表示一个具体的频率，并且在空间上是无限的。相对地，被限定在有限的输入空间上的基函数由多个频率组合而成。在信号处理领域，考虑在空间和频率上都是有限的基函数是很有用的，它们被称为 <strong>小波(waveles)</strong>。</p>\n<h3 id=\"Maximum-likelihood-and-least-squares\"><a href=\"#Maximum-likelihood-and-least-squares\" class=\"headerlink\" title=\"Maximum likelihood and least squares\"></a>Maximum likelihood and least squares</h3><p>我们假设目标变量t由下式得到</p>\n<p>$$t = y(\\vec x, \\vec w) + \\epsilon \\tag{3.5}$$</p>\n<p>$\\epsilon$ 是一个零均值的高斯随机变量，其精度为 $\\beta = \\frac{1}{\\sigma ^2}$<br>因此</p>\n<p>$$p(t|\\vec x, \\vec w, \\beta) = \\mathcal N(t|y(\\vec x, \\vec w), \\beta^{-1}) \\tag{3.6}$$</p>\n<p>如果我们的损失函数是平方损失，那么最优的预测就是目标变量的条件期望。在（3.6）式的高斯条件分布下，它的条件期望为</p>\n<p>$$\\mathbb E[t|\\vec x] = \\int tp(t|\\vec x)dt = y(\\vec x, \\vec w) \\tag{3.7}$$</p>\n<p>注意，高斯噪声这样的假设暗示着给定x下t的条件期望是单峰的，这可能在一些应用上不适用。</p>\n<p>现在假设我们由N个观察到的输入数据 $\\mathbf X = {\\vec x_1, …, \\vec x_N}$ 相对应的目标值是 $t_1, …, t_N$. 这里把（3.6）写成矩阵形式得到的似然函数为：</p>\n<p>$$p(t|\\mathbf x, \\vec w, \\beta) = \\prod_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1}) \\tag{3.8}$$</p>\n<p>注意在监督学习问题中（分类和回归），我们并不要求对输入变量的分布建模。因此x可能不会出现在条件变量上。例如 $p(t|\\vec w, \\beta)$</p>\n<p>对式（3.8）取对数有：</p>\n<p>$$\\ln p(t|w, \\beta) = \\sum_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1})\\ = \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln(2\\pi) - \\beta E_D(\\vec w) \\tag{3.9}$$</p>\n<p>这里平方和误差为</p>\n<p>$$E_D(\\vec w) = \\frac{1}{2} \\sum_{n=1}^{N} {t_n - \\vec w^T \\phi(\\vec x_n)}^2 \\tag{3.10}$$</p>\n<p>最大化似然函数可通过对似然函数求导：</p>\n<p>$$\\frac{\\partial \\ln p(\\vec t |\\vec w, \\beta)}{\\partial \\vec w} = \\sum_{n=1}^{N} {t_n - \\vec w^T \\phi(\\vec x_n)} \\phi(\\vec x_n)^T \\tag{3.11}$$</p>\n<p>令导数为0得到：</p>\n<p>$$\\vec w_{ML} = (\\Phi ^T \\Phi)^{-1} \\Phi ^T \\vec t \\tag{3.12}$$</p>\n<p>这个方程被称为 <strong>正则方程(normal equations)</strong> .</p>\n<p>$$\\Phi = \\left [ \\begin{matrix} \\phi_0(\\vec x_1) &amp; \\phi_1(\\vec x_1) … \\phi_{M-1}(\\vec x_1)\\ \\phi_0(\\vec x_2) &amp; \\phi_1(\\vec x_2) … \\phi_{M-1}(\\vec x_2)\\ … &amp; …\\ \\phi_0(\\vec x_N) &amp; \\phi_1(\\vec x_N) … \\phi_{M-1}(\\vec x_N\\end{matrix}\\right] \\tag{3.13}$$</p>\n<p>$\\Phi ^+ = ((\\Phi ^T \\Phi)^{-1} \\Phi ^T)$ 被称为矩阵 $\\Phi$ 的 <strong>Moor-Penrose pseudo-inverse</strong></p>\n<p>同样我们也能得到 $\\beta$ 的最大似然估计量。<br>$$\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}{t_n - \\vec w_{ML}^T \\phi(\\vec x_n)}^2$$</p>\n<h3 id=\"Geometry-of-least-squares\"><a href=\"#Geometry-of-least-squares\" class=\"headerlink\" title=\"Geometry of least squares\"></a>Geometry of least squares</h3><p>考虑这样一个N维空间，其以$t_n$为坐标轴，因此 $\\vec t = (t_1, …, t_N)^T$ 是该空间的一个向量。在N个数据上的每一个基函数 $\\phi_j(\\vec x_n)$ 也能表示为相同空间中的向量。我们定义 $\\vec y$ 是一个N维向量，它的第n个元素是 $y(\\vec x_n, \\vec w)$. 由于 $\\vec y$ 是 $\\phi_j(\\vec x_n)$ 在M维空间的任意线性组合。误差平方和等价于 $\\vec y$和 $t$ 之间的欧几里得距离。 因此最小二乘解就是选择在子空间中最接近 $\\vec t$的 $\\vec y$.</p>\n<p><img src=\"/images/lmfr.PNG\" alt=\"\"></p>\n<h3 id=\"Sequential-learning\"><a href=\"#Sequential-learning\" class=\"headerlink\" title=\"Sequential learning\"></a>Sequential learning</h3><p>批处理技术使得可以一次处理很大的训练数据集。如果数据集是足够大，此时使用序列算法可能更有用，序列算法也被称作 <strong>在线（on-line）算法</strong>。这种算法在每一次表示后都更新模型的参数。序列学习适用于一些观察数据是连续产生的实时应用，这些应用必须利用目前所有观测到的数据来预测。</p>\n<p>我们能应用随机梯度下降技术来获得序列学习算法。</p>\n<p>$$w^{\\tau + 1} = w^\\tau - \\eta \\nabla E_n \\tag{3.22}$$</p>\n<p>这里 $\\tau$ 是迭代的次数，$\\eta$ 是学习率。对于（3.10）那样的平方和误差函数，上式可写为：</p>\n<p>$$w^{\\tau + 1} = w^\\tau + \\eta (t_n - w^{(\\tau)T}\\Phi_n)\\Phi_n \\tag{3.23}$$</p>\n<p>$\\Phi_n = \\Phi(x_n)$ 这就是 <strong>least-mean-squares(LMS)</strong> 算法。</p>\n<h3 id=\"Regularized-learst-squares\"><a href=\"#Regularized-learst-squares\" class=\"headerlink\" title=\"Regularized learst squares\"></a>Regularized learst squares</h3><p>我们给误差函数增加一个正则项来控制模型的过拟合。新的误差函数为。</p>\n<p>$$E_D(W) + \\lambda E_w(w) \\tag{3.24}$$</p>\n<p>$\\lambda$ 是正则系数用来控制由数据决定的误差和由正则项引入的误差的相对重要程度。一个最简单的正则形式为权重向量的平方和：</p>\n<p>$$E_w(\\vec w) = \\frac{1}{2}\\vec w^T \\vec w \\tag{3.25}$$</p>\n<p>如果我们考虑平方和误差函数，那么总的误差为：</p>\n<p>$$\\frac{1}{2}\\sum_{n=1}^{N}{t_n - \\vec w^T \\Phi(\\vec x_n)}^2 + \\frac{\\lambda}{2}\\vec w^T \\vec w \\tag{3.27}$$</p>\n<p>在机器学习文献中正则的一个解释是 <strong>权重衰减</strong>，因为在序列学习中，它鼓励权重向朝着0的方向变化。<br>在统计学中它提供一种参数收缩的方法。它的优点是误差函数保持为w的二次型，因此可以得到精确的最小化解。</p>\n<p>$$\\vec w = (\\lambda \\mathbf I + \\Phi^T\\Phi)^{-1}\\Phi^T \\vec t \\tag{3.28}$$</p>\n<p>有时也会使用更一般的正则化形式如：</p>\n<p>$$\\frac{1}{2}\\sum_{n=1}^{N}{t_n - \\vec w^T \\Phi(\\vec x_n)}^2 + \\frac{\\lambda}{2}\\sum_{j=1}^M |w_j|^q \\tag{3.29}$$</p>\n<p>$q=1$ 时为统计学中所说的lasso。它有这样的特点：如果 $\\lambda$ 足够大，一些系数就被学习为0，与之对应的基函数就没有起作用。这学得一个稀疏的模型。</p>\n<p><img src=\"/images/lmfr_f3.PNG\" alt=\"\"></p>\n<p>正则化允许在大小有限的数据集上训练复杂的模型而不导致严重的过拟合，这实质上是通过限制有效的模型复杂度来实现的。然而，决定最优模型复杂度的问题从寻找合适基函数的数量转变为决定一个合适的正则化系数 $\\lambda$。</p>\n<p><img src=\"/images/lmfr_f4.PNG\" alt=\"\"></p>\n<h3 id=\"Multiple-outputs\"><a href=\"#Multiple-outputs\" class=\"headerlink\" title=\"Multiple outputs\"></a>Multiple outputs</h3><p>到目前为止我们已经考虑了单个目标变量的例子，在某些应用中我们可能希望预测多个目标变量，我们将它们定义为一个目标向量 $\\vec t$。这可能通过分别对每一个目标变量定义一组基函数，依照单变量回归那样做。然而一个更合适更常用的方法是，使用同样的一组基函数来对所有的目标变量建模。</p>\n<p>$$y(\\vec x, \\vec w) = \\mathbf W^T \\phi(\\vec x) \\tag{3.31}$$</p>\n<p>这里 $\\vec y$ 是一个K维的列向量，$\\mathbf W$ 是一个$M \\times K$的参数矩阵。$\\phi(\\vec x)$ 是一个M维的列向量其中 $\\phi_0(\\vec x) = 0$.假设目标向量的条件分布是一个各向同性的高斯分布。</p>\n<p>$$p(\\vec t|\\vec x, \\mathbf W, \\beta) = \\mathcal N(\\vec t|\\mathbf W^T \\phi(\\vec x),\\beta^{-1}\\mathbf I) \\tag{3.32}$$</p>\n<p>如果我们有一组观察集 $\\vec t_1, …, \\vec t_N$, 把它们组合进一个大小 $N\\times K$ 的矩阵$T$. 则对数似然函数为：</p>\n<p>$$\\ln p(\\mathbf T|\\mathbf X, \\mathbf W, \\beta) = \\sum_{n=1}^{N}\\mathcal N(\\vec t_n|\\mathbf W^T \\phi(\\vec x_n), \\beta^{-1}\\mathbf I)\\ = \\frac{NK}{2}\\ln(\\frac{\\beta}{2\\pi}) - \\frac{\\beta}{2}\\sum_{n=1}^{N}||\\vec t_n - \\mathbf W^T\\phi(\\vec x_n)||^2 \\tag{3.33}$$</p>\n<p>我们最大化该似然函数得到：</p>\n<p>$$\\mathbf W_{ML} = (\\Phi^T\\Phi)^{-1}\\Phi^T \\mathbf T \\tag{3.34}$$</p>\n<p>如果我们测试每一个目标的结果我们有：</p>\n<p>$$\\vec w_k = (\\Phi^T\\Phi)^{-1}\\Phi^T \\vec t_k$$</p>\n<p>$\\vec t_k$ 是一个N维的列向量。</p>\n<h2 id=\"The-Bias-Variance-Decomposition\"><a href=\"#The-Bias-Variance-Decomposition\" class=\"headerlink\" title=\"The Bias-Variance Decomposition\"></a>The Bias-Variance Decomposition</h2><p>在我们目前考虑的线性回归模型中，我们假定了基函数的数量和形式都是固定的。如果使⽤有限规模的数据集来训练复杂的模型，那么使⽤最⼤似然⽅法（或最⼩平⽅⽅法），会导致严重的过拟合问题。然⽽，通过限制基函数的数量来避免过拟合问题有⼀个负作⽤，即限制了模型描述数据中有趣且重要的规律的灵活性。虽然引⼊正则化项可以控制具有多个参数的模型的过拟合问题，但是这就产⽣了⼀个问题：如何确定正则化系数 $\\lambda$ 的合适的值。同时关于权值 $w$ 和正则化系数 $\\lambda$ 来最小化正则化的误差函数显然不是⼀个正确的⽅法，因为这样做会使得 $\\lambda = 0$ ，从⽽产⽣非正则化的解。</p>\n<p>从频率学家的观点考虑⼀下模型的复杂度问题被称为 <strong>偏置-⽅差折中（ bias-variance trade-off ）</strong></p>\n<p>当我们讨论回归问题的决策论时，我们考虑了不同的损失函数。⼀旦我们知道了<br>条件概率分布 $p(t | x)$ ，每⼀种损失函数都能够给出对应的最优预测结果。使⽤最多的⼀个选择是平方损失函数，此时最优的预测由条件期望给出，即：</p>\n<p>$$h(\\vec x) = \\mathbb E[t | \\vec x] = \\int tp(t|\\vec x)dt \\tag{3.36}$$</p>\n<p>现在，有必要区分决策论中出现的平⽅损失函数以及模型参数的最⼤似然估计中出现的平⽅和误差函数。我们可以使⽤⽐最⼩平⽅更复杂的⽅法，例如正则化或者纯粹的贝叶斯⽅法，来确定条件概率分布 $p(t | x)$ 。为了进⾏预测，这些⽅法都可以与平⽅损失函数相结合。</p>\n<p>平方损失函数的期望可以写成：</p>\n<p>$$\\mathbb E[L] = \\int{y(\\vec x) - h(\\vec x)}^2p(\\vec x)d\\vec x + \\int \\int {h(\\vec x - t)}^2p(\\vec x, t)d\\vec x dt \\tag{3.37}$$</p>\n<p>回忆⼀下，与 y(x) ⽆关的第⼆项，是由数据本⾝的噪声造成的，表⽰期望损失能够达到的最⼩值。第⼀项与我们对函数 y(x) 的选择有关，我们要找⼀个 y(x) 的解，使得这⼀项最⼩。由于它是⾮负的，因此我们希望能够让这⼀项的最⼩值等于零。如果我们有⽆限多的数据（以及⽆限多的计算资源），那么原则上我们能够以任意的精度寻找回归函数 h(x) ，这会给出 y(x) 的最优解。然⽽，在实际应⽤中，我们的数据集 D 只有有限的 N 个数据点，从⽽我们不能够精确地知道回归函数 h(x) 。</p>\n<p>如果我们使⽤由参数向量 w 控制的函数 y(x,w) 对 h(x) 建模，那么从贝叶斯的观点来看我们模型的不确定性是通过 w 的后验概率分布来表⽰的。但是，频率学家的⽅法涉及到根据数据集 D 对 w 进⾏点估计，然后试着通过下⾯的思想实验来表⽰估计的不确定性。假设我们有许多数据集，每个数据集的⼤⼩为 N ，并且每个数据集都独⽴地从分布 p(t,x) 中抽取。对于任意给定的数据集 D ，我们可以运⾏我们的学习算法，得到⼀个预测函数 y(x;D) 。不同的数据集给出不同的函数，从⽽给出不同的平⽅损失的值。这样，特定的学习算法的表现就可以通过取各个数据集上的表现的平均值来进⾏评估。</p>\n<p>考虑公式（3.37）的第⼀项的被积函数，对于⼀个特定的数据集 D ，它的形式为</p>\n<p>$${y(\\vec x;D) − h(\\vec x)}^2 \\tag{3.38}$$</p>\n<p>由于这个量与特定的数据集 D 相关，因此我们对所有的数据集取平均.我们有:</p>\n<p>$${y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)] + \\mathbb E_D[y(\\vec x;D)] − h(x)}^2 \\ = {y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)]}^2 + {\\mathbb E_D[y(\\vec x;D)] − h(x)}^2 + \\ 2{y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)]}{\\mathbb E_D[y(\\vec x;D)] − h(\\vec x)} \\tag{3.39}$$</p>\n<p>关于D求期望得到, 注意最后一项为0：</p>\n<p>$$\\mathbb E_D[{y(\\vec x; D) - h(\\vec x)}^2] \\ = {\\mathbb E_D[y(\\vec x; D)] - h(\\vec x)}^2 + \\mathbb E_D[{y(\\vec x; D) - \\mathbb E_D[y(\\vec x; D)]}^2] \\tag{3.40}$$</p>\n<p>$y(x;D)$ 与回归函数 $h(x)$ 的差的平⽅的期望可以表⽰为两项的和。第⼀项，被称为平⽅偏置（ <strong>bias</strong> ），表⽰所有数据集的平均预测与预期的回归函数之间的差异。第⼆项，被称为⽅差（ <strong>variance</strong> ），度量了对于单独的数据集，模型所给出的解在平均值附近波动的情况，此也就度量了函数 $y(x;D)$ 对于特定的数据集的选择的敏感程度。</p>\n<p>如果我们把这个展开式带回到公式（3.37）中，那么我们就得到了下⾯的对于期望平⽅损失的分解</p>\n<p>$$expected = (bias)^2 + variance + noise \\tag{3.41}$$</p>\n<p>$$ (bias)^2 = \\int {\\mathbb E_D[y(x;D)] − h(x)}^2p(x)dx \\<br>    variance = \\int \\mathbb E_D[{y(\\vec x; D) - \\mathbb E_D[y(\\vec x; D)]}^2] p(x)dx \\<br>    noise = \\int {h(x) - t}^2p(x,t)dxdt<br>$$</p>\n<p>现在，偏置和⽅差指的是积分后的量。我们的⽬标是最⼩化期望损失，它可以分解为（平⽅）偏置、⽅差和⼀个常数噪声项的和。正如我们将看到的那样，在偏置和⽅差之间有⼀个折中。对于⾮常灵活的模型来说，偏置较⼩，⽅差较⼤。对于相对固定的模型来说，偏置较⼤，⽅差较⼩。有着最优预测能⼒的模型时在偏置和⽅差之间取得最优的平衡的模型。</p>\n<p>将多个解加权平均是贝叶斯⽅法的核⼼，虽然这种求平均针对的是参数的后验分布，⽽不是针对多个数据集。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Linear-Basis-Function-Models\"><a href=\"#Linear-Basis-Function-Models\" class=\"headerlink\" title=\"Linear Basis Function Models\"></a>Linear Basis Function Models</h2><p>对于回归任务最简单的线性模型是：输入变量的线性组合。</p>\n<p>$$y(\\vec x, \\vec w) = w_0+ w_1x_1 + … + w_Dx_D \\tag{3.1}$$</p>\n<p>这就是我们所说的线性回归。</p>\n<p>这个模型既是参数的线性函数也是输入的线性函数，然而这会带来很多限制。因此我们对输入变量进行一个非线性处理。</p>\n<p>$$y(\\vec x, \\vec w) = w_0 + \\sum_{j=1}^{M-1}w_j\\phi_j(\\vec x) = \\sum_{j=0}^{M-1}w_j\\phi_j(\\vec x) = \\vec w^T \\phi(\\vec x) \\tag{3.2}$$</p>\n<p>这里的 $\\phi_j(\\vec x)$ 就是所说 <strong>基函数（basis function）</strong> , 其中 $\\phi_0(\\vec x) = 1$, 注意 $\\vec w, \\vec \\phi$ 均为列向量。</p>\n<p>在许多模式识别的实际应⽤中，我们会对原始的数据变量进⾏某种固定形式的预处理或者特征抽取。如果原始变量由向量 x 组成，那么特征可以⽤基函数 ${\\phi_j(\\vec x)}$ 来表示。</p>\n<p>基函数的选择有很多种形式，比如：</p>\n<p>$$\\phi_j(x) = exp{-\\frac{(x - \\mu_j)^2}{2s^2}} \\tag{3.3}$$</p>\n<p>$\\mu_j$ 决定了基函数在输入空间的位置，$s$决定了空间的范围. 但这些参数都不是重要的，因为它们还要乘以一个自适应的系数 $w_j$.</p>\n<p>$$\\phi_j = \\sigma(\\frac{x- \\mu_j}{s}) \\tag{3.4}\\ \\sigma(a) = \\frac{1}{1 + exp(-a)}$$</p>\n<p>除此之外还有傅里叶基函数，比如对sin函数的扩展。每一个基函数表示一个具体的频率，并且在空间上是无限的。相对地，被限定在有限的输入空间上的基函数由多个频率组合而成。在信号处理领域，考虑在空间和频率上都是有限的基函数是很有用的，它们被称为 <strong>小波(waveles)</strong>。</p>\n<h3 id=\"Maximum-likelihood-and-least-squares\"><a href=\"#Maximum-likelihood-and-least-squares\" class=\"headerlink\" title=\"Maximum likelihood and least squares\"></a>Maximum likelihood and least squares</h3><p>我们假设目标变量t由下式得到</p>\n<p>$$t = y(\\vec x, \\vec w) + \\epsilon \\tag{3.5}$$</p>\n<p>$\\epsilon$ 是一个零均值的高斯随机变量，其精度为 $\\beta = \\frac{1}{\\sigma ^2}$<br>因此</p>\n<p>$$p(t|\\vec x, \\vec w, \\beta) = \\mathcal N(t|y(\\vec x, \\vec w), \\beta^{-1}) \\tag{3.6}$$</p>\n<p>如果我们的损失函数是平方损失，那么最优的预测就是目标变量的条件期望。在（3.6）式的高斯条件分布下，它的条件期望为</p>\n<p>$$\\mathbb E[t|\\vec x] = \\int tp(t|\\vec x)dt = y(\\vec x, \\vec w) \\tag{3.7}$$</p>\n<p>注意，高斯噪声这样的假设暗示着给定x下t的条件期望是单峰的，这可能在一些应用上不适用。</p>\n<p>现在假设我们由N个观察到的输入数据 $\\mathbf X = {\\vec x_1, …, \\vec x_N}$ 相对应的目标值是 $t_1, …, t_N$. 这里把（3.6）写成矩阵形式得到的似然函数为：</p>\n<p>$$p(t|\\mathbf x, \\vec w, \\beta) = \\prod_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1}) \\tag{3.8}$$</p>\n<p>注意在监督学习问题中（分类和回归），我们并不要求对输入变量的分布建模。因此x可能不会出现在条件变量上。例如 $p(t|\\vec w, \\beta)$</p>\n<p>对式（3.8）取对数有：</p>\n<p>$$\\ln p(t|w, \\beta) = \\sum_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1})\\ = \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln(2\\pi) - \\beta E_D(\\vec w) \\tag{3.9}$$</p>\n<p>这里平方和误差为</p>\n<p>$$E_D(\\vec w) = \\frac{1}{2} \\sum_{n=1}^{N} {t_n - \\vec w^T \\phi(\\vec x_n)}^2 \\tag{3.10}$$</p>\n<p>最大化似然函数可通过对似然函数求导：</p>\n<p>$$\\frac{\\partial \\ln p(\\vec t |\\vec w, \\beta)}{\\partial \\vec w} = \\sum_{n=1}^{N} {t_n - \\vec w^T \\phi(\\vec x_n)} \\phi(\\vec x_n)^T \\tag{3.11}$$</p>\n<p>令导数为0得到：</p>\n<p>$$\\vec w_{ML} = (\\Phi ^T \\Phi)^{-1} \\Phi ^T \\vec t \\tag{3.12}$$</p>\n<p>这个方程被称为 <strong>正则方程(normal equations)</strong> .</p>\n<p>$$\\Phi = \\left [ \\begin{matrix} \\phi_0(\\vec x_1) &amp; \\phi_1(\\vec x_1) … \\phi_{M-1}(\\vec x_1)\\ \\phi_0(\\vec x_2) &amp; \\phi_1(\\vec x_2) … \\phi_{M-1}(\\vec x_2)\\ … &amp; …\\ \\phi_0(\\vec x_N) &amp; \\phi_1(\\vec x_N) … \\phi_{M-1}(\\vec x_N\\end{matrix}\\right] \\tag{3.13}$$</p>\n<p>$\\Phi ^+ = ((\\Phi ^T \\Phi)^{-1} \\Phi ^T)$ 被称为矩阵 $\\Phi$ 的 <strong>Moor-Penrose pseudo-inverse</strong></p>\n<p>同样我们也能得到 $\\beta$ 的最大似然估计量。<br>$$\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}{t_n - \\vec w_{ML}^T \\phi(\\vec x_n)}^2$$</p>\n<h3 id=\"Geometry-of-least-squares\"><a href=\"#Geometry-of-least-squares\" class=\"headerlink\" title=\"Geometry of least squares\"></a>Geometry of least squares</h3><p>考虑这样一个N维空间，其以$t_n$为坐标轴，因此 $\\vec t = (t_1, …, t_N)^T$ 是该空间的一个向量。在N个数据上的每一个基函数 $\\phi_j(\\vec x_n)$ 也能表示为相同空间中的向量。我们定义 $\\vec y$ 是一个N维向量，它的第n个元素是 $y(\\vec x_n, \\vec w)$. 由于 $\\vec y$ 是 $\\phi_j(\\vec x_n)$ 在M维空间的任意线性组合。误差平方和等价于 $\\vec y$和 $t$ 之间的欧几里得距离。 因此最小二乘解就是选择在子空间中最接近 $\\vec t$的 $\\vec y$.</p>\n<p><img src=\"/images/lmfr.PNG\" alt=\"\"></p>\n<h3 id=\"Sequential-learning\"><a href=\"#Sequential-learning\" class=\"headerlink\" title=\"Sequential learning\"></a>Sequential learning</h3><p>批处理技术使得可以一次处理很大的训练数据集。如果数据集是足够大，此时使用序列算法可能更有用，序列算法也被称作 <strong>在线（on-line）算法</strong>。这种算法在每一次表示后都更新模型的参数。序列学习适用于一些观察数据是连续产生的实时应用，这些应用必须利用目前所有观测到的数据来预测。</p>\n<p>我们能应用随机梯度下降技术来获得序列学习算法。</p>\n<p>$$w^{\\tau + 1} = w^\\tau - \\eta \\nabla E_n \\tag{3.22}$$</p>\n<p>这里 $\\tau$ 是迭代的次数，$\\eta$ 是学习率。对于（3.10）那样的平方和误差函数，上式可写为：</p>\n<p>$$w^{\\tau + 1} = w^\\tau + \\eta (t_n - w^{(\\tau)T}\\Phi_n)\\Phi_n \\tag{3.23}$$</p>\n<p>$\\Phi_n = \\Phi(x_n)$ 这就是 <strong>least-mean-squares(LMS)</strong> 算法。</p>\n<h3 id=\"Regularized-learst-squares\"><a href=\"#Regularized-learst-squares\" class=\"headerlink\" title=\"Regularized learst squares\"></a>Regularized learst squares</h3><p>我们给误差函数增加一个正则项来控制模型的过拟合。新的误差函数为。</p>\n<p>$$E_D(W) + \\lambda E_w(w) \\tag{3.24}$$</p>\n<p>$\\lambda$ 是正则系数用来控制由数据决定的误差和由正则项引入的误差的相对重要程度。一个最简单的正则形式为权重向量的平方和：</p>\n<p>$$E_w(\\vec w) = \\frac{1}{2}\\vec w^T \\vec w \\tag{3.25}$$</p>\n<p>如果我们考虑平方和误差函数，那么总的误差为：</p>\n<p>$$\\frac{1}{2}\\sum_{n=1}^{N}{t_n - \\vec w^T \\Phi(\\vec x_n)}^2 + \\frac{\\lambda}{2}\\vec w^T \\vec w \\tag{3.27}$$</p>\n<p>在机器学习文献中正则的一个解释是 <strong>权重衰减</strong>，因为在序列学习中，它鼓励权重向朝着0的方向变化。<br>在统计学中它提供一种参数收缩的方法。它的优点是误差函数保持为w的二次型，因此可以得到精确的最小化解。</p>\n<p>$$\\vec w = (\\lambda \\mathbf I + \\Phi^T\\Phi)^{-1}\\Phi^T \\vec t \\tag{3.28}$$</p>\n<p>有时也会使用更一般的正则化形式如：</p>\n<p>$$\\frac{1}{2}\\sum_{n=1}^{N}{t_n - \\vec w^T \\Phi(\\vec x_n)}^2 + \\frac{\\lambda}{2}\\sum_{j=1}^M |w_j|^q \\tag{3.29}$$</p>\n<p>$q=1$ 时为统计学中所说的lasso。它有这样的特点：如果 $\\lambda$ 足够大，一些系数就被学习为0，与之对应的基函数就没有起作用。这学得一个稀疏的模型。</p>\n<p><img src=\"/images/lmfr_f3.PNG\" alt=\"\"></p>\n<p>正则化允许在大小有限的数据集上训练复杂的模型而不导致严重的过拟合，这实质上是通过限制有效的模型复杂度来实现的。然而，决定最优模型复杂度的问题从寻找合适基函数的数量转变为决定一个合适的正则化系数 $\\lambda$。</p>\n<p><img src=\"/images/lmfr_f4.PNG\" alt=\"\"></p>\n<h3 id=\"Multiple-outputs\"><a href=\"#Multiple-outputs\" class=\"headerlink\" title=\"Multiple outputs\"></a>Multiple outputs</h3><p>到目前为止我们已经考虑了单个目标变量的例子，在某些应用中我们可能希望预测多个目标变量，我们将它们定义为一个目标向量 $\\vec t$。这可能通过分别对每一个目标变量定义一组基函数，依照单变量回归那样做。然而一个更合适更常用的方法是，使用同样的一组基函数来对所有的目标变量建模。</p>\n<p>$$y(\\vec x, \\vec w) = \\mathbf W^T \\phi(\\vec x) \\tag{3.31}$$</p>\n<p>这里 $\\vec y$ 是一个K维的列向量，$\\mathbf W$ 是一个$M \\times K$的参数矩阵。$\\phi(\\vec x)$ 是一个M维的列向量其中 $\\phi_0(\\vec x) = 0$.假设目标向量的条件分布是一个各向同性的高斯分布。</p>\n<p>$$p(\\vec t|\\vec x, \\mathbf W, \\beta) = \\mathcal N(\\vec t|\\mathbf W^T \\phi(\\vec x),\\beta^{-1}\\mathbf I) \\tag{3.32}$$</p>\n<p>如果我们有一组观察集 $\\vec t_1, …, \\vec t_N$, 把它们组合进一个大小 $N\\times K$ 的矩阵$T$. 则对数似然函数为：</p>\n<p>$$\\ln p(\\mathbf T|\\mathbf X, \\mathbf W, \\beta) = \\sum_{n=1}^{N}\\mathcal N(\\vec t_n|\\mathbf W^T \\phi(\\vec x_n), \\beta^{-1}\\mathbf I)\\ = \\frac{NK}{2}\\ln(\\frac{\\beta}{2\\pi}) - \\frac{\\beta}{2}\\sum_{n=1}^{N}||\\vec t_n - \\mathbf W^T\\phi(\\vec x_n)||^2 \\tag{3.33}$$</p>\n<p>我们最大化该似然函数得到：</p>\n<p>$$\\mathbf W_{ML} = (\\Phi^T\\Phi)^{-1}\\Phi^T \\mathbf T \\tag{3.34}$$</p>\n<p>如果我们测试每一个目标的结果我们有：</p>\n<p>$$\\vec w_k = (\\Phi^T\\Phi)^{-1}\\Phi^T \\vec t_k$$</p>\n<p>$\\vec t_k$ 是一个N维的列向量。</p>\n<h2 id=\"The-Bias-Variance-Decomposition\"><a href=\"#The-Bias-Variance-Decomposition\" class=\"headerlink\" title=\"The Bias-Variance Decomposition\"></a>The Bias-Variance Decomposition</h2><p>在我们目前考虑的线性回归模型中，我们假定了基函数的数量和形式都是固定的。如果使⽤有限规模的数据集来训练复杂的模型，那么使⽤最⼤似然⽅法（或最⼩平⽅⽅法），会导致严重的过拟合问题。然⽽，通过限制基函数的数量来避免过拟合问题有⼀个负作⽤，即限制了模型描述数据中有趣且重要的规律的灵活性。虽然引⼊正则化项可以控制具有多个参数的模型的过拟合问题，但是这就产⽣了⼀个问题：如何确定正则化系数 $\\lambda$ 的合适的值。同时关于权值 $w$ 和正则化系数 $\\lambda$ 来最小化正则化的误差函数显然不是⼀个正确的⽅法，因为这样做会使得 $\\lambda = 0$ ，从⽽产⽣非正则化的解。</p>\n<p>从频率学家的观点考虑⼀下模型的复杂度问题被称为 <strong>偏置-⽅差折中（ bias-variance trade-off ）</strong></p>\n<p>当我们讨论回归问题的决策论时，我们考虑了不同的损失函数。⼀旦我们知道了<br>条件概率分布 $p(t | x)$ ，每⼀种损失函数都能够给出对应的最优预测结果。使⽤最多的⼀个选择是平方损失函数，此时最优的预测由条件期望给出，即：</p>\n<p>$$h(\\vec x) = \\mathbb E[t | \\vec x] = \\int tp(t|\\vec x)dt \\tag{3.36}$$</p>\n<p>现在，有必要区分决策论中出现的平⽅损失函数以及模型参数的最⼤似然估计中出现的平⽅和误差函数。我们可以使⽤⽐最⼩平⽅更复杂的⽅法，例如正则化或者纯粹的贝叶斯⽅法，来确定条件概率分布 $p(t | x)$ 。为了进⾏预测，这些⽅法都可以与平⽅损失函数相结合。</p>\n<p>平方损失函数的期望可以写成：</p>\n<p>$$\\mathbb E[L] = \\int{y(\\vec x) - h(\\vec x)}^2p(\\vec x)d\\vec x + \\int \\int {h(\\vec x - t)}^2p(\\vec x, t)d\\vec x dt \\tag{3.37}$$</p>\n<p>回忆⼀下，与 y(x) ⽆关的第⼆项，是由数据本⾝的噪声造成的，表⽰期望损失能够达到的最⼩值。第⼀项与我们对函数 y(x) 的选择有关，我们要找⼀个 y(x) 的解，使得这⼀项最⼩。由于它是⾮负的，因此我们希望能够让这⼀项的最⼩值等于零。如果我们有⽆限多的数据（以及⽆限多的计算资源），那么原则上我们能够以任意的精度寻找回归函数 h(x) ，这会给出 y(x) 的最优解。然⽽，在实际应⽤中，我们的数据集 D 只有有限的 N 个数据点，从⽽我们不能够精确地知道回归函数 h(x) 。</p>\n<p>如果我们使⽤由参数向量 w 控制的函数 y(x,w) 对 h(x) 建模，那么从贝叶斯的观点来看我们模型的不确定性是通过 w 的后验概率分布来表⽰的。但是，频率学家的⽅法涉及到根据数据集 D 对 w 进⾏点估计，然后试着通过下⾯的思想实验来表⽰估计的不确定性。假设我们有许多数据集，每个数据集的⼤⼩为 N ，并且每个数据集都独⽴地从分布 p(t,x) 中抽取。对于任意给定的数据集 D ，我们可以运⾏我们的学习算法，得到⼀个预测函数 y(x;D) 。不同的数据集给出不同的函数，从⽽给出不同的平⽅损失的值。这样，特定的学习算法的表现就可以通过取各个数据集上的表现的平均值来进⾏评估。</p>\n<p>考虑公式（3.37）的第⼀项的被积函数，对于⼀个特定的数据集 D ，它的形式为</p>\n<p>$${y(\\vec x;D) − h(\\vec x)}^2 \\tag{3.38}$$</p>\n<p>由于这个量与特定的数据集 D 相关，因此我们对所有的数据集取平均.我们有:</p>\n<p>$${y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)] + \\mathbb E_D[y(\\vec x;D)] − h(x)}^2 \\ = {y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)]}^2 + {\\mathbb E_D[y(\\vec x;D)] − h(x)}^2 + \\ 2{y(\\vec x;D) − \\mathbb E_D[y(\\vec x;D)]}{\\mathbb E_D[y(\\vec x;D)] − h(\\vec x)} \\tag{3.39}$$</p>\n<p>关于D求期望得到, 注意最后一项为0：</p>\n<p>$$\\mathbb E_D[{y(\\vec x; D) - h(\\vec x)}^2] \\ = {\\mathbb E_D[y(\\vec x; D)] - h(\\vec x)}^2 + \\mathbb E_D[{y(\\vec x; D) - \\mathbb E_D[y(\\vec x; D)]}^2] \\tag{3.40}$$</p>\n<p>$y(x;D)$ 与回归函数 $h(x)$ 的差的平⽅的期望可以表⽰为两项的和。第⼀项，被称为平⽅偏置（ <strong>bias</strong> ），表⽰所有数据集的平均预测与预期的回归函数之间的差异。第⼆项，被称为⽅差（ <strong>variance</strong> ），度量了对于单独的数据集，模型所给出的解在平均值附近波动的情况，此也就度量了函数 $y(x;D)$ 对于特定的数据集的选择的敏感程度。</p>\n<p>如果我们把这个展开式带回到公式（3.37）中，那么我们就得到了下⾯的对于期望平⽅损失的分解</p>\n<p>$$expected = (bias)^2 + variance + noise \\tag{3.41}$$</p>\n<p>$$ (bias)^2 = \\int {\\mathbb E_D[y(x;D)] − h(x)}^2p(x)dx \\<br>    variance = \\int \\mathbb E_D[{y(\\vec x; D) - \\mathbb E_D[y(\\vec x; D)]}^2] p(x)dx \\<br>    noise = \\int {h(x) - t}^2p(x,t)dxdt<br>$$</p>\n<p>现在，偏置和⽅差指的是积分后的量。我们的⽬标是最⼩化期望损失，它可以分解为（平⽅）偏置、⽅差和⼀个常数噪声项的和。正如我们将看到的那样，在偏置和⽅差之间有⼀个折中。对于⾮常灵活的模型来说，偏置较⼩，⽅差较⼤。对于相对固定的模型来说，偏置较⼤，⽅差较⼩。有着最优预测能⼒的模型时在偏置和⽅差之间取得最优的平衡的模型。</p>\n<p>将多个解加权平均是贝叶斯⽅法的核⼼，虽然这种求平均针对的是参数的后验分布，⽽不是针对多个数据集。</p>\n"},{"title":"Gradient Descent Famliy","date":"2018-08-07T00:59:26.000Z","mathjax":true,"_content":"## (Batch) Gradient Descent\n\n``` python\nX = data_input\nY = labels\nparameters = initialize_parameters(layers_dims)\nfor i in range(0, num_iterations):\n    # Forward propagation\n    a, caches = forward_propagation(X, parameters)\n    # Compute cost.\n    cost = compute_cost(a, Y)\n    # Backward propagation.\n    grads = backward_propagation(a, caches, parameters)\n    # Update parameters.\n    parameters = update_parameters(parameters, grads)     \n```\n\n## Stochastic Gradient Descent\n\n```python\nX = data_input\nY = labels\nparameters = initialize_parameters(layers_dims)\nfor i in range(0, num_iterations):\n    for j in range(0, m):\n        # Forward propagation\n        a, caches = forward_propagation(X[:,j], parameters)\n        # Compute cost\n        cost = compute_cost(a, Y[:,j])\n        # Backward propagation\n        grads = backward_propagation(a, caches, parameters)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads)\n```\n\n## Mini-Batch Gradient descent\n\n- **Shuffle**:\n\n<img src=\"/images/shuffle.png\" style=\"width:550px;height:300px;\">\n\n- **Partition**:\n\n<img src=\"/images/partition.png\" style=\"width:550px;height:300px;\">\n\nNote that the last mini-batch might end up smaller than `mini_batch_size=64`. Let $\\lfloor s \\rfloor$ represents $s$ rounded down to the nearest integer (this is `math.floor(s)` in Python). If the total number of examples is not a multiple of `mini_batch_size=64` then there will be $\\lfloor \\frac{m}{mini_batch_size}\\rfloor$ mini-batches with a full 64 examples, and the number of examples in the final mini-batch will be ($m-mini_batch_size \\times \\lfloor \\frac{m}{mini_batch_size}\\rfloor$). \n\n```python\ndef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    Arguments:\n    X -- input data, of shape (input size, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    mini_batch_size -- size of the mini-batches, integer\n    \n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    \n    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n    m = X.shape[1]                  # number of training examples\n    mini_batches = []\n        \n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[:, permutation]\n    shuffled_Y = Y[:, permutation].reshape((1,m))\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k+1) * mini_batch_size]\n        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k+1) * mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size: ]\n        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size: ]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    return mini_batches\n```\n\n## Momentum\n\nBecause mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will \"oscillate\" toward convergence. Using momentum can reduce these oscillations. \n\nMomentum takes into account the past gradients to smooth out the update. We will store the 'direction' of the previous gradients in the variable $v$. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of $v$ as the \"velocity\" of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill. \n\n<img src=\"/images/momentum.png\" style=\"width:400px;height:250px;\">\n<caption><center> <u><font color='purple'>**Figure 3**</u><font color='purple'>: The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence $v$ and then take a step in the direction of $v$.<br> <font color='black'> </center>\n\n```python\ndef initialize_velocity(parameters):\n    \"\"\"\n    Initializes the velocity as a python dictionary with:\n                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n    Arguments:\n    parameters -- python dictionary containing your parameters.\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    \n    Returns:\n    v -- python dictionary containing the current velocity.\n                    v['dW' + str(l)] = velocity of dWl\n                    v['db' + str(l)] = velocity of dbl\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks\n    v = {}    \n    # Initialize velocity\n    for l in range(L):\n        v[\"dW\" + str(l+1)] = np.zeros((parameters['W' + str(l+1)].shape[0], parameters['W' + str(l+1)].shape[1]))\n        v[\"db\" + str(l+1)] = np.zeros((parameters['b' + str(l+1)].shape[0], parameters['b' + str(l+1)].shape[1]))\n        \n    return v\n```\n\n$$\\begin{cases}\nv_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]} \\\\\nW^{[l]} = W^{[l]} - \\alpha v_{dW^{[l]}}\n\\end{cases}\\tag{3}$$\n\n$$\\begin{cases}\nv_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]} \\\\\nb^{[l]} = b^{[l]} - \\alpha v_{db^{[l]}} \n\\end{cases}\\tag{4}$$\n\nwhere L is the number of layers, $\\beta$ is the momentum and $\\alpha$ is the learning rate. All parameters should be stored in the `parameters` dictionary.  Note that the iterator `l` starts at 0 in the `for` loop while the first parameters are $W^{[1]}$ and $b^{[1]}$ (that's a \"one\" on the superscript). So you will need to shift `l` to `l+1` when coding.\n\n```python\ndef update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n    \"\"\"\n    Update parameters using Momentum\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters:\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    grads -- python dictionary containing your gradients for each parameters:\n                    grads['dW' + str(l)] = dWl\n                    grads['db' + str(l)] = dbl\n    v -- python dictionary containing the current velocity:\n                    v['dW' + str(l)] = ...\n                    v['db' + str(l)] = ...\n    beta -- the momentum hyperparameter, scalar\n    learning_rate -- the learning rate, scalar\n    \n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    v -- python dictionary containing your updated velocities\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks    \n    # Momentum update for each parameter\n    for l in range(L):        \n        # compute velocities\n        v[\"dW\" + str(l+1)] = beta * v['dW' + str(l+1)] + (1 - beta) * grads['dW' + str(l+1)]\n        v[\"db\" + str(l+1)] = beta * v['db' + str(l+1)] + (1 - beta) * grads['db' + str(l+1)]\n        # update parameters\n        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v[\"dW\" + str(l+1)]\n        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v[\"db\" + str(l+1)]\n    return parameters, v\n```\n\n\n**How do you choose $\\beta$?**\n\n- The larger the momentum $\\beta$ is, the smoother the update because the more we take the past gradients into account. But if $\\beta$ is too big, it could also smooth out the updates too much. \n- Common values for $\\beta$ range from 0.8 to 0.999. If you don't feel inclined to tune this, $\\beta = 0.9$ is often a reasonable default. \n- Tuning the optimal $\\beta$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$. \n\n## Adam\n\nAdam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum. \n\n**How does Adam work?**\n1. It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction). \n2. It calculates an exponentially weighted average of the squares of the past gradients, and  stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction). \n3. It updates parameters in a direction based on combining information from \"1\" and \"2\".\n\nThe update rule is, for $l = 1, ..., L$: \n\n<img src=\"/images/adam.PNG\" style=\"width:550px;height:300px;\">\n\nwhere:\n- t counts the number of steps taken of Adam \n- L is the number of layers\n- $\\beta_1$ and $\\beta_2$ are hyperparameters that control the two exponentially weighted averages. \n- $\\alpha$ is the learning rate\n- $\\varepsilon$ is a very small number to avoid dividing by zero\n\nAs usual, we will store all parameters in the `parameters` dictionary\n\n```python\ndef initialize_adam(parameters) :\n    \"\"\"\n    Initializes v and s as two python dictionaries with:\n                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters.\n                    parameters[\"W\" + str(l)] = Wl\n                    parameters[\"b\" + str(l)] = bl\n    \n    Returns: \n    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n                    v[\"dW\" + str(l)] = ...\n                    v[\"db\" + str(l)] = ...\n    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n                    s[\"dW\" + str(l)] = ...\n                    s[\"db\" + str(l)] = ...\n\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks\n    v = {}\n    s = {}    \n    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n    for l in range(L):\n        v[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0], parameters[\"W\" + str(l+1)].shape[1]))\n        v[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0], parameters[\"b\" + str(l+1)].shape[1]))\n        s[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0], parameters[\"W\" + str(l+1)].shape[1]))\n        s[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0], parameters[\"b\" + str(l+1)].shape[1]))\n    return v, s\n```\n\n```python\ndef update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n    \"\"\"\n    Update parameters using Adam\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters:\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    grads -- python dictionary containing your gradients for each parameters:\n                    grads['dW' + str(l)] = dWl\n                    grads['db' + str(l)] = dbl\n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\n    learning_rate -- the learning rate, scalar.\n    beta1 -- Exponential decay hyperparameter for the first moment estimates \n    beta2 -- Exponential decay hyperparameter for the second moment estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\n    \"\"\"\n    L = len(parameters) // 2                 # number of layers in the neural networks\n    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n    s_corrected = {}                         # Initializing second moment estimate, python dictionary    \n    # Perform Adam update on all parameters\n    for l in range(L):\n        # Moving average of the gradients.\n        v[\"dW\" + str(l+1)] = beta1 * v[\"dW\" + str(l+1)] + (1 - beta1) * grads['dW' + str(l+1)]\n        v[\"db\" + str(l+1)] = beta1 * v[\"db\" + str(l+1)] + (1 - beta1) * grads['db' + str(l+1)]\n        # Compute bias-corrected first moment estimate.\n        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)] / (1 - beta1 ** t)\n        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)] / (1 - beta1 ** t)\n        # Moving average of the squared gradients.\n        s[\"dW\" + str(l+1)] = beta2 * s[\"dW\" + str(l+1)] + (1 - beta2) * (grads['dW' + str(l+1)] ** 2)\n        s[\"db\" + str(l+1)] = beta2 * s[\"db\" + str(l+1)] + (1 - beta2) * (grads['db' + str(l+1)] ** 2)\n        # Compute bias-corrected second raw moment estimate.\n        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)] / (1 - beta2 ** t)\n        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)] / (1 - beta2 ** t)\n        # Update parameters. \n        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v_corrected[\"dW\" + str(l+1)] / (np.sqrt(s_corrected[\"dW\" + str(l+1)]) + epsilon)\n        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v_corrected[\"db\" + str(l+1)] / (np.sqrt(s_corrected[\"db\" + str(l+1)]) + epsilon)\n    return parameters, v, s\n```\n\n## Model with different optimization algorithms\n\n```python\ndef model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9,\n          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 10000, print_cost = True):\n    \"\"\"\n    3-layer neural network model which can be run in different optimizer modes.\n    \n    Arguments:\n    X -- input data, of shape (2, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    layers_dims -- python list, containing the size of each layer\n    learning_rate -- the learning rate, scalar.\n    mini_batch_size -- the size of a mini batch\n    beta -- Momentum hyperparameter\n    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n    num_epochs -- number of epochs\n    print_cost -- True to print the cost every 1000 epochs\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    \"\"\"\n\n    L = len(layers_dims)             # number of layers in the neural networks\n    costs = []                       # to keep track of the cost\n    t = 0                            # initializing the counter required for Adam update\n    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n    \n    # Initialize parameters\n    parameters = initialize_parameters(layers_dims)\n\n    # Initialize the optimizer\n    if optimizer == \"gd\":\n        pass # no initialization required for gradient descent\n    elif optimizer == \"momentum\":\n        v = initialize_velocity(parameters)\n    elif optimizer == \"adam\":\n        v, s = initialize_adam(parameters)\n    \n    # Optimization loop\n    for i in range(num_epochs):\n        \n        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n        seed = seed + 1\n        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n\n        for minibatch in minibatches:\n\n            # Select a minibatch\n            (minibatch_X, minibatch_Y) = minibatch\n\n            # Forward propagation\n            a3, caches = forward_propagation(minibatch_X, parameters)\n\n            # Compute cost\n            cost = compute_cost(a3, minibatch_Y)\n\n            # Backward propagation\n            grads = backward_propagation(minibatch_X, minibatch_Y, caches)\n\n            # Update parameters\n            if optimizer == \"gd\":\n                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n            elif optimizer == \"momentum\":\n                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n            elif optimizer == \"adam\":\n                t = t + 1 # Adam counter\n                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t, learning_rate, beta1, beta2,  epsilon)\n        # Print the cost every 1000 epoch\n        if print_cost and i % 1000 == 0:\n            print (\"Cost after epoch %i: %f\" %(i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)  \n    # plot the cost\n    plt.plot(costs)\n    plt.ylabel('cost')\n    plt.xlabel('epochs (per 100)')\n    plt.title(\"Learning rate = \" + str(learning_rate))\n    plt.show()\n    return parameters\n\ntrain_X, train_Y = load_dataset()\n\n# train 3-layer model\nlayers_dims = [train_X.shape[0], 5, 2, 1]\nparameters = model(train_X, train_Y, layers_dims, optimizer = \"gd\")\n\n# Predict\npredictions = predict(train_X, train_Y, parameters)\n\n# Plot decision boundary\nplt.title(\"Model with Gradient Descent optimization\")\naxes = plt.gca()\naxes.set_xlim([-1.5,2.5])\naxes.set_ylim([-1,1.5])\nplot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)\n```\n## Summary\n\n![](/images/sgd.png)\n![](/images/minibatch.png)\n\n- **The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.**\n- **You have to tune a learning rate hyperparameter $\\alpha$.**\n- **With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).**\n- **Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.**\n\n- **Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.**\n\n- **Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you've seen that Adam converges a lot faster.**\n\n**Some advantages of Adam include:**\n- Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum) \n- Usually works well even with little tuning of hyperparameters (except $\\alpha$)","source":"_posts/Gradient-Descent-Famliy.md","raw":"---\ntitle: Gradient Descent Famliy\ndate: 2018-08-07 08:59:26\ntags: 优化算法\ncategories: 深度学习\nmathjax: true\n---\n## (Batch) Gradient Descent\n\n``` python\nX = data_input\nY = labels\nparameters = initialize_parameters(layers_dims)\nfor i in range(0, num_iterations):\n    # Forward propagation\n    a, caches = forward_propagation(X, parameters)\n    # Compute cost.\n    cost = compute_cost(a, Y)\n    # Backward propagation.\n    grads = backward_propagation(a, caches, parameters)\n    # Update parameters.\n    parameters = update_parameters(parameters, grads)     \n```\n\n## Stochastic Gradient Descent\n\n```python\nX = data_input\nY = labels\nparameters = initialize_parameters(layers_dims)\nfor i in range(0, num_iterations):\n    for j in range(0, m):\n        # Forward propagation\n        a, caches = forward_propagation(X[:,j], parameters)\n        # Compute cost\n        cost = compute_cost(a, Y[:,j])\n        # Backward propagation\n        grads = backward_propagation(a, caches, parameters)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads)\n```\n\n## Mini-Batch Gradient descent\n\n- **Shuffle**:\n\n<img src=\"/images/shuffle.png\" style=\"width:550px;height:300px;\">\n\n- **Partition**:\n\n<img src=\"/images/partition.png\" style=\"width:550px;height:300px;\">\n\nNote that the last mini-batch might end up smaller than `mini_batch_size=64`. Let $\\lfloor s \\rfloor$ represents $s$ rounded down to the nearest integer (this is `math.floor(s)` in Python). If the total number of examples is not a multiple of `mini_batch_size=64` then there will be $\\lfloor \\frac{m}{mini_batch_size}\\rfloor$ mini-batches with a full 64 examples, and the number of examples in the final mini-batch will be ($m-mini_batch_size \\times \\lfloor \\frac{m}{mini_batch_size}\\rfloor$). \n\n```python\ndef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    Arguments:\n    X -- input data, of shape (input size, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    mini_batch_size -- size of the mini-batches, integer\n    \n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    \n    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n    m = X.shape[1]                  # number of training examples\n    mini_batches = []\n        \n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[:, permutation]\n    shuffled_Y = Y[:, permutation].reshape((1,m))\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k+1) * mini_batch_size]\n        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k+1) * mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size: ]\n        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size: ]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    return mini_batches\n```\n\n## Momentum\n\nBecause mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will \"oscillate\" toward convergence. Using momentum can reduce these oscillations. \n\nMomentum takes into account the past gradients to smooth out the update. We will store the 'direction' of the previous gradients in the variable $v$. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of $v$ as the \"velocity\" of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill. \n\n<img src=\"/images/momentum.png\" style=\"width:400px;height:250px;\">\n<caption><center> <u><font color='purple'>**Figure 3**</u><font color='purple'>: The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence $v$ and then take a step in the direction of $v$.<br> <font color='black'> </center>\n\n```python\ndef initialize_velocity(parameters):\n    \"\"\"\n    Initializes the velocity as a python dictionary with:\n                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n    Arguments:\n    parameters -- python dictionary containing your parameters.\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    \n    Returns:\n    v -- python dictionary containing the current velocity.\n                    v['dW' + str(l)] = velocity of dWl\n                    v['db' + str(l)] = velocity of dbl\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks\n    v = {}    \n    # Initialize velocity\n    for l in range(L):\n        v[\"dW\" + str(l+1)] = np.zeros((parameters['W' + str(l+1)].shape[0], parameters['W' + str(l+1)].shape[1]))\n        v[\"db\" + str(l+1)] = np.zeros((parameters['b' + str(l+1)].shape[0], parameters['b' + str(l+1)].shape[1]))\n        \n    return v\n```\n\n$$\\begin{cases}\nv_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]} \\\\\nW^{[l]} = W^{[l]} - \\alpha v_{dW^{[l]}}\n\\end{cases}\\tag{3}$$\n\n$$\\begin{cases}\nv_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]} \\\\\nb^{[l]} = b^{[l]} - \\alpha v_{db^{[l]}} \n\\end{cases}\\tag{4}$$\n\nwhere L is the number of layers, $\\beta$ is the momentum and $\\alpha$ is the learning rate. All parameters should be stored in the `parameters` dictionary.  Note that the iterator `l` starts at 0 in the `for` loop while the first parameters are $W^{[1]}$ and $b^{[1]}$ (that's a \"one\" on the superscript). So you will need to shift `l` to `l+1` when coding.\n\n```python\ndef update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n    \"\"\"\n    Update parameters using Momentum\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters:\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    grads -- python dictionary containing your gradients for each parameters:\n                    grads['dW' + str(l)] = dWl\n                    grads['db' + str(l)] = dbl\n    v -- python dictionary containing the current velocity:\n                    v['dW' + str(l)] = ...\n                    v['db' + str(l)] = ...\n    beta -- the momentum hyperparameter, scalar\n    learning_rate -- the learning rate, scalar\n    \n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    v -- python dictionary containing your updated velocities\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks    \n    # Momentum update for each parameter\n    for l in range(L):        \n        # compute velocities\n        v[\"dW\" + str(l+1)] = beta * v['dW' + str(l+1)] + (1 - beta) * grads['dW' + str(l+1)]\n        v[\"db\" + str(l+1)] = beta * v['db' + str(l+1)] + (1 - beta) * grads['db' + str(l+1)]\n        # update parameters\n        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v[\"dW\" + str(l+1)]\n        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v[\"db\" + str(l+1)]\n    return parameters, v\n```\n\n\n**How do you choose $\\beta$?**\n\n- The larger the momentum $\\beta$ is, the smoother the update because the more we take the past gradients into account. But if $\\beta$ is too big, it could also smooth out the updates too much. \n- Common values for $\\beta$ range from 0.8 to 0.999. If you don't feel inclined to tune this, $\\beta = 0.9$ is often a reasonable default. \n- Tuning the optimal $\\beta$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$. \n\n## Adam\n\nAdam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum. \n\n**How does Adam work?**\n1. It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction). \n2. It calculates an exponentially weighted average of the squares of the past gradients, and  stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction). \n3. It updates parameters in a direction based on combining information from \"1\" and \"2\".\n\nThe update rule is, for $l = 1, ..., L$: \n\n<img src=\"/images/adam.PNG\" style=\"width:550px;height:300px;\">\n\nwhere:\n- t counts the number of steps taken of Adam \n- L is the number of layers\n- $\\beta_1$ and $\\beta_2$ are hyperparameters that control the two exponentially weighted averages. \n- $\\alpha$ is the learning rate\n- $\\varepsilon$ is a very small number to avoid dividing by zero\n\nAs usual, we will store all parameters in the `parameters` dictionary\n\n```python\ndef initialize_adam(parameters) :\n    \"\"\"\n    Initializes v and s as two python dictionaries with:\n                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters.\n                    parameters[\"W\" + str(l)] = Wl\n                    parameters[\"b\" + str(l)] = bl\n    \n    Returns: \n    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n                    v[\"dW\" + str(l)] = ...\n                    v[\"db\" + str(l)] = ...\n    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n                    s[\"dW\" + str(l)] = ...\n                    s[\"db\" + str(l)] = ...\n\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks\n    v = {}\n    s = {}    \n    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n    for l in range(L):\n        v[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0], parameters[\"W\" + str(l+1)].shape[1]))\n        v[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0], parameters[\"b\" + str(l+1)].shape[1]))\n        s[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0], parameters[\"W\" + str(l+1)].shape[1]))\n        s[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0], parameters[\"b\" + str(l+1)].shape[1]))\n    return v, s\n```\n\n```python\ndef update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n    \"\"\"\n    Update parameters using Adam\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters:\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    grads -- python dictionary containing your gradients for each parameters:\n                    grads['dW' + str(l)] = dWl\n                    grads['db' + str(l)] = dbl\n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\n    learning_rate -- the learning rate, scalar.\n    beta1 -- Exponential decay hyperparameter for the first moment estimates \n    beta2 -- Exponential decay hyperparameter for the second moment estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\n    \"\"\"\n    L = len(parameters) // 2                 # number of layers in the neural networks\n    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n    s_corrected = {}                         # Initializing second moment estimate, python dictionary    \n    # Perform Adam update on all parameters\n    for l in range(L):\n        # Moving average of the gradients.\n        v[\"dW\" + str(l+1)] = beta1 * v[\"dW\" + str(l+1)] + (1 - beta1) * grads['dW' + str(l+1)]\n        v[\"db\" + str(l+1)] = beta1 * v[\"db\" + str(l+1)] + (1 - beta1) * grads['db' + str(l+1)]\n        # Compute bias-corrected first moment estimate.\n        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)] / (1 - beta1 ** t)\n        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)] / (1 - beta1 ** t)\n        # Moving average of the squared gradients.\n        s[\"dW\" + str(l+1)] = beta2 * s[\"dW\" + str(l+1)] + (1 - beta2) * (grads['dW' + str(l+1)] ** 2)\n        s[\"db\" + str(l+1)] = beta2 * s[\"db\" + str(l+1)] + (1 - beta2) * (grads['db' + str(l+1)] ** 2)\n        # Compute bias-corrected second raw moment estimate.\n        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)] / (1 - beta2 ** t)\n        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)] / (1 - beta2 ** t)\n        # Update parameters. \n        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v_corrected[\"dW\" + str(l+1)] / (np.sqrt(s_corrected[\"dW\" + str(l+1)]) + epsilon)\n        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v_corrected[\"db\" + str(l+1)] / (np.sqrt(s_corrected[\"db\" + str(l+1)]) + epsilon)\n    return parameters, v, s\n```\n\n## Model with different optimization algorithms\n\n```python\ndef model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9,\n          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 10000, print_cost = True):\n    \"\"\"\n    3-layer neural network model which can be run in different optimizer modes.\n    \n    Arguments:\n    X -- input data, of shape (2, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    layers_dims -- python list, containing the size of each layer\n    learning_rate -- the learning rate, scalar.\n    mini_batch_size -- the size of a mini batch\n    beta -- Momentum hyperparameter\n    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n    num_epochs -- number of epochs\n    print_cost -- True to print the cost every 1000 epochs\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    \"\"\"\n\n    L = len(layers_dims)             # number of layers in the neural networks\n    costs = []                       # to keep track of the cost\n    t = 0                            # initializing the counter required for Adam update\n    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n    \n    # Initialize parameters\n    parameters = initialize_parameters(layers_dims)\n\n    # Initialize the optimizer\n    if optimizer == \"gd\":\n        pass # no initialization required for gradient descent\n    elif optimizer == \"momentum\":\n        v = initialize_velocity(parameters)\n    elif optimizer == \"adam\":\n        v, s = initialize_adam(parameters)\n    \n    # Optimization loop\n    for i in range(num_epochs):\n        \n        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n        seed = seed + 1\n        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n\n        for minibatch in minibatches:\n\n            # Select a minibatch\n            (minibatch_X, minibatch_Y) = minibatch\n\n            # Forward propagation\n            a3, caches = forward_propagation(minibatch_X, parameters)\n\n            # Compute cost\n            cost = compute_cost(a3, minibatch_Y)\n\n            # Backward propagation\n            grads = backward_propagation(minibatch_X, minibatch_Y, caches)\n\n            # Update parameters\n            if optimizer == \"gd\":\n                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n            elif optimizer == \"momentum\":\n                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n            elif optimizer == \"adam\":\n                t = t + 1 # Adam counter\n                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t, learning_rate, beta1, beta2,  epsilon)\n        # Print the cost every 1000 epoch\n        if print_cost and i % 1000 == 0:\n            print (\"Cost after epoch %i: %f\" %(i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)  \n    # plot the cost\n    plt.plot(costs)\n    plt.ylabel('cost')\n    plt.xlabel('epochs (per 100)')\n    plt.title(\"Learning rate = \" + str(learning_rate))\n    plt.show()\n    return parameters\n\ntrain_X, train_Y = load_dataset()\n\n# train 3-layer model\nlayers_dims = [train_X.shape[0], 5, 2, 1]\nparameters = model(train_X, train_Y, layers_dims, optimizer = \"gd\")\n\n# Predict\npredictions = predict(train_X, train_Y, parameters)\n\n# Plot decision boundary\nplt.title(\"Model with Gradient Descent optimization\")\naxes = plt.gca()\naxes.set_xlim([-1.5,2.5])\naxes.set_ylim([-1,1.5])\nplot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)\n```\n## Summary\n\n![](/images/sgd.png)\n![](/images/minibatch.png)\n\n- **The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.**\n- **You have to tune a learning rate hyperparameter $\\alpha$.**\n- **With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).**\n- **Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.**\n\n- **Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.**\n\n- **Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you've seen that Adam converges a lot faster.**\n\n**Some advantages of Adam include:**\n- Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum) \n- Usually works well even with little tuning of hyperparameters (except $\\alpha$)","slug":"Gradient-Descent-Famliy","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds2g000npcvouxxv9u41","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Batch-Gradient-Descent\"><a href=\"#Batch-Gradient-Descent\" class=\"headerlink\" title=\"(Batch) Gradient Descent\"></a>(Batch) Gradient Descent</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = data_input</span><br><span class=\"line\">Y = labels</span><br><span class=\"line\">parameters = initialize_parameters(layers_dims)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_iterations):</span><br><span class=\"line\">    <span class=\"comment\"># Forward propagation</span></span><br><span class=\"line\">    a, caches = forward_propagation(X, parameters)</span><br><span class=\"line\">    <span class=\"comment\"># Compute cost.</span></span><br><span class=\"line\">    cost = compute_cost(a, Y)</span><br><span class=\"line\">    <span class=\"comment\"># Backward propagation.</span></span><br><span class=\"line\">    grads = backward_propagation(a, caches, parameters)</span><br><span class=\"line\">    <span class=\"comment\"># Update parameters.</span></span><br><span class=\"line\">    parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Stochastic-Gradient-Descent\"><a href=\"#Stochastic-Gradient-Descent\" class=\"headerlink\" title=\"Stochastic Gradient Descent\"></a>Stochastic Gradient Descent</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = data_input</span><br><span class=\"line\">Y = labels</span><br><span class=\"line\">parameters = initialize_parameters(layers_dims)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_iterations):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, m):</span><br><span class=\"line\">        <span class=\"comment\"># Forward propagation</span></span><br><span class=\"line\">        a, caches = forward_propagation(X[:,j], parameters)</span><br><span class=\"line\">        <span class=\"comment\"># Compute cost</span></span><br><span class=\"line\">        cost = compute_cost(a, Y[:,j])</span><br><span class=\"line\">        <span class=\"comment\"># Backward propagation</span></span><br><span class=\"line\">        grads = backward_propagation(a, caches, parameters)</span><br><span class=\"line\">        <span class=\"comment\"># Update parameters.</span></span><br><span class=\"line\">        parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Mini-Batch-Gradient-descent\"><a href=\"#Mini-Batch-Gradient-descent\" class=\"headerlink\" title=\"Mini-Batch Gradient descent\"></a>Mini-Batch Gradient descent</h2><ul>\n<li><strong>Shuffle</strong>:</li>\n</ul>\n<p><img src=\"/images/shuffle.png\" style=\"width:550px;height:300px;\"></p>\n<ul>\n<li><strong>Partition</strong>:</li>\n</ul>\n<p><img src=\"/images/partition.png\" style=\"width:550px;height:300px;\"></p>\n<p>Note that the last mini-batch might end up smaller than <code>mini_batch_size=64</code>. Let $\\lfloor s \\rfloor$ represents $s$ rounded down to the nearest integer (this is <code>math.floor(s)</code> in Python). If the total number of examples is not a multiple of <code>mini_batch_size=64</code> then there will be $\\lfloor \\frac{m}{mini_batch_size}\\rfloor$ mini-batches with a full 64 examples, and the number of examples in the final mini-batch will be ($m-mini_batch_size \\times \\lfloor \\frac{m}{mini_batch_size}\\rfloor$). </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">random_mini_batches</span><span class=\"params\">(X, Y, mini_batch_size = <span class=\"number\">64</span>, seed = <span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Creates a list of random minibatches from (X, Y)</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- input data, of shape (input size, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    mini_batch_size -- size of the mini-batches, integer</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    np.random.seed(seed)            <span class=\"comment\"># To make your \"random\" minibatches the same as ours</span></span><br><span class=\"line\">    m = X.shape[<span class=\"number\">1</span>]                  <span class=\"comment\"># number of training examples</span></span><br><span class=\"line\">    mini_batches = []</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"comment\"># Step 1: Shuffle (X, Y)</span></span><br><span class=\"line\">    permutation = list(np.random.permutation(m))</span><br><span class=\"line\">    shuffled_X = X[:, permutation]</span><br><span class=\"line\">    shuffled_Y = Y[:, permutation].reshape((<span class=\"number\">1</span>,m))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.</span></span><br><span class=\"line\">    num_complete_minibatches = math.floor(m/mini_batch_size) <span class=\"comment\"># number of mini batches of size mini_batch_size in your partitionning</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_complete_minibatches):</span><br><span class=\"line\">        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k+<span class=\"number\">1</span>) * mini_batch_size]</span><br><span class=\"line\">        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k+<span class=\"number\">1</span>) * mini_batch_size]</span><br><span class=\"line\">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class=\"line\">        mini_batches.append(mini_batch)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Handling the end case (last mini-batch &lt; mini_batch_size)</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> m % mini_batch_size != <span class=\"number\">0</span>:</span><br><span class=\"line\">        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size: ]</span><br><span class=\"line\">        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size: ]</span><br><span class=\"line\">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class=\"line\">        mini_batches.append(mini_batch)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mini_batches</span><br></pre></td></tr></table></figure>\n<h2 id=\"Momentum\"><a href=\"#Momentum\" class=\"headerlink\" title=\"Momentum\"></a>Momentum</h2><p>Because mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will “oscillate” toward convergence. Using momentum can reduce these oscillations. </p>\n<p>Momentum takes into account the past gradients to smooth out the update. We will store the ‘direction’ of the previous gradients in the variable $v$. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of $v$ as the “velocity” of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill. </p>\n<p><img src=\"/images/momentum.png\" style=\"width:400px;height:250px;\"></p>\n<p><caption><center> <u><font color=\"purple\"><strong>Figure 3</strong></font></u><font color=\"purple\">: The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence $v$ and then take a step in the direction of $v$.<br> <font color=\"black\"> </font></font></center></caption></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">initialize_velocity</span><span class=\"params\">(parameters)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Initializes the velocity as a python dictionary with:</span></span><br><span class=\"line\"><span class=\"string\">                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" </span></span><br><span class=\"line\"><span class=\"string\">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters.</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['W' + str(l)] = Wl</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['b' + str(l)] = bl</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    v -- python dictionary containing the current velocity.</span></span><br><span class=\"line\"><span class=\"string\">                    v['dW' + str(l)] = velocity of dWl</span></span><br><span class=\"line\"><span class=\"string\">                    v['db' + str(l)] = velocity of dbl</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span> <span class=\"comment\"># number of layers in the neural networks</span></span><br><span class=\"line\">    v = &#123;&#125;    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize velocity</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):</span><br><span class=\"line\">        v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">'W'</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">'W'</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">'b'</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">'b'</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">return</span> v</span><br></pre></td></tr></table></figure>\n<p>$$\\begin{cases}<br>v_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]} \\<br>W^{[l]} = W^{[l]} - \\alpha v_{dW^{[l]}}<br>\\end{cases}\\tag{3}$$</p>\n<p>$$\\begin{cases}<br>v_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]} \\<br>b^{[l]} = b^{[l]} - \\alpha v_{db^{[l]}}<br>\\end{cases}\\tag{4}$$</p>\n<p>where L is the number of layers, $\\beta$ is the momentum and $\\alpha$ is the learning rate. All parameters should be stored in the <code>parameters</code> dictionary.  Note that the iterator <code>l</code> starts at 0 in the <code>for</code> loop while the first parameters are $W^{[1]}$ and $b^{[1]}$ (that’s a “one” on the superscript). So you will need to shift <code>l</code> to <code>l+1</code> when coding.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">update_parameters_with_momentum</span><span class=\"params\">(parameters, grads, v, beta, learning_rate)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Update parameters using Momentum</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters:</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['W' + str(l)] = Wl</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['b' + str(l)] = bl</span></span><br><span class=\"line\"><span class=\"string\">    grads -- python dictionary containing your gradients for each parameters:</span></span><br><span class=\"line\"><span class=\"string\">                    grads['dW' + str(l)] = dWl</span></span><br><span class=\"line\"><span class=\"string\">                    grads['db' + str(l)] = dbl</span></span><br><span class=\"line\"><span class=\"string\">    v -- python dictionary containing the current velocity:</span></span><br><span class=\"line\"><span class=\"string\">                    v['dW' + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">                    v['db' + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">    beta -- the momentum hyperparameter, scalar</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- the learning rate, scalar</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your updated parameters </span></span><br><span class=\"line\"><span class=\"string\">    v -- python dictionary containing your updated velocities</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span> <span class=\"comment\"># number of layers in the neural networks    </span></span><br><span class=\"line\">    <span class=\"comment\"># Momentum update for each parameter</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):        </span><br><span class=\"line\">        <span class=\"comment\"># compute velocities</span></span><br><span class=\"line\">        v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = beta * v[<span class=\"string\">'dW'</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta) * grads[<span class=\"string\">'dW'</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = beta * v[<span class=\"string\">'db'</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta) * grads[<span class=\"string\">'db'</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        <span class=\"comment\"># update parameters</span></span><br><span class=\"line\">        parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)] - learning_rate * v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)] - learning_rate * v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters, v</span><br></pre></td></tr></table></figure>\n<p><strong>How do you choose $\\beta$?</strong></p>\n<ul>\n<li>The larger the momentum $\\beta$ is, the smoother the update because the more we take the past gradients into account. But if $\\beta$ is too big, it could also smooth out the updates too much. </li>\n<li>Common values for $\\beta$ range from 0.8 to 0.999. If you don’t feel inclined to tune this, $\\beta = 0.9$ is often a reasonable default. </li>\n<li>Tuning the optimal $\\beta$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$. </li>\n</ul>\n<h2 id=\"Adam\"><a href=\"#Adam\" class=\"headerlink\" title=\"Adam\"></a>Adam</h2><p>Adam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum. </p>\n<p><strong>How does Adam work?</strong></p>\n<ol>\n<li>It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction). </li>\n<li>It calculates an exponentially weighted average of the squares of the past gradients, and  stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction). </li>\n<li>It updates parameters in a direction based on combining information from “1” and “2”.</li>\n</ol>\n<p>The update rule is, for $l = 1, …, L$: </p>\n<p><img src=\"/images/adam.PNG\" style=\"width:550px;height:300px;\"></p>\n<p>where:</p>\n<ul>\n<li>t counts the number of steps taken of Adam </li>\n<li>L is the number of layers</li>\n<li>$\\beta_1$ and $\\beta_2$ are hyperparameters that control the two exponentially weighted averages. </li>\n<li>$\\alpha$ is the learning rate</li>\n<li>$\\varepsilon$ is a very small number to avoid dividing by zero</li>\n</ul>\n<p>As usual, we will store all parameters in the <code>parameters</code> dictionary</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">initialize_adam</span><span class=\"params\">(parameters)</span> :</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Initializes v and s as two python dictionaries with:</span></span><br><span class=\"line\"><span class=\"string\">                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" </span></span><br><span class=\"line\"><span class=\"string\">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters.</span></span><br><span class=\"line\"><span class=\"string\">                    parameters[\"W\" + str(l)] = Wl</span></span><br><span class=\"line\"><span class=\"string\">                    parameters[\"b\" + str(l)] = bl</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Returns: </span></span><br><span class=\"line\"><span class=\"string\">    v -- python dictionary that will contain the exponentially weighted average of the gradient.</span></span><br><span class=\"line\"><span class=\"string\">                    v[\"dW\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">                    v[\"db\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.</span></span><br><span class=\"line\"><span class=\"string\">                    s[\"dW\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">                    s[\"db\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span> <span class=\"comment\"># number of layers in the neural networks</span></span><br><span class=\"line\">    v = &#123;&#125;</span><br><span class=\"line\">    s = &#123;&#125;    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):</span><br><span class=\"line\">        v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        s[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        s[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> v, s</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">update_parameters_with_adam</span><span class=\"params\">(parameters, grads, v, s, t, learning_rate = <span class=\"number\">0.01</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                                beta1 = <span class=\"number\">0.9</span>, beta2 = <span class=\"number\">0.999</span>,  epsilon = <span class=\"number\">1e-8</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Update parameters using Adam</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters:</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['W' + str(l)] = Wl</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['b' + str(l)] = bl</span></span><br><span class=\"line\"><span class=\"string\">    grads -- python dictionary containing your gradients for each parameters:</span></span><br><span class=\"line\"><span class=\"string\">                    grads['dW' + str(l)] = dWl</span></span><br><span class=\"line\"><span class=\"string\">                    grads['db' + str(l)] = dbl</span></span><br><span class=\"line\"><span class=\"string\">    v -- Adam variable, moving average of the first gradient, python dictionary</span></span><br><span class=\"line\"><span class=\"string\">    s -- Adam variable, moving average of the squared gradient, python dictionary</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- the learning rate, scalar.</span></span><br><span class=\"line\"><span class=\"string\">    beta1 -- Exponential decay hyperparameter for the first moment estimates </span></span><br><span class=\"line\"><span class=\"string\">    beta2 -- Exponential decay hyperparameter for the second moment estimates </span></span><br><span class=\"line\"><span class=\"string\">    epsilon -- hyperparameter preventing division by zero in Adam updates</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your updated parameters </span></span><br><span class=\"line\"><span class=\"string\">    v -- Adam variable, moving average of the first gradient, python dictionary</span></span><br><span class=\"line\"><span class=\"string\">    s -- Adam variable, moving average of the squared gradient, python dictionary</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span>                 <span class=\"comment\"># number of layers in the neural networks</span></span><br><span class=\"line\">    v_corrected = &#123;&#125;                         <span class=\"comment\"># Initializing first moment estimate, python dictionary</span></span><br><span class=\"line\">    s_corrected = &#123;&#125;                         <span class=\"comment\"># Initializing second moment estimate, python dictionary    </span></span><br><span class=\"line\">    <span class=\"comment\"># Perform Adam update on all parameters</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):</span><br><span class=\"line\">        <span class=\"comment\"># Moving average of the gradients.</span></span><br><span class=\"line\">        v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = beta1 * v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta1) * grads[<span class=\"string\">'dW'</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = beta1 * v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta1) * grads[<span class=\"string\">'db'</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        <span class=\"comment\"># Compute bias-corrected first moment estimate.</span></span><br><span class=\"line\">        v_corrected[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] / (<span class=\"number\">1</span> - beta1 ** t)</span><br><span class=\"line\">        v_corrected[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] / (<span class=\"number\">1</span> - beta1 ** t)</span><br><span class=\"line\">        <span class=\"comment\"># Moving average of the squared gradients.</span></span><br><span class=\"line\">        s[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = beta2 * s[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta2) * (grads[<span class=\"string\">'dW'</span> + str(l+<span class=\"number\">1</span>)] ** <span class=\"number\">2</span>)</span><br><span class=\"line\">        s[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = beta2 * s[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta2) * (grads[<span class=\"string\">'db'</span> + str(l+<span class=\"number\">1</span>)] ** <span class=\"number\">2</span>)</span><br><span class=\"line\">        <span class=\"comment\"># Compute bias-corrected second raw moment estimate.</span></span><br><span class=\"line\">        s_corrected[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = s[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] / (<span class=\"number\">1</span> - beta2 ** t)</span><br><span class=\"line\">        s_corrected[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = s[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] / (<span class=\"number\">1</span> - beta2 ** t)</span><br><span class=\"line\">        <span class=\"comment\"># Update parameters. </span></span><br><span class=\"line\">        parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)] - learning_rate * v_corrected[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] / (np.sqrt(s_corrected[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)]) + epsilon)</span><br><span class=\"line\">        parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)] - learning_rate * v_corrected[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] / (np.sqrt(s_corrected[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)]) + epsilon)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters, v, s</span><br></pre></td></tr></table></figure>\n<h2 id=\"Model-with-different-optimization-algorithms\"><a href=\"#Model-with-different-optimization-algorithms\" class=\"headerlink\" title=\"Model with different optimization algorithms\"></a>Model with different optimization algorithms</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">model</span><span class=\"params\">(X, Y, layers_dims, optimizer, learning_rate = <span class=\"number\">0.0007</span>, mini_batch_size = <span class=\"number\">64</span>, beta = <span class=\"number\">0.9</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">          beta1 = <span class=\"number\">0.9</span>, beta2 = <span class=\"number\">0.999</span>,  epsilon = <span class=\"number\">1e-8</span>, num_epochs = <span class=\"number\">10000</span>, print_cost = True)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    3-layer neural network model which can be run in different optimizer modes.</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- input data, of shape (2, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    layers_dims -- python list, containing the size of each layer</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- the learning rate, scalar.</span></span><br><span class=\"line\"><span class=\"string\">    mini_batch_size -- the size of a mini batch</span></span><br><span class=\"line\"><span class=\"string\">    beta -- Momentum hyperparameter</span></span><br><span class=\"line\"><span class=\"string\">    beta1 -- Exponential decay hyperparameter for the past gradients estimates </span></span><br><span class=\"line\"><span class=\"string\">    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates </span></span><br><span class=\"line\"><span class=\"string\">    epsilon -- hyperparameter preventing division by zero in Adam updates</span></span><br><span class=\"line\"><span class=\"string\">    num_epochs -- number of epochs</span></span><br><span class=\"line\"><span class=\"string\">    print_cost -- True to print the cost every 1000 epochs</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your updated parameters </span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    L = len(layers_dims)             <span class=\"comment\"># number of layers in the neural networks</span></span><br><span class=\"line\">    costs = []                       <span class=\"comment\"># to keep track of the cost</span></span><br><span class=\"line\">    t = <span class=\"number\">0</span>                            <span class=\"comment\"># initializing the counter required for Adam update</span></span><br><span class=\"line\">    seed = <span class=\"number\">10</span>                        <span class=\"comment\"># For grading purposes, so that your \"random\" minibatches are the same as ours</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize parameters</span></span><br><span class=\"line\">    parameters = initialize_parameters(layers_dims)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Initialize the optimizer</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> optimizer == <span class=\"string\">\"gd\"</span>:</span><br><span class=\"line\">        <span class=\"keyword\">pass</span> <span class=\"comment\"># no initialization required for gradient descent</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> optimizer == <span class=\"string\">\"momentum\"</span>:</span><br><span class=\"line\">        v = initialize_velocity(parameters)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> optimizer == <span class=\"string\">\"adam\"</span>:</span><br><span class=\"line\">        v, s = initialize_adam(parameters)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Optimization loop</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(num_epochs):</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch</span></span><br><span class=\"line\">        seed = seed + <span class=\"number\">1</span></span><br><span class=\"line\">        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> minibatch <span class=\"keyword\">in</span> minibatches:</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Select a minibatch</span></span><br><span class=\"line\">            (minibatch_X, minibatch_Y) = minibatch</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Forward propagation</span></span><br><span class=\"line\">            a3, caches = forward_propagation(minibatch_X, parameters)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Compute cost</span></span><br><span class=\"line\">            cost = compute_cost(a3, minibatch_Y)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Backward propagation</span></span><br><span class=\"line\">            grads = backward_propagation(minibatch_X, minibatch_Y, caches)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Update parameters</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> optimizer == <span class=\"string\">\"gd\"</span>:</span><br><span class=\"line\">                parameters = update_parameters_with_gd(parameters, grads, learning_rate)</span><br><span class=\"line\">            <span class=\"keyword\">elif</span> optimizer == <span class=\"string\">\"momentum\"</span>:</span><br><span class=\"line\">                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)</span><br><span class=\"line\">            <span class=\"keyword\">elif</span> optimizer == <span class=\"string\">\"adam\"</span>:</span><br><span class=\"line\">                t = t + <span class=\"number\">1</span> <span class=\"comment\"># Adam counter</span></span><br><span class=\"line\">                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t, learning_rate, beta1, beta2,  epsilon)</span><br><span class=\"line\">        <span class=\"comment\"># Print the cost every 1000 epoch</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">1000</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"keyword\">print</span> (<span class=\"string\">\"Cost after epoch %i: %f\"</span> %(i, cost))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            costs.append(cost)  </span><br><span class=\"line\">    <span class=\"comment\"># plot the cost</span></span><br><span class=\"line\">    plt.plot(costs)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">'cost'</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">'epochs (per 100)'</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">\"Learning rate = \"</span> + str(learning_rate))</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br><span class=\"line\"></span><br><span class=\"line\">train_X, train_Y = load_dataset()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># train 3-layer model</span></span><br><span class=\"line\">layers_dims = [train_X.shape[<span class=\"number\">0</span>], <span class=\"number\">5</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\">parameters = model(train_X, train_Y, layers_dims, optimizer = <span class=\"string\">\"gd\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Predict</span></span><br><span class=\"line\">predictions = predict(train_X, train_Y, parameters)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot decision boundary</span></span><br><span class=\"line\">plt.title(<span class=\"string\">\"Model with Gradient Descent optimization\"</span>)</span><br><span class=\"line\">axes = plt.gca()</span><br><span class=\"line\">axes.set_xlim([<span class=\"number\">-1.5</span>,<span class=\"number\">2.5</span>])</span><br><span class=\"line\">axes.set_ylim([<span class=\"number\">-1</span>,<span class=\"number\">1.5</span>])</span><br><span class=\"line\">plot_decision_boundary(<span class=\"keyword\">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p><img src=\"/images/sgd.png\" alt=\"\"><br><img src=\"/images/minibatch.png\" alt=\"\"></p>\n<ul>\n<li><strong>The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.</strong></li>\n<li><strong>You have to tune a learning rate hyperparameter $\\alpha$.</strong></li>\n<li><strong>With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).</strong></li>\n<li><p><strong>Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.</strong></p>\n</li>\n<li><p><strong>Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.</strong></p>\n</li>\n<li><p><strong>Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you’ve seen that Adam converges a lot faster.</strong></p>\n</li>\n</ul>\n<p><strong>Some advantages of Adam include:</strong></p>\n<ul>\n<li>Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum) </li>\n<li>Usually works well even with little tuning of hyperparameters (except $\\alpha$)</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Batch-Gradient-Descent\"><a href=\"#Batch-Gradient-Descent\" class=\"headerlink\" title=\"(Batch) Gradient Descent\"></a>(Batch) Gradient Descent</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = data_input</span><br><span class=\"line\">Y = labels</span><br><span class=\"line\">parameters = initialize_parameters(layers_dims)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_iterations):</span><br><span class=\"line\">    <span class=\"comment\"># Forward propagation</span></span><br><span class=\"line\">    a, caches = forward_propagation(X, parameters)</span><br><span class=\"line\">    <span class=\"comment\"># Compute cost.</span></span><br><span class=\"line\">    cost = compute_cost(a, Y)</span><br><span class=\"line\">    <span class=\"comment\"># Backward propagation.</span></span><br><span class=\"line\">    grads = backward_propagation(a, caches, parameters)</span><br><span class=\"line\">    <span class=\"comment\"># Update parameters.</span></span><br><span class=\"line\">    parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Stochastic-Gradient-Descent\"><a href=\"#Stochastic-Gradient-Descent\" class=\"headerlink\" title=\"Stochastic Gradient Descent\"></a>Stochastic Gradient Descent</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = data_input</span><br><span class=\"line\">Y = labels</span><br><span class=\"line\">parameters = initialize_parameters(layers_dims)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_iterations):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, m):</span><br><span class=\"line\">        <span class=\"comment\"># Forward propagation</span></span><br><span class=\"line\">        a, caches = forward_propagation(X[:,j], parameters)</span><br><span class=\"line\">        <span class=\"comment\"># Compute cost</span></span><br><span class=\"line\">        cost = compute_cost(a, Y[:,j])</span><br><span class=\"line\">        <span class=\"comment\"># Backward propagation</span></span><br><span class=\"line\">        grads = backward_propagation(a, caches, parameters)</span><br><span class=\"line\">        <span class=\"comment\"># Update parameters.</span></span><br><span class=\"line\">        parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Mini-Batch-Gradient-descent\"><a href=\"#Mini-Batch-Gradient-descent\" class=\"headerlink\" title=\"Mini-Batch Gradient descent\"></a>Mini-Batch Gradient descent</h2><ul>\n<li><strong>Shuffle</strong>:</li>\n</ul>\n<p><img src=\"/images/shuffle.png\" style=\"width:550px;height:300px;\"></p>\n<ul>\n<li><strong>Partition</strong>:</li>\n</ul>\n<p><img src=\"/images/partition.png\" style=\"width:550px;height:300px;\"></p>\n<p>Note that the last mini-batch might end up smaller than <code>mini_batch_size=64</code>. Let $\\lfloor s \\rfloor$ represents $s$ rounded down to the nearest integer (this is <code>math.floor(s)</code> in Python). If the total number of examples is not a multiple of <code>mini_batch_size=64</code> then there will be $\\lfloor \\frac{m}{mini_batch_size}\\rfloor$ mini-batches with a full 64 examples, and the number of examples in the final mini-batch will be ($m-mini_batch_size \\times \\lfloor \\frac{m}{mini_batch_size}\\rfloor$). </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">random_mini_batches</span><span class=\"params\">(X, Y, mini_batch_size = <span class=\"number\">64</span>, seed = <span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Creates a list of random minibatches from (X, Y)</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- input data, of shape (input size, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    mini_batch_size -- size of the mini-batches, integer</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    np.random.seed(seed)            <span class=\"comment\"># To make your \"random\" minibatches the same as ours</span></span><br><span class=\"line\">    m = X.shape[<span class=\"number\">1</span>]                  <span class=\"comment\"># number of training examples</span></span><br><span class=\"line\">    mini_batches = []</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"comment\"># Step 1: Shuffle (X, Y)</span></span><br><span class=\"line\">    permutation = list(np.random.permutation(m))</span><br><span class=\"line\">    shuffled_X = X[:, permutation]</span><br><span class=\"line\">    shuffled_Y = Y[:, permutation].reshape((<span class=\"number\">1</span>,m))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.</span></span><br><span class=\"line\">    num_complete_minibatches = math.floor(m/mini_batch_size) <span class=\"comment\"># number of mini batches of size mini_batch_size in your partitionning</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_complete_minibatches):</span><br><span class=\"line\">        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k+<span class=\"number\">1</span>) * mini_batch_size]</span><br><span class=\"line\">        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k+<span class=\"number\">1</span>) * mini_batch_size]</span><br><span class=\"line\">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class=\"line\">        mini_batches.append(mini_batch)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Handling the end case (last mini-batch &lt; mini_batch_size)</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> m % mini_batch_size != <span class=\"number\">0</span>:</span><br><span class=\"line\">        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size: ]</span><br><span class=\"line\">        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size: ]</span><br><span class=\"line\">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class=\"line\">        mini_batches.append(mini_batch)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mini_batches</span><br></pre></td></tr></table></figure>\n<h2 id=\"Momentum\"><a href=\"#Momentum\" class=\"headerlink\" title=\"Momentum\"></a>Momentum</h2><p>Because mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will “oscillate” toward convergence. Using momentum can reduce these oscillations. </p>\n<p>Momentum takes into account the past gradients to smooth out the update. We will store the ‘direction’ of the previous gradients in the variable $v$. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of $v$ as the “velocity” of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill. </p>\n<p><img src=\"/images/momentum.png\" style=\"width:400px;height:250px;\"></p>\n<p><caption><center> <u><font color=\"purple\"><strong>Figure 3</strong></font></u><font color=\"purple\">: The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence $v$ and then take a step in the direction of $v$.<br> <font color=\"black\"> </font></font></center></caption></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">initialize_velocity</span><span class=\"params\">(parameters)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Initializes the velocity as a python dictionary with:</span></span><br><span class=\"line\"><span class=\"string\">                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" </span></span><br><span class=\"line\"><span class=\"string\">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters.</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['W' + str(l)] = Wl</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['b' + str(l)] = bl</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    v -- python dictionary containing the current velocity.</span></span><br><span class=\"line\"><span class=\"string\">                    v['dW' + str(l)] = velocity of dWl</span></span><br><span class=\"line\"><span class=\"string\">                    v['db' + str(l)] = velocity of dbl</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span> <span class=\"comment\"># number of layers in the neural networks</span></span><br><span class=\"line\">    v = &#123;&#125;    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize velocity</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):</span><br><span class=\"line\">        v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">'W'</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">'W'</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">'b'</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">'b'</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">return</span> v</span><br></pre></td></tr></table></figure>\n<p>$$\\begin{cases}<br>v_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]} \\<br>W^{[l]} = W^{[l]} - \\alpha v_{dW^{[l]}}<br>\\end{cases}\\tag{3}$$</p>\n<p>$$\\begin{cases}<br>v_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]} \\<br>b^{[l]} = b^{[l]} - \\alpha v_{db^{[l]}}<br>\\end{cases}\\tag{4}$$</p>\n<p>where L is the number of layers, $\\beta$ is the momentum and $\\alpha$ is the learning rate. All parameters should be stored in the <code>parameters</code> dictionary.  Note that the iterator <code>l</code> starts at 0 in the <code>for</code> loop while the first parameters are $W^{[1]}$ and $b^{[1]}$ (that’s a “one” on the superscript). So you will need to shift <code>l</code> to <code>l+1</code> when coding.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">update_parameters_with_momentum</span><span class=\"params\">(parameters, grads, v, beta, learning_rate)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Update parameters using Momentum</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters:</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['W' + str(l)] = Wl</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['b' + str(l)] = bl</span></span><br><span class=\"line\"><span class=\"string\">    grads -- python dictionary containing your gradients for each parameters:</span></span><br><span class=\"line\"><span class=\"string\">                    grads['dW' + str(l)] = dWl</span></span><br><span class=\"line\"><span class=\"string\">                    grads['db' + str(l)] = dbl</span></span><br><span class=\"line\"><span class=\"string\">    v -- python dictionary containing the current velocity:</span></span><br><span class=\"line\"><span class=\"string\">                    v['dW' + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">                    v['db' + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">    beta -- the momentum hyperparameter, scalar</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- the learning rate, scalar</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your updated parameters </span></span><br><span class=\"line\"><span class=\"string\">    v -- python dictionary containing your updated velocities</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span> <span class=\"comment\"># number of layers in the neural networks    </span></span><br><span class=\"line\">    <span class=\"comment\"># Momentum update for each parameter</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):        </span><br><span class=\"line\">        <span class=\"comment\"># compute velocities</span></span><br><span class=\"line\">        v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = beta * v[<span class=\"string\">'dW'</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta) * grads[<span class=\"string\">'dW'</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = beta * v[<span class=\"string\">'db'</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta) * grads[<span class=\"string\">'db'</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        <span class=\"comment\"># update parameters</span></span><br><span class=\"line\">        parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)] - learning_rate * v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)] - learning_rate * v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters, v</span><br></pre></td></tr></table></figure>\n<p><strong>How do you choose $\\beta$?</strong></p>\n<ul>\n<li>The larger the momentum $\\beta$ is, the smoother the update because the more we take the past gradients into account. But if $\\beta$ is too big, it could also smooth out the updates too much. </li>\n<li>Common values for $\\beta$ range from 0.8 to 0.999. If you don’t feel inclined to tune this, $\\beta = 0.9$ is often a reasonable default. </li>\n<li>Tuning the optimal $\\beta$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$. </li>\n</ul>\n<h2 id=\"Adam\"><a href=\"#Adam\" class=\"headerlink\" title=\"Adam\"></a>Adam</h2><p>Adam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum. </p>\n<p><strong>How does Adam work?</strong></p>\n<ol>\n<li>It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction). </li>\n<li>It calculates an exponentially weighted average of the squares of the past gradients, and  stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction). </li>\n<li>It updates parameters in a direction based on combining information from “1” and “2”.</li>\n</ol>\n<p>The update rule is, for $l = 1, …, L$: </p>\n<p><img src=\"/images/adam.PNG\" style=\"width:550px;height:300px;\"></p>\n<p>where:</p>\n<ul>\n<li>t counts the number of steps taken of Adam </li>\n<li>L is the number of layers</li>\n<li>$\\beta_1$ and $\\beta_2$ are hyperparameters that control the two exponentially weighted averages. </li>\n<li>$\\alpha$ is the learning rate</li>\n<li>$\\varepsilon$ is a very small number to avoid dividing by zero</li>\n</ul>\n<p>As usual, we will store all parameters in the <code>parameters</code> dictionary</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">initialize_adam</span><span class=\"params\">(parameters)</span> :</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Initializes v and s as two python dictionaries with:</span></span><br><span class=\"line\"><span class=\"string\">                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" </span></span><br><span class=\"line\"><span class=\"string\">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters.</span></span><br><span class=\"line\"><span class=\"string\">                    parameters[\"W\" + str(l)] = Wl</span></span><br><span class=\"line\"><span class=\"string\">                    parameters[\"b\" + str(l)] = bl</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Returns: </span></span><br><span class=\"line\"><span class=\"string\">    v -- python dictionary that will contain the exponentially weighted average of the gradient.</span></span><br><span class=\"line\"><span class=\"string\">                    v[\"dW\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">                    v[\"db\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.</span></span><br><span class=\"line\"><span class=\"string\">                    s[\"dW\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">                    s[\"db\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span> <span class=\"comment\"># number of layers in the neural networks</span></span><br><span class=\"line\">    v = &#123;&#125;</span><br><span class=\"line\">    s = &#123;&#125;    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):</span><br><span class=\"line\">        v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        s[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        s[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = np.zeros((parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">0</span>], parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)].shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> v, s</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">update_parameters_with_adam</span><span class=\"params\">(parameters, grads, v, s, t, learning_rate = <span class=\"number\">0.01</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                                beta1 = <span class=\"number\">0.9</span>, beta2 = <span class=\"number\">0.999</span>,  epsilon = <span class=\"number\">1e-8</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Update parameters using Adam</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters:</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['W' + str(l)] = Wl</span></span><br><span class=\"line\"><span class=\"string\">                    parameters['b' + str(l)] = bl</span></span><br><span class=\"line\"><span class=\"string\">    grads -- python dictionary containing your gradients for each parameters:</span></span><br><span class=\"line\"><span class=\"string\">                    grads['dW' + str(l)] = dWl</span></span><br><span class=\"line\"><span class=\"string\">                    grads['db' + str(l)] = dbl</span></span><br><span class=\"line\"><span class=\"string\">    v -- Adam variable, moving average of the first gradient, python dictionary</span></span><br><span class=\"line\"><span class=\"string\">    s -- Adam variable, moving average of the squared gradient, python dictionary</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- the learning rate, scalar.</span></span><br><span class=\"line\"><span class=\"string\">    beta1 -- Exponential decay hyperparameter for the first moment estimates </span></span><br><span class=\"line\"><span class=\"string\">    beta2 -- Exponential decay hyperparameter for the second moment estimates </span></span><br><span class=\"line\"><span class=\"string\">    epsilon -- hyperparameter preventing division by zero in Adam updates</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your updated parameters </span></span><br><span class=\"line\"><span class=\"string\">    v -- Adam variable, moving average of the first gradient, python dictionary</span></span><br><span class=\"line\"><span class=\"string\">    s -- Adam variable, moving average of the squared gradient, python dictionary</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span>                 <span class=\"comment\"># number of layers in the neural networks</span></span><br><span class=\"line\">    v_corrected = &#123;&#125;                         <span class=\"comment\"># Initializing first moment estimate, python dictionary</span></span><br><span class=\"line\">    s_corrected = &#123;&#125;                         <span class=\"comment\"># Initializing second moment estimate, python dictionary    </span></span><br><span class=\"line\">    <span class=\"comment\"># Perform Adam update on all parameters</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):</span><br><span class=\"line\">        <span class=\"comment\"># Moving average of the gradients.</span></span><br><span class=\"line\">        v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = beta1 * v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta1) * grads[<span class=\"string\">'dW'</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = beta1 * v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta1) * grads[<span class=\"string\">'db'</span> + str(l+<span class=\"number\">1</span>)]</span><br><span class=\"line\">        <span class=\"comment\"># Compute bias-corrected first moment estimate.</span></span><br><span class=\"line\">        v_corrected[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = v[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] / (<span class=\"number\">1</span> - beta1 ** t)</span><br><span class=\"line\">        v_corrected[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = v[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] / (<span class=\"number\">1</span> - beta1 ** t)</span><br><span class=\"line\">        <span class=\"comment\"># Moving average of the squared gradients.</span></span><br><span class=\"line\">        s[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = beta2 * s[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta2) * (grads[<span class=\"string\">'dW'</span> + str(l+<span class=\"number\">1</span>)] ** <span class=\"number\">2</span>)</span><br><span class=\"line\">        s[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = beta2 * s[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] + (<span class=\"number\">1</span> - beta2) * (grads[<span class=\"string\">'db'</span> + str(l+<span class=\"number\">1</span>)] ** <span class=\"number\">2</span>)</span><br><span class=\"line\">        <span class=\"comment\"># Compute bias-corrected second raw moment estimate.</span></span><br><span class=\"line\">        s_corrected[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] = s[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] / (<span class=\"number\">1</span> - beta2 ** t)</span><br><span class=\"line\">        s_corrected[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] = s[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] / (<span class=\"number\">1</span> - beta2 ** t)</span><br><span class=\"line\">        <span class=\"comment\"># Update parameters. </span></span><br><span class=\"line\">        parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"W\"</span> + str(l+<span class=\"number\">1</span>)] - learning_rate * v_corrected[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)] / (np.sqrt(s_corrected[<span class=\"string\">\"dW\"</span> + str(l+<span class=\"number\">1</span>)]) + epsilon)</span><br><span class=\"line\">        parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"b\"</span> + str(l+<span class=\"number\">1</span>)] - learning_rate * v_corrected[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)] / (np.sqrt(s_corrected[<span class=\"string\">\"db\"</span> + str(l+<span class=\"number\">1</span>)]) + epsilon)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters, v, s</span><br></pre></td></tr></table></figure>\n<h2 id=\"Model-with-different-optimization-algorithms\"><a href=\"#Model-with-different-optimization-algorithms\" class=\"headerlink\" title=\"Model with different optimization algorithms\"></a>Model with different optimization algorithms</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">model</span><span class=\"params\">(X, Y, layers_dims, optimizer, learning_rate = <span class=\"number\">0.0007</span>, mini_batch_size = <span class=\"number\">64</span>, beta = <span class=\"number\">0.9</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">          beta1 = <span class=\"number\">0.9</span>, beta2 = <span class=\"number\">0.999</span>,  epsilon = <span class=\"number\">1e-8</span>, num_epochs = <span class=\"number\">10000</span>, print_cost = True)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    3-layer neural network model which can be run in different optimizer modes.</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- input data, of shape (2, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    layers_dims -- python list, containing the size of each layer</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- the learning rate, scalar.</span></span><br><span class=\"line\"><span class=\"string\">    mini_batch_size -- the size of a mini batch</span></span><br><span class=\"line\"><span class=\"string\">    beta -- Momentum hyperparameter</span></span><br><span class=\"line\"><span class=\"string\">    beta1 -- Exponential decay hyperparameter for the past gradients estimates </span></span><br><span class=\"line\"><span class=\"string\">    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates </span></span><br><span class=\"line\"><span class=\"string\">    epsilon -- hyperparameter preventing division by zero in Adam updates</span></span><br><span class=\"line\"><span class=\"string\">    num_epochs -- number of epochs</span></span><br><span class=\"line\"><span class=\"string\">    print_cost -- True to print the cost every 1000 epochs</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your updated parameters </span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    L = len(layers_dims)             <span class=\"comment\"># number of layers in the neural networks</span></span><br><span class=\"line\">    costs = []                       <span class=\"comment\"># to keep track of the cost</span></span><br><span class=\"line\">    t = <span class=\"number\">0</span>                            <span class=\"comment\"># initializing the counter required for Adam update</span></span><br><span class=\"line\">    seed = <span class=\"number\">10</span>                        <span class=\"comment\"># For grading purposes, so that your \"random\" minibatches are the same as ours</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize parameters</span></span><br><span class=\"line\">    parameters = initialize_parameters(layers_dims)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Initialize the optimizer</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> optimizer == <span class=\"string\">\"gd\"</span>:</span><br><span class=\"line\">        <span class=\"keyword\">pass</span> <span class=\"comment\"># no initialization required for gradient descent</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> optimizer == <span class=\"string\">\"momentum\"</span>:</span><br><span class=\"line\">        v = initialize_velocity(parameters)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> optimizer == <span class=\"string\">\"adam\"</span>:</span><br><span class=\"line\">        v, s = initialize_adam(parameters)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Optimization loop</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(num_epochs):</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch</span></span><br><span class=\"line\">        seed = seed + <span class=\"number\">1</span></span><br><span class=\"line\">        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> minibatch <span class=\"keyword\">in</span> minibatches:</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Select a minibatch</span></span><br><span class=\"line\">            (minibatch_X, minibatch_Y) = minibatch</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Forward propagation</span></span><br><span class=\"line\">            a3, caches = forward_propagation(minibatch_X, parameters)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Compute cost</span></span><br><span class=\"line\">            cost = compute_cost(a3, minibatch_Y)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Backward propagation</span></span><br><span class=\"line\">            grads = backward_propagation(minibatch_X, minibatch_Y, caches)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Update parameters</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> optimizer == <span class=\"string\">\"gd\"</span>:</span><br><span class=\"line\">                parameters = update_parameters_with_gd(parameters, grads, learning_rate)</span><br><span class=\"line\">            <span class=\"keyword\">elif</span> optimizer == <span class=\"string\">\"momentum\"</span>:</span><br><span class=\"line\">                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)</span><br><span class=\"line\">            <span class=\"keyword\">elif</span> optimizer == <span class=\"string\">\"adam\"</span>:</span><br><span class=\"line\">                t = t + <span class=\"number\">1</span> <span class=\"comment\"># Adam counter</span></span><br><span class=\"line\">                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t, learning_rate, beta1, beta2,  epsilon)</span><br><span class=\"line\">        <span class=\"comment\"># Print the cost every 1000 epoch</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">1000</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"keyword\">print</span> (<span class=\"string\">\"Cost after epoch %i: %f\"</span> %(i, cost))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            costs.append(cost)  </span><br><span class=\"line\">    <span class=\"comment\"># plot the cost</span></span><br><span class=\"line\">    plt.plot(costs)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">'cost'</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">'epochs (per 100)'</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">\"Learning rate = \"</span> + str(learning_rate))</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br><span class=\"line\"></span><br><span class=\"line\">train_X, train_Y = load_dataset()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># train 3-layer model</span></span><br><span class=\"line\">layers_dims = [train_X.shape[<span class=\"number\">0</span>], <span class=\"number\">5</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\">parameters = model(train_X, train_Y, layers_dims, optimizer = <span class=\"string\">\"gd\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Predict</span></span><br><span class=\"line\">predictions = predict(train_X, train_Y, parameters)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot decision boundary</span></span><br><span class=\"line\">plt.title(<span class=\"string\">\"Model with Gradient Descent optimization\"</span>)</span><br><span class=\"line\">axes = plt.gca()</span><br><span class=\"line\">axes.set_xlim([<span class=\"number\">-1.5</span>,<span class=\"number\">2.5</span>])</span><br><span class=\"line\">axes.set_ylim([<span class=\"number\">-1</span>,<span class=\"number\">1.5</span>])</span><br><span class=\"line\">plot_decision_boundary(<span class=\"keyword\">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p><img src=\"/images/sgd.png\" alt=\"\"><br><img src=\"/images/minibatch.png\" alt=\"\"></p>\n<ul>\n<li><strong>The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.</strong></li>\n<li><strong>You have to tune a learning rate hyperparameter $\\alpha$.</strong></li>\n<li><strong>With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).</strong></li>\n<li><p><strong>Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.</strong></p>\n</li>\n<li><p><strong>Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.</strong></p>\n</li>\n<li><p><strong>Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you’ve seen that Adam converges a lot faster.</strong></p>\n</li>\n</ul>\n<p><strong>Some advantages of Adam include:</strong></p>\n<ul>\n<li>Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum) </li>\n<li>Usually works well even with little tuning of hyperparameters (except $\\alpha$)</li>\n</ul>\n"},{"title":"ImageNet Classification wih Deep Convolutional Neural Network","date":"2018-08-28T07:07:25.000Z","mathjax":true,"_content":"这是一篇由Alex Krizhevsky, Ilya Sutskever, Geoffrey E.Hinton发表在NIPS上的[Paper](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。该论文中提出了一种新型网络架构即 **AlexNet**.\n\n## AlexNet\n\nAlexNet首次在大规模图像数据集实现了深层卷积神经网络结构，点燃了深度学习应用在计算机视觉领域的这把火。其在 *ImageNet LSVRC-2012* $^{[1]}$ 目标识别竞赛的 *top-5 error* $^{[2]}$ 为15.3%，同期第二名仅为26.2%，碾压其他传统的hand-craft 特征方法，使得计算机视觉从业者从繁重的特征工程中解脱出来，转向思考能够从数据中自动提取需要的特征，做到数据驱动。\n\n### 数据集\n\n对原始高清图像进行下采样得到固定的256\\*256的图像。具体方法是，给一个矩形图像，先调整短边长度为256然后裁剪出中间部分256\\*256的图片。最后按RGB像素值减去训练集中所有图像的均值图像像素。\n\n### 架构\n\n![](/images/alexnet_architecture.PNG)\n\n第二、第四和第五卷积层的内核只连接到位于同一GPU上的前一层内核映射。第三个卷积层的内核连接到第二层的所有内核映射。完全连接层的神经元与前一层的所有神经元连接。局部响应归一化接在第一，第二个卷积层后面。最大池化层跟随着局部响应层和第五个卷积层。\n\n#### ReLU Nonlinearity\n\n标准的神经元模型输出是sigmoid, tanh这些的函数。用梯度下降训练时在训练时间上，这些饱和非线性函数比非饱和非线性函数需要的时间要多得多。相比于tanh单元，深度卷积网络使用ReLU训练得更快。\n\n#### 在多个GPU上训练\n\n当前的gpu特别适合于cross-gpu并行化，因为它们能够直接从彼此的内存中读取和写入，而无需通过主机内存。并行化方案实际上是将一半的内核(或神经元)放在每个GPU上，还有一个额外的技巧:GPU只在特定层进行通信。这个方案使top-1和top-5的错误率分别降低了1.7%和1.2%。\n\n#### 局部响应归一化\n\n$$b^{i}\\_{x, y} = a^{i}\\_{x, y} / (k + \\alpha \\sum_{j = max(0, i - n/2)}^{min(N - 1, i + n/2)} (a^{i}_{x, y})^2)^{\\beta}$$\n\n$a^{i}\\_{x, y}$ 是应用卷积(包括非线性单元)操作后第i个通道位于(x, y)的值, $b^{i}\\_{x, y}$ 是应用局部响应归一化后的同一位置上值。常数$k, n, \\alpha, \\beta$ 是超参数。这里设置为$k = 2, n = 5, \\alpha=10^{-4}, \\beta=0.75$\n\n来源于生物学上的概念: **侧抑制**, 指被激化的神经元抑制相邻神经元的现象。这使得响应比较大的值相对更大，提高了模型的泛化能力。这个方案使top-1和top-5的错误率分别降低了1.4%和1.2%。\n\n#### 重叠池化\n\nCNNs中的池化层汇总了同一核映射中相邻神经元群的输出。传统的池化，相邻池单元不会重叠，即步长$s=z$ 池化单元大小。如果$s < z$则得到重叠的池化。在整个网络中使用$s = 2, z=3$。这个方案使top-1和top-5的错误率分别降低了0.4%和0.3%。\n\n### 降低过拟合\n\n#### 数据增强\n\n关于图像数据最简单也最常用的降低过拟合的方法是通过保留标签对图像进行简单变换的方法人为地扩大数据集。\n\n第一种形式是：将图像进行水平翻转。通过从256\\*256的图像中随机抽取227\\*227的块，还有它们的水平翻转，用这些图像去训练网络。在测试时，通过抽取测试图像的四个角落和中间227\\*227的块，以及它们的水平翻转，一共10个块来输入进网络，最后以它们的平均值作为预测结果。\n\n第二种形式是：改变RGB通道的强度。具体来说，在整个训练集中对RGB像素值集执行PCA。对于每个训练图像，添加已找到的主成分的倍数。与对应的特征值成正比的大小乘以均值为0和标准差为0.1的高斯随机变量。\n\n对每个像素值 $I\\_{xy} = [I^{R}\\_{xy}, I^{G}\\_{xy}, I^{B}\\_{xy}]^T$ 加上以下数量：\n$$[p_1, p_2, p_3][\\alpha_1 \\lambda_1, \\alpha_2 \\lambda_2, \\alpha_3 \\lambda_3]^T$$\n$p_i, \\lambda_i$ 分别是RGB像素协方差矩阵的第i个特征向量和特征值, $\\alpha_i$ 是随机变量，每个 $\\alpha_i$ 只一个训练图像的一个像素。这个方案使top-1降低了1%。\n\n#### Dropout\n\n以一定概率使神经元的输出置为0。这种技术减少了神经元复杂的协同适应，因为神经元不能依赖于特定的其他神经元的存在。因此，它不得不学习更健壮的特性，这些特性与其他神经元的许多不同随机子集一起使用。\n\n### 注解\n\n[1]: ImageNet数据集大约包含2.2万种不同种类的1500万张高清图像。年度的图像识别竞赛**the ImageNet Large-Scale Visual Recognition Challenge\n(ILSVRC)** 从2010开始举行。 ILSVRC 使用大约1000种类每类1000张图片的数据集。\n\n[2]: the top-5 错误率是：测试图像的预测结果前五位不包含真实标签的比例。\n\n[3]: The model result in ILSVRC-2010\n\n![](/images/alexnet_ilsvrc.PNG)\n","source":"_posts/ImageNet-Classification-wih-Deep-Convolutional-Neural-Network.md","raw":"---\ntitle: ImageNet Classification wih Deep Convolutional Neural Network\ndate: 2018-08-28 15:07:25\ntags: CNN\ncategories: 深度学习\nmathjax: true\n---\n这是一篇由Alex Krizhevsky, Ilya Sutskever, Geoffrey E.Hinton发表在NIPS上的[Paper](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。该论文中提出了一种新型网络架构即 **AlexNet**.\n\n## AlexNet\n\nAlexNet首次在大规模图像数据集实现了深层卷积神经网络结构，点燃了深度学习应用在计算机视觉领域的这把火。其在 *ImageNet LSVRC-2012* $^{[1]}$ 目标识别竞赛的 *top-5 error* $^{[2]}$ 为15.3%，同期第二名仅为26.2%，碾压其他传统的hand-craft 特征方法，使得计算机视觉从业者从繁重的特征工程中解脱出来，转向思考能够从数据中自动提取需要的特征，做到数据驱动。\n\n### 数据集\n\n对原始高清图像进行下采样得到固定的256\\*256的图像。具体方法是，给一个矩形图像，先调整短边长度为256然后裁剪出中间部分256\\*256的图片。最后按RGB像素值减去训练集中所有图像的均值图像像素。\n\n### 架构\n\n![](/images/alexnet_architecture.PNG)\n\n第二、第四和第五卷积层的内核只连接到位于同一GPU上的前一层内核映射。第三个卷积层的内核连接到第二层的所有内核映射。完全连接层的神经元与前一层的所有神经元连接。局部响应归一化接在第一，第二个卷积层后面。最大池化层跟随着局部响应层和第五个卷积层。\n\n#### ReLU Nonlinearity\n\n标准的神经元模型输出是sigmoid, tanh这些的函数。用梯度下降训练时在训练时间上，这些饱和非线性函数比非饱和非线性函数需要的时间要多得多。相比于tanh单元，深度卷积网络使用ReLU训练得更快。\n\n#### 在多个GPU上训练\n\n当前的gpu特别适合于cross-gpu并行化，因为它们能够直接从彼此的内存中读取和写入，而无需通过主机内存。并行化方案实际上是将一半的内核(或神经元)放在每个GPU上，还有一个额外的技巧:GPU只在特定层进行通信。这个方案使top-1和top-5的错误率分别降低了1.7%和1.2%。\n\n#### 局部响应归一化\n\n$$b^{i}\\_{x, y} = a^{i}\\_{x, y} / (k + \\alpha \\sum_{j = max(0, i - n/2)}^{min(N - 1, i + n/2)} (a^{i}_{x, y})^2)^{\\beta}$$\n\n$a^{i}\\_{x, y}$ 是应用卷积(包括非线性单元)操作后第i个通道位于(x, y)的值, $b^{i}\\_{x, y}$ 是应用局部响应归一化后的同一位置上值。常数$k, n, \\alpha, \\beta$ 是超参数。这里设置为$k = 2, n = 5, \\alpha=10^{-4}, \\beta=0.75$\n\n来源于生物学上的概念: **侧抑制**, 指被激化的神经元抑制相邻神经元的现象。这使得响应比较大的值相对更大，提高了模型的泛化能力。这个方案使top-1和top-5的错误率分别降低了1.4%和1.2%。\n\n#### 重叠池化\n\nCNNs中的池化层汇总了同一核映射中相邻神经元群的输出。传统的池化，相邻池单元不会重叠，即步长$s=z$ 池化单元大小。如果$s < z$则得到重叠的池化。在整个网络中使用$s = 2, z=3$。这个方案使top-1和top-5的错误率分别降低了0.4%和0.3%。\n\n### 降低过拟合\n\n#### 数据增强\n\n关于图像数据最简单也最常用的降低过拟合的方法是通过保留标签对图像进行简单变换的方法人为地扩大数据集。\n\n第一种形式是：将图像进行水平翻转。通过从256\\*256的图像中随机抽取227\\*227的块，还有它们的水平翻转，用这些图像去训练网络。在测试时，通过抽取测试图像的四个角落和中间227\\*227的块，以及它们的水平翻转，一共10个块来输入进网络，最后以它们的平均值作为预测结果。\n\n第二种形式是：改变RGB通道的强度。具体来说，在整个训练集中对RGB像素值集执行PCA。对于每个训练图像，添加已找到的主成分的倍数。与对应的特征值成正比的大小乘以均值为0和标准差为0.1的高斯随机变量。\n\n对每个像素值 $I\\_{xy} = [I^{R}\\_{xy}, I^{G}\\_{xy}, I^{B}\\_{xy}]^T$ 加上以下数量：\n$$[p_1, p_2, p_3][\\alpha_1 \\lambda_1, \\alpha_2 \\lambda_2, \\alpha_3 \\lambda_3]^T$$\n$p_i, \\lambda_i$ 分别是RGB像素协方差矩阵的第i个特征向量和特征值, $\\alpha_i$ 是随机变量，每个 $\\alpha_i$ 只一个训练图像的一个像素。这个方案使top-1降低了1%。\n\n#### Dropout\n\n以一定概率使神经元的输出置为0。这种技术减少了神经元复杂的协同适应，因为神经元不能依赖于特定的其他神经元的存在。因此，它不得不学习更健壮的特性，这些特性与其他神经元的许多不同随机子集一起使用。\n\n### 注解\n\n[1]: ImageNet数据集大约包含2.2万种不同种类的1500万张高清图像。年度的图像识别竞赛**the ImageNet Large-Scale Visual Recognition Challenge\n(ILSVRC)** 从2010开始举行。 ILSVRC 使用大约1000种类每类1000张图片的数据集。\n\n[2]: the top-5 错误率是：测试图像的预测结果前五位不包含真实标签的比例。\n\n[3]: The model result in ILSVRC-2010\n\n![](/images/alexnet_ilsvrc.PNG)\n","slug":"ImageNet-Classification-wih-Deep-Convolutional-Neural-Network","published":1,"updated":"2018-08-28T07:25:42.186Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds2g000qpcvon2d72175","content":"<p>这是一篇由Alex Krizhevsky, Ilya Sutskever, Geoffrey E.Hinton发表在NIPS上的<a href=\"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" target=\"_blank\" rel=\"noopener\">Paper</a>。该论文中提出了一种新型网络架构即 <strong>AlexNet</strong>.</p>\n<h2 id=\"AlexNet\"><a href=\"#AlexNet\" class=\"headerlink\" title=\"AlexNet\"></a>AlexNet</h2><p>AlexNet首次在大规模图像数据集实现了深层卷积神经网络结构，点燃了深度学习应用在计算机视觉领域的这把火。其在 <em>ImageNet LSVRC-2012</em> $^{[1]}$ 目标识别竞赛的 <em>top-5 error</em> $^{[2]}$ 为15.3%，同期第二名仅为26.2%，碾压其他传统的hand-craft 特征方法，使得计算机视觉从业者从繁重的特征工程中解脱出来，转向思考能够从数据中自动提取需要的特征，做到数据驱动。</p>\n<h3 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h3><p>对原始高清图像进行下采样得到固定的256*256的图像。具体方法是，给一个矩形图像，先调整短边长度为256然后裁剪出中间部分256*256的图片。最后按RGB像素值减去训练集中所有图像的均值图像像素。</p>\n<h3 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h3><p><img src=\"/images/alexnet_architecture.PNG\" alt=\"\"></p>\n<p>第二、第四和第五卷积层的内核只连接到位于同一GPU上的前一层内核映射。第三个卷积层的内核连接到第二层的所有内核映射。完全连接层的神经元与前一层的所有神经元连接。局部响应归一化接在第一，第二个卷积层后面。最大池化层跟随着局部响应层和第五个卷积层。</p>\n<h4 id=\"ReLU-Nonlinearity\"><a href=\"#ReLU-Nonlinearity\" class=\"headerlink\" title=\"ReLU Nonlinearity\"></a>ReLU Nonlinearity</h4><p>标准的神经元模型输出是sigmoid, tanh这些的函数。用梯度下降训练时在训练时间上，这些饱和非线性函数比非饱和非线性函数需要的时间要多得多。相比于tanh单元，深度卷积网络使用ReLU训练得更快。</p>\n<h4 id=\"在多个GPU上训练\"><a href=\"#在多个GPU上训练\" class=\"headerlink\" title=\"在多个GPU上训练\"></a>在多个GPU上训练</h4><p>当前的gpu特别适合于cross-gpu并行化，因为它们能够直接从彼此的内存中读取和写入，而无需通过主机内存。并行化方案实际上是将一半的内核(或神经元)放在每个GPU上，还有一个额外的技巧:GPU只在特定层进行通信。这个方案使top-1和top-5的错误率分别降低了1.7%和1.2%。</p>\n<h4 id=\"局部响应归一化\"><a href=\"#局部响应归一化\" class=\"headerlink\" title=\"局部响应归一化\"></a>局部响应归一化</h4><p>$$b^{i}_{x, y} = a^{i}_{x, y} / (k + \\alpha \\sum_{j = max(0, i - n/2)}^{min(N - 1, i + n/2)} (a^{i}_{x, y})^2)^{\\beta}$$</p>\n<p>$a^{i}_{x, y}$ 是应用卷积(包括非线性单元)操作后第i个通道位于(x, y)的值, $b^{i}_{x, y}$ 是应用局部响应归一化后的同一位置上值。常数$k, n, \\alpha, \\beta$ 是超参数。这里设置为$k = 2, n = 5, \\alpha=10^{-4}, \\beta=0.75$</p>\n<p>来源于生物学上的概念: <strong>侧抑制</strong>, 指被激化的神经元抑制相邻神经元的现象。这使得响应比较大的值相对更大，提高了模型的泛化能力。这个方案使top-1和top-5的错误率分别降低了1.4%和1.2%。</p>\n<h4 id=\"重叠池化\"><a href=\"#重叠池化\" class=\"headerlink\" title=\"重叠池化\"></a>重叠池化</h4><p>CNNs中的池化层汇总了同一核映射中相邻神经元群的输出。传统的池化，相邻池单元不会重叠，即步长$s=z$ 池化单元大小。如果$s &lt; z$则得到重叠的池化。在整个网络中使用$s = 2, z=3$。这个方案使top-1和top-5的错误率分别降低了0.4%和0.3%。</p>\n<h3 id=\"降低过拟合\"><a href=\"#降低过拟合\" class=\"headerlink\" title=\"降低过拟合\"></a>降低过拟合</h3><h4 id=\"数据增强\"><a href=\"#数据增强\" class=\"headerlink\" title=\"数据增强\"></a>数据增强</h4><p>关于图像数据最简单也最常用的降低过拟合的方法是通过保留标签对图像进行简单变换的方法人为地扩大数据集。</p>\n<p>第一种形式是：将图像进行水平翻转。通过从256*256的图像中随机抽取227*227的块，还有它们的水平翻转，用这些图像去训练网络。在测试时，通过抽取测试图像的四个角落和中间227*227的块，以及它们的水平翻转，一共10个块来输入进网络，最后以它们的平均值作为预测结果。</p>\n<p>第二种形式是：改变RGB通道的强度。具体来说，在整个训练集中对RGB像素值集执行PCA。对于每个训练图像，添加已找到的主成分的倍数。与对应的特征值成正比的大小乘以均值为0和标准差为0.1的高斯随机变量。</p>\n<p>对每个像素值 $I_{xy} = [I^{R}_{xy}, I^{G}_{xy}, I^{B}_{xy}]^T$ 加上以下数量：<br>$$[p_1, p_2, p_3][\\alpha_1 \\lambda_1, \\alpha_2 \\lambda_2, \\alpha_3 \\lambda_3]^T$$<br>$p_i, \\lambda_i$ 分别是RGB像素协方差矩阵的第i个特征向量和特征值, $\\alpha_i$ 是随机变量，每个 $\\alpha_i$ 只一个训练图像的一个像素。这个方案使top-1降低了1%。</p>\n<h4 id=\"Dropout\"><a href=\"#Dropout\" class=\"headerlink\" title=\"Dropout\"></a>Dropout</h4><p>以一定概率使神经元的输出置为0。这种技术减少了神经元复杂的协同适应，因为神经元不能依赖于特定的其他神经元的存在。因此，它不得不学习更健壮的特性，这些特性与其他神经元的许多不同随机子集一起使用。</p>\n<h3 id=\"注解\"><a href=\"#注解\" class=\"headerlink\" title=\"注解\"></a>注解</h3><p>[1]: ImageNet数据集大约包含2.2万种不同种类的1500万张高清图像。年度的图像识别竞赛<strong>the ImageNet Large-Scale Visual Recognition Challenge<br>(ILSVRC)</strong> 从2010开始举行。 ILSVRC 使用大约1000种类每类1000张图片的数据集。</p>\n<p>[2]: the top-5 错误率是：测试图像的预测结果前五位不包含真实标签的比例。</p>\n<p>[3]: The model result in ILSVRC-2010</p>\n<p><img src=\"/images/alexnet_ilsvrc.PNG\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>这是一篇由Alex Krizhevsky, Ilya Sutskever, Geoffrey E.Hinton发表在NIPS上的<a href=\"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" target=\"_blank\" rel=\"noopener\">Paper</a>。该论文中提出了一种新型网络架构即 <strong>AlexNet</strong>.</p>\n<h2 id=\"AlexNet\"><a href=\"#AlexNet\" class=\"headerlink\" title=\"AlexNet\"></a>AlexNet</h2><p>AlexNet首次在大规模图像数据集实现了深层卷积神经网络结构，点燃了深度学习应用在计算机视觉领域的这把火。其在 <em>ImageNet LSVRC-2012</em> $^{[1]}$ 目标识别竞赛的 <em>top-5 error</em> $^{[2]}$ 为15.3%，同期第二名仅为26.2%，碾压其他传统的hand-craft 特征方法，使得计算机视觉从业者从繁重的特征工程中解脱出来，转向思考能够从数据中自动提取需要的特征，做到数据驱动。</p>\n<h3 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h3><p>对原始高清图像进行下采样得到固定的256*256的图像。具体方法是，给一个矩形图像，先调整短边长度为256然后裁剪出中间部分256*256的图片。最后按RGB像素值减去训练集中所有图像的均值图像像素。</p>\n<h3 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h3><p><img src=\"/images/alexnet_architecture.PNG\" alt=\"\"></p>\n<p>第二、第四和第五卷积层的内核只连接到位于同一GPU上的前一层内核映射。第三个卷积层的内核连接到第二层的所有内核映射。完全连接层的神经元与前一层的所有神经元连接。局部响应归一化接在第一，第二个卷积层后面。最大池化层跟随着局部响应层和第五个卷积层。</p>\n<h4 id=\"ReLU-Nonlinearity\"><a href=\"#ReLU-Nonlinearity\" class=\"headerlink\" title=\"ReLU Nonlinearity\"></a>ReLU Nonlinearity</h4><p>标准的神经元模型输出是sigmoid, tanh这些的函数。用梯度下降训练时在训练时间上，这些饱和非线性函数比非饱和非线性函数需要的时间要多得多。相比于tanh单元，深度卷积网络使用ReLU训练得更快。</p>\n<h4 id=\"在多个GPU上训练\"><a href=\"#在多个GPU上训练\" class=\"headerlink\" title=\"在多个GPU上训练\"></a>在多个GPU上训练</h4><p>当前的gpu特别适合于cross-gpu并行化，因为它们能够直接从彼此的内存中读取和写入，而无需通过主机内存。并行化方案实际上是将一半的内核(或神经元)放在每个GPU上，还有一个额外的技巧:GPU只在特定层进行通信。这个方案使top-1和top-5的错误率分别降低了1.7%和1.2%。</p>\n<h4 id=\"局部响应归一化\"><a href=\"#局部响应归一化\" class=\"headerlink\" title=\"局部响应归一化\"></a>局部响应归一化</h4><p>$$b^{i}_{x, y} = a^{i}_{x, y} / (k + \\alpha \\sum_{j = max(0, i - n/2)}^{min(N - 1, i + n/2)} (a^{i}_{x, y})^2)^{\\beta}$$</p>\n<p>$a^{i}_{x, y}$ 是应用卷积(包括非线性单元)操作后第i个通道位于(x, y)的值, $b^{i}_{x, y}$ 是应用局部响应归一化后的同一位置上值。常数$k, n, \\alpha, \\beta$ 是超参数。这里设置为$k = 2, n = 5, \\alpha=10^{-4}, \\beta=0.75$</p>\n<p>来源于生物学上的概念: <strong>侧抑制</strong>, 指被激化的神经元抑制相邻神经元的现象。这使得响应比较大的值相对更大，提高了模型的泛化能力。这个方案使top-1和top-5的错误率分别降低了1.4%和1.2%。</p>\n<h4 id=\"重叠池化\"><a href=\"#重叠池化\" class=\"headerlink\" title=\"重叠池化\"></a>重叠池化</h4><p>CNNs中的池化层汇总了同一核映射中相邻神经元群的输出。传统的池化，相邻池单元不会重叠，即步长$s=z$ 池化单元大小。如果$s &lt; z$则得到重叠的池化。在整个网络中使用$s = 2, z=3$。这个方案使top-1和top-5的错误率分别降低了0.4%和0.3%。</p>\n<h3 id=\"降低过拟合\"><a href=\"#降低过拟合\" class=\"headerlink\" title=\"降低过拟合\"></a>降低过拟合</h3><h4 id=\"数据增强\"><a href=\"#数据增强\" class=\"headerlink\" title=\"数据增强\"></a>数据增强</h4><p>关于图像数据最简单也最常用的降低过拟合的方法是通过保留标签对图像进行简单变换的方法人为地扩大数据集。</p>\n<p>第一种形式是：将图像进行水平翻转。通过从256*256的图像中随机抽取227*227的块，还有它们的水平翻转，用这些图像去训练网络。在测试时，通过抽取测试图像的四个角落和中间227*227的块，以及它们的水平翻转，一共10个块来输入进网络，最后以它们的平均值作为预测结果。</p>\n<p>第二种形式是：改变RGB通道的强度。具体来说，在整个训练集中对RGB像素值集执行PCA。对于每个训练图像，添加已找到的主成分的倍数。与对应的特征值成正比的大小乘以均值为0和标准差为0.1的高斯随机变量。</p>\n<p>对每个像素值 $I_{xy} = [I^{R}_{xy}, I^{G}_{xy}, I^{B}_{xy}]^T$ 加上以下数量：<br>$$[p_1, p_2, p_3][\\alpha_1 \\lambda_1, \\alpha_2 \\lambda_2, \\alpha_3 \\lambda_3]^T$$<br>$p_i, \\lambda_i$ 分别是RGB像素协方差矩阵的第i个特征向量和特征值, $\\alpha_i$ 是随机变量，每个 $\\alpha_i$ 只一个训练图像的一个像素。这个方案使top-1降低了1%。</p>\n<h4 id=\"Dropout\"><a href=\"#Dropout\" class=\"headerlink\" title=\"Dropout\"></a>Dropout</h4><p>以一定概率使神经元的输出置为0。这种技术减少了神经元复杂的协同适应，因为神经元不能依赖于特定的其他神经元的存在。因此，它不得不学习更健壮的特性，这些特性与其他神经元的许多不同随机子集一起使用。</p>\n<h3 id=\"注解\"><a href=\"#注解\" class=\"headerlink\" title=\"注解\"></a>注解</h3><p>[1]: ImageNet数据集大约包含2.2万种不同种类的1500万张高清图像。年度的图像识别竞赛<strong>the ImageNet Large-Scale Visual Recognition Challenge<br>(ILSVRC)</strong> 从2010开始举行。 ILSVRC 使用大约1000种类每类1000张图片的数据集。</p>\n<p>[2]: the top-5 错误率是：测试图像的预测结果前五位不包含真实标签的比例。</p>\n<p>[3]: The model result in ILSVRC-2010</p>\n<p><img src=\"/images/alexnet_ilsvrc.PNG\" alt=\"\"></p>\n"},{"title":"MNIST数据集","date":"2018-09-04T13:21:44.000Z","_content":"### [MNIST](http://yann.lecun.com/exdb/mnist/)\n\nThe MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n\n### Tensorflow `v1.10` API\n\n```python\nmnist = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n# type(mnist) is Tuple of Numpy arrays:\n# `(x_train, y_train), (x_test, y_test)`.\n(x_train, y_train), (x_test, y_test) = mnist\nx_train.shape == (60000, 28, 28)\nx_test.shape == (10000, 28, 28)\ny_train.shape == (60000,)\ny_test.shape == (10000,)\n# x_train[0, :, :] (0, 255) uint8\n# y_train[0] (0, 10) uint8\n\n# show the pic\nfrom PIL import Image\nim = Image.fromarray(x_train[0,:,:])\nim.show()\n```\n\nOther Low-level API\n```python\nfrom tensorflow.examples.tutorials.mnist import input_data\n# Or use following import method\n# from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\nmnist = input_data.read_data_sets('./mnist/', one_hot=True)\nmnist.train.images.shape == (55000, 784) # normalized to (0, 1) float32\nmnist.test.images.shape == (10000, 784)\nmnist.train.labels.shape == (55000, 10) # one_hot vector\n# if one_hot is False(default) the axis 1 will be removed and label is (0, 10)\nmnist.test.labels.shape == (10000, 10)\nmnist.validation.images.shape == (5000, 784)\nmnist.validation.labels.shape == (5000, 10)\n\nx, y = mnist.train.next_batch(batch_size)\n# x.shape == (batch_size, 784)\n# y.shape == (batch_size, 10)\n```\n\n### scikit-learn\n\n```python\n#sklearn.datasets.fetch_mldata(dataname, target_name=’label’, data_name=’data’, transpose_data=True, data_home=None)\n# Fetch an mldata.org data set\n\nfrom sklearn.datasets import fetch_mldata\nmnist = fetch_mldata('MNIST original', data_home='./')\n# you should put the mnist_original.mat in ./mldata\n\nmnist.data.shape == (70000, 784) # scalar (0, 255) uint8\nmnist.target.shape == (70000,) # scalar (0, 10) with increasing order\n```\n\n[mldata.org](ml.data.org) a machine learning data set repository\n","source":"_posts/MNIST数据集.md","raw":"---\ntitle: MNIST数据集\ndate: 2018-09-04 21:21:44\ntags: 数据集\ncategories: 深度学习\n---\n### [MNIST](http://yann.lecun.com/exdb/mnist/)\n\nThe MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n\n### Tensorflow `v1.10` API\n\n```python\nmnist = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n# type(mnist) is Tuple of Numpy arrays:\n# `(x_train, y_train), (x_test, y_test)`.\n(x_train, y_train), (x_test, y_test) = mnist\nx_train.shape == (60000, 28, 28)\nx_test.shape == (10000, 28, 28)\ny_train.shape == (60000,)\ny_test.shape == (10000,)\n# x_train[0, :, :] (0, 255) uint8\n# y_train[0] (0, 10) uint8\n\n# show the pic\nfrom PIL import Image\nim = Image.fromarray(x_train[0,:,:])\nim.show()\n```\n\nOther Low-level API\n```python\nfrom tensorflow.examples.tutorials.mnist import input_data\n# Or use following import method\n# from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\nmnist = input_data.read_data_sets('./mnist/', one_hot=True)\nmnist.train.images.shape == (55000, 784) # normalized to (0, 1) float32\nmnist.test.images.shape == (10000, 784)\nmnist.train.labels.shape == (55000, 10) # one_hot vector\n# if one_hot is False(default) the axis 1 will be removed and label is (0, 10)\nmnist.test.labels.shape == (10000, 10)\nmnist.validation.images.shape == (5000, 784)\nmnist.validation.labels.shape == (5000, 10)\n\nx, y = mnist.train.next_batch(batch_size)\n# x.shape == (batch_size, 784)\n# y.shape == (batch_size, 10)\n```\n\n### scikit-learn\n\n```python\n#sklearn.datasets.fetch_mldata(dataname, target_name=’label’, data_name=’data’, transpose_data=True, data_home=None)\n# Fetch an mldata.org data set\n\nfrom sklearn.datasets import fetch_mldata\nmnist = fetch_mldata('MNIST original', data_home='./')\n# you should put the mnist_original.mat in ./mldata\n\nmnist.data.shape == (70000, 784) # scalar (0, 255) uint8\nmnist.target.shape == (70000,) # scalar (0, 10) with increasing order\n```\n\n[mldata.org](ml.data.org) a machine learning data set repository\n","slug":"MNIST数据集","published":1,"updated":"2018-09-07T10:13:39.495Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds2g000upcvor9w6x298","content":"<h3 id=\"MNIST\"><a href=\"#MNIST\" class=\"headerlink\" title=\"MNIST\"></a><a href=\"http://yann.lecun.com/exdb/mnist/\" target=\"_blank\" rel=\"noopener\">MNIST</a></h3><p>The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.</p>\n<h3 id=\"Tensorflow-v1-10-API\"><a href=\"#Tensorflow-v1-10-API\" class=\"headerlink\" title=\"Tensorflow v1.10 API\"></a>Tensorflow <code>v1.10</code> API</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mnist = tf.keras.datasets.mnist.load_data(path=<span class=\"string\">'mnist.npz'</span>)</span><br><span class=\"line\"><span class=\"comment\"># type(mnist) is Tuple of Numpy arrays:</span></span><br><span class=\"line\"><span class=\"comment\"># `(x_train, y_train), (x_test, y_test)`.</span></span><br><span class=\"line\">(x_train, y_train), (x_test, y_test) = mnist</span><br><span class=\"line\">x_train.shape == (<span class=\"number\">60000</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>)</span><br><span class=\"line\">x_test.shape == (<span class=\"number\">10000</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>)</span><br><span class=\"line\">y_train.shape == (<span class=\"number\">60000</span>,)</span><br><span class=\"line\">y_test.shape == (<span class=\"number\">10000</span>,)</span><br><span class=\"line\"><span class=\"comment\"># x_train[0, :, :] (0, 255) uint8</span></span><br><span class=\"line\"><span class=\"comment\"># y_train[0] (0, 10) uint8</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show the pic</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\">im = Image.fromarray(x_train[<span class=\"number\">0</span>,:,:])</span><br><span class=\"line\">im.show()</span><br></pre></td></tr></table></figure>\n<p>Other Low-level API<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.examples.tutorials.mnist <span class=\"keyword\">import</span> input_data</span><br><span class=\"line\"><span class=\"comment\"># Or use following import method</span></span><br><span class=\"line\"><span class=\"comment\"># from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets</span></span><br><span class=\"line\">mnist = input_data.read_data_sets(<span class=\"string\">'./mnist/'</span>, one_hot=<span class=\"keyword\">True</span>)</span><br><span class=\"line\">mnist.train.images.shape == (<span class=\"number\">55000</span>, <span class=\"number\">784</span>) <span class=\"comment\"># normalized to (0, 1) float32</span></span><br><span class=\"line\">mnist.test.images.shape == (<span class=\"number\">10000</span>, <span class=\"number\">784</span>)</span><br><span class=\"line\">mnist.train.labels.shape == (<span class=\"number\">55000</span>, <span class=\"number\">10</span>) <span class=\"comment\"># one_hot vector</span></span><br><span class=\"line\"><span class=\"comment\"># if one_hot is False(default) the axis 1 will be removed and label is (0, 10)</span></span><br><span class=\"line\">mnist.test.labels.shape == (<span class=\"number\">10000</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">mnist.validation.images.shape == (<span class=\"number\">5000</span>, <span class=\"number\">784</span>)</span><br><span class=\"line\">mnist.validation.labels.shape == (<span class=\"number\">5000</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">x, y = mnist.train.next_batch(batch_size)</span><br><span class=\"line\"><span class=\"comment\"># x.shape == (batch_size, 784)</span></span><br><span class=\"line\"><span class=\"comment\"># y.shape == (batch_size, 10)</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"scikit-learn\"><a href=\"#scikit-learn\" class=\"headerlink\" title=\"scikit-learn\"></a>scikit-learn</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#sklearn.datasets.fetch_mldata(dataname, target_name=’label’, data_name=’data’, transpose_data=True, data_home=None)</span></span><br><span class=\"line\"><span class=\"comment\"># Fetch an mldata.org data set</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> fetch_mldata</span><br><span class=\"line\">mnist = fetch_mldata(<span class=\"string\">'MNIST original'</span>, data_home=<span class=\"string\">'./'</span>)</span><br><span class=\"line\"><span class=\"comment\"># you should put the mnist_original.mat in ./mldata</span></span><br><span class=\"line\"></span><br><span class=\"line\">mnist.data.shape == (<span class=\"number\">70000</span>, <span class=\"number\">784</span>) <span class=\"comment\"># scalar (0, 255) uint8</span></span><br><span class=\"line\">mnist.target.shape == (<span class=\"number\">70000</span>,) <span class=\"comment\"># scalar (0, 10) with increasing order</span></span><br></pre></td></tr></table></figure>\n<p><a href=\"ml.data.org\">mldata.org</a> a machine learning data set repository</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"MNIST\"><a href=\"#MNIST\" class=\"headerlink\" title=\"MNIST\"></a><a href=\"http://yann.lecun.com/exdb/mnist/\" target=\"_blank\" rel=\"noopener\">MNIST</a></h3><p>The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.</p>\n<h3 id=\"Tensorflow-v1-10-API\"><a href=\"#Tensorflow-v1-10-API\" class=\"headerlink\" title=\"Tensorflow v1.10 API\"></a>Tensorflow <code>v1.10</code> API</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mnist = tf.keras.datasets.mnist.load_data(path=<span class=\"string\">'mnist.npz'</span>)</span><br><span class=\"line\"><span class=\"comment\"># type(mnist) is Tuple of Numpy arrays:</span></span><br><span class=\"line\"><span class=\"comment\"># `(x_train, y_train), (x_test, y_test)`.</span></span><br><span class=\"line\">(x_train, y_train), (x_test, y_test) = mnist</span><br><span class=\"line\">x_train.shape == (<span class=\"number\">60000</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>)</span><br><span class=\"line\">x_test.shape == (<span class=\"number\">10000</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>)</span><br><span class=\"line\">y_train.shape == (<span class=\"number\">60000</span>,)</span><br><span class=\"line\">y_test.shape == (<span class=\"number\">10000</span>,)</span><br><span class=\"line\"><span class=\"comment\"># x_train[0, :, :] (0, 255) uint8</span></span><br><span class=\"line\"><span class=\"comment\"># y_train[0] (0, 10) uint8</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show the pic</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\">im = Image.fromarray(x_train[<span class=\"number\">0</span>,:,:])</span><br><span class=\"line\">im.show()</span><br></pre></td></tr></table></figure>\n<p>Other Low-level API<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.examples.tutorials.mnist <span class=\"keyword\">import</span> input_data</span><br><span class=\"line\"><span class=\"comment\"># Or use following import method</span></span><br><span class=\"line\"><span class=\"comment\"># from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets</span></span><br><span class=\"line\">mnist = input_data.read_data_sets(<span class=\"string\">'./mnist/'</span>, one_hot=<span class=\"keyword\">True</span>)</span><br><span class=\"line\">mnist.train.images.shape == (<span class=\"number\">55000</span>, <span class=\"number\">784</span>) <span class=\"comment\"># normalized to (0, 1) float32</span></span><br><span class=\"line\">mnist.test.images.shape == (<span class=\"number\">10000</span>, <span class=\"number\">784</span>)</span><br><span class=\"line\">mnist.train.labels.shape == (<span class=\"number\">55000</span>, <span class=\"number\">10</span>) <span class=\"comment\"># one_hot vector</span></span><br><span class=\"line\"><span class=\"comment\"># if one_hot is False(default) the axis 1 will be removed and label is (0, 10)</span></span><br><span class=\"line\">mnist.test.labels.shape == (<span class=\"number\">10000</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">mnist.validation.images.shape == (<span class=\"number\">5000</span>, <span class=\"number\">784</span>)</span><br><span class=\"line\">mnist.validation.labels.shape == (<span class=\"number\">5000</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">x, y = mnist.train.next_batch(batch_size)</span><br><span class=\"line\"><span class=\"comment\"># x.shape == (batch_size, 784)</span></span><br><span class=\"line\"><span class=\"comment\"># y.shape == (batch_size, 10)</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"scikit-learn\"><a href=\"#scikit-learn\" class=\"headerlink\" title=\"scikit-learn\"></a>scikit-learn</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#sklearn.datasets.fetch_mldata(dataname, target_name=’label’, data_name=’data’, transpose_data=True, data_home=None)</span></span><br><span class=\"line\"><span class=\"comment\"># Fetch an mldata.org data set</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> fetch_mldata</span><br><span class=\"line\">mnist = fetch_mldata(<span class=\"string\">'MNIST original'</span>, data_home=<span class=\"string\">'./'</span>)</span><br><span class=\"line\"><span class=\"comment\"># you should put the mnist_original.mat in ./mldata</span></span><br><span class=\"line\"></span><br><span class=\"line\">mnist.data.shape == (<span class=\"number\">70000</span>, <span class=\"number\">784</span>) <span class=\"comment\"># scalar (0, 255) uint8</span></span><br><span class=\"line\">mnist.target.shape == (<span class=\"number\">70000</span>,) <span class=\"comment\"># scalar (0, 10) with increasing order</span></span><br></pre></td></tr></table></figure>\n<p><a href=\"ml.data.org\">mldata.org</a> a machine learning data set repository</p>\n"},{"title":"Permutation generate","date":"2018-09-04T01:49:58.000Z","_content":"\n### Permutation\n\nIn mathematics, the notion of permutation relates to the act of arranging all the members of a set into some sequence or order, or if the set is already ordered, rearranging (reordering) its elements, a process called permuting. These differ from combinations, which are selections of some members of a set where order is disregarded.\n\n### Algorithms to generate permutations\n\n#### Random generation of permutations\n\nThe **Fisher–Yates shuffle** is an algorithm for generating a random permutation of a finite sequence—in plain terms, the algorithm shuffles the sequence. The algorithm effectively puts all the elements into a hat; it continually determines the next element by randomly drawing an element from the hat until no elements remain. The algorithm produces an unbiased permutation: every permutation is equally likely.\n\nThe basic method given for generating a random permutation of the numbers 1 through N goes as follows:\n\n```python\n# 1. Write down the numbers from 1 through N.\n# 2. Pick a random number k between one and the number of unstruck numbers remaining (inclusive).\n# 3. Counting from the low end, strike out the kth number not yet struck out, and write it down at the end of a separate list.\n# 4. Repeat from step 2 until all the numbers have been struck out.\n# 5. The sequence of numbers written down in step 3 is now a random permutation of the original numbers.\n\nscatch = [1, 2, 3, 4, 5]\nresult = []\nfor i in range(len(scatch)):\n    roll = random.randint(1, len(scatch))\n    struck = scatch.pop(roll-1)\n    result.append(struck)\n```\n\n**The modern version of the algorithm** is efficient: it takes time proportional to the number of items being shuffled and shuffles them in place. The modern version of the Fisher–Yates shuffle, designed for computer use, was introduced by Richard Durstenfeld in 1964[2] and popularized by Donald E. Knuth in **The Art of Computer Programming** as \"Algorithm P (Shuffling)\".\n\n```python\n# To shuffle an array a of n elements (indices 0..n-1):\nfor i from n−1 downto 1 do\n     j ← random integer such that 0 ≤ j ≤ i\n     exchange a[j] and a[i]\n\n# An equivalent version which shuffles the array in the opposite direction (from lowest index to highest) is:\n\nfor i from 0 to n−2 do\n     j ← random integer such that i ≤ j < n\n     exchange a[i] and a[j]\n```\n\n**Sattolo's algorithm**\n\nA very similar algorithm was published in 1986 by Sandra Sattolo for generating uniformly distributed cycles of (maximal) length n.[6][7] The only difference between Durstenfeld's and Sattolo's algorithms is that in the latter, in step 2 above, the random number j is chosen from the range between 1 and i−1 (rather than between 1 and i) inclusive. This simple change modifies the algorithm so that the resulting permutation always consists of a single cycle.\n\n```python\nfrom random import randrange\n\ndef sattoloCycle(items):\n    i = len(items)\n    while i > 1:\n        i = i - 1\n        j = randrange(i)  # 0 <= j <= i-1\n        items[j], items[i] = items[i], items[j]\n```\n\n#### Generation in lexicographic order\n\nThe following algorithm generates the next permutation lexicographically after a given permutation. It changes the given permutation in-place.\n\n```python\n# 1. Find the largest index k such that a[k] < a[k + 1]. If no such index exists, the permutation is the last permutation.\n# 2. Find the largest index l greater than k such that a[k] < a[l].\n# 3. Swap the value of a[k] with that of a[l].\n# 4. Reverse the sequence from a[k + 1] up to and including the final element a[n].\n\nk = -1\nl = -1\nfor i in reversed(range(len(a) - 1)):\n    if a[i] < a[i + 1]:\n        k = i\n        break\nif k == -1:\n    return\nfor j in reversed(range(len(a))):\n    if a[j] > a[k]:\n        l = j\n        break\na[k], a[l] = a[l], a[k]\na= a[:k + 1] + list(reversed(a[k + 1:]))\n```\n\n#### Generation with minimal changes\n\n**Heap's algorithm** generates all possible permutations of n objects. It was first proposed by B. R. Heap in 1963.[1] The algorithm minimizes movement: it generates each permutation from the previous one by interchanging a single pair of elements; the other n−2 elements are not disturbed.\n\nSuppose we have a permutation containing n different elements. Heap found a systematic method for choosing at each step a pair of elements to switch, in order to produce every possible permutation of these elements exactly once. Let us describe Heap's method in a recursive way. First we set a counter i to 0. Now we perform the following steps repeatedly until i is equal to n. We use the algorithm to generate the (n−1)! permutations of the first n−1 elements, adjoining the last element to each of these. This generates all of the permutations that end with the last element. Then if n is odd, we switch the first element and the last one, while if n is even we can switch the ith element and the last one (there is no difference between n even and odd in the first iteration). We add one to the counter i and repeat. In each iteration, the algorithm will produce all of the permutations that end with the element that has just been moved to the \"last\" position. The following pseudocode outputs all permutations of a data array of length n.\n\n```python\ndef generate(n, A):\n    if n == 1:\n          return A\n    else:\n        for i in range(n-1):\n            generate(n - 1, A)\n            if n % 2 == 0:\n                A[n-1], A[i] = A[i], A[n-1]\n            else:\n                A[n-1], A[0] = A[0], A[n-1]\n        generate(n - 1, A)\n\n# a non-recursive format\ndef generate(n, A):\n    c = []\n    for i in range(n):\n        c[i] = 0\n    print(A)\n    i = 0\n    while i < n:\n        if  c[i] < i:\n            if i % 2 == 0:\n                A[i], A[0] = A[0], A[i]\n            else:\n                A[i], A[c[i]] = A[c[i]], A[i]\n            print(A)\n            c[i] = c[i] + 1\n            i = 0\n        else:\n            c[i] = 0\n            i = i + 1\n```\n","source":"_posts/Permutation-generate.md","raw":"---\ntitle: Permutation generate\ndate: 2018-09-04 09:49:58\ntags: Permutation\ncategories: 算法导论\n---\n\n### Permutation\n\nIn mathematics, the notion of permutation relates to the act of arranging all the members of a set into some sequence or order, or if the set is already ordered, rearranging (reordering) its elements, a process called permuting. These differ from combinations, which are selections of some members of a set where order is disregarded.\n\n### Algorithms to generate permutations\n\n#### Random generation of permutations\n\nThe **Fisher–Yates shuffle** is an algorithm for generating a random permutation of a finite sequence—in plain terms, the algorithm shuffles the sequence. The algorithm effectively puts all the elements into a hat; it continually determines the next element by randomly drawing an element from the hat until no elements remain. The algorithm produces an unbiased permutation: every permutation is equally likely.\n\nThe basic method given for generating a random permutation of the numbers 1 through N goes as follows:\n\n```python\n# 1. Write down the numbers from 1 through N.\n# 2. Pick a random number k between one and the number of unstruck numbers remaining (inclusive).\n# 3. Counting from the low end, strike out the kth number not yet struck out, and write it down at the end of a separate list.\n# 4. Repeat from step 2 until all the numbers have been struck out.\n# 5. The sequence of numbers written down in step 3 is now a random permutation of the original numbers.\n\nscatch = [1, 2, 3, 4, 5]\nresult = []\nfor i in range(len(scatch)):\n    roll = random.randint(1, len(scatch))\n    struck = scatch.pop(roll-1)\n    result.append(struck)\n```\n\n**The modern version of the algorithm** is efficient: it takes time proportional to the number of items being shuffled and shuffles them in place. The modern version of the Fisher–Yates shuffle, designed for computer use, was introduced by Richard Durstenfeld in 1964[2] and popularized by Donald E. Knuth in **The Art of Computer Programming** as \"Algorithm P (Shuffling)\".\n\n```python\n# To shuffle an array a of n elements (indices 0..n-1):\nfor i from n−1 downto 1 do\n     j ← random integer such that 0 ≤ j ≤ i\n     exchange a[j] and a[i]\n\n# An equivalent version which shuffles the array in the opposite direction (from lowest index to highest) is:\n\nfor i from 0 to n−2 do\n     j ← random integer such that i ≤ j < n\n     exchange a[i] and a[j]\n```\n\n**Sattolo's algorithm**\n\nA very similar algorithm was published in 1986 by Sandra Sattolo for generating uniformly distributed cycles of (maximal) length n.[6][7] The only difference between Durstenfeld's and Sattolo's algorithms is that in the latter, in step 2 above, the random number j is chosen from the range between 1 and i−1 (rather than between 1 and i) inclusive. This simple change modifies the algorithm so that the resulting permutation always consists of a single cycle.\n\n```python\nfrom random import randrange\n\ndef sattoloCycle(items):\n    i = len(items)\n    while i > 1:\n        i = i - 1\n        j = randrange(i)  # 0 <= j <= i-1\n        items[j], items[i] = items[i], items[j]\n```\n\n#### Generation in lexicographic order\n\nThe following algorithm generates the next permutation lexicographically after a given permutation. It changes the given permutation in-place.\n\n```python\n# 1. Find the largest index k such that a[k] < a[k + 1]. If no such index exists, the permutation is the last permutation.\n# 2. Find the largest index l greater than k such that a[k] < a[l].\n# 3. Swap the value of a[k] with that of a[l].\n# 4. Reverse the sequence from a[k + 1] up to and including the final element a[n].\n\nk = -1\nl = -1\nfor i in reversed(range(len(a) - 1)):\n    if a[i] < a[i + 1]:\n        k = i\n        break\nif k == -1:\n    return\nfor j in reversed(range(len(a))):\n    if a[j] > a[k]:\n        l = j\n        break\na[k], a[l] = a[l], a[k]\na= a[:k + 1] + list(reversed(a[k + 1:]))\n```\n\n#### Generation with minimal changes\n\n**Heap's algorithm** generates all possible permutations of n objects. It was first proposed by B. R. Heap in 1963.[1] The algorithm minimizes movement: it generates each permutation from the previous one by interchanging a single pair of elements; the other n−2 elements are not disturbed.\n\nSuppose we have a permutation containing n different elements. Heap found a systematic method for choosing at each step a pair of elements to switch, in order to produce every possible permutation of these elements exactly once. Let us describe Heap's method in a recursive way. First we set a counter i to 0. Now we perform the following steps repeatedly until i is equal to n. We use the algorithm to generate the (n−1)! permutations of the first n−1 elements, adjoining the last element to each of these. This generates all of the permutations that end with the last element. Then if n is odd, we switch the first element and the last one, while if n is even we can switch the ith element and the last one (there is no difference between n even and odd in the first iteration). We add one to the counter i and repeat. In each iteration, the algorithm will produce all of the permutations that end with the element that has just been moved to the \"last\" position. The following pseudocode outputs all permutations of a data array of length n.\n\n```python\ndef generate(n, A):\n    if n == 1:\n          return A\n    else:\n        for i in range(n-1):\n            generate(n - 1, A)\n            if n % 2 == 0:\n                A[n-1], A[i] = A[i], A[n-1]\n            else:\n                A[n-1], A[0] = A[0], A[n-1]\n        generate(n - 1, A)\n\n# a non-recursive format\ndef generate(n, A):\n    c = []\n    for i in range(n):\n        c[i] = 0\n    print(A)\n    i = 0\n    while i < n:\n        if  c[i] < i:\n            if i % 2 == 0:\n                A[i], A[0] = A[0], A[i]\n            else:\n                A[i], A[c[i]] = A[c[i]], A[i]\n            print(A)\n            c[i] = c[i] + 1\n            i = 0\n        else:\n            c[i] = 0\n            i = i + 1\n```\n","slug":"Permutation-generate","published":1,"updated":"2018-09-05T13:18:11.624Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds2v000wpcvoa6m6h01e","content":"<h3 id=\"Permutation\"><a href=\"#Permutation\" class=\"headerlink\" title=\"Permutation\"></a>Permutation</h3><p>In mathematics, the notion of permutation relates to the act of arranging all the members of a set into some sequence or order, or if the set is already ordered, rearranging (reordering) its elements, a process called permuting. These differ from combinations, which are selections of some members of a set where order is disregarded.</p>\n<h3 id=\"Algorithms-to-generate-permutations\"><a href=\"#Algorithms-to-generate-permutations\" class=\"headerlink\" title=\"Algorithms to generate permutations\"></a>Algorithms to generate permutations</h3><h4 id=\"Random-generation-of-permutations\"><a href=\"#Random-generation-of-permutations\" class=\"headerlink\" title=\"Random generation of permutations\"></a>Random generation of permutations</h4><p>The <strong>Fisher–Yates shuffle</strong> is an algorithm for generating a random permutation of a finite sequence—in plain terms, the algorithm shuffles the sequence. The algorithm effectively puts all the elements into a hat; it continually determines the next element by randomly drawing an element from the hat until no elements remain. The algorithm produces an unbiased permutation: every permutation is equally likely.</p>\n<p>The basic method given for generating a random permutation of the numbers 1 through N goes as follows:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. Write down the numbers from 1 through N.</span></span><br><span class=\"line\"><span class=\"comment\"># 2. Pick a random number k between one and the number of unstruck numbers remaining (inclusive).</span></span><br><span class=\"line\"><span class=\"comment\"># 3. Counting from the low end, strike out the kth number not yet struck out, and write it down at the end of a separate list.</span></span><br><span class=\"line\"><span class=\"comment\"># 4. Repeat from step 2 until all the numbers have been struck out.</span></span><br><span class=\"line\"><span class=\"comment\"># 5. The sequence of numbers written down in step 3 is now a random permutation of the original numbers.</span></span><br><span class=\"line\"></span><br><span class=\"line\">scatch = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>]</span><br><span class=\"line\">result = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(scatch)):</span><br><span class=\"line\">    roll = random.randint(<span class=\"number\">1</span>, len(scatch))</span><br><span class=\"line\">    struck = scatch.pop(roll<span class=\"number\">-1</span>)</span><br><span class=\"line\">    result.append(struck)</span><br></pre></td></tr></table></figure>\n<p><strong>The modern version of the algorithm</strong> is efficient: it takes time proportional to the number of items being shuffled and shuffles them in place. The modern version of the Fisher–Yates shuffle, designed for computer use, was introduced by Richard Durstenfeld in 1964[2] and popularized by Donald E. Knuth in <strong>The Art of Computer Programming</strong> as “Algorithm P (Shuffling)”.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># To shuffle an array a of n elements (indices 0..n-1):</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">from</span> n−<span class=\"number\">1</span> downto <span class=\"number\">1</span> do</span><br><span class=\"line\">     j ← random integer such that <span class=\"number\">0</span> ≤ j ≤ i</span><br><span class=\"line\">     exchange a[j] <span class=\"keyword\">and</span> a[i]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># An equivalent version which shuffles the array in the opposite direction (from lowest index to highest) is:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">from</span> <span class=\"number\">0</span> to n−<span class=\"number\">2</span> do</span><br><span class=\"line\">     j ← random integer such that i ≤ j &lt; n</span><br><span class=\"line\">     exchange a[i] <span class=\"keyword\">and</span> a[j]</span><br></pre></td></tr></table></figure>\n<p><strong>Sattolo’s algorithm</strong></p>\n<p>A very similar algorithm was published in 1986 by Sandra Sattolo for generating uniformly distributed cycles of (maximal) length n.[6][7] The only difference between Durstenfeld’s and Sattolo’s algorithms is that in the latter, in step 2 above, the random number j is chosen from the range between 1 and i−1 (rather than between 1 and i) inclusive. This simple change modifies the algorithm so that the resulting permutation always consists of a single cycle.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> random <span class=\"keyword\">import</span> randrange</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sattoloCycle</span><span class=\"params\">(items)</span>:</span></span><br><span class=\"line\">    i = len(items)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> i &gt; <span class=\"number\">1</span>:</span><br><span class=\"line\">        i = i - <span class=\"number\">1</span></span><br><span class=\"line\">        j = randrange(i)  <span class=\"comment\"># 0 &lt;= j &lt;= i-1</span></span><br><span class=\"line\">        items[j], items[i] = items[i], items[j]</span><br></pre></td></tr></table></figure>\n<h4 id=\"Generation-in-lexicographic-order\"><a href=\"#Generation-in-lexicographic-order\" class=\"headerlink\" title=\"Generation in lexicographic order\"></a>Generation in lexicographic order</h4><p>The following algorithm generates the next permutation lexicographically after a given permutation. It changes the given permutation in-place.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. Find the largest index k such that a[k] &lt; a[k + 1]. If no such index exists, the permutation is the last permutation.</span></span><br><span class=\"line\"><span class=\"comment\"># 2. Find the largest index l greater than k such that a[k] &lt; a[l].</span></span><br><span class=\"line\"><span class=\"comment\"># 3. Swap the value of a[k] with that of a[l].</span></span><br><span class=\"line\"><span class=\"comment\"># 4. Reverse the sequence from a[k + 1] up to and including the final element a[n].</span></span><br><span class=\"line\"></span><br><span class=\"line\">k = <span class=\"number\">-1</span></span><br><span class=\"line\">l = <span class=\"number\">-1</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> reversed(range(len(a) - <span class=\"number\">1</span>)):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> a[i] &lt; a[i + <span class=\"number\">1</span>]:</span><br><span class=\"line\">        k = i</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> k == <span class=\"number\">-1</span>:</span><br><span class=\"line\">    <span class=\"keyword\">return</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> reversed(range(len(a))):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> a[j] &gt; a[k]:</span><br><span class=\"line\">        l = j</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">a[k], a[l] = a[l], a[k]</span><br><span class=\"line\">a= a[:k + <span class=\"number\">1</span>] + list(reversed(a[k + <span class=\"number\">1</span>:]))</span><br></pre></td></tr></table></figure>\n<h4 id=\"Generation-with-minimal-changes\"><a href=\"#Generation-with-minimal-changes\" class=\"headerlink\" title=\"Generation with minimal changes\"></a>Generation with minimal changes</h4><p><strong>Heap’s algorithm</strong> generates all possible permutations of n objects. It was first proposed by B. R. Heap in 1963.[1] The algorithm minimizes movement: it generates each permutation from the previous one by interchanging a single pair of elements; the other n−2 elements are not disturbed.</p>\n<p>Suppose we have a permutation containing n different elements. Heap found a systematic method for choosing at each step a pair of elements to switch, in order to produce every possible permutation of these elements exactly once. Let us describe Heap’s method in a recursive way. First we set a counter i to 0. Now we perform the following steps repeatedly until i is equal to n. We use the algorithm to generate the (n−1)! permutations of the first n−1 elements, adjoining the last element to each of these. This generates all of the permutations that end with the last element. Then if n is odd, we switch the first element and the last one, while if n is even we can switch the ith element and the last one (there is no difference between n even and odd in the first iteration). We add one to the counter i and repeat. In each iteration, the algorithm will produce all of the permutations that end with the element that has just been moved to the “last” position. The following pseudocode outputs all permutations of a data array of length n.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate</span><span class=\"params\">(n, A)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> n == <span class=\"number\">1</span>:</span><br><span class=\"line\">          <span class=\"keyword\">return</span> A</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n<span class=\"number\">-1</span>):</span><br><span class=\"line\">            generate(n - <span class=\"number\">1</span>, A)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> n % <span class=\"number\">2</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">                A[n<span class=\"number\">-1</span>], A[i] = A[i], A[n<span class=\"number\">-1</span>]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                A[n<span class=\"number\">-1</span>], A[<span class=\"number\">0</span>] = A[<span class=\"number\">0</span>], A[n<span class=\"number\">-1</span>]</span><br><span class=\"line\">        generate(n - <span class=\"number\">1</span>, A)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># a non-recursive format</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate</span><span class=\"params\">(n, A)</span>:</span></span><br><span class=\"line\">    c = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):</span><br><span class=\"line\">        c[i] = <span class=\"number\">0</span></span><br><span class=\"line\">    print(A)</span><br><span class=\"line\">    i = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> i &lt; n:</span><br><span class=\"line\">        <span class=\"keyword\">if</span>  c[i] &lt; i:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> i % <span class=\"number\">2</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">                A[i], A[<span class=\"number\">0</span>] = A[<span class=\"number\">0</span>], A[i]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                A[i], A[c[i]] = A[c[i]], A[i]</span><br><span class=\"line\">            print(A)</span><br><span class=\"line\">            c[i] = c[i] + <span class=\"number\">1</span></span><br><span class=\"line\">            i = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            c[i] = <span class=\"number\">0</span></span><br><span class=\"line\">            i = i + <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Permutation\"><a href=\"#Permutation\" class=\"headerlink\" title=\"Permutation\"></a>Permutation</h3><p>In mathematics, the notion of permutation relates to the act of arranging all the members of a set into some sequence or order, or if the set is already ordered, rearranging (reordering) its elements, a process called permuting. These differ from combinations, which are selections of some members of a set where order is disregarded.</p>\n<h3 id=\"Algorithms-to-generate-permutations\"><a href=\"#Algorithms-to-generate-permutations\" class=\"headerlink\" title=\"Algorithms to generate permutations\"></a>Algorithms to generate permutations</h3><h4 id=\"Random-generation-of-permutations\"><a href=\"#Random-generation-of-permutations\" class=\"headerlink\" title=\"Random generation of permutations\"></a>Random generation of permutations</h4><p>The <strong>Fisher–Yates shuffle</strong> is an algorithm for generating a random permutation of a finite sequence—in plain terms, the algorithm shuffles the sequence. The algorithm effectively puts all the elements into a hat; it continually determines the next element by randomly drawing an element from the hat until no elements remain. The algorithm produces an unbiased permutation: every permutation is equally likely.</p>\n<p>The basic method given for generating a random permutation of the numbers 1 through N goes as follows:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. Write down the numbers from 1 through N.</span></span><br><span class=\"line\"><span class=\"comment\"># 2. Pick a random number k between one and the number of unstruck numbers remaining (inclusive).</span></span><br><span class=\"line\"><span class=\"comment\"># 3. Counting from the low end, strike out the kth number not yet struck out, and write it down at the end of a separate list.</span></span><br><span class=\"line\"><span class=\"comment\"># 4. Repeat from step 2 until all the numbers have been struck out.</span></span><br><span class=\"line\"><span class=\"comment\"># 5. The sequence of numbers written down in step 3 is now a random permutation of the original numbers.</span></span><br><span class=\"line\"></span><br><span class=\"line\">scatch = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>]</span><br><span class=\"line\">result = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(scatch)):</span><br><span class=\"line\">    roll = random.randint(<span class=\"number\">1</span>, len(scatch))</span><br><span class=\"line\">    struck = scatch.pop(roll<span class=\"number\">-1</span>)</span><br><span class=\"line\">    result.append(struck)</span><br></pre></td></tr></table></figure>\n<p><strong>The modern version of the algorithm</strong> is efficient: it takes time proportional to the number of items being shuffled and shuffles them in place. The modern version of the Fisher–Yates shuffle, designed for computer use, was introduced by Richard Durstenfeld in 1964[2] and popularized by Donald E. Knuth in <strong>The Art of Computer Programming</strong> as “Algorithm P (Shuffling)”.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># To shuffle an array a of n elements (indices 0..n-1):</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">from</span> n−<span class=\"number\">1</span> downto <span class=\"number\">1</span> do</span><br><span class=\"line\">     j ← random integer such that <span class=\"number\">0</span> ≤ j ≤ i</span><br><span class=\"line\">     exchange a[j] <span class=\"keyword\">and</span> a[i]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># An equivalent version which shuffles the array in the opposite direction (from lowest index to highest) is:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">from</span> <span class=\"number\">0</span> to n−<span class=\"number\">2</span> do</span><br><span class=\"line\">     j ← random integer such that i ≤ j &lt; n</span><br><span class=\"line\">     exchange a[i] <span class=\"keyword\">and</span> a[j]</span><br></pre></td></tr></table></figure>\n<p><strong>Sattolo’s algorithm</strong></p>\n<p>A very similar algorithm was published in 1986 by Sandra Sattolo for generating uniformly distributed cycles of (maximal) length n.[6][7] The only difference between Durstenfeld’s and Sattolo’s algorithms is that in the latter, in step 2 above, the random number j is chosen from the range between 1 and i−1 (rather than between 1 and i) inclusive. This simple change modifies the algorithm so that the resulting permutation always consists of a single cycle.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> random <span class=\"keyword\">import</span> randrange</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sattoloCycle</span><span class=\"params\">(items)</span>:</span></span><br><span class=\"line\">    i = len(items)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> i &gt; <span class=\"number\">1</span>:</span><br><span class=\"line\">        i = i - <span class=\"number\">1</span></span><br><span class=\"line\">        j = randrange(i)  <span class=\"comment\"># 0 &lt;= j &lt;= i-1</span></span><br><span class=\"line\">        items[j], items[i] = items[i], items[j]</span><br></pre></td></tr></table></figure>\n<h4 id=\"Generation-in-lexicographic-order\"><a href=\"#Generation-in-lexicographic-order\" class=\"headerlink\" title=\"Generation in lexicographic order\"></a>Generation in lexicographic order</h4><p>The following algorithm generates the next permutation lexicographically after a given permutation. It changes the given permutation in-place.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. Find the largest index k such that a[k] &lt; a[k + 1]. If no such index exists, the permutation is the last permutation.</span></span><br><span class=\"line\"><span class=\"comment\"># 2. Find the largest index l greater than k such that a[k] &lt; a[l].</span></span><br><span class=\"line\"><span class=\"comment\"># 3. Swap the value of a[k] with that of a[l].</span></span><br><span class=\"line\"><span class=\"comment\"># 4. Reverse the sequence from a[k + 1] up to and including the final element a[n].</span></span><br><span class=\"line\"></span><br><span class=\"line\">k = <span class=\"number\">-1</span></span><br><span class=\"line\">l = <span class=\"number\">-1</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> reversed(range(len(a) - <span class=\"number\">1</span>)):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> a[i] &lt; a[i + <span class=\"number\">1</span>]:</span><br><span class=\"line\">        k = i</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> k == <span class=\"number\">-1</span>:</span><br><span class=\"line\">    <span class=\"keyword\">return</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> reversed(range(len(a))):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> a[j] &gt; a[k]:</span><br><span class=\"line\">        l = j</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">a[k], a[l] = a[l], a[k]</span><br><span class=\"line\">a= a[:k + <span class=\"number\">1</span>] + list(reversed(a[k + <span class=\"number\">1</span>:]))</span><br></pre></td></tr></table></figure>\n<h4 id=\"Generation-with-minimal-changes\"><a href=\"#Generation-with-minimal-changes\" class=\"headerlink\" title=\"Generation with minimal changes\"></a>Generation with minimal changes</h4><p><strong>Heap’s algorithm</strong> generates all possible permutations of n objects. It was first proposed by B. R. Heap in 1963.[1] The algorithm minimizes movement: it generates each permutation from the previous one by interchanging a single pair of elements; the other n−2 elements are not disturbed.</p>\n<p>Suppose we have a permutation containing n different elements. Heap found a systematic method for choosing at each step a pair of elements to switch, in order to produce every possible permutation of these elements exactly once. Let us describe Heap’s method in a recursive way. First we set a counter i to 0. Now we perform the following steps repeatedly until i is equal to n. We use the algorithm to generate the (n−1)! permutations of the first n−1 elements, adjoining the last element to each of these. This generates all of the permutations that end with the last element. Then if n is odd, we switch the first element and the last one, while if n is even we can switch the ith element and the last one (there is no difference between n even and odd in the first iteration). We add one to the counter i and repeat. In each iteration, the algorithm will produce all of the permutations that end with the element that has just been moved to the “last” position. The following pseudocode outputs all permutations of a data array of length n.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate</span><span class=\"params\">(n, A)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> n == <span class=\"number\">1</span>:</span><br><span class=\"line\">          <span class=\"keyword\">return</span> A</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n<span class=\"number\">-1</span>):</span><br><span class=\"line\">            generate(n - <span class=\"number\">1</span>, A)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> n % <span class=\"number\">2</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">                A[n<span class=\"number\">-1</span>], A[i] = A[i], A[n<span class=\"number\">-1</span>]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                A[n<span class=\"number\">-1</span>], A[<span class=\"number\">0</span>] = A[<span class=\"number\">0</span>], A[n<span class=\"number\">-1</span>]</span><br><span class=\"line\">        generate(n - <span class=\"number\">1</span>, A)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># a non-recursive format</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate</span><span class=\"params\">(n, A)</span>:</span></span><br><span class=\"line\">    c = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):</span><br><span class=\"line\">        c[i] = <span class=\"number\">0</span></span><br><span class=\"line\">    print(A)</span><br><span class=\"line\">    i = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> i &lt; n:</span><br><span class=\"line\">        <span class=\"keyword\">if</span>  c[i] &lt; i:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> i % <span class=\"number\">2</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">                A[i], A[<span class=\"number\">0</span>] = A[<span class=\"number\">0</span>], A[i]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                A[i], A[c[i]] = A[c[i]], A[i]</span><br><span class=\"line\">            print(A)</span><br><span class=\"line\">            c[i] = c[i] + <span class=\"number\">1</span></span><br><span class=\"line\">            i = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            c[i] = <span class=\"number\">0</span></span><br><span class=\"line\">            i = i + <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n"},{"title":"Very Deep Convolutional Networks for Large-Scale Image Recongnition","date":"2018-08-31T02:08:37.000Z","mathjax":true,"_content":"## 概述\n\n这是一篇由牛津大学视觉几何组(VGG)2015年发表在ICLR上的论文。该论文中，他们主要研究了卷积网络深度对大尺度图像识别精度的影响。主要的贡献是，对使用同一小卷积核但深度不同的网络性能的完整评估，当把深度加到16-19层时，它相对于先前技术在性能上有了很大改善。文中的网络架构被称为 **VGG**, 它也在ImageNet Challenge 2014上取得了定位第一，分类第二的好成绩。\n\n## 网络配置\n\n所有的网络使用相同的卷积池化操作只是深度不同。使用'SAME'卷积, 卷积核大小均为 $3 \\times 3$ , 步长为1. 使用最大池化, 池化单元大小均为 $2 \\times 2$, 步长为2. 卷积核个数(通道数)从64开始以2倍增长直到512. 每层卷积层的非线性函数为ReLU. 最后三个全连接层的大小分别为4096, 4096, 1000.\n\n![](/images/vgg_architecture.PNG)\n\n亮点：**使用3个堆叠的3\\*3卷积而不是采样像alexnet中的7\\*7卷积.**\n\n理由：在3个堆叠的卷积层中都包含了ReLU非线性单元，这使决策函数更具有分辨力；其次减少了参数，相比于7\\*7的卷积需要参数( $7 \\times7 C^2$ ), 3个3\\*3卷积层需要更少的参数( $3\\times 3 \\times 3 C^2$ )\n\n## 分类任务的训练和测试\n\n### 训练阶段\n\n利用带动量的小批量梯度下降法优化多项逻辑回归目标。$batch size=256, momentum=0.9, L2=5*10^{-4}, dropout=0.5, learning\\_rate=0.01$\n先训练小网络A, 再将训练后A的权重给其他网络初始化, 其他还未初始化的层，权重使用均值为0方差为0.01的正态分布初始化，偏差初始化为0.\n在每个SGD迭代过程，对每幅输入图像进行随机裁剪到固定大小224\\*224.\n\n训练图像的大小(S: 是经过各向同性调整后的最小边长)：\n\n方法一：单尺度训练，固定S=256/S=384. 先用S=256训练，将参数保留然后再用S=384进行微调(学习率下降到0.001)。\n\n方法二：多尺度训练，S从[256, 512]中随机取值，先用S=384训练再将其参数保留用多尺度方法训练。\n\n### 测试阶段\n\n给一个测试图像，先将其进行各向同性调整到预定义的最小尺寸Q. 将全连接层转换为卷积层(第一个全连接层变为7\\*7的卷积层，第二，三个全连接层变为1\\*1的卷积层，核的大小均与之前全连接层的单元数相等)。将整个未裁剪的图像应用在整个卷积网络上。结果是一个类的得分映射，通道数等于类数，以及一个可变的空间分辨率，取决于输入的图像大小。最后，为了获得图像的类分数的固定大小向量，类分数被进行空间平均（一个类的得分为该通道上像素的平均值）。还能通过水平翻转的方式来增强测试集。\n\n亮点：**测试时将全连接层转换为卷积层。**\n\n理由：在测试时不需要生成多个裁剪的图像重复进行计算。对输入图像的大小没有限制。\n\n## 分类任务的评估\n\n该数据集包含1000个类的图像，并分为三组:训练(130万张图像)、验证(50K图像)和测试(100K带有提示标签的图像)。\n\n### 单尺度评估(Q不变)\n\n$对于固定的S, Q=S; 对于 S \\in [S_{min}, S_{max}], Q = 0.5(S_{min} + S_{max})$\n![](/images/vgg_performance_1.PNG)\n\n### 多尺度评估(Q变化)\n\n$对于固定的S, Q=\\{S-32, S, S+32\\}; 对于 S \\in [S_{min}, S_{max}], Q = \\{S_{min}, 0.5(S_{min} + S_{max}), S_{max}\\}$\n![](/images/vgg_performance_2.PNG)\n\n### Multi-crop 评估(S变化)\n\n![](/images/vgg_performance_3.PNG)\n","source":"_posts/Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recongnition.md","raw":"---\ntitle: Very Deep Convolutional Networks for Large-Scale Image Recongnition\ndate: 2018-08-31 10:08:37\ntags: CNN, VGG\ncategories: 深度学习\nmathjax: true\n---\n## 概述\n\n这是一篇由牛津大学视觉几何组(VGG)2015年发表在ICLR上的论文。该论文中，他们主要研究了卷积网络深度对大尺度图像识别精度的影响。主要的贡献是，对使用同一小卷积核但深度不同的网络性能的完整评估，当把深度加到16-19层时，它相对于先前技术在性能上有了很大改善。文中的网络架构被称为 **VGG**, 它也在ImageNet Challenge 2014上取得了定位第一，分类第二的好成绩。\n\n## 网络配置\n\n所有的网络使用相同的卷积池化操作只是深度不同。使用'SAME'卷积, 卷积核大小均为 $3 \\times 3$ , 步长为1. 使用最大池化, 池化单元大小均为 $2 \\times 2$, 步长为2. 卷积核个数(通道数)从64开始以2倍增长直到512. 每层卷积层的非线性函数为ReLU. 最后三个全连接层的大小分别为4096, 4096, 1000.\n\n![](/images/vgg_architecture.PNG)\n\n亮点：**使用3个堆叠的3\\*3卷积而不是采样像alexnet中的7\\*7卷积.**\n\n理由：在3个堆叠的卷积层中都包含了ReLU非线性单元，这使决策函数更具有分辨力；其次减少了参数，相比于7\\*7的卷积需要参数( $7 \\times7 C^2$ ), 3个3\\*3卷积层需要更少的参数( $3\\times 3 \\times 3 C^2$ )\n\n## 分类任务的训练和测试\n\n### 训练阶段\n\n利用带动量的小批量梯度下降法优化多项逻辑回归目标。$batch size=256, momentum=0.9, L2=5*10^{-4}, dropout=0.5, learning\\_rate=0.01$\n先训练小网络A, 再将训练后A的权重给其他网络初始化, 其他还未初始化的层，权重使用均值为0方差为0.01的正态分布初始化，偏差初始化为0.\n在每个SGD迭代过程，对每幅输入图像进行随机裁剪到固定大小224\\*224.\n\n训练图像的大小(S: 是经过各向同性调整后的最小边长)：\n\n方法一：单尺度训练，固定S=256/S=384. 先用S=256训练，将参数保留然后再用S=384进行微调(学习率下降到0.001)。\n\n方法二：多尺度训练，S从[256, 512]中随机取值，先用S=384训练再将其参数保留用多尺度方法训练。\n\n### 测试阶段\n\n给一个测试图像，先将其进行各向同性调整到预定义的最小尺寸Q. 将全连接层转换为卷积层(第一个全连接层变为7\\*7的卷积层，第二，三个全连接层变为1\\*1的卷积层，核的大小均与之前全连接层的单元数相等)。将整个未裁剪的图像应用在整个卷积网络上。结果是一个类的得分映射，通道数等于类数，以及一个可变的空间分辨率，取决于输入的图像大小。最后，为了获得图像的类分数的固定大小向量，类分数被进行空间平均（一个类的得分为该通道上像素的平均值）。还能通过水平翻转的方式来增强测试集。\n\n亮点：**测试时将全连接层转换为卷积层。**\n\n理由：在测试时不需要生成多个裁剪的图像重复进行计算。对输入图像的大小没有限制。\n\n## 分类任务的评估\n\n该数据集包含1000个类的图像，并分为三组:训练(130万张图像)、验证(50K图像)和测试(100K带有提示标签的图像)。\n\n### 单尺度评估(Q不变)\n\n$对于固定的S, Q=S; 对于 S \\in [S_{min}, S_{max}], Q = 0.5(S_{min} + S_{max})$\n![](/images/vgg_performance_1.PNG)\n\n### 多尺度评估(Q变化)\n\n$对于固定的S, Q=\\{S-32, S, S+32\\}; 对于 S \\in [S_{min}, S_{max}], Q = \\{S_{min}, 0.5(S_{min} + S_{max}), S_{max}\\}$\n![](/images/vgg_performance_2.PNG)\n\n### Multi-crop 评估(S变化)\n\n![](/images/vgg_performance_3.PNG)\n","slug":"Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recongnition","published":1,"updated":"2018-08-31T04:06:06.157Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds2v0010pcvovvzvo1nq","content":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>这是一篇由牛津大学视觉几何组(VGG)2015年发表在ICLR上的论文。该论文中，他们主要研究了卷积网络深度对大尺度图像识别精度的影响。主要的贡献是，对使用同一小卷积核但深度不同的网络性能的完整评估，当把深度加到16-19层时，它相对于先前技术在性能上有了很大改善。文中的网络架构被称为 <strong>VGG</strong>, 它也在ImageNet Challenge 2014上取得了定位第一，分类第二的好成绩。</p>\n<h2 id=\"网络配置\"><a href=\"#网络配置\" class=\"headerlink\" title=\"网络配置\"></a>网络配置</h2><p>所有的网络使用相同的卷积池化操作只是深度不同。使用’SAME’卷积, 卷积核大小均为 $3 \\times 3$ , 步长为1. 使用最大池化, 池化单元大小均为 $2 \\times 2$, 步长为2. 卷积核个数(通道数)从64开始以2倍增长直到512. 每层卷积层的非线性函数为ReLU. 最后三个全连接层的大小分别为4096, 4096, 1000.</p>\n<p><img src=\"/images/vgg_architecture.PNG\" alt=\"\"></p>\n<p>亮点：<strong>使用3个堆叠的3*3卷积而不是采样像alexnet中的7*7卷积.</strong></p>\n<p>理由：在3个堆叠的卷积层中都包含了ReLU非线性单元，这使决策函数更具有分辨力；其次减少了参数，相比于7*7的卷积需要参数( $7 \\times7 C^2$ ), 3个3*3卷积层需要更少的参数( $3\\times 3 \\times 3 C^2$ )</p>\n<h2 id=\"分类任务的训练和测试\"><a href=\"#分类任务的训练和测试\" class=\"headerlink\" title=\"分类任务的训练和测试\"></a>分类任务的训练和测试</h2><h3 id=\"训练阶段\"><a href=\"#训练阶段\" class=\"headerlink\" title=\"训练阶段\"></a>训练阶段</h3><p>利用带动量的小批量梯度下降法优化多项逻辑回归目标。$batch size=256, momentum=0.9, L2=5<em>10^{-4}, dropout=0.5, learning_rate=0.01$<br>先训练小网络A, 再将训练后A的权重给其他网络初始化, 其他还未初始化的层，权重使用均值为0方差为0.01的正态分布初始化，偏差初始化为0.<br>在每个SGD迭代过程，对每幅输入图像进行随机裁剪到固定大小224\\</em>224.</p>\n<p>训练图像的大小(S: 是经过各向同性调整后的最小边长)：</p>\n<p>方法一：单尺度训练，固定S=256/S=384. 先用S=256训练，将参数保留然后再用S=384进行微调(学习率下降到0.001)。</p>\n<p>方法二：多尺度训练，S从[256, 512]中随机取值，先用S=384训练再将其参数保留用多尺度方法训练。</p>\n<h3 id=\"测试阶段\"><a href=\"#测试阶段\" class=\"headerlink\" title=\"测试阶段\"></a>测试阶段</h3><p>给一个测试图像，先将其进行各向同性调整到预定义的最小尺寸Q. 将全连接层转换为卷积层(第一个全连接层变为7*7的卷积层，第二，三个全连接层变为1*1的卷积层，核的大小均与之前全连接层的单元数相等)。将整个未裁剪的图像应用在整个卷积网络上。结果是一个类的得分映射，通道数等于类数，以及一个可变的空间分辨率，取决于输入的图像大小。最后，为了获得图像的类分数的固定大小向量，类分数被进行空间平均（一个类的得分为该通道上像素的平均值）。还能通过水平翻转的方式来增强测试集。</p>\n<p>亮点：<strong>测试时将全连接层转换为卷积层。</strong></p>\n<p>理由：在测试时不需要生成多个裁剪的图像重复进行计算。对输入图像的大小没有限制。</p>\n<h2 id=\"分类任务的评估\"><a href=\"#分类任务的评估\" class=\"headerlink\" title=\"分类任务的评估\"></a>分类任务的评估</h2><p>该数据集包含1000个类的图像，并分为三组:训练(130万张图像)、验证(50K图像)和测试(100K带有提示标签的图像)。</p>\n<h3 id=\"单尺度评估-Q不变\"><a href=\"#单尺度评估-Q不变\" class=\"headerlink\" title=\"单尺度评估(Q不变)\"></a>单尺度评估(Q不变)</h3><p>$对于固定的S, Q=S; 对于 S \\in [S_{min}, S_{max}], Q = 0.5(S_{min} + S_{max})$<br><img src=\"/images/vgg_performance_1.PNG\" alt=\"\"></p>\n<h3 id=\"多尺度评估-Q变化\"><a href=\"#多尺度评估-Q变化\" class=\"headerlink\" title=\"多尺度评估(Q变化)\"></a>多尺度评估(Q变化)</h3><p>$对于固定的S, Q={S-32, S, S+32}; 对于 S \\in [S_{min}, S_{max}], Q = {S_{min}, 0.5(S_{min} + S_{max}), S_{max}}$<br><img src=\"/images/vgg_performance_2.PNG\" alt=\"\"></p>\n<h3 id=\"Multi-crop-评估-S变化\"><a href=\"#Multi-crop-评估-S变化\" class=\"headerlink\" title=\"Multi-crop 评估(S变化)\"></a>Multi-crop 评估(S变化)</h3><p><img src=\"/images/vgg_performance_3.PNG\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>这是一篇由牛津大学视觉几何组(VGG)2015年发表在ICLR上的论文。该论文中，他们主要研究了卷积网络深度对大尺度图像识别精度的影响。主要的贡献是，对使用同一小卷积核但深度不同的网络性能的完整评估，当把深度加到16-19层时，它相对于先前技术在性能上有了很大改善。文中的网络架构被称为 <strong>VGG</strong>, 它也在ImageNet Challenge 2014上取得了定位第一，分类第二的好成绩。</p>\n<h2 id=\"网络配置\"><a href=\"#网络配置\" class=\"headerlink\" title=\"网络配置\"></a>网络配置</h2><p>所有的网络使用相同的卷积池化操作只是深度不同。使用’SAME’卷积, 卷积核大小均为 $3 \\times 3$ , 步长为1. 使用最大池化, 池化单元大小均为 $2 \\times 2$, 步长为2. 卷积核个数(通道数)从64开始以2倍增长直到512. 每层卷积层的非线性函数为ReLU. 最后三个全连接层的大小分别为4096, 4096, 1000.</p>\n<p><img src=\"/images/vgg_architecture.PNG\" alt=\"\"></p>\n<p>亮点：<strong>使用3个堆叠的3*3卷积而不是采样像alexnet中的7*7卷积.</strong></p>\n<p>理由：在3个堆叠的卷积层中都包含了ReLU非线性单元，这使决策函数更具有分辨力；其次减少了参数，相比于7*7的卷积需要参数( $7 \\times7 C^2$ ), 3个3*3卷积层需要更少的参数( $3\\times 3 \\times 3 C^2$ )</p>\n<h2 id=\"分类任务的训练和测试\"><a href=\"#分类任务的训练和测试\" class=\"headerlink\" title=\"分类任务的训练和测试\"></a>分类任务的训练和测试</h2><h3 id=\"训练阶段\"><a href=\"#训练阶段\" class=\"headerlink\" title=\"训练阶段\"></a>训练阶段</h3><p>利用带动量的小批量梯度下降法优化多项逻辑回归目标。$batch size=256, momentum=0.9, L2=5<em>10^{-4}, dropout=0.5, learning_rate=0.01$<br>先训练小网络A, 再将训练后A的权重给其他网络初始化, 其他还未初始化的层，权重使用均值为0方差为0.01的正态分布初始化，偏差初始化为0.<br>在每个SGD迭代过程，对每幅输入图像进行随机裁剪到固定大小224\\</em>224.</p>\n<p>训练图像的大小(S: 是经过各向同性调整后的最小边长)：</p>\n<p>方法一：单尺度训练，固定S=256/S=384. 先用S=256训练，将参数保留然后再用S=384进行微调(学习率下降到0.001)。</p>\n<p>方法二：多尺度训练，S从[256, 512]中随机取值，先用S=384训练再将其参数保留用多尺度方法训练。</p>\n<h3 id=\"测试阶段\"><a href=\"#测试阶段\" class=\"headerlink\" title=\"测试阶段\"></a>测试阶段</h3><p>给一个测试图像，先将其进行各向同性调整到预定义的最小尺寸Q. 将全连接层转换为卷积层(第一个全连接层变为7*7的卷积层，第二，三个全连接层变为1*1的卷积层，核的大小均与之前全连接层的单元数相等)。将整个未裁剪的图像应用在整个卷积网络上。结果是一个类的得分映射，通道数等于类数，以及一个可变的空间分辨率，取决于输入的图像大小。最后，为了获得图像的类分数的固定大小向量，类分数被进行空间平均（一个类的得分为该通道上像素的平均值）。还能通过水平翻转的方式来增强测试集。</p>\n<p>亮点：<strong>测试时将全连接层转换为卷积层。</strong></p>\n<p>理由：在测试时不需要生成多个裁剪的图像重复进行计算。对输入图像的大小没有限制。</p>\n<h2 id=\"分类任务的评估\"><a href=\"#分类任务的评估\" class=\"headerlink\" title=\"分类任务的评估\"></a>分类任务的评估</h2><p>该数据集包含1000个类的图像，并分为三组:训练(130万张图像)、验证(50K图像)和测试(100K带有提示标签的图像)。</p>\n<h3 id=\"单尺度评估-Q不变\"><a href=\"#单尺度评估-Q不变\" class=\"headerlink\" title=\"单尺度评估(Q不变)\"></a>单尺度评估(Q不变)</h3><p>$对于固定的S, Q=S; 对于 S \\in [S_{min}, S_{max}], Q = 0.5(S_{min} + S_{max})$<br><img src=\"/images/vgg_performance_1.PNG\" alt=\"\"></p>\n<h3 id=\"多尺度评估-Q变化\"><a href=\"#多尺度评估-Q变化\" class=\"headerlink\" title=\"多尺度评估(Q变化)\"></a>多尺度评估(Q变化)</h3><p>$对于固定的S, Q={S-32, S, S+32}; 对于 S \\in [S_{min}, S_{max}], Q = {S_{min}, 0.5(S_{min} + S_{max}), S_{max}}$<br><img src=\"/images/vgg_performance_2.PNG\" alt=\"\"></p>\n<h3 id=\"Multi-crop-评估-S变化\"><a href=\"#Multi-crop-评估-S变化\" class=\"headerlink\" title=\"Multi-crop 评估(S变化)\"></a>Multi-crop 评估(S变化)</h3><p><img src=\"/images/vgg_performance_3.PNG\" alt=\"\"></p>\n"},{"title":"github使用手册","date":"2018-08-05T02:45:20.000Z","_content":"## git clone\n\n### clone地址https和SSH的区别\n\n前者可以随意克隆github上的项目，而不管是谁的；而后者则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。\n\nhttps url 在push的时候是需要验证用户名和密码的；而 SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。\n\n### 在github上添加ssh key的方法\n\n1. \t首先需要检查你电脑是否已经有 SSH key \n\n`cd ~/.ssh/ | ls` 检查是否有文件id_rsa.pub, 若存在则跳过第二步\n\n2. 创建一个ssh key\n\n`ssh-keygen -t rsa -C \"your_email@example.com\"` 使用默认设置，可设置密码用于push操作。完成后将得到两个文件，放在./ssh目录下，分别为id_rsa和id_rsa.pub\n\n3. 添加ssh key到github\n\n拷贝id_rsa.pub文件的内容，复制到github账户的sshkey设置页面处。\n\n4. 测试ssh key\n\n`ssh -T git@github.com`\n\n### clone指定分支\n\n`git clone -b <分支名> <address.git>`\n\n## 添加新的分支\n\n1. 先将仓库克隆到本地\n2. `git branch`查看分支。`git branch <分支名>` 新建分支\n3. `git checkout <分支名>` 切换到新分支\n4. `git push -u origin <分支名>` 同步分支到github\n","source":"_posts/github使用手册.md","raw":"---\ntitle: github使用手册\ndate: 2018-08-05 10:45:20\ntags: git\ncategories: 程序员实用工具\n---\n## git clone\n\n### clone地址https和SSH的区别\n\n前者可以随意克隆github上的项目，而不管是谁的；而后者则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。\n\nhttps url 在push的时候是需要验证用户名和密码的；而 SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。\n\n### 在github上添加ssh key的方法\n\n1. \t首先需要检查你电脑是否已经有 SSH key \n\n`cd ~/.ssh/ | ls` 检查是否有文件id_rsa.pub, 若存在则跳过第二步\n\n2. 创建一个ssh key\n\n`ssh-keygen -t rsa -C \"your_email@example.com\"` 使用默认设置，可设置密码用于push操作。完成后将得到两个文件，放在./ssh目录下，分别为id_rsa和id_rsa.pub\n\n3. 添加ssh key到github\n\n拷贝id_rsa.pub文件的内容，复制到github账户的sshkey设置页面处。\n\n4. 测试ssh key\n\n`ssh -T git@github.com`\n\n### clone指定分支\n\n`git clone -b <分支名> <address.git>`\n\n## 添加新的分支\n\n1. 先将仓库克隆到本地\n2. `git branch`查看分支。`git branch <分支名>` 新建分支\n3. `git checkout <分支名>` 切换到新分支\n4. `git push -u origin <分支名>` 同步分支到github\n","slug":"github使用手册","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds3b0014pcvoiig0jwry","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"git-clone\"><a href=\"#git-clone\" class=\"headerlink\" title=\"git clone\"></a>git clone</h2><h3 id=\"clone地址https和SSH的区别\"><a href=\"#clone地址https和SSH的区别\" class=\"headerlink\" title=\"clone地址https和SSH的区别\"></a>clone地址https和SSH的区别</h3><p>前者可以随意克隆github上的项目，而不管是谁的；而后者则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。</p>\n<p>https url 在push的时候是需要验证用户名和密码的；而 SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。</p>\n<h3 id=\"在github上添加ssh-key的方法\"><a href=\"#在github上添加ssh-key的方法\" class=\"headerlink\" title=\"在github上添加ssh key的方法\"></a>在github上添加ssh key的方法</h3><ol>\n<li>首先需要检查你电脑是否已经有 SSH key </li>\n</ol>\n<p><code>cd ~/.ssh/ | ls</code> 检查是否有文件id_rsa.pub, 若存在则跳过第二步</p>\n<ol start=\"2\">\n<li>创建一个ssh key</li>\n</ol>\n<p><code>ssh-keygen -t rsa -C &quot;your_email@example.com&quot;</code> 使用默认设置，可设置密码用于push操作。完成后将得到两个文件，放在./ssh目录下，分别为id_rsa和id_rsa.pub</p>\n<ol start=\"3\">\n<li>添加ssh key到github</li>\n</ol>\n<p>拷贝id_rsa.pub文件的内容，复制到github账户的sshkey设置页面处。</p>\n<ol start=\"4\">\n<li>测试ssh key</li>\n</ol>\n<p><code>ssh -T git@github.com</code></p>\n<h3 id=\"clone指定分支\"><a href=\"#clone指定分支\" class=\"headerlink\" title=\"clone指定分支\"></a>clone指定分支</h3><p><code>git clone -b &lt;分支名&gt; &lt;address.git&gt;</code></p>\n<h2 id=\"添加新的分支\"><a href=\"#添加新的分支\" class=\"headerlink\" title=\"添加新的分支\"></a>添加新的分支</h2><ol>\n<li>先将仓库克隆到本地</li>\n<li><code>git branch</code>查看分支。<code>git branch &lt;分支名&gt;</code> 新建分支</li>\n<li><code>git checkout &lt;分支名&gt;</code> 切换到新分支</li>\n<li><code>git push -u origin &lt;分支名&gt;</code> 同步分支到github</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"git-clone\"><a href=\"#git-clone\" class=\"headerlink\" title=\"git clone\"></a>git clone</h2><h3 id=\"clone地址https和SSH的区别\"><a href=\"#clone地址https和SSH的区别\" class=\"headerlink\" title=\"clone地址https和SSH的区别\"></a>clone地址https和SSH的区别</h3><p>前者可以随意克隆github上的项目，而不管是谁的；而后者则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。</p>\n<p>https url 在push的时候是需要验证用户名和密码的；而 SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。</p>\n<h3 id=\"在github上添加ssh-key的方法\"><a href=\"#在github上添加ssh-key的方法\" class=\"headerlink\" title=\"在github上添加ssh key的方法\"></a>在github上添加ssh key的方法</h3><ol>\n<li>首先需要检查你电脑是否已经有 SSH key </li>\n</ol>\n<p><code>cd ~/.ssh/ | ls</code> 检查是否有文件id_rsa.pub, 若存在则跳过第二步</p>\n<ol start=\"2\">\n<li>创建一个ssh key</li>\n</ol>\n<p><code>ssh-keygen -t rsa -C &quot;your_email@example.com&quot;</code> 使用默认设置，可设置密码用于push操作。完成后将得到两个文件，放在./ssh目录下，分别为id_rsa和id_rsa.pub</p>\n<ol start=\"3\">\n<li>添加ssh key到github</li>\n</ol>\n<p>拷贝id_rsa.pub文件的内容，复制到github账户的sshkey设置页面处。</p>\n<ol start=\"4\">\n<li>测试ssh key</li>\n</ol>\n<p><code>ssh -T git@github.com</code></p>\n<h3 id=\"clone指定分支\"><a href=\"#clone指定分支\" class=\"headerlink\" title=\"clone指定分支\"></a>clone指定分支</h3><p><code>git clone -b &lt;分支名&gt; &lt;address.git&gt;</code></p>\n<h2 id=\"添加新的分支\"><a href=\"#添加新的分支\" class=\"headerlink\" title=\"添加新的分支\"></a>添加新的分支</h2><ol>\n<li>先将仓库克隆到本地</li>\n<li><code>git branch</code>查看分支。<code>git branch &lt;分支名&gt;</code> 新建分支</li>\n<li><code>git checkout &lt;分支名&gt;</code> 切换到新分支</li>\n<li><code>git push -u origin &lt;分支名&gt;</code> 同步分支到github</li>\n</ol>\n"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ncategories: web\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2018-08-19T01:59:35.792Z","updated":"2018-08-19T01:59:35.792Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds3b0017pcvoicsckkqj","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n"},{"title":"matplotlib","date":"2018-08-15T23:51:58.000Z","_content":"\n## 快速绘图\n\n### 使用pyplot模块绘图\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.figure(figsize=(8,4))\nplt.plot(x, y, label=\"$sin(x)$\", color=\"red\", linewidth=2)\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Volt\")\nplt.title(\"pyplot first example\")\nplt.ylim(-1.2, 1.2)\nplt.legend()\nplt.show()\n```\n\n保存图片`plt.savefig('test.png', dpi=120)`的像素值由参数`matplotlib.rcParams[\"savefig.dpi\"]`决定，默认为100.\n保存对象不一定是文件，还可是和文件对象有相同调用接口的对象.\n\n```python\nfrom StringIO import StringIO\nbuf = StringIO()\nplt.savefig(buf, fmt='png')\nbuf.getvalue()[:20]\n```\n\n### 以面向对象方式绘图\n\n```python\nfig = plt.gcf()  # get current figure\naxes = plt.gca()  # get current axes\n```\n\n在pyplot模块中，许多函数都是对当前的Figure和Axes对象进行处理.\n\n### 配置属性\n\n使用matplotlib绘制的图表的每个组成部分都和一个对象对应，可以通过调用这些对象的属性设置方法`set_*()`或pyplot模块的属性设置函数`setp()`来设它们的属性值.\n\n```\nx = np.arange(0, 5, 0.1)\nline = plt.plot(x, x*x)[0]\nline.set_antialiased(False)\n\nlines = plt.plot(x, np.sin(x), x, np.cos(x))\nplt.setp(lines, color=\"r\", linewidth=2.0)\n```\n\n同样可以调用Line2D对象的`get_*()`或`plt.getp()`来获取对象的属性值.\n\n```python\nline.get_linewidth()\n\n# getp()只能对一个对象操作\nplt.getp(lines[0], \"color\")\nplt.getp(lines[1])  # 输出全部属性\n\nf = plt.gcf()\nplt.getp(f)\n\nallines = plt.getp(plt.gca(), \"lines\")\nallines = f.axes[0].lines\n```\n\n### 绘制多个子图\n\n一个Figure对象可以包含多个子图Axes.\n\n`subplot(numRows, numCols, plotNum)`\n\n`subplot(323), subplot(3, 2, 3)`\n\n```python\n# 绘制6个子图并设置不同的背景颜色\nfor idx, color in enumerate(\"rgbyck\"):\n    plt.subplot(321 + idx, axisbg=color)\nplt.show()\n```\n\n`plt.subplot(212)  # 占据第二整行`\n\n```python\n同时在多幅图表、多个子图中进行绘制\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(1)  # 创建图表1\nplt.figure(2)\nax1 = plt.subplot(211)  # 在图表2中创建子图1\nax2 = plt.subplot(212)\n\nx = np.linspace(0, 3, 100)\nfor i in xrange(5):\n    plt.figure(1)  # 选择图表1\n    plt.plot(x, np.exp(i * x / 3)\n    plt.sca(ax1)  # 选择图表2的子图1\n    plt.plot(x, np.sin(x * i))\n    plt.sca(ax2)  # 选择图表2的子图2\n    plt.plot(x, np.cos(i * x))\nplt.show()\n```\n\n### 配置文件\n\n绘制一幅图表要对许多对象的属性进行配置。我们通常采用了默认配置，matplotlib将这些默认配置保存在一个名为“matplotlibrc”的配置文件中。\n\n```python\nmatplotlib.get_configdir()  # 获取用户配置路径\nmatplotlib.matplotlib_fname()  # 获得目前使用的配置文件的路径\nmatplotlib.rc_params()  # 配置文件的读入，返回字典\nmatplotlib.rc(\"lines\", marker='x', linewidth=2, color=\"red\")  # 对配置字典进行设置\nmatplotlib.rcdefaults()  # 回复默认配置\n``````\n\n### 在图表中显示中文\n\n```pythno\nfrom matplotlib.font_manager import fontManager\n# 获得所有可用的字体列表\nfontManager.ttflist\n\n# 获得字体文件的全路径和字体名\nfontManager.ttflist[0].name\nfontManager.ttflist[0].fname\n\n\n```python\n# 显示所有的中文字体\nfrom matplotlib.font_manager import fontManager\nimport matplotlib.pyplot as plt\nimport os\n\nfig = plt.figure(figsize=(12, 6))\nax = fig.add_subplot(111)\nplt.subplot_adjust(0, 0, 1, 1, 0, 0)\nplt.xticks([])\nplt.yticks([])\nx, y = 0.05, 0.08\nfonts = [font.name for font in fontManager.ttflist if os.path.exists(font.fname) and os.stat(font.fname).st_size>1e6]\nfont = set(fonts)\ndy = (1.0 - y) / (len(fonts) / 4 + (len(fonts) % 4 != 0))\nfor font in fonts:\n    t = ax.text(x, y, u\"中文字体\", {'fontname': font, 'fontsize': 14}, transform=ax.transAxes)\n    ax.test(x, y - dy / 2, font, transform=ax.transAxes)\n    x += 0.25\n    if x >= 1.0:\n        y += dy\n        x = 0.05\nplt.show()\n```\n\n```python\n# 使用ttc字体文件\nfrom matplotlib.font_Manager import FontProperties\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfont = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)\nt = np.linspace(0, 10, 100)\ny = np.sin(t)\nplt.plot(t, y)\nplt.title(u\"正弦波\", fontproperties=font)\nplt.show()\n```\n\n直接修改配置文件，设置默认字体。\n\n`plt.rcParams[\"font.family\"] = \"SimHei\"`\n\n## Artist对象\n","source":"_posts/matplotlib.md","raw":"---\ntitle: matplotlib\ndate: 2018-08-16 07:51:58\ntags: python\ncategories: python包和模块\n---\n\n## 快速绘图\n\n### 使用pyplot模块绘图\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.figure(figsize=(8,4))\nplt.plot(x, y, label=\"$sin(x)$\", color=\"red\", linewidth=2)\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Volt\")\nplt.title(\"pyplot first example\")\nplt.ylim(-1.2, 1.2)\nplt.legend()\nplt.show()\n```\n\n保存图片`plt.savefig('test.png', dpi=120)`的像素值由参数`matplotlib.rcParams[\"savefig.dpi\"]`决定，默认为100.\n保存对象不一定是文件，还可是和文件对象有相同调用接口的对象.\n\n```python\nfrom StringIO import StringIO\nbuf = StringIO()\nplt.savefig(buf, fmt='png')\nbuf.getvalue()[:20]\n```\n\n### 以面向对象方式绘图\n\n```python\nfig = plt.gcf()  # get current figure\naxes = plt.gca()  # get current axes\n```\n\n在pyplot模块中，许多函数都是对当前的Figure和Axes对象进行处理.\n\n### 配置属性\n\n使用matplotlib绘制的图表的每个组成部分都和一个对象对应，可以通过调用这些对象的属性设置方法`set_*()`或pyplot模块的属性设置函数`setp()`来设它们的属性值.\n\n```\nx = np.arange(0, 5, 0.1)\nline = plt.plot(x, x*x)[0]\nline.set_antialiased(False)\n\nlines = plt.plot(x, np.sin(x), x, np.cos(x))\nplt.setp(lines, color=\"r\", linewidth=2.0)\n```\n\n同样可以调用Line2D对象的`get_*()`或`plt.getp()`来获取对象的属性值.\n\n```python\nline.get_linewidth()\n\n# getp()只能对一个对象操作\nplt.getp(lines[0], \"color\")\nplt.getp(lines[1])  # 输出全部属性\n\nf = plt.gcf()\nplt.getp(f)\n\nallines = plt.getp(plt.gca(), \"lines\")\nallines = f.axes[0].lines\n```\n\n### 绘制多个子图\n\n一个Figure对象可以包含多个子图Axes.\n\n`subplot(numRows, numCols, plotNum)`\n\n`subplot(323), subplot(3, 2, 3)`\n\n```python\n# 绘制6个子图并设置不同的背景颜色\nfor idx, color in enumerate(\"rgbyck\"):\n    plt.subplot(321 + idx, axisbg=color)\nplt.show()\n```\n\n`plt.subplot(212)  # 占据第二整行`\n\n```python\n同时在多幅图表、多个子图中进行绘制\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(1)  # 创建图表1\nplt.figure(2)\nax1 = plt.subplot(211)  # 在图表2中创建子图1\nax2 = plt.subplot(212)\n\nx = np.linspace(0, 3, 100)\nfor i in xrange(5):\n    plt.figure(1)  # 选择图表1\n    plt.plot(x, np.exp(i * x / 3)\n    plt.sca(ax1)  # 选择图表2的子图1\n    plt.plot(x, np.sin(x * i))\n    plt.sca(ax2)  # 选择图表2的子图2\n    plt.plot(x, np.cos(i * x))\nplt.show()\n```\n\n### 配置文件\n\n绘制一幅图表要对许多对象的属性进行配置。我们通常采用了默认配置，matplotlib将这些默认配置保存在一个名为“matplotlibrc”的配置文件中。\n\n```python\nmatplotlib.get_configdir()  # 获取用户配置路径\nmatplotlib.matplotlib_fname()  # 获得目前使用的配置文件的路径\nmatplotlib.rc_params()  # 配置文件的读入，返回字典\nmatplotlib.rc(\"lines\", marker='x', linewidth=2, color=\"red\")  # 对配置字典进行设置\nmatplotlib.rcdefaults()  # 回复默认配置\n``````\n\n### 在图表中显示中文\n\n```pythno\nfrom matplotlib.font_manager import fontManager\n# 获得所有可用的字体列表\nfontManager.ttflist\n\n# 获得字体文件的全路径和字体名\nfontManager.ttflist[0].name\nfontManager.ttflist[0].fname\n\n\n```python\n# 显示所有的中文字体\nfrom matplotlib.font_manager import fontManager\nimport matplotlib.pyplot as plt\nimport os\n\nfig = plt.figure(figsize=(12, 6))\nax = fig.add_subplot(111)\nplt.subplot_adjust(0, 0, 1, 1, 0, 0)\nplt.xticks([])\nplt.yticks([])\nx, y = 0.05, 0.08\nfonts = [font.name for font in fontManager.ttflist if os.path.exists(font.fname) and os.stat(font.fname).st_size>1e6]\nfont = set(fonts)\ndy = (1.0 - y) / (len(fonts) / 4 + (len(fonts) % 4 != 0))\nfor font in fonts:\n    t = ax.text(x, y, u\"中文字体\", {'fontname': font, 'fontsize': 14}, transform=ax.transAxes)\n    ax.test(x, y - dy / 2, font, transform=ax.transAxes)\n    x += 0.25\n    if x >= 1.0:\n        y += dy\n        x = 0.05\nplt.show()\n```\n\n```python\n# 使用ttc字体文件\nfrom matplotlib.font_Manager import FontProperties\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfont = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)\nt = np.linspace(0, 10, 100)\ny = np.sin(t)\nplt.plot(t, y)\nplt.title(u\"正弦波\", fontproperties=font)\nplt.show()\n```\n\n直接修改配置文件，设置默认字体。\n\n`plt.rcParams[\"font.family\"] = \"SimHei\"`\n\n## Artist对象\n","slug":"matplotlib","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds3b001apcvo43y1gs1f","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"快速绘图\"><a href=\"#快速绘图\" class=\"headerlink\" title=\"快速绘图\"></a>快速绘图</h2><h3 id=\"使用pyplot模块绘图\"><a href=\"#使用pyplot模块绘图\" class=\"headerlink\" title=\"使用pyplot模块绘图\"></a>使用pyplot模块绘图</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.sin(x)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">plt.plot(x, y, label=<span class=\"string\">\"$sin(x)$\"</span>, color=<span class=\"string\">\"red\"</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">\"Time(s)\"</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">\"Volt\"</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">\"pyplot first example\"</span>)</span><br><span class=\"line\">plt.ylim(<span class=\"number\">-1.2</span>, <span class=\"number\">1.2</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>保存图片<code>plt.savefig(&#39;test.png&#39;, dpi=120)</code>的像素值由参数<code>matplotlib.rcParams[&quot;savefig.dpi&quot;]</code>决定，默认为100.<br>保存对象不一定是文件，还可是和文件对象有相同调用接口的对象.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> StringIO <span class=\"keyword\">import</span> StringIO</span><br><span class=\"line\">buf = StringIO()</span><br><span class=\"line\">plt.savefig(buf, fmt=<span class=\"string\">'png'</span>)</span><br><span class=\"line\">buf.getvalue()[:<span class=\"number\">20</span>]</span><br></pre></td></tr></table></figure>\n<h3 id=\"以面向对象方式绘图\"><a href=\"#以面向对象方式绘图\" class=\"headerlink\" title=\"以面向对象方式绘图\"></a>以面向对象方式绘图</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fig = plt.gcf()  <span class=\"comment\"># get current figure</span></span><br><span class=\"line\">axes = plt.gca()  <span class=\"comment\"># get current axes</span></span><br></pre></td></tr></table></figure>\n<p>在pyplot模块中，许多函数都是对当前的Figure和Axes对象进行处理.</p>\n<h3 id=\"配置属性\"><a href=\"#配置属性\" class=\"headerlink\" title=\"配置属性\"></a>配置属性</h3><p>使用matplotlib绘制的图表的每个组成部分都和一个对象对应，可以通过调用这些对象的属性设置方法<code>set_*()</code>或pyplot模块的属性设置函数<code>setp()</code>来设它们的属性值.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = np.arange(0, 5, 0.1)</span><br><span class=\"line\">line = plt.plot(x, x*x)[0]</span><br><span class=\"line\">line.set_antialiased(False)</span><br><span class=\"line\"></span><br><span class=\"line\">lines = plt.plot(x, np.sin(x), x, np.cos(x))</span><br><span class=\"line\">plt.setp(lines, color=&quot;r&quot;, linewidth=2.0)</span><br></pre></td></tr></table></figure>\n<p>同样可以调用Line2D对象的<code>get_*()</code>或<code>plt.getp()</code>来获取对象的属性值.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">line.get_linewidth()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># getp()只能对一个对象操作</span></span><br><span class=\"line\">plt.getp(lines[<span class=\"number\">0</span>], <span class=\"string\">\"color\"</span>)</span><br><span class=\"line\">plt.getp(lines[<span class=\"number\">1</span>])  <span class=\"comment\"># 输出全部属性</span></span><br><span class=\"line\"></span><br><span class=\"line\">f = plt.gcf()</span><br><span class=\"line\">plt.getp(f)</span><br><span class=\"line\"></span><br><span class=\"line\">allines = plt.getp(plt.gca(), <span class=\"string\">\"lines\"</span>)</span><br><span class=\"line\">allines = f.axes[<span class=\"number\">0</span>].lines</span><br></pre></td></tr></table></figure>\n<h3 id=\"绘制多个子图\"><a href=\"#绘制多个子图\" class=\"headerlink\" title=\"绘制多个子图\"></a>绘制多个子图</h3><p>一个Figure对象可以包含多个子图Axes.</p>\n<p><code>subplot(numRows, numCols, plotNum)</code></p>\n<p><code>subplot(323), subplot(3, 2, 3)</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 绘制6个子图并设置不同的背景颜色</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> idx, color <span class=\"keyword\">in</span> enumerate(<span class=\"string\">\"rgbyck\"</span>):</span><br><span class=\"line\">    plt.subplot(<span class=\"number\">321</span> + idx, axisbg=color)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><code>plt.subplot(212)  # 占据第二整行</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">同时在多幅图表、多个子图中进行绘制</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(<span class=\"number\">1</span>)  <span class=\"comment\"># 创建图表1</span></span><br><span class=\"line\">plt.figure(<span class=\"number\">2</span>)</span><br><span class=\"line\">ax1 = plt.subplot(<span class=\"number\">211</span>)  <span class=\"comment\"># 在图表2中创建子图1</span></span><br><span class=\"line\">ax2 = plt.subplot(<span class=\"number\">212</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">3</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> xrange(<span class=\"number\">5</span>):</span><br><span class=\"line\">    plt.figure(<span class=\"number\">1</span>)  <span class=\"comment\"># 选择图表1</span></span><br><span class=\"line\">    plt.plot(x, np.exp(i * x / <span class=\"number\">3</span>)</span><br><span class=\"line\">    plt.sca(ax1)  <span class=\"comment\"># 选择图表2的子图1</span></span><br><span class=\"line\">    plt.plot(x, np.sin(x * i))</span><br><span class=\"line\">    plt.sca(ax2)  <span class=\"comment\"># 选择图表2的子图2</span></span><br><span class=\"line\">    plt.plot(x, np.cos(i * x))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置文件\"><a href=\"#配置文件\" class=\"headerlink\" title=\"配置文件\"></a>配置文件</h3><p>绘制一幅图表要对许多对象的属性进行配置。我们通常采用了默认配置，matplotlib将这些默认配置保存在一个名为“matplotlibrc”的配置文件中。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">matplotlib.get_configdir()  <span class=\"comment\"># 获取用户配置路径</span></span><br><span class=\"line\">matplotlib.matplotlib_fname()  <span class=\"comment\"># 获得目前使用的配置文件的路径</span></span><br><span class=\"line\">matplotlib.rc_params()  <span class=\"comment\"># 配置文件的读入，返回字典</span></span><br><span class=\"line\">matplotlib.rc(<span class=\"string\">\"lines\"</span>, marker=<span class=\"string\">'x'</span>, linewidth=<span class=\"number\">2</span>, color=<span class=\"string\">\"red\"</span>)  <span class=\"comment\"># 对配置字典进行设置</span></span><br><span class=\"line\">matplotlib.rcdefaults()  <span class=\"comment\"># 回复默认配置</span></span><br><span class=\"line\">```</span><br></pre></td></tr></table></figure>\n<h3 id=\"在图表中显示中文\"><a href=\"#在图表中显示中文\" class=\"headerlink\" title=\"在图表中显示中文\"></a>在图表中显示中文</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from matplotlib.font_manager import fontManager</span><br><span class=\"line\"># 获得所有可用的字体列表</span><br><span class=\"line\">fontManager.ttflist</span><br><span class=\"line\"></span><br><span class=\"line\"># 获得字体文件的全路径和字体名</span><br><span class=\"line\">fontManager.ttflist[0].name</span><br><span class=\"line\">fontManager.ttflist[0].fname</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">```python</span><br><span class=\"line\"># 显示所有的中文字体</span><br><span class=\"line\">from matplotlib.font_manager import fontManager</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">import os</span><br><span class=\"line\"></span><br><span class=\"line\">fig = plt.figure(figsize=(12, 6))</span><br><span class=\"line\">ax = fig.add_subplot(111)</span><br><span class=\"line\">plt.subplot_adjust(0, 0, 1, 1, 0, 0)</span><br><span class=\"line\">plt.xticks([])</span><br><span class=\"line\">plt.yticks([])</span><br><span class=\"line\">x, y = 0.05, 0.08</span><br><span class=\"line\">fonts = [font.name for font in fontManager.ttflist if os.path.exists(font.fname) and os.stat(font.fname).st_size&gt;1e6]</span><br><span class=\"line\">font = set(fonts)</span><br><span class=\"line\">dy = (1.0 - y) / (len(fonts) / 4 + (len(fonts) % 4 != 0))</span><br><span class=\"line\">for font in fonts:</span><br><span class=\"line\">    t = ax.text(x, y, u&quot;中文字体&quot;, &#123;&apos;fontname&apos;: font, &apos;fontsize&apos;: 14&#125;, transform=ax.transAxes)</span><br><span class=\"line\">    ax.test(x, y - dy / 2, font, transform=ax.transAxes)</span><br><span class=\"line\">    x += 0.25</span><br><span class=\"line\">    if x &gt;= 1.0:</span><br><span class=\"line\">        y += dy</span><br><span class=\"line\">        x = 0.05</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用ttc字体文件</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.font_Manager <span class=\"keyword\">import</span> FontProperties</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">font = FontProperties(fname=<span class=\"string\">r\"c:\\windows\\fonts\\simsun.ttc\"</span>, size=<span class=\"number\">14</span>)</span><br><span class=\"line\">t = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.sin(t)</span><br><span class=\"line\">plt.plot(t, y)</span><br><span class=\"line\">plt.title(<span class=\"string\">u\"正弦波\"</span>, fontproperties=font)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>直接修改配置文件，设置默认字体。</p>\n<p><code>plt.rcParams[&quot;font.family&quot;] = &quot;SimHei&quot;</code></p>\n<h2 id=\"Artist对象\"><a href=\"#Artist对象\" class=\"headerlink\" title=\"Artist对象\"></a>Artist对象</h2>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"快速绘图\"><a href=\"#快速绘图\" class=\"headerlink\" title=\"快速绘图\"></a>快速绘图</h2><h3 id=\"使用pyplot模块绘图\"><a href=\"#使用pyplot模块绘图\" class=\"headerlink\" title=\"使用pyplot模块绘图\"></a>使用pyplot模块绘图</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.sin(x)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">plt.plot(x, y, label=<span class=\"string\">\"$sin(x)$\"</span>, color=<span class=\"string\">\"red\"</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">\"Time(s)\"</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">\"Volt\"</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">\"pyplot first example\"</span>)</span><br><span class=\"line\">plt.ylim(<span class=\"number\">-1.2</span>, <span class=\"number\">1.2</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>保存图片<code>plt.savefig(&#39;test.png&#39;, dpi=120)</code>的像素值由参数<code>matplotlib.rcParams[&quot;savefig.dpi&quot;]</code>决定，默认为100.<br>保存对象不一定是文件，还可是和文件对象有相同调用接口的对象.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> StringIO <span class=\"keyword\">import</span> StringIO</span><br><span class=\"line\">buf = StringIO()</span><br><span class=\"line\">plt.savefig(buf, fmt=<span class=\"string\">'png'</span>)</span><br><span class=\"line\">buf.getvalue()[:<span class=\"number\">20</span>]</span><br></pre></td></tr></table></figure>\n<h3 id=\"以面向对象方式绘图\"><a href=\"#以面向对象方式绘图\" class=\"headerlink\" title=\"以面向对象方式绘图\"></a>以面向对象方式绘图</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fig = plt.gcf()  <span class=\"comment\"># get current figure</span></span><br><span class=\"line\">axes = plt.gca()  <span class=\"comment\"># get current axes</span></span><br></pre></td></tr></table></figure>\n<p>在pyplot模块中，许多函数都是对当前的Figure和Axes对象进行处理.</p>\n<h3 id=\"配置属性\"><a href=\"#配置属性\" class=\"headerlink\" title=\"配置属性\"></a>配置属性</h3><p>使用matplotlib绘制的图表的每个组成部分都和一个对象对应，可以通过调用这些对象的属性设置方法<code>set_*()</code>或pyplot模块的属性设置函数<code>setp()</code>来设它们的属性值.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = np.arange(0, 5, 0.1)</span><br><span class=\"line\">line = plt.plot(x, x*x)[0]</span><br><span class=\"line\">line.set_antialiased(False)</span><br><span class=\"line\"></span><br><span class=\"line\">lines = plt.plot(x, np.sin(x), x, np.cos(x))</span><br><span class=\"line\">plt.setp(lines, color=&quot;r&quot;, linewidth=2.0)</span><br></pre></td></tr></table></figure>\n<p>同样可以调用Line2D对象的<code>get_*()</code>或<code>plt.getp()</code>来获取对象的属性值.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">line.get_linewidth()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># getp()只能对一个对象操作</span></span><br><span class=\"line\">plt.getp(lines[<span class=\"number\">0</span>], <span class=\"string\">\"color\"</span>)</span><br><span class=\"line\">plt.getp(lines[<span class=\"number\">1</span>])  <span class=\"comment\"># 输出全部属性</span></span><br><span class=\"line\"></span><br><span class=\"line\">f = plt.gcf()</span><br><span class=\"line\">plt.getp(f)</span><br><span class=\"line\"></span><br><span class=\"line\">allines = plt.getp(plt.gca(), <span class=\"string\">\"lines\"</span>)</span><br><span class=\"line\">allines = f.axes[<span class=\"number\">0</span>].lines</span><br></pre></td></tr></table></figure>\n<h3 id=\"绘制多个子图\"><a href=\"#绘制多个子图\" class=\"headerlink\" title=\"绘制多个子图\"></a>绘制多个子图</h3><p>一个Figure对象可以包含多个子图Axes.</p>\n<p><code>subplot(numRows, numCols, plotNum)</code></p>\n<p><code>subplot(323), subplot(3, 2, 3)</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 绘制6个子图并设置不同的背景颜色</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> idx, color <span class=\"keyword\">in</span> enumerate(<span class=\"string\">\"rgbyck\"</span>):</span><br><span class=\"line\">    plt.subplot(<span class=\"number\">321</span> + idx, axisbg=color)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><code>plt.subplot(212)  # 占据第二整行</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">同时在多幅图表、多个子图中进行绘制</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(<span class=\"number\">1</span>)  <span class=\"comment\"># 创建图表1</span></span><br><span class=\"line\">plt.figure(<span class=\"number\">2</span>)</span><br><span class=\"line\">ax1 = plt.subplot(<span class=\"number\">211</span>)  <span class=\"comment\"># 在图表2中创建子图1</span></span><br><span class=\"line\">ax2 = plt.subplot(<span class=\"number\">212</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">3</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> xrange(<span class=\"number\">5</span>):</span><br><span class=\"line\">    plt.figure(<span class=\"number\">1</span>)  <span class=\"comment\"># 选择图表1</span></span><br><span class=\"line\">    plt.plot(x, np.exp(i * x / <span class=\"number\">3</span>)</span><br><span class=\"line\">    plt.sca(ax1)  <span class=\"comment\"># 选择图表2的子图1</span></span><br><span class=\"line\">    plt.plot(x, np.sin(x * i))</span><br><span class=\"line\">    plt.sca(ax2)  <span class=\"comment\"># 选择图表2的子图2</span></span><br><span class=\"line\">    plt.plot(x, np.cos(i * x))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置文件\"><a href=\"#配置文件\" class=\"headerlink\" title=\"配置文件\"></a>配置文件</h3><p>绘制一幅图表要对许多对象的属性进行配置。我们通常采用了默认配置，matplotlib将这些默认配置保存在一个名为“matplotlibrc”的配置文件中。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">matplotlib.get_configdir()  <span class=\"comment\"># 获取用户配置路径</span></span><br><span class=\"line\">matplotlib.matplotlib_fname()  <span class=\"comment\"># 获得目前使用的配置文件的路径</span></span><br><span class=\"line\">matplotlib.rc_params()  <span class=\"comment\"># 配置文件的读入，返回字典</span></span><br><span class=\"line\">matplotlib.rc(<span class=\"string\">\"lines\"</span>, marker=<span class=\"string\">'x'</span>, linewidth=<span class=\"number\">2</span>, color=<span class=\"string\">\"red\"</span>)  <span class=\"comment\"># 对配置字典进行设置</span></span><br><span class=\"line\">matplotlib.rcdefaults()  <span class=\"comment\"># 回复默认配置</span></span><br><span class=\"line\">```</span><br></pre></td></tr></table></figure>\n<h3 id=\"在图表中显示中文\"><a href=\"#在图表中显示中文\" class=\"headerlink\" title=\"在图表中显示中文\"></a>在图表中显示中文</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from matplotlib.font_manager import fontManager</span><br><span class=\"line\"># 获得所有可用的字体列表</span><br><span class=\"line\">fontManager.ttflist</span><br><span class=\"line\"></span><br><span class=\"line\"># 获得字体文件的全路径和字体名</span><br><span class=\"line\">fontManager.ttflist[0].name</span><br><span class=\"line\">fontManager.ttflist[0].fname</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">```python</span><br><span class=\"line\"># 显示所有的中文字体</span><br><span class=\"line\">from matplotlib.font_manager import fontManager</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">import os</span><br><span class=\"line\"></span><br><span class=\"line\">fig = plt.figure(figsize=(12, 6))</span><br><span class=\"line\">ax = fig.add_subplot(111)</span><br><span class=\"line\">plt.subplot_adjust(0, 0, 1, 1, 0, 0)</span><br><span class=\"line\">plt.xticks([])</span><br><span class=\"line\">plt.yticks([])</span><br><span class=\"line\">x, y = 0.05, 0.08</span><br><span class=\"line\">fonts = [font.name for font in fontManager.ttflist if os.path.exists(font.fname) and os.stat(font.fname).st_size&gt;1e6]</span><br><span class=\"line\">font = set(fonts)</span><br><span class=\"line\">dy = (1.0 - y) / (len(fonts) / 4 + (len(fonts) % 4 != 0))</span><br><span class=\"line\">for font in fonts:</span><br><span class=\"line\">    t = ax.text(x, y, u&quot;中文字体&quot;, &#123;&apos;fontname&apos;: font, &apos;fontsize&apos;: 14&#125;, transform=ax.transAxes)</span><br><span class=\"line\">    ax.test(x, y - dy / 2, font, transform=ax.transAxes)</span><br><span class=\"line\">    x += 0.25</span><br><span class=\"line\">    if x &gt;= 1.0:</span><br><span class=\"line\">        y += dy</span><br><span class=\"line\">        x = 0.05</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用ttc字体文件</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.font_Manager <span class=\"keyword\">import</span> FontProperties</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">font = FontProperties(fname=<span class=\"string\">r\"c:\\windows\\fonts\\simsun.ttc\"</span>, size=<span class=\"number\">14</span>)</span><br><span class=\"line\">t = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.sin(t)</span><br><span class=\"line\">plt.plot(t, y)</span><br><span class=\"line\">plt.title(<span class=\"string\">u\"正弦波\"</span>, fontproperties=font)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>直接修改配置文件，设置默认字体。</p>\n<p><code>plt.rcParams[&quot;font.family&quot;] = &quot;SimHei&quot;</code></p>\n<h2 id=\"Artist对象\"><a href=\"#Artist对象\" class=\"headerlink\" title=\"Artist对象\"></a>Artist对象</h2>"},{"title":"dropout 正则化","date":"2018-07-20T08:18:24.000Z","mathjax":true,"_content":"## dropout 正则化\n\n**dropout（随机失活）**是在神经网络的隐藏层为每个神经元结点设置一个随机消除的概率，保留下来的神经元形成一个结点较少、规模较小的网络用于训练。dropout 正则化较多地被使用在**计算机视觉（Computer Vision）**领域。\n\n![dropout_regularization](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dropout_regularization.png)\n\n### 反向随机失活（Inverted dropout）\n\n反向随机失活是实现 dropout 的方法。对第`l`层进行 dropout：\n\n```python\nkeep_prob = 0.8    # 设置神经元保留概率\ndl = np.random.rand(al.shape[0], al.shape[1]) < keep_prob\nal = np.multiply(al, dl)\nal /= keep_prob\n\n# 反向传播过程为\ndal = dal * dl\ndal /= keep_prob\n```\n\n最后一步`al /= keep_prob`是因为 $a^{[l]}$中的一部分元素失活（相当于被归零），为了在下一层计算时不影响 $Z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$的期望值，因此除以一个`keep_prob`。\n\n**注意**，在**测试阶段不要使用 dropout**，因为那样会使得预测结果变得随机。\n\n### 理解 dropout\n\n对于单个神经元，其工作是接收输入并产生一些有意义的输出。但是加入了 dropout 后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征，即不会给任何一个输入特征设置太大的权重。\n\n因此，通过传播过程，dropout 将产生和 L2 正则化相同的**收缩权重**的效果。\n\n对于不同的层，设置的`keep_prob`也不同。一般来说，神经元较少的层，会设`keep_prob`为 1.0，而神经元多的层则会设置比较小的`keep_prob`。\n\ndropout 的一大**缺点**是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将`keep_prob`全部设置为 1.0 后运行代码，确保 $J(w, b)$函数单调递减，再打开 dropout。\n\n## 其他正则化方法\n\n* 数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。\n* 早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，在两者开始发生较大偏差时及时停止迭代，避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。\n","source":"_posts/dropout.md","raw":"---\ntitle: dropout 正则化\ndate: 2018-07-20 16:18:24\ntags: dropout\ncategories: 深度学习\nmathjax: true\n---\n## dropout 正则化\n\n**dropout（随机失活）**是在神经网络的隐藏层为每个神经元结点设置一个随机消除的概率，保留下来的神经元形成一个结点较少、规模较小的网络用于训练。dropout 正则化较多地被使用在**计算机视觉（Computer Vision）**领域。\n\n![dropout_regularization](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dropout_regularization.png)\n\n### 反向随机失活（Inverted dropout）\n\n反向随机失活是实现 dropout 的方法。对第`l`层进行 dropout：\n\n```python\nkeep_prob = 0.8    # 设置神经元保留概率\ndl = np.random.rand(al.shape[0], al.shape[1]) < keep_prob\nal = np.multiply(al, dl)\nal /= keep_prob\n\n# 反向传播过程为\ndal = dal * dl\ndal /= keep_prob\n```\n\n最后一步`al /= keep_prob`是因为 $a^{[l]}$中的一部分元素失活（相当于被归零），为了在下一层计算时不影响 $Z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$的期望值，因此除以一个`keep_prob`。\n\n**注意**，在**测试阶段不要使用 dropout**，因为那样会使得预测结果变得随机。\n\n### 理解 dropout\n\n对于单个神经元，其工作是接收输入并产生一些有意义的输出。但是加入了 dropout 后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征，即不会给任何一个输入特征设置太大的权重。\n\n因此，通过传播过程，dropout 将产生和 L2 正则化相同的**收缩权重**的效果。\n\n对于不同的层，设置的`keep_prob`也不同。一般来说，神经元较少的层，会设`keep_prob`为 1.0，而神经元多的层则会设置比较小的`keep_prob`。\n\ndropout 的一大**缺点**是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将`keep_prob`全部设置为 1.0 后运行代码，确保 $J(w, b)$函数单调递减，再打开 dropout。\n\n## 其他正则化方法\n\n* 数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。\n* 早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，在两者开始发生较大偏差时及时停止迭代，避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。\n","slug":"dropout","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds3r001epcvorq5ejjza","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"dropout-正则化\"><a href=\"#dropout-正则化\" class=\"headerlink\" title=\"dropout 正则化\"></a>dropout 正则化</h2><p><strong>dropout（随机失活）</strong>是在神经网络的隐藏层为每个神经元结点设置一个随机消除的概率，保留下来的神经元形成一个结点较少、规模较小的网络用于训练。dropout 正则化较多地被使用在<strong>计算机视觉（Computer Vision）</strong>领域。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dropout_regularization.png\" alt=\"dropout_regularization\"></p>\n<h3 id=\"反向随机失活（Inverted-dropout）\"><a href=\"#反向随机失活（Inverted-dropout）\" class=\"headerlink\" title=\"反向随机失活（Inverted dropout）\"></a>反向随机失活（Inverted dropout）</h3><p>反向随机失活是实现 dropout 的方法。对第<code>l</code>层进行 dropout：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keep_prob = <span class=\"number\">0.8</span>    <span class=\"comment\"># 设置神经元保留概率</span></span><br><span class=\"line\">dl = np.random.rand(al.shape[<span class=\"number\">0</span>], al.shape[<span class=\"number\">1</span>]) &lt; keep_prob</span><br><span class=\"line\">al = np.multiply(al, dl)</span><br><span class=\"line\">al /= keep_prob</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 反向传播过程为</span></span><br><span class=\"line\">dal = dal * dl</span><br><span class=\"line\">dal /= keep_prob</span><br></pre></td></tr></table></figure>\n<p>最后一步<code>al /= keep_prob</code>是因为 $a^{[l]}$中的一部分元素失活（相当于被归零），为了在下一层计算时不影响 $Z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$的期望值，因此除以一个<code>keep_prob</code>。</p>\n<p><strong>注意</strong>，在<strong>测试阶段不要使用 dropout</strong>，因为那样会使得预测结果变得随机。</p>\n<h3 id=\"理解-dropout\"><a href=\"#理解-dropout\" class=\"headerlink\" title=\"理解 dropout\"></a>理解 dropout</h3><p>对于单个神经元，其工作是接收输入并产生一些有意义的输出。但是加入了 dropout 后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征，即不会给任何一个输入特征设置太大的权重。</p>\n<p>因此，通过传播过程，dropout 将产生和 L2 正则化相同的<strong>收缩权重</strong>的效果。</p>\n<p>对于不同的层，设置的<code>keep_prob</code>也不同。一般来说，神经元较少的层，会设<code>keep_prob</code>为 1.0，而神经元多的层则会设置比较小的<code>keep_prob</code>。</p>\n<p>dropout 的一大<strong>缺点</strong>是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将<code>keep_prob</code>全部设置为 1.0 后运行代码，确保 $J(w, b)$函数单调递减，再打开 dropout。</p>\n<h2 id=\"其他正则化方法\"><a href=\"#其他正则化方法\" class=\"headerlink\" title=\"其他正则化方法\"></a>其他正则化方法</h2><ul>\n<li>数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。</li>\n<li>早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，在两者开始发生较大偏差时及时停止迭代，避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"dropout-正则化\"><a href=\"#dropout-正则化\" class=\"headerlink\" title=\"dropout 正则化\"></a>dropout 正则化</h2><p><strong>dropout（随机失活）</strong>是在神经网络的隐藏层为每个神经元结点设置一个随机消除的概率，保留下来的神经元形成一个结点较少、规模较小的网络用于训练。dropout 正则化较多地被使用在<strong>计算机视觉（Computer Vision）</strong>领域。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dropout_regularization.png\" alt=\"dropout_regularization\"></p>\n<h3 id=\"反向随机失活（Inverted-dropout）\"><a href=\"#反向随机失活（Inverted-dropout）\" class=\"headerlink\" title=\"反向随机失活（Inverted dropout）\"></a>反向随机失活（Inverted dropout）</h3><p>反向随机失活是实现 dropout 的方法。对第<code>l</code>层进行 dropout：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keep_prob = <span class=\"number\">0.8</span>    <span class=\"comment\"># 设置神经元保留概率</span></span><br><span class=\"line\">dl = np.random.rand(al.shape[<span class=\"number\">0</span>], al.shape[<span class=\"number\">1</span>]) &lt; keep_prob</span><br><span class=\"line\">al = np.multiply(al, dl)</span><br><span class=\"line\">al /= keep_prob</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 反向传播过程为</span></span><br><span class=\"line\">dal = dal * dl</span><br><span class=\"line\">dal /= keep_prob</span><br></pre></td></tr></table></figure>\n<p>最后一步<code>al /= keep_prob</code>是因为 $a^{[l]}$中的一部分元素失活（相当于被归零），为了在下一层计算时不影响 $Z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$的期望值，因此除以一个<code>keep_prob</code>。</p>\n<p><strong>注意</strong>，在<strong>测试阶段不要使用 dropout</strong>，因为那样会使得预测结果变得随机。</p>\n<h3 id=\"理解-dropout\"><a href=\"#理解-dropout\" class=\"headerlink\" title=\"理解 dropout\"></a>理解 dropout</h3><p>对于单个神经元，其工作是接收输入并产生一些有意义的输出。但是加入了 dropout 后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征，即不会给任何一个输入特征设置太大的权重。</p>\n<p>因此，通过传播过程，dropout 将产生和 L2 正则化相同的<strong>收缩权重</strong>的效果。</p>\n<p>对于不同的层，设置的<code>keep_prob</code>也不同。一般来说，神经元较少的层，会设<code>keep_prob</code>为 1.0，而神经元多的层则会设置比较小的<code>keep_prob</code>。</p>\n<p>dropout 的一大<strong>缺点</strong>是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将<code>keep_prob</code>全部设置为 1.0 后运行代码，确保 $J(w, b)$函数单调递减，再打开 dropout。</p>\n<h2 id=\"其他正则化方法\"><a href=\"#其他正则化方法\" class=\"headerlink\" title=\"其他正则化方法\"></a>其他正则化方法</h2><ul>\n<li>数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。</li>\n<li>早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，在两者开始发生较大偏差时及时停止迭代，避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。</li>\n</ul>\n"},{"title":"python内置小工具","date":"2018-08-04T23:24:47.000Z","_content":"\n## 极简文件下载（Web）服务器\n\n### 作用\n\n快速共享文件\n\n### 实用方法\n\nIn python2：\n\n`python -m SimpleHttpServer`\n\nIn python3:\n\n`python -m http.server`\n\n执行上述命令会在当前目录启动一个文件下载服务器，默认端口8000。**若当前目录存在一个名为`index.html`的文件，则默认会显示该文件的内容**\n\n## 使用python解压zip压缩包\n\n`$ python -m zipfile\nUsage:\n    zipfile.py -l zipfile.zip        # Show listing of a zipfile\n    zipfile.py -t zipfile.zip        # Test if a zipfile is valid\n    zipfile.py -e zipfile.zip target # Extract zipfile into target dir\n    zipfile.py -c zipfile.zip src ... # Create zipfile from sources\n`\n","source":"_posts/python内置小工具.md","raw":"---\ntitle: python内置小工具\ndate: 2018-08-05 07:24:47\ntags: python\ncategories: 程序员实用工具\n---\n\n## 极简文件下载（Web）服务器\n\n### 作用\n\n快速共享文件\n\n### 实用方法\n\nIn python2：\n\n`python -m SimpleHttpServer`\n\nIn python3:\n\n`python -m http.server`\n\n执行上述命令会在当前目录启动一个文件下载服务器，默认端口8000。**若当前目录存在一个名为`index.html`的文件，则默认会显示该文件的内容**\n\n## 使用python解压zip压缩包\n\n`$ python -m zipfile\nUsage:\n    zipfile.py -l zipfile.zip        # Show listing of a zipfile\n    zipfile.py -t zipfile.zip        # Test if a zipfile is valid\n    zipfile.py -e zipfile.zip target # Extract zipfile into target dir\n    zipfile.py -c zipfile.zip src ... # Create zipfile from sources\n`\n","slug":"python内置小工具","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds3r001ipcvoe9cme28i","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"极简文件下载（Web）服务器\"><a href=\"#极简文件下载（Web）服务器\" class=\"headerlink\" title=\"极简文件下载（Web）服务器\"></a>极简文件下载（Web）服务器</h2><h3 id=\"作用\"><a href=\"#作用\" class=\"headerlink\" title=\"作用\"></a>作用</h3><p>快速共享文件</p>\n<h3 id=\"实用方法\"><a href=\"#实用方法\" class=\"headerlink\" title=\"实用方法\"></a>实用方法</h3><p>In python2：</p>\n<p><code>python -m SimpleHttpServer</code></p>\n<p>In python3:</p>\n<p><code>python -m http.server</code></p>\n<p>执行上述命令会在当前目录启动一个文件下载服务器，默认端口8000。<strong>若当前目录存在一个名为<code>index.html</code>的文件，则默认会显示该文件的内容</strong></p>\n<h2 id=\"使用python解压zip压缩包\"><a href=\"#使用python解压zip压缩包\" class=\"headerlink\" title=\"使用python解压zip压缩包\"></a>使用python解压zip压缩包</h2><p><code>$ python -m zipfile\nUsage:\n    zipfile.py -l zipfile.zip        # Show listing of a zipfile\n    zipfile.py -t zipfile.zip        # Test if a zipfile is valid\n    zipfile.py -e zipfile.zip target # Extract zipfile into target dir\n    zipfile.py -c zipfile.zip src ... # Create zipfile from sources</code></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"极简文件下载（Web）服务器\"><a href=\"#极简文件下载（Web）服务器\" class=\"headerlink\" title=\"极简文件下载（Web）服务器\"></a>极简文件下载（Web）服务器</h2><h3 id=\"作用\"><a href=\"#作用\" class=\"headerlink\" title=\"作用\"></a>作用</h3><p>快速共享文件</p>\n<h3 id=\"实用方法\"><a href=\"#实用方法\" class=\"headerlink\" title=\"实用方法\"></a>实用方法</h3><p>In python2：</p>\n<p><code>python -m SimpleHttpServer</code></p>\n<p>In python3:</p>\n<p><code>python -m http.server</code></p>\n<p>执行上述命令会在当前目录启动一个文件下载服务器，默认端口8000。<strong>若当前目录存在一个名为<code>index.html</code>的文件，则默认会显示该文件的内容</strong></p>\n<h2 id=\"使用python解压zip压缩包\"><a href=\"#使用python解压zip压缩包\" class=\"headerlink\" title=\"使用python解压zip压缩包\"></a>使用python解压zip压缩包</h2><p><code>$ python -m zipfile\nUsage:\n    zipfile.py -l zipfile.zip        # Show listing of a zipfile\n    zipfile.py -t zipfile.zip        # Test if a zipfile is valid\n    zipfile.py -e zipfile.zip target # Extract zipfile into target dir\n    zipfile.py -c zipfile.zip src ... # Create zipfile from sources</code></p>\n"},{"title":"Requests","date":"2018-08-14T00:15:18.000Z","_content":"\n## [Requests](cn.python-requests.org)\n\nRequests is an elegant and simple HTTP library for python, built for human beings.\n\n## Beloved Features\n\n* Keep-Alive & Connection Pooling\n* International Domains and URLs\n* Session with Cookie Persistence\n* Browser-style SSL Verification\n* Automatic Content Decoding\n* Basic/Digest Authentication\n* Elegant Key/Value Cookie\n* Automatic Decompression\n* Unicode Response Bodies\n* HTTP(S) Proxy Support\n* Multipart File Uploads\n* Streaming Downloads\n* Connection Timeouts\n* Chunked Requests\n* `.netrc` Support\n\n## 快速上手\n\n### 发送请求\n\n```python\nimport requests\nr = requests.get(url)\n```\n`r`为Response对象，requests的方法还有`put, delete, head, options`\n\n### 传递URL参数\n\n如url为`http://httpbin.org/get?key2=value2&key1=value1`\n```python\npayload = {'key1':'value1', 'key2':'value2'}\nr = requests.get(\"http://httpbin.org/get\", params=payload)\n```\n\n### 响应内容\n\n`r.text` 响应文本\n`r.encoding` 编码格式\n\n### 二进制响应内容\n\n`r.content` 以字节的方式访问响应体\n\n```python\nfrom PIL import Image\nfrom io import BytesIO\ni = Image.open(BytesIO(r.content))\n```\n\n### JSON响应内容\n\n`r.josn()`\n\n### 原始响应内容\n\n```python\nr = requests.get(url, stream=True)\nr.raw\nr.raw.read(10)\n\nwith open(filename, 'wb') as fd:\n    for chunk in r.iter_content(chunk_size):\n        fd.write(chunk)\n```\n\n### 定制请求头\n\n`headers = {'user-agent': 'my_-app/0.0.1'}`\n`r = requests.get(url, headers=headers)`\n\n### 更复杂的POST请求\n\n```python\npayload = {'key1':'value1', 'key2':'value2'}\nr = requests.post(\"http://httpbin.org/get\", data=payload)\n\npayload = (('key1', 'value1'), ('key2', 'value2'))\nr = requests.post(\"http://httpbin.org/get\", data=payload)\n\nr = requests.post(url, json=payload)\n```\n\n### POST一个多部分编码的文件\n\n```python\nfiles = {'file': open('report.xls', 'rb')}\nr = requests.post(url, files=files)\n\n# 你还可以显式地设置文件名，文件类型和请求头\nfiles = {'file': ('report.xls', open('report.xls', 'rb'), 'application/vnd.ms-excel', {'Expires': '0'})}\n```\n\n### 响应状态码\n\n`r.status_code` 检查响应状态码\n`r.status_code == requests.codes.ok` 内置的状态码查询对象\n`r.raise_for_status()` 抛出异常\n\n### 响应头\n\n`r.headers`\n```json\n{\n    'content-encoding': 'gzip',\n    'transfer-encoding': 'chunked',\n    'connection': 'close',\n    'server': 'nginx/1.0.4',\n    'x-runtime': '148ms',\n    'etag': '\"e1ca502697e5c9317743dc078f67693f\"',\n    'content-type': 'application/json'\n}\n```\n\n### Cookie\n\n`r.cookies`\n```python\ncookies = dict(cookies_are='working')\nr = requests.get(url, cookies=cookies)\n```\n\nCookie 的返回对象为 RequestsCookieJar，它的行为和字典类似，但接口更为完整，适合跨域名跨路径使用。你还可以把 Cookie Jar 传到 Requests 中：\n\n```python\njar = requests.cookies.RequestsCookieJar()\njar.set('tasty_cookie', 'yum', domain='httpbin.org', path='/cookies')\nr = requests.get(url, cookies=jar)\n```\n\n### 重定向和请求历史\n\nResponse.history 是一个 Response 对象的列表，为了完成请求而创建了这些对象。这个对象列表按照从最老到最近的请求进行排序。\n\n```python\nr = requests.get(url, allow_redirects=False)\nr.history\n```\n\n### 超时\n\n`r = requests.get(url, timeouts=0.01)`\n\n### 错误与异常\n\n遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出一个 ConnectionError 异常\n\n如果 HTTP 请求返回了不成功的状态码， Response.raise_for_status() 会抛出一个 HTTPError 异常\n\n若请求超时，则抛出一个 Timeout 异常。\n\n若请求超过了设定的最大重定向次数，则会抛出一个 TooManyRedirects 异常。\n\n所有Requests显式抛出的异常都继承自 requests.exceptions.RequestException 。\n","source":"_posts/requests.md","raw":"---\ntitle: Requests\ndate: 2018-08-14 08:15:18\ntags: python\ncategories: python包和模块\n---\n\n## [Requests](cn.python-requests.org)\n\nRequests is an elegant and simple HTTP library for python, built for human beings.\n\n## Beloved Features\n\n* Keep-Alive & Connection Pooling\n* International Domains and URLs\n* Session with Cookie Persistence\n* Browser-style SSL Verification\n* Automatic Content Decoding\n* Basic/Digest Authentication\n* Elegant Key/Value Cookie\n* Automatic Decompression\n* Unicode Response Bodies\n* HTTP(S) Proxy Support\n* Multipart File Uploads\n* Streaming Downloads\n* Connection Timeouts\n* Chunked Requests\n* `.netrc` Support\n\n## 快速上手\n\n### 发送请求\n\n```python\nimport requests\nr = requests.get(url)\n```\n`r`为Response对象，requests的方法还有`put, delete, head, options`\n\n### 传递URL参数\n\n如url为`http://httpbin.org/get?key2=value2&key1=value1`\n```python\npayload = {'key1':'value1', 'key2':'value2'}\nr = requests.get(\"http://httpbin.org/get\", params=payload)\n```\n\n### 响应内容\n\n`r.text` 响应文本\n`r.encoding` 编码格式\n\n### 二进制响应内容\n\n`r.content` 以字节的方式访问响应体\n\n```python\nfrom PIL import Image\nfrom io import BytesIO\ni = Image.open(BytesIO(r.content))\n```\n\n### JSON响应内容\n\n`r.josn()`\n\n### 原始响应内容\n\n```python\nr = requests.get(url, stream=True)\nr.raw\nr.raw.read(10)\n\nwith open(filename, 'wb') as fd:\n    for chunk in r.iter_content(chunk_size):\n        fd.write(chunk)\n```\n\n### 定制请求头\n\n`headers = {'user-agent': 'my_-app/0.0.1'}`\n`r = requests.get(url, headers=headers)`\n\n### 更复杂的POST请求\n\n```python\npayload = {'key1':'value1', 'key2':'value2'}\nr = requests.post(\"http://httpbin.org/get\", data=payload)\n\npayload = (('key1', 'value1'), ('key2', 'value2'))\nr = requests.post(\"http://httpbin.org/get\", data=payload)\n\nr = requests.post(url, json=payload)\n```\n\n### POST一个多部分编码的文件\n\n```python\nfiles = {'file': open('report.xls', 'rb')}\nr = requests.post(url, files=files)\n\n# 你还可以显式地设置文件名，文件类型和请求头\nfiles = {'file': ('report.xls', open('report.xls', 'rb'), 'application/vnd.ms-excel', {'Expires': '0'})}\n```\n\n### 响应状态码\n\n`r.status_code` 检查响应状态码\n`r.status_code == requests.codes.ok` 内置的状态码查询对象\n`r.raise_for_status()` 抛出异常\n\n### 响应头\n\n`r.headers`\n```json\n{\n    'content-encoding': 'gzip',\n    'transfer-encoding': 'chunked',\n    'connection': 'close',\n    'server': 'nginx/1.0.4',\n    'x-runtime': '148ms',\n    'etag': '\"e1ca502697e5c9317743dc078f67693f\"',\n    'content-type': 'application/json'\n}\n```\n\n### Cookie\n\n`r.cookies`\n```python\ncookies = dict(cookies_are='working')\nr = requests.get(url, cookies=cookies)\n```\n\nCookie 的返回对象为 RequestsCookieJar，它的行为和字典类似，但接口更为完整，适合跨域名跨路径使用。你还可以把 Cookie Jar 传到 Requests 中：\n\n```python\njar = requests.cookies.RequestsCookieJar()\njar.set('tasty_cookie', 'yum', domain='httpbin.org', path='/cookies')\nr = requests.get(url, cookies=jar)\n```\n\n### 重定向和请求历史\n\nResponse.history 是一个 Response 对象的列表，为了完成请求而创建了这些对象。这个对象列表按照从最老到最近的请求进行排序。\n\n```python\nr = requests.get(url, allow_redirects=False)\nr.history\n```\n\n### 超时\n\n`r = requests.get(url, timeouts=0.01)`\n\n### 错误与异常\n\n遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出一个 ConnectionError 异常\n\n如果 HTTP 请求返回了不成功的状态码， Response.raise_for_status() 会抛出一个 HTTPError 异常\n\n若请求超时，则抛出一个 Timeout 异常。\n\n若请求超过了设定的最大重定向次数，则会抛出一个 TooManyRedirects 异常。\n\n所有Requests显式抛出的异常都继承自 requests.exceptions.RequestException 。\n","slug":"requests","published":1,"updated":"2018-09-28T06:50:38.143Z","_id":"cjmk9ds3r001lpcvot6j5sa83","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Requests\"><a href=\"#Requests\" class=\"headerlink\" title=\"Requests\"></a><a href=\"cn.python-requests.org\">Requests</a></h2><p>Requests is an elegant and simple HTTP library for python, built for human beings.</p>\n<h2 id=\"Beloved-Features\"><a href=\"#Beloved-Features\" class=\"headerlink\" title=\"Beloved Features\"></a>Beloved Features</h2><ul>\n<li>Keep-Alive &amp; Connection Pooling</li>\n<li>International Domains and URLs</li>\n<li>Session with Cookie Persistence</li>\n<li>Browser-style SSL Verification</li>\n<li>Automatic Content Decoding</li>\n<li>Basic/Digest Authentication</li>\n<li>Elegant Key/Value Cookie</li>\n<li>Automatic Decompression</li>\n<li>Unicode Response Bodies</li>\n<li>HTTP(S) Proxy Support</li>\n<li>Multipart File Uploads</li>\n<li>Streaming Downloads</li>\n<li>Connection Timeouts</li>\n<li>Chunked Requests</li>\n<li><code>.netrc</code> Support</li>\n</ul>\n<h2 id=\"快速上手\"><a href=\"#快速上手\" class=\"headerlink\" title=\"快速上手\"></a>快速上手</h2><h3 id=\"发送请求\"><a href=\"#发送请求\" class=\"headerlink\" title=\"发送请求\"></a>发送请求</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> requests</span><br><span class=\"line\">r = requests.get(url)</span><br></pre></td></tr></table></figure>\n<p><code>r</code>为Response对象，requests的方法还有<code>put, delete, head, options</code></p>\n<h3 id=\"传递URL参数\"><a href=\"#传递URL参数\" class=\"headerlink\" title=\"传递URL参数\"></a>传递URL参数</h3><p>如url为<code>http://httpbin.org/get?key2=value2&amp;key1=value1</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">payload = &#123;<span class=\"string\">'key1'</span>:<span class=\"string\">'value1'</span>, <span class=\"string\">'key2'</span>:<span class=\"string\">'value2'</span>&#125;</span><br><span class=\"line\">r = requests.get(<span class=\"string\">\"http://httpbin.org/get\"</span>, params=payload)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"响应内容\"><a href=\"#响应内容\" class=\"headerlink\" title=\"响应内容\"></a>响应内容</h3><p><code>r.text</code> 响应文本<br><code>r.encoding</code> 编码格式</p>\n<h3 id=\"二进制响应内容\"><a href=\"#二进制响应内容\" class=\"headerlink\" title=\"二进制响应内容\"></a>二进制响应内容</h3><p><code>r.content</code> 以字节的方式访问响应体</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">from</span> io <span class=\"keyword\">import</span> BytesIO</span><br><span class=\"line\">i = Image.open(BytesIO(r.content))</span><br></pre></td></tr></table></figure>\n<h3 id=\"JSON响应内容\"><a href=\"#JSON响应内容\" class=\"headerlink\" title=\"JSON响应内容\"></a>JSON响应内容</h3><p><code>r.josn()</code></p>\n<h3 id=\"原始响应内容\"><a href=\"#原始响应内容\" class=\"headerlink\" title=\"原始响应内容\"></a>原始响应内容</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r = requests.get(url, stream=<span class=\"keyword\">True</span>)</span><br><span class=\"line\">r.raw</span><br><span class=\"line\">r.raw.read(<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> open(filename, <span class=\"string\">'wb'</span>) <span class=\"keyword\">as</span> fd:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> chunk <span class=\"keyword\">in</span> r.iter_content(chunk_size):</span><br><span class=\"line\">        fd.write(chunk)</span><br></pre></td></tr></table></figure>\n<h3 id=\"定制请求头\"><a href=\"#定制请求头\" class=\"headerlink\" title=\"定制请求头\"></a>定制请求头</h3><p><code>headers = {&#39;user-agent&#39;: &#39;my_-app/0.0.1&#39;}</code><br><code>r = requests.get(url, headers=headers)</code></p>\n<h3 id=\"更复杂的POST请求\"><a href=\"#更复杂的POST请求\" class=\"headerlink\" title=\"更复杂的POST请求\"></a>更复杂的POST请求</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">payload = &#123;<span class=\"string\">'key1'</span>:<span class=\"string\">'value1'</span>, <span class=\"string\">'key2'</span>:<span class=\"string\">'value2'</span>&#125;</span><br><span class=\"line\">r = requests.post(<span class=\"string\">\"http://httpbin.org/get\"</span>, data=payload)</span><br><span class=\"line\"></span><br><span class=\"line\">payload = ((<span class=\"string\">'key1'</span>, <span class=\"string\">'value1'</span>), (<span class=\"string\">'key2'</span>, <span class=\"string\">'value2'</span>))</span><br><span class=\"line\">r = requests.post(<span class=\"string\">\"http://httpbin.org/get\"</span>, data=payload)</span><br><span class=\"line\"></span><br><span class=\"line\">r = requests.post(url, json=payload)</span><br></pre></td></tr></table></figure>\n<h3 id=\"POST一个多部分编码的文件\"><a href=\"#POST一个多部分编码的文件\" class=\"headerlink\" title=\"POST一个多部分编码的文件\"></a>POST一个多部分编码的文件</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">files = &#123;<span class=\"string\">'file'</span>: open(<span class=\"string\">'report.xls'</span>, <span class=\"string\">'rb'</span>)&#125;</span><br><span class=\"line\">r = requests.post(url, files=files)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 你还可以显式地设置文件名，文件类型和请求头</span></span><br><span class=\"line\">files = &#123;<span class=\"string\">'file'</span>: (<span class=\"string\">'report.xls'</span>, open(<span class=\"string\">'report.xls'</span>, <span class=\"string\">'rb'</span>), <span class=\"string\">'application/vnd.ms-excel'</span>, &#123;<span class=\"string\">'Expires'</span>: <span class=\"string\">'0'</span>&#125;)&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"响应状态码\"><a href=\"#响应状态码\" class=\"headerlink\" title=\"响应状态码\"></a>响应状态码</h3><p><code>r.status_code</code> 检查响应状态码<br><code>r.status_code == requests.codes.ok</code> 内置的状态码查询对象<br><code>r.raise_for_status()</code> 抛出异常</p>\n<h3 id=\"响应头\"><a href=\"#响应头\" class=\"headerlink\" title=\"响应头\"></a>响应头</h3><p><code>r.headers</code><br><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    'content-encoding': 'gzip',</span><br><span class=\"line\">    'transfer-encoding': 'chunked',</span><br><span class=\"line\">    'connection': 'close',</span><br><span class=\"line\">    'server': 'nginx/1.0.4',</span><br><span class=\"line\">    'x-runtime': '148ms',</span><br><span class=\"line\">    'etag': '\"e1ca502697e5c9317743dc078f67693f\"',</span><br><span class=\"line\">    'content-type': 'application/json'</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Cookie\"><a href=\"#Cookie\" class=\"headerlink\" title=\"Cookie\"></a>Cookie</h3><p><code>r.cookies</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cookies = dict(cookies_are=<span class=\"string\">'working'</span>)</span><br><span class=\"line\">r = requests.get(url, cookies=cookies)</span><br></pre></td></tr></table></figure></p>\n<p>Cookie 的返回对象为 RequestsCookieJar，它的行为和字典类似，但接口更为完整，适合跨域名跨路径使用。你还可以把 Cookie Jar 传到 Requests 中：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jar = requests.cookies.RequestsCookieJar()</span><br><span class=\"line\">jar.set(<span class=\"string\">'tasty_cookie'</span>, <span class=\"string\">'yum'</span>, domain=<span class=\"string\">'httpbin.org'</span>, path=<span class=\"string\">'/cookies'</span>)</span><br><span class=\"line\">r = requests.get(url, cookies=jar)</span><br></pre></td></tr></table></figure>\n<h3 id=\"重定向和请求历史\"><a href=\"#重定向和请求历史\" class=\"headerlink\" title=\"重定向和请求历史\"></a>重定向和请求历史</h3><p>Response.history 是一个 Response 对象的列表，为了完成请求而创建了这些对象。这个对象列表按照从最老到最近的请求进行排序。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r = requests.get(url, allow_redirects=<span class=\"keyword\">False</span>)</span><br><span class=\"line\">r.history</span><br></pre></td></tr></table></figure>\n<h3 id=\"超时\"><a href=\"#超时\" class=\"headerlink\" title=\"超时\"></a>超时</h3><p><code>r = requests.get(url, timeouts=0.01)</code></p>\n<h3 id=\"错误与异常\"><a href=\"#错误与异常\" class=\"headerlink\" title=\"错误与异常\"></a>错误与异常</h3><p>遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出一个 ConnectionError 异常</p>\n<p>如果 HTTP 请求返回了不成功的状态码， Response.raise_for_status() 会抛出一个 HTTPError 异常</p>\n<p>若请求超时，则抛出一个 Timeout 异常。</p>\n<p>若请求超过了设定的最大重定向次数，则会抛出一个 TooManyRedirects 异常。</p>\n<p>所有Requests显式抛出的异常都继承自 requests.exceptions.RequestException 。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Requests\"><a href=\"#Requests\" class=\"headerlink\" title=\"Requests\"></a><a href=\"cn.python-requests.org\">Requests</a></h2><p>Requests is an elegant and simple HTTP library for python, built for human beings.</p>\n<h2 id=\"Beloved-Features\"><a href=\"#Beloved-Features\" class=\"headerlink\" title=\"Beloved Features\"></a>Beloved Features</h2><ul>\n<li>Keep-Alive &amp; Connection Pooling</li>\n<li>International Domains and URLs</li>\n<li>Session with Cookie Persistence</li>\n<li>Browser-style SSL Verification</li>\n<li>Automatic Content Decoding</li>\n<li>Basic/Digest Authentication</li>\n<li>Elegant Key/Value Cookie</li>\n<li>Automatic Decompression</li>\n<li>Unicode Response Bodies</li>\n<li>HTTP(S) Proxy Support</li>\n<li>Multipart File Uploads</li>\n<li>Streaming Downloads</li>\n<li>Connection Timeouts</li>\n<li>Chunked Requests</li>\n<li><code>.netrc</code> Support</li>\n</ul>\n<h2 id=\"快速上手\"><a href=\"#快速上手\" class=\"headerlink\" title=\"快速上手\"></a>快速上手</h2><h3 id=\"发送请求\"><a href=\"#发送请求\" class=\"headerlink\" title=\"发送请求\"></a>发送请求</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> requests</span><br><span class=\"line\">r = requests.get(url)</span><br></pre></td></tr></table></figure>\n<p><code>r</code>为Response对象，requests的方法还有<code>put, delete, head, options</code></p>\n<h3 id=\"传递URL参数\"><a href=\"#传递URL参数\" class=\"headerlink\" title=\"传递URL参数\"></a>传递URL参数</h3><p>如url为<code>http://httpbin.org/get?key2=value2&amp;key1=value1</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">payload = &#123;<span class=\"string\">'key1'</span>:<span class=\"string\">'value1'</span>, <span class=\"string\">'key2'</span>:<span class=\"string\">'value2'</span>&#125;</span><br><span class=\"line\">r = requests.get(<span class=\"string\">\"http://httpbin.org/get\"</span>, params=payload)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"响应内容\"><a href=\"#响应内容\" class=\"headerlink\" title=\"响应内容\"></a>响应内容</h3><p><code>r.text</code> 响应文本<br><code>r.encoding</code> 编码格式</p>\n<h3 id=\"二进制响应内容\"><a href=\"#二进制响应内容\" class=\"headerlink\" title=\"二进制响应内容\"></a>二进制响应内容</h3><p><code>r.content</code> 以字节的方式访问响应体</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">from</span> io <span class=\"keyword\">import</span> BytesIO</span><br><span class=\"line\">i = Image.open(BytesIO(r.content))</span><br></pre></td></tr></table></figure>\n<h3 id=\"JSON响应内容\"><a href=\"#JSON响应内容\" class=\"headerlink\" title=\"JSON响应内容\"></a>JSON响应内容</h3><p><code>r.josn()</code></p>\n<h3 id=\"原始响应内容\"><a href=\"#原始响应内容\" class=\"headerlink\" title=\"原始响应内容\"></a>原始响应内容</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r = requests.get(url, stream=<span class=\"keyword\">True</span>)</span><br><span class=\"line\">r.raw</span><br><span class=\"line\">r.raw.read(<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> open(filename, <span class=\"string\">'wb'</span>) <span class=\"keyword\">as</span> fd:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> chunk <span class=\"keyword\">in</span> r.iter_content(chunk_size):</span><br><span class=\"line\">        fd.write(chunk)</span><br></pre></td></tr></table></figure>\n<h3 id=\"定制请求头\"><a href=\"#定制请求头\" class=\"headerlink\" title=\"定制请求头\"></a>定制请求头</h3><p><code>headers = {&#39;user-agent&#39;: &#39;my_-app/0.0.1&#39;}</code><br><code>r = requests.get(url, headers=headers)</code></p>\n<h3 id=\"更复杂的POST请求\"><a href=\"#更复杂的POST请求\" class=\"headerlink\" title=\"更复杂的POST请求\"></a>更复杂的POST请求</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">payload = &#123;<span class=\"string\">'key1'</span>:<span class=\"string\">'value1'</span>, <span class=\"string\">'key2'</span>:<span class=\"string\">'value2'</span>&#125;</span><br><span class=\"line\">r = requests.post(<span class=\"string\">\"http://httpbin.org/get\"</span>, data=payload)</span><br><span class=\"line\"></span><br><span class=\"line\">payload = ((<span class=\"string\">'key1'</span>, <span class=\"string\">'value1'</span>), (<span class=\"string\">'key2'</span>, <span class=\"string\">'value2'</span>))</span><br><span class=\"line\">r = requests.post(<span class=\"string\">\"http://httpbin.org/get\"</span>, data=payload)</span><br><span class=\"line\"></span><br><span class=\"line\">r = requests.post(url, json=payload)</span><br></pre></td></tr></table></figure>\n<h3 id=\"POST一个多部分编码的文件\"><a href=\"#POST一个多部分编码的文件\" class=\"headerlink\" title=\"POST一个多部分编码的文件\"></a>POST一个多部分编码的文件</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">files = &#123;<span class=\"string\">'file'</span>: open(<span class=\"string\">'report.xls'</span>, <span class=\"string\">'rb'</span>)&#125;</span><br><span class=\"line\">r = requests.post(url, files=files)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 你还可以显式地设置文件名，文件类型和请求头</span></span><br><span class=\"line\">files = &#123;<span class=\"string\">'file'</span>: (<span class=\"string\">'report.xls'</span>, open(<span class=\"string\">'report.xls'</span>, <span class=\"string\">'rb'</span>), <span class=\"string\">'application/vnd.ms-excel'</span>, &#123;<span class=\"string\">'Expires'</span>: <span class=\"string\">'0'</span>&#125;)&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"响应状态码\"><a href=\"#响应状态码\" class=\"headerlink\" title=\"响应状态码\"></a>响应状态码</h3><p><code>r.status_code</code> 检查响应状态码<br><code>r.status_code == requests.codes.ok</code> 内置的状态码查询对象<br><code>r.raise_for_status()</code> 抛出异常</p>\n<h3 id=\"响应头\"><a href=\"#响应头\" class=\"headerlink\" title=\"响应头\"></a>响应头</h3><p><code>r.headers</code><br><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    'content-encoding': 'gzip',</span><br><span class=\"line\">    'transfer-encoding': 'chunked',</span><br><span class=\"line\">    'connection': 'close',</span><br><span class=\"line\">    'server': 'nginx/1.0.4',</span><br><span class=\"line\">    'x-runtime': '148ms',</span><br><span class=\"line\">    'etag': '\"e1ca502697e5c9317743dc078f67693f\"',</span><br><span class=\"line\">    'content-type': 'application/json'</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Cookie\"><a href=\"#Cookie\" class=\"headerlink\" title=\"Cookie\"></a>Cookie</h3><p><code>r.cookies</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cookies = dict(cookies_are=<span class=\"string\">'working'</span>)</span><br><span class=\"line\">r = requests.get(url, cookies=cookies)</span><br></pre></td></tr></table></figure></p>\n<p>Cookie 的返回对象为 RequestsCookieJar，它的行为和字典类似，但接口更为完整，适合跨域名跨路径使用。你还可以把 Cookie Jar 传到 Requests 中：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jar = requests.cookies.RequestsCookieJar()</span><br><span class=\"line\">jar.set(<span class=\"string\">'tasty_cookie'</span>, <span class=\"string\">'yum'</span>, domain=<span class=\"string\">'httpbin.org'</span>, path=<span class=\"string\">'/cookies'</span>)</span><br><span class=\"line\">r = requests.get(url, cookies=jar)</span><br></pre></td></tr></table></figure>\n<h3 id=\"重定向和请求历史\"><a href=\"#重定向和请求历史\" class=\"headerlink\" title=\"重定向和请求历史\"></a>重定向和请求历史</h3><p>Response.history 是一个 Response 对象的列表，为了完成请求而创建了这些对象。这个对象列表按照从最老到最近的请求进行排序。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r = requests.get(url, allow_redirects=<span class=\"keyword\">False</span>)</span><br><span class=\"line\">r.history</span><br></pre></td></tr></table></figure>\n<h3 id=\"超时\"><a href=\"#超时\" class=\"headerlink\" title=\"超时\"></a>超时</h3><p><code>r = requests.get(url, timeouts=0.01)</code></p>\n<h3 id=\"错误与异常\"><a href=\"#错误与异常\" class=\"headerlink\" title=\"错误与异常\"></a>错误与异常</h3><p>遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出一个 ConnectionError 异常</p>\n<p>如果 HTTP 请求返回了不成功的状态码， Response.raise_for_status() 会抛出一个 HTTPError 异常</p>\n<p>若请求超时，则抛出一个 Timeout 异常。</p>\n<p>若请求超过了设定的最大重定向次数，则会抛出一个 TooManyRedirects 异常。</p>\n<p>所有Requests显式抛出的异常都继承自 requests.exceptions.RequestException 。</p>\n"},{"title":"tensorflow graphs","date":"2018-09-05T09:03:01.000Z","_content":"TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.\n\n### Dataflow\n![](https://tensorflow.google.cn/images/tensors_flowing.gif)\n\nDataflow is a common programming model for parallel computing. In a dataflow graph, the nodes represent units of computation, and the edges represent the data consumed or produced by a computation\n\nDataflow has several advantages that TensorFlow leverages when executing your programs:\n\n * **Parallelism**. By using explicit edges to represent dependencies between operations, it is easy for the system to identify operations that can execute in parallel.\n\n * **Distributed execution**. By using explicit edges to represent the values that flow between operations, it is possible for TensorFlow to partition your program across multiple devices (CPUs, GPUs, and TPUs) attached to different machines. TensorFlow inserts the necessary communication and coordination between devices.\n\n * **Compilation**. TensorFlow's XLA compiler can use the information in your dataflow graph to generate faster code, for example, by fusing together adjacent operations.\n\n * **Portability**. The dataflow graph is a language-independent representation of the code in your model. You can build a dataflow graph in Python, store it in a SavedModel, and restore it in a C++ program for low-latency inference.\n\n### What is a tf.Graph?\n\n A tf.Graph contains two relevant kinds of information:\n\n  * **Graph structure**. The nodes and edges of the graph, indicating how individual operations are composed together, but not prescribing how they should be used. The graph structure is like assembly code: inspecting it can convey some useful information, but it does not contain all of the useful context that source code conveys.\n\n  * **Graph collections**. TensorFlow provides a general mechanism for storing collections of metadata in a tf.Graph. The **tf.add_to_collection** function enables you to associate a list of objects with a key (where **tf.GraphKeys** defines some of the standard keys), and **tf.get_collection** enables you to look up all objects associated with a key. Many parts of the TensorFlow library use this facility: for example, when you create a tf.Variable, it is added by default to collections representing \"global variables\" and \"trainable variables\". When you later come to create a tf.train.Saver or tf.train.Optimizer, the variables in these collections are used as the default arguments.\n\n### Building a tf.Graph\n\n  Most TensorFlow programs start with a dataflow graph construction phase. In this phase, you invoke TensorFlow API functions that construct new **tf.Operation (node)** and **tf.Tensor (edge)** objects and add them to a **tf.Graph instance**. TensorFlow provides a default graph that is an implicit argument to all API functions in the same context.\n\n### Naming operations\n A tf.Graph object defines a namespace for the tf.Operation objects it contains. TensorFlow automatically chooses a unique name for each operation in your graph, but giving operations descriptive names can make your program easier to read and debug. The TensorFlow API provides two ways to override the name of an operation:\n\n * Each API function that creates a new tf.Operation or returns a new tf.Tensor accepts an optional name argument. For example, tf.constant(42.0, name=\"answer\") creates a new tf.Operation named \"answer\" and returns a tf.Tensor named \"answer:0\". If the default graph already contains an operation named \"answer\", then TensorFlow would append \"\\_1\", \"\\_2\", and so on to the name, in order to make it unique.\n\n * The **tf.name_scope** function makes it possible to add a name scope prefix to all operations created in a particular context. The current name scope prefix is a \"/\"-delimited list of the names of all active tf.name_scope context managers. If a name scope has already been used in the current context, TensorFlow appends \"\\_1\", \"\\_2\", and so on. For example:\n\n```python\n c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n # Already-used names will be \"uniquified\".\n c_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n # Name scopes add a prefix to all operations created in the same context.\n with tf.name_scope(\"outer\"):\n     c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n     # Name scopes nest like paths in a hierarchical file system.\n     with tf.name_scope(\"inner\"):\n         c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n     # Already-used name scopes will be \"uniquified\".\n     with tf.name_scope(\"inner\"):\n         c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\"\n```\n\n### Placing operations on different devices\n\nIf you want your TensorFlow program to use multiple different devices, the tf.device function provides a convenient way to request that all operations created in a particular context are placed on the same device (or type of device).\n\nA device specification has the following form:\n\n    /job:<JOB_NAME>/task:<TASK_INDEX>/device:<DEVICE_TYPE>:<DEVICE_INDEX>\n    where:\n        <JOB_NAME> is an alpha-numeric string that does not start with a number.\n        <DEVICE_TYPE> is a registered device type (such as GPU or CPU).\n        <TASK_INDEX> is a non-negative integer representing the index of the task in the job named <JOB_NAME>. See tf.train.ClusterSpec for an explanation of jobs and tasks.\n        <DEVICE_INDEX> is a non-negative integer representing the index of the device, for example, to distinguish between different GPU devices used in the same process.\n\n```python\n# Operations created outside either context will run on the \"best possible\"\n# device. For example, if you have a GPU and a CPU available, and the operation\n# has a GPU implementation, TensorFlow will choose the GPU.\nweights = tf.random_normal(...)\n\nwith tf.device(\"/device:CPU:0\"):\n  # Operations created in this context will be pinned to the CPU.\n  img = tf.decode_jpeg(tf.read_file(\"img.jpg\"))\n\nwith tf.device(\"/device:GPU:0\"):\n  # Operations created in this context will be pinned to the GPU.\n  result = tf.matmul(weights, img)\n```\n\n### Visualizing your graph\nTensorFlow includes tools that can help you to understand the code in a graph. The graph visualizer is a component of TensorBoard that renders the structure of your graph visually in a browser. The easiest way to create a visualization is to pass a tf.Graph when creating the **tf.summary.FileWriter**:\n\n```python\n# Build your graph.\nx = tf.constant([[37.0, -23.0], [1.0, 4.0]])\nw = tf.Variable(tf.random_uniform([2, 2]))\ny = tf.matmul(x, w)\n# ...\nloss = ...\ntrain_op = tf.train.AdagradOptimizer(0.01).minimize(loss)\n\nwith tf.Session() as sess:\n  writer = tf.summary.FileWriter(\"/tmp/log/...\", sess.graph)\n  # Perform your computation...\n  for i in range(1000):\n    sess.run(train_op)\n    # ...\n  writer.close()\n```\n\n### Programming with multiple graphs\n\nYou can install a different tf.Graph as the default graph, using the tf.Graph.as_default context manager:\n```python\ng_1 = tf.Graph()\nwith g_1.as_default():\n  # Operations created in this scope will be added to `g_1`.\n  c = tf.constant(\"Node in g_1\")\n  # Sessions created in this scope will run operations from `g_1`.\n  sess_1 = tf.Session()\n\ng_2 = tf.Graph()\nwith g_2.as_default():\n  # Operations created in this scope will be added to `g_2`.\n  d = tf.constant(\"Node in g_2\")\n\n# `sess_2` will run operations from `g_2`.\nsess_2 = tf.Session(graph=g_2)\n\nassert c.graph is g_1\nassert sess_1.graph is g_1\n\nassert d.graph is g_2\nassert sess_2.graph is g_2\n```\n\nTo inspect the current default graph, call tf.get_default_graph, which returns a tf.Graph object:\n```python\n# Print all of the operations in the default graph.\ng = tf.get_default_graph()\nprint(g.get_operations())\n```\n","source":"_posts/tensorflow-graphs.md","raw":"---\ntitle: tensorflow graphs\ndate: 2018-09-05 17:03:01\ntags: tensorflow_python_API\ncategories: Tensorflow\n---\nTensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.\n\n### Dataflow\n![](https://tensorflow.google.cn/images/tensors_flowing.gif)\n\nDataflow is a common programming model for parallel computing. In a dataflow graph, the nodes represent units of computation, and the edges represent the data consumed or produced by a computation\n\nDataflow has several advantages that TensorFlow leverages when executing your programs:\n\n * **Parallelism**. By using explicit edges to represent dependencies between operations, it is easy for the system to identify operations that can execute in parallel.\n\n * **Distributed execution**. By using explicit edges to represent the values that flow between operations, it is possible for TensorFlow to partition your program across multiple devices (CPUs, GPUs, and TPUs) attached to different machines. TensorFlow inserts the necessary communication and coordination between devices.\n\n * **Compilation**. TensorFlow's XLA compiler can use the information in your dataflow graph to generate faster code, for example, by fusing together adjacent operations.\n\n * **Portability**. The dataflow graph is a language-independent representation of the code in your model. You can build a dataflow graph in Python, store it in a SavedModel, and restore it in a C++ program for low-latency inference.\n\n### What is a tf.Graph?\n\n A tf.Graph contains two relevant kinds of information:\n\n  * **Graph structure**. The nodes and edges of the graph, indicating how individual operations are composed together, but not prescribing how they should be used. The graph structure is like assembly code: inspecting it can convey some useful information, but it does not contain all of the useful context that source code conveys.\n\n  * **Graph collections**. TensorFlow provides a general mechanism for storing collections of metadata in a tf.Graph. The **tf.add_to_collection** function enables you to associate a list of objects with a key (where **tf.GraphKeys** defines some of the standard keys), and **tf.get_collection** enables you to look up all objects associated with a key. Many parts of the TensorFlow library use this facility: for example, when you create a tf.Variable, it is added by default to collections representing \"global variables\" and \"trainable variables\". When you later come to create a tf.train.Saver or tf.train.Optimizer, the variables in these collections are used as the default arguments.\n\n### Building a tf.Graph\n\n  Most TensorFlow programs start with a dataflow graph construction phase. In this phase, you invoke TensorFlow API functions that construct new **tf.Operation (node)** and **tf.Tensor (edge)** objects and add them to a **tf.Graph instance**. TensorFlow provides a default graph that is an implicit argument to all API functions in the same context.\n\n### Naming operations\n A tf.Graph object defines a namespace for the tf.Operation objects it contains. TensorFlow automatically chooses a unique name for each operation in your graph, but giving operations descriptive names can make your program easier to read and debug. The TensorFlow API provides two ways to override the name of an operation:\n\n * Each API function that creates a new tf.Operation or returns a new tf.Tensor accepts an optional name argument. For example, tf.constant(42.0, name=\"answer\") creates a new tf.Operation named \"answer\" and returns a tf.Tensor named \"answer:0\". If the default graph already contains an operation named \"answer\", then TensorFlow would append \"\\_1\", \"\\_2\", and so on to the name, in order to make it unique.\n\n * The **tf.name_scope** function makes it possible to add a name scope prefix to all operations created in a particular context. The current name scope prefix is a \"/\"-delimited list of the names of all active tf.name_scope context managers. If a name scope has already been used in the current context, TensorFlow appends \"\\_1\", \"\\_2\", and so on. For example:\n\n```python\n c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n # Already-used names will be \"uniquified\".\n c_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n # Name scopes add a prefix to all operations created in the same context.\n with tf.name_scope(\"outer\"):\n     c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n     # Name scopes nest like paths in a hierarchical file system.\n     with tf.name_scope(\"inner\"):\n         c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n     # Already-used name scopes will be \"uniquified\".\n     with tf.name_scope(\"inner\"):\n         c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\"\n```\n\n### Placing operations on different devices\n\nIf you want your TensorFlow program to use multiple different devices, the tf.device function provides a convenient way to request that all operations created in a particular context are placed on the same device (or type of device).\n\nA device specification has the following form:\n\n    /job:<JOB_NAME>/task:<TASK_INDEX>/device:<DEVICE_TYPE>:<DEVICE_INDEX>\n    where:\n        <JOB_NAME> is an alpha-numeric string that does not start with a number.\n        <DEVICE_TYPE> is a registered device type (such as GPU or CPU).\n        <TASK_INDEX> is a non-negative integer representing the index of the task in the job named <JOB_NAME>. See tf.train.ClusterSpec for an explanation of jobs and tasks.\n        <DEVICE_INDEX> is a non-negative integer representing the index of the device, for example, to distinguish between different GPU devices used in the same process.\n\n```python\n# Operations created outside either context will run on the \"best possible\"\n# device. For example, if you have a GPU and a CPU available, and the operation\n# has a GPU implementation, TensorFlow will choose the GPU.\nweights = tf.random_normal(...)\n\nwith tf.device(\"/device:CPU:0\"):\n  # Operations created in this context will be pinned to the CPU.\n  img = tf.decode_jpeg(tf.read_file(\"img.jpg\"))\n\nwith tf.device(\"/device:GPU:0\"):\n  # Operations created in this context will be pinned to the GPU.\n  result = tf.matmul(weights, img)\n```\n\n### Visualizing your graph\nTensorFlow includes tools that can help you to understand the code in a graph. The graph visualizer is a component of TensorBoard that renders the structure of your graph visually in a browser. The easiest way to create a visualization is to pass a tf.Graph when creating the **tf.summary.FileWriter**:\n\n```python\n# Build your graph.\nx = tf.constant([[37.0, -23.0], [1.0, 4.0]])\nw = tf.Variable(tf.random_uniform([2, 2]))\ny = tf.matmul(x, w)\n# ...\nloss = ...\ntrain_op = tf.train.AdagradOptimizer(0.01).minimize(loss)\n\nwith tf.Session() as sess:\n  writer = tf.summary.FileWriter(\"/tmp/log/...\", sess.graph)\n  # Perform your computation...\n  for i in range(1000):\n    sess.run(train_op)\n    # ...\n  writer.close()\n```\n\n### Programming with multiple graphs\n\nYou can install a different tf.Graph as the default graph, using the tf.Graph.as_default context manager:\n```python\ng_1 = tf.Graph()\nwith g_1.as_default():\n  # Operations created in this scope will be added to `g_1`.\n  c = tf.constant(\"Node in g_1\")\n  # Sessions created in this scope will run operations from `g_1`.\n  sess_1 = tf.Session()\n\ng_2 = tf.Graph()\nwith g_2.as_default():\n  # Operations created in this scope will be added to `g_2`.\n  d = tf.constant(\"Node in g_2\")\n\n# `sess_2` will run operations from `g_2`.\nsess_2 = tf.Session(graph=g_2)\n\nassert c.graph is g_1\nassert sess_1.graph is g_1\n\nassert d.graph is g_2\nassert sess_2.graph is g_2\n```\n\nTo inspect the current default graph, call tf.get_default_graph, which returns a tf.Graph object:\n```python\n# Print all of the operations in the default graph.\ng = tf.get_default_graph()\nprint(g.get_operations())\n```\n","slug":"tensorflow-graphs","published":1,"updated":"2018-09-05T09:58:38.618Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds3r001qpcvoq1xl4c9h","content":"<p>TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.</p>\n<h3 id=\"Dataflow\"><a href=\"#Dataflow\" class=\"headerlink\" title=\"Dataflow\"></a>Dataflow</h3><p><img src=\"https://tensorflow.google.cn/images/tensors_flowing.gif\" alt=\"\"></p>\n<p>Dataflow is a common programming model for parallel computing. In a dataflow graph, the nodes represent units of computation, and the edges represent the data consumed or produced by a computation</p>\n<p>Dataflow has several advantages that TensorFlow leverages when executing your programs:</p>\n<ul>\n<li><p><strong>Parallelism</strong>. By using explicit edges to represent dependencies between operations, it is easy for the system to identify operations that can execute in parallel.</p>\n</li>\n<li><p><strong>Distributed execution</strong>. By using explicit edges to represent the values that flow between operations, it is possible for TensorFlow to partition your program across multiple devices (CPUs, GPUs, and TPUs) attached to different machines. TensorFlow inserts the necessary communication and coordination between devices.</p>\n</li>\n<li><p><strong>Compilation</strong>. TensorFlow’s XLA compiler can use the information in your dataflow graph to generate faster code, for example, by fusing together adjacent operations.</p>\n</li>\n<li><p><strong>Portability</strong>. The dataflow graph is a language-independent representation of the code in your model. You can build a dataflow graph in Python, store it in a SavedModel, and restore it in a C++ program for low-latency inference.</p>\n</li>\n</ul>\n<h3 id=\"What-is-a-tf-Graph\"><a href=\"#What-is-a-tf-Graph\" class=\"headerlink\" title=\"What is a tf.Graph?\"></a>What is a tf.Graph?</h3><p> A tf.Graph contains two relevant kinds of information:</p>\n<ul>\n<li><p><strong>Graph structure</strong>. The nodes and edges of the graph, indicating how individual operations are composed together, but not prescribing how they should be used. The graph structure is like assembly code: inspecting it can convey some useful information, but it does not contain all of the useful context that source code conveys.</p>\n</li>\n<li><p><strong>Graph collections</strong>. TensorFlow provides a general mechanism for storing collections of metadata in a tf.Graph. The <strong>tf.add_to_collection</strong> function enables you to associate a list of objects with a key (where <strong>tf.GraphKeys</strong> defines some of the standard keys), and <strong>tf.get_collection</strong> enables you to look up all objects associated with a key. Many parts of the TensorFlow library use this facility: for example, when you create a tf.Variable, it is added by default to collections representing “global variables” and “trainable variables”. When you later come to create a tf.train.Saver or tf.train.Optimizer, the variables in these collections are used as the default arguments.</p>\n</li>\n</ul>\n<h3 id=\"Building-a-tf-Graph\"><a href=\"#Building-a-tf-Graph\" class=\"headerlink\" title=\"Building a tf.Graph\"></a>Building a tf.Graph</h3><p>  Most TensorFlow programs start with a dataflow graph construction phase. In this phase, you invoke TensorFlow API functions that construct new <strong>tf.Operation (node)</strong> and <strong>tf.Tensor (edge)</strong> objects and add them to a <strong>tf.Graph instance</strong>. TensorFlow provides a default graph that is an implicit argument to all API functions in the same context.</p>\n<h3 id=\"Naming-operations\"><a href=\"#Naming-operations\" class=\"headerlink\" title=\"Naming operations\"></a>Naming operations</h3><p> A tf.Graph object defines a namespace for the tf.Operation objects it contains. TensorFlow automatically chooses a unique name for each operation in your graph, but giving operations descriptive names can make your program easier to read and debug. The TensorFlow API provides two ways to override the name of an operation:</p>\n<ul>\n<li><p>Each API function that creates a new tf.Operation or returns a new tf.Tensor accepts an optional name argument. For example, tf.constant(42.0, name=”answer”) creates a new tf.Operation named “answer” and returns a tf.Tensor named “answer:0”. If the default graph already contains an operation named “answer”, then TensorFlow would append “_1”, “_2”, and so on to the name, in order to make it unique.</p>\n</li>\n<li><p>The <strong>tf.name_scope</strong> function makes it possible to add a name scope prefix to all operations created in a particular context. The current name scope prefix is a “/“-delimited list of the names of all active tf.name_scope context managers. If a name scope has already been used in the current context, TensorFlow appends “_1”, “_2”, and so on. For example:</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c_0 = tf.constant(<span class=\"number\">0</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"c\"</span></span><br><span class=\"line\"><span class=\"comment\"># Already-used names will be \"uniquified\".</span></span><br><span class=\"line\">c_1 = tf.constant(<span class=\"number\">2</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"c_1\"</span></span><br><span class=\"line\"><span class=\"comment\"># Name scopes add a prefix to all operations created in the same context.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"outer\"</span>):</span><br><span class=\"line\">    c_2 = tf.constant(<span class=\"number\">2</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"outer/c\"</span></span><br><span class=\"line\">    <span class=\"comment\"># Name scopes nest like paths in a hierarchical file system.</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"inner\"</span>):</span><br><span class=\"line\">        c_3 = tf.constant(<span class=\"number\">3</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"outer/inner/c\"</span></span><br><span class=\"line\">    <span class=\"comment\"># Already-used name scopes will be \"uniquified\".</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"inner\"</span>):</span><br><span class=\"line\">        c_5 = tf.constant(<span class=\"number\">5</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"outer/inner_1/c\"</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Placing-operations-on-different-devices\"><a href=\"#Placing-operations-on-different-devices\" class=\"headerlink\" title=\"Placing operations on different devices\"></a>Placing operations on different devices</h3><p>If you want your TensorFlow program to use multiple different devices, the tf.device function provides a convenient way to request that all operations created in a particular context are placed on the same device (or type of device).</p>\n<p>A device specification has the following form:</p>\n<pre><code>/job:&lt;JOB_NAME&gt;/task:&lt;TASK_INDEX&gt;/device:&lt;DEVICE_TYPE&gt;:&lt;DEVICE_INDEX&gt;\nwhere:\n    &lt;JOB_NAME&gt; is an alpha-numeric string that does not start with a number.\n    &lt;DEVICE_TYPE&gt; is a registered device type (such as GPU or CPU).\n    &lt;TASK_INDEX&gt; is a non-negative integer representing the index of the task in the job named &lt;JOB_NAME&gt;. See tf.train.ClusterSpec for an explanation of jobs and tasks.\n    &lt;DEVICE_INDEX&gt; is a non-negative integer representing the index of the device, for example, to distinguish between different GPU devices used in the same process.\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Operations created outside either context will run on the \"best possible\"</span></span><br><span class=\"line\"><span class=\"comment\"># device. For example, if you have a GPU and a CPU available, and the operation</span></span><br><span class=\"line\"><span class=\"comment\"># has a GPU implementation, TensorFlow will choose the GPU.</span></span><br><span class=\"line\">weights = tf.random_normal(...)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.device(<span class=\"string\">\"/device:CPU:0\"</span>):</span><br><span class=\"line\">  <span class=\"comment\"># Operations created in this context will be pinned to the CPU.</span></span><br><span class=\"line\">  img = tf.decode_jpeg(tf.read_file(<span class=\"string\">\"img.jpg\"</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.device(<span class=\"string\">\"/device:GPU:0\"</span>):</span><br><span class=\"line\">  <span class=\"comment\"># Operations created in this context will be pinned to the GPU.</span></span><br><span class=\"line\">  result = tf.matmul(weights, img)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Visualizing-your-graph\"><a href=\"#Visualizing-your-graph\" class=\"headerlink\" title=\"Visualizing your graph\"></a>Visualizing your graph</h3><p>TensorFlow includes tools that can help you to understand the code in a graph. The graph visualizer is a component of TensorBoard that renders the structure of your graph visually in a browser. The easiest way to create a visualization is to pass a tf.Graph when creating the <strong>tf.summary.FileWriter</strong>:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Build your graph.</span></span><br><span class=\"line\">x = tf.constant([[<span class=\"number\">37.0</span>, <span class=\"number\">-23.0</span>], [<span class=\"number\">1.0</span>, <span class=\"number\">4.0</span>]])</span><br><span class=\"line\">w = tf.Variable(tf.random_uniform([<span class=\"number\">2</span>, <span class=\"number\">2</span>]))</span><br><span class=\"line\">y = tf.matmul(x, w)</span><br><span class=\"line\"><span class=\"comment\"># ...</span></span><br><span class=\"line\">loss = ...</span><br><span class=\"line\">train_op = tf.train.AdagradOptimizer(<span class=\"number\">0.01</span>).minimize(loss)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">  writer = tf.summary.FileWriter(<span class=\"string\">\"/tmp/log/...\"</span>, sess.graph)</span><br><span class=\"line\">  <span class=\"comment\"># Perform your computation...</span></span><br><span class=\"line\">  <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>):</span><br><span class=\"line\">    sess.run(train_op)</span><br><span class=\"line\">    <span class=\"comment\"># ...</span></span><br><span class=\"line\">  writer.close()</span><br></pre></td></tr></table></figure>\n<h3 id=\"Programming-with-multiple-graphs\"><a href=\"#Programming-with-multiple-graphs\" class=\"headerlink\" title=\"Programming with multiple graphs\"></a>Programming with multiple graphs</h3><p>You can install a different tf.Graph as the default graph, using the tf.Graph.as_default context manager:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g_1 = tf.Graph()</span><br><span class=\"line\"><span class=\"keyword\">with</span> g_1.as_default():</span><br><span class=\"line\">  <span class=\"comment\"># Operations created in this scope will be added to `g_1`.</span></span><br><span class=\"line\">  c = tf.constant(<span class=\"string\">\"Node in g_1\"</span>)</span><br><span class=\"line\">  <span class=\"comment\"># Sessions created in this scope will run operations from `g_1`.</span></span><br><span class=\"line\">  sess_1 = tf.Session()</span><br><span class=\"line\"></span><br><span class=\"line\">g_2 = tf.Graph()</span><br><span class=\"line\"><span class=\"keyword\">with</span> g_2.as_default():</span><br><span class=\"line\">  <span class=\"comment\"># Operations created in this scope will be added to `g_2`.</span></span><br><span class=\"line\">  d = tf.constant(<span class=\"string\">\"Node in g_2\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># `sess_2` will run operations from `g_2`.</span></span><br><span class=\"line\">sess_2 = tf.Session(graph=g_2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> c.graph <span class=\"keyword\">is</span> g_1</span><br><span class=\"line\"><span class=\"keyword\">assert</span> sess_1.graph <span class=\"keyword\">is</span> g_1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> d.graph <span class=\"keyword\">is</span> g_2</span><br><span class=\"line\"><span class=\"keyword\">assert</span> sess_2.graph <span class=\"keyword\">is</span> g_2</span><br></pre></td></tr></table></figure></p>\n<p>To inspect the current default graph, call tf.get_default_graph, which returns a tf.Graph object:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Print all of the operations in the default graph.</span></span><br><span class=\"line\">g = tf.get_default_graph()</span><br><span class=\"line\">print(g.get_operations())</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<p>TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.</p>\n<h3 id=\"Dataflow\"><a href=\"#Dataflow\" class=\"headerlink\" title=\"Dataflow\"></a>Dataflow</h3><p><img src=\"https://tensorflow.google.cn/images/tensors_flowing.gif\" alt=\"\"></p>\n<p>Dataflow is a common programming model for parallel computing. In a dataflow graph, the nodes represent units of computation, and the edges represent the data consumed or produced by a computation</p>\n<p>Dataflow has several advantages that TensorFlow leverages when executing your programs:</p>\n<ul>\n<li><p><strong>Parallelism</strong>. By using explicit edges to represent dependencies between operations, it is easy for the system to identify operations that can execute in parallel.</p>\n</li>\n<li><p><strong>Distributed execution</strong>. By using explicit edges to represent the values that flow between operations, it is possible for TensorFlow to partition your program across multiple devices (CPUs, GPUs, and TPUs) attached to different machines. TensorFlow inserts the necessary communication and coordination between devices.</p>\n</li>\n<li><p><strong>Compilation</strong>. TensorFlow’s XLA compiler can use the information in your dataflow graph to generate faster code, for example, by fusing together adjacent operations.</p>\n</li>\n<li><p><strong>Portability</strong>. The dataflow graph is a language-independent representation of the code in your model. You can build a dataflow graph in Python, store it in a SavedModel, and restore it in a C++ program for low-latency inference.</p>\n</li>\n</ul>\n<h3 id=\"What-is-a-tf-Graph\"><a href=\"#What-is-a-tf-Graph\" class=\"headerlink\" title=\"What is a tf.Graph?\"></a>What is a tf.Graph?</h3><p> A tf.Graph contains two relevant kinds of information:</p>\n<ul>\n<li><p><strong>Graph structure</strong>. The nodes and edges of the graph, indicating how individual operations are composed together, but not prescribing how they should be used. The graph structure is like assembly code: inspecting it can convey some useful information, but it does not contain all of the useful context that source code conveys.</p>\n</li>\n<li><p><strong>Graph collections</strong>. TensorFlow provides a general mechanism for storing collections of metadata in a tf.Graph. The <strong>tf.add_to_collection</strong> function enables you to associate a list of objects with a key (where <strong>tf.GraphKeys</strong> defines some of the standard keys), and <strong>tf.get_collection</strong> enables you to look up all objects associated with a key. Many parts of the TensorFlow library use this facility: for example, when you create a tf.Variable, it is added by default to collections representing “global variables” and “trainable variables”. When you later come to create a tf.train.Saver or tf.train.Optimizer, the variables in these collections are used as the default arguments.</p>\n</li>\n</ul>\n<h3 id=\"Building-a-tf-Graph\"><a href=\"#Building-a-tf-Graph\" class=\"headerlink\" title=\"Building a tf.Graph\"></a>Building a tf.Graph</h3><p>  Most TensorFlow programs start with a dataflow graph construction phase. In this phase, you invoke TensorFlow API functions that construct new <strong>tf.Operation (node)</strong> and <strong>tf.Tensor (edge)</strong> objects and add them to a <strong>tf.Graph instance</strong>. TensorFlow provides a default graph that is an implicit argument to all API functions in the same context.</p>\n<h3 id=\"Naming-operations\"><a href=\"#Naming-operations\" class=\"headerlink\" title=\"Naming operations\"></a>Naming operations</h3><p> A tf.Graph object defines a namespace for the tf.Operation objects it contains. TensorFlow automatically chooses a unique name for each operation in your graph, but giving operations descriptive names can make your program easier to read and debug. The TensorFlow API provides two ways to override the name of an operation:</p>\n<ul>\n<li><p>Each API function that creates a new tf.Operation or returns a new tf.Tensor accepts an optional name argument. For example, tf.constant(42.0, name=”answer”) creates a new tf.Operation named “answer” and returns a tf.Tensor named “answer:0”. If the default graph already contains an operation named “answer”, then TensorFlow would append “_1”, “_2”, and so on to the name, in order to make it unique.</p>\n</li>\n<li><p>The <strong>tf.name_scope</strong> function makes it possible to add a name scope prefix to all operations created in a particular context. The current name scope prefix is a “/“-delimited list of the names of all active tf.name_scope context managers. If a name scope has already been used in the current context, TensorFlow appends “_1”, “_2”, and so on. For example:</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c_0 = tf.constant(<span class=\"number\">0</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"c\"</span></span><br><span class=\"line\"><span class=\"comment\"># Already-used names will be \"uniquified\".</span></span><br><span class=\"line\">c_1 = tf.constant(<span class=\"number\">2</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"c_1\"</span></span><br><span class=\"line\"><span class=\"comment\"># Name scopes add a prefix to all operations created in the same context.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"outer\"</span>):</span><br><span class=\"line\">    c_2 = tf.constant(<span class=\"number\">2</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"outer/c\"</span></span><br><span class=\"line\">    <span class=\"comment\"># Name scopes nest like paths in a hierarchical file system.</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"inner\"</span>):</span><br><span class=\"line\">        c_3 = tf.constant(<span class=\"number\">3</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"outer/inner/c\"</span></span><br><span class=\"line\">    <span class=\"comment\"># Already-used name scopes will be \"uniquified\".</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"inner\"</span>):</span><br><span class=\"line\">        c_5 = tf.constant(<span class=\"number\">5</span>, name=<span class=\"string\">\"c\"</span>)  <span class=\"comment\"># =&gt; operation named \"outer/inner_1/c\"</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Placing-operations-on-different-devices\"><a href=\"#Placing-operations-on-different-devices\" class=\"headerlink\" title=\"Placing operations on different devices\"></a>Placing operations on different devices</h3><p>If you want your TensorFlow program to use multiple different devices, the tf.device function provides a convenient way to request that all operations created in a particular context are placed on the same device (or type of device).</p>\n<p>A device specification has the following form:</p>\n<pre><code>/job:&lt;JOB_NAME&gt;/task:&lt;TASK_INDEX&gt;/device:&lt;DEVICE_TYPE&gt;:&lt;DEVICE_INDEX&gt;\nwhere:\n    &lt;JOB_NAME&gt; is an alpha-numeric string that does not start with a number.\n    &lt;DEVICE_TYPE&gt; is a registered device type (such as GPU or CPU).\n    &lt;TASK_INDEX&gt; is a non-negative integer representing the index of the task in the job named &lt;JOB_NAME&gt;. See tf.train.ClusterSpec for an explanation of jobs and tasks.\n    &lt;DEVICE_INDEX&gt; is a non-negative integer representing the index of the device, for example, to distinguish between different GPU devices used in the same process.\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Operations created outside either context will run on the \"best possible\"</span></span><br><span class=\"line\"><span class=\"comment\"># device. For example, if you have a GPU and a CPU available, and the operation</span></span><br><span class=\"line\"><span class=\"comment\"># has a GPU implementation, TensorFlow will choose the GPU.</span></span><br><span class=\"line\">weights = tf.random_normal(...)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.device(<span class=\"string\">\"/device:CPU:0\"</span>):</span><br><span class=\"line\">  <span class=\"comment\"># Operations created in this context will be pinned to the CPU.</span></span><br><span class=\"line\">  img = tf.decode_jpeg(tf.read_file(<span class=\"string\">\"img.jpg\"</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.device(<span class=\"string\">\"/device:GPU:0\"</span>):</span><br><span class=\"line\">  <span class=\"comment\"># Operations created in this context will be pinned to the GPU.</span></span><br><span class=\"line\">  result = tf.matmul(weights, img)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Visualizing-your-graph\"><a href=\"#Visualizing-your-graph\" class=\"headerlink\" title=\"Visualizing your graph\"></a>Visualizing your graph</h3><p>TensorFlow includes tools that can help you to understand the code in a graph. The graph visualizer is a component of TensorBoard that renders the structure of your graph visually in a browser. The easiest way to create a visualization is to pass a tf.Graph when creating the <strong>tf.summary.FileWriter</strong>:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Build your graph.</span></span><br><span class=\"line\">x = tf.constant([[<span class=\"number\">37.0</span>, <span class=\"number\">-23.0</span>], [<span class=\"number\">1.0</span>, <span class=\"number\">4.0</span>]])</span><br><span class=\"line\">w = tf.Variable(tf.random_uniform([<span class=\"number\">2</span>, <span class=\"number\">2</span>]))</span><br><span class=\"line\">y = tf.matmul(x, w)</span><br><span class=\"line\"><span class=\"comment\"># ...</span></span><br><span class=\"line\">loss = ...</span><br><span class=\"line\">train_op = tf.train.AdagradOptimizer(<span class=\"number\">0.01</span>).minimize(loss)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">  writer = tf.summary.FileWriter(<span class=\"string\">\"/tmp/log/...\"</span>, sess.graph)</span><br><span class=\"line\">  <span class=\"comment\"># Perform your computation...</span></span><br><span class=\"line\">  <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>):</span><br><span class=\"line\">    sess.run(train_op)</span><br><span class=\"line\">    <span class=\"comment\"># ...</span></span><br><span class=\"line\">  writer.close()</span><br></pre></td></tr></table></figure>\n<h3 id=\"Programming-with-multiple-graphs\"><a href=\"#Programming-with-multiple-graphs\" class=\"headerlink\" title=\"Programming with multiple graphs\"></a>Programming with multiple graphs</h3><p>You can install a different tf.Graph as the default graph, using the tf.Graph.as_default context manager:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g_1 = tf.Graph()</span><br><span class=\"line\"><span class=\"keyword\">with</span> g_1.as_default():</span><br><span class=\"line\">  <span class=\"comment\"># Operations created in this scope will be added to `g_1`.</span></span><br><span class=\"line\">  c = tf.constant(<span class=\"string\">\"Node in g_1\"</span>)</span><br><span class=\"line\">  <span class=\"comment\"># Sessions created in this scope will run operations from `g_1`.</span></span><br><span class=\"line\">  sess_1 = tf.Session()</span><br><span class=\"line\"></span><br><span class=\"line\">g_2 = tf.Graph()</span><br><span class=\"line\"><span class=\"keyword\">with</span> g_2.as_default():</span><br><span class=\"line\">  <span class=\"comment\"># Operations created in this scope will be added to `g_2`.</span></span><br><span class=\"line\">  d = tf.constant(<span class=\"string\">\"Node in g_2\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># `sess_2` will run operations from `g_2`.</span></span><br><span class=\"line\">sess_2 = tf.Session(graph=g_2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> c.graph <span class=\"keyword\">is</span> g_1</span><br><span class=\"line\"><span class=\"keyword\">assert</span> sess_1.graph <span class=\"keyword\">is</span> g_1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> d.graph <span class=\"keyword\">is</span> g_2</span><br><span class=\"line\"><span class=\"keyword\">assert</span> sess_2.graph <span class=\"keyword\">is</span> g_2</span><br></pre></td></tr></table></figure></p>\n<p>To inspect the current default graph, call tf.get_default_graph, which returns a tf.Graph object:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Print all of the operations in the default graph.</span></span><br><span class=\"line\">g = tf.get_default_graph()</span><br><span class=\"line\">print(g.get_operations())</span><br></pre></td></tr></table></figure></p>\n"},{"title":"tensorflow session","date":"2018-09-05T09:03:16.000Z","_content":"### Executing a graph in a tf.Session\nTensorFlow uses the tf.Session class to represent a connection between the client program---typically a Python program, although a similar interface is available in other languages---and the C++ runtime. A tf.Session object provides access to devices in the local machine, and remote devices using the distributed TensorFlow runtime. It also caches information about your tf.Graph so that you can efficiently run the same computation multiple times.\n\n### Creating a tf.Session\n\n```python\n# Create a default in-process session.\nwith tf.Session() as sess:\n  # ...\n# Create a remote session.\nwith tf.Session(\"grpc://example.org:2222\"):\n  # ...\n```\n\n### Using tf.Session.run to execute operations\nThe tf.Session.run method is the main mechanism for running a tf.Operation or evaluating a tf.Tensor. You can pass one or more tf.Operation or tf.Tensor objects to tf.Session.run, and TensorFlow will execute the operations that are needed to compute the result.\n\n```python\n# Define a placeholder that expects a vector of three floating-point values,\n# and a computation that depends on it.\nx = tf.placeholder(tf.float32, shape=[3])\ny = tf.square(x)\n\nwith tf.Session() as sess:\n  # Feeding a value changes the result that is returned when you evaluate `y`.\n  print(sess.run(y, {x: [1.0, 2.0, 3.0]}))  # => \"[1.0, 4.0, 9.0]\"\n  print(sess.run(y, {x: [0.0, 0.0, 5.0]}))  # => \"[0.0, 0.0, 25.0]\"\n ```\n","source":"_posts/tensorflow-session.md","raw":"---\ntitle: tensorflow session\ndate: 2018-09-05 17:03:16\ntags: tensorflow_python_API\ncategories: Tensorflow\n---\n### Executing a graph in a tf.Session\nTensorFlow uses the tf.Session class to represent a connection between the client program---typically a Python program, although a similar interface is available in other languages---and the C++ runtime. A tf.Session object provides access to devices in the local machine, and remote devices using the distributed TensorFlow runtime. It also caches information about your tf.Graph so that you can efficiently run the same computation multiple times.\n\n### Creating a tf.Session\n\n```python\n# Create a default in-process session.\nwith tf.Session() as sess:\n  # ...\n# Create a remote session.\nwith tf.Session(\"grpc://example.org:2222\"):\n  # ...\n```\n\n### Using tf.Session.run to execute operations\nThe tf.Session.run method is the main mechanism for running a tf.Operation or evaluating a tf.Tensor. You can pass one or more tf.Operation or tf.Tensor objects to tf.Session.run, and TensorFlow will execute the operations that are needed to compute the result.\n\n```python\n# Define a placeholder that expects a vector of three floating-point values,\n# and a computation that depends on it.\nx = tf.placeholder(tf.float32, shape=[3])\ny = tf.square(x)\n\nwith tf.Session() as sess:\n  # Feeding a value changes the result that is returned when you evaluate `y`.\n  print(sess.run(y, {x: [1.0, 2.0, 3.0]}))  # => \"[1.0, 4.0, 9.0]\"\n  print(sess.run(y, {x: [0.0, 0.0, 5.0]}))  # => \"[0.0, 0.0, 25.0]\"\n ```\n","slug":"tensorflow-session","published":1,"updated":"2018-09-05T09:26:00.927Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds3r001tpcvootry7me7","content":"<h3 id=\"Executing-a-graph-in-a-tf-Session\"><a href=\"#Executing-a-graph-in-a-tf-Session\" class=\"headerlink\" title=\"Executing a graph in a tf.Session\"></a>Executing a graph in a tf.Session</h3><p>TensorFlow uses the tf.Session class to represent a connection between the client program—typically a Python program, although a similar interface is available in other languages—and the C++ runtime. A tf.Session object provides access to devices in the local machine, and remote devices using the distributed TensorFlow runtime. It also caches information about your tf.Graph so that you can efficiently run the same computation multiple times.</p>\n<h3 id=\"Creating-a-tf-Session\"><a href=\"#Creating-a-tf-Session\" class=\"headerlink\" title=\"Creating a tf.Session\"></a>Creating a tf.Session</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Create a default in-process session.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">  <span class=\"comment\"># ...</span></span><br><span class=\"line\"><span class=\"comment\"># Create a remote session.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session(<span class=\"string\">\"grpc://example.org:2222\"</span>):</span><br><span class=\"line\">  <span class=\"comment\"># ...</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Using-tf-Session-run-to-execute-operations\"><a href=\"#Using-tf-Session-run-to-execute-operations\" class=\"headerlink\" title=\"Using tf.Session.run to execute operations\"></a>Using tf.Session.run to execute operations</h3><p>The tf.Session.run method is the main mechanism for running a tf.Operation or evaluating a tf.Tensor. You can pass one or more tf.Operation or tf.Tensor objects to tf.Session.run, and TensorFlow will execute the operations that are needed to compute the result.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Define a placeholder that expects a vector of three floating-point values,</span></span><br><span class=\"line\"><span class=\"comment\"># and a computation that depends on it.</span></span><br><span class=\"line\">x = tf.placeholder(tf.float32, shape=[<span class=\"number\">3</span>])</span><br><span class=\"line\">y = tf.square(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">  <span class=\"comment\"># Feeding a value changes the result that is returned when you evaluate `y`.</span></span><br><span class=\"line\">  print(sess.run(y, &#123;x: [<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>, <span class=\"number\">3.0</span>]&#125;))  <span class=\"comment\"># =&gt; \"[1.0, 4.0, 9.0]\"</span></span><br><span class=\"line\">  print(sess.run(y, &#123;x: [<span class=\"number\">0.0</span>, <span class=\"number\">0.0</span>, <span class=\"number\">5.0</span>]&#125;))  <span class=\"comment\"># =&gt; \"[0.0, 0.0, 25.0]\"</span></span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Executing-a-graph-in-a-tf-Session\"><a href=\"#Executing-a-graph-in-a-tf-Session\" class=\"headerlink\" title=\"Executing a graph in a tf.Session\"></a>Executing a graph in a tf.Session</h3><p>TensorFlow uses the tf.Session class to represent a connection between the client program—typically a Python program, although a similar interface is available in other languages—and the C++ runtime. A tf.Session object provides access to devices in the local machine, and remote devices using the distributed TensorFlow runtime. It also caches information about your tf.Graph so that you can efficiently run the same computation multiple times.</p>\n<h3 id=\"Creating-a-tf-Session\"><a href=\"#Creating-a-tf-Session\" class=\"headerlink\" title=\"Creating a tf.Session\"></a>Creating a tf.Session</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Create a default in-process session.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">  <span class=\"comment\"># ...</span></span><br><span class=\"line\"><span class=\"comment\"># Create a remote session.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session(<span class=\"string\">\"grpc://example.org:2222\"</span>):</span><br><span class=\"line\">  <span class=\"comment\"># ...</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Using-tf-Session-run-to-execute-operations\"><a href=\"#Using-tf-Session-run-to-execute-operations\" class=\"headerlink\" title=\"Using tf.Session.run to execute operations\"></a>Using tf.Session.run to execute operations</h3><p>The tf.Session.run method is the main mechanism for running a tf.Operation or evaluating a tf.Tensor. You can pass one or more tf.Operation or tf.Tensor objects to tf.Session.run, and TensorFlow will execute the operations that are needed to compute the result.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Define a placeholder that expects a vector of three floating-point values,</span></span><br><span class=\"line\"><span class=\"comment\"># and a computation that depends on it.</span></span><br><span class=\"line\">x = tf.placeholder(tf.float32, shape=[<span class=\"number\">3</span>])</span><br><span class=\"line\">y = tf.square(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">  <span class=\"comment\"># Feeding a value changes the result that is returned when you evaluate `y`.</span></span><br><span class=\"line\">  print(sess.run(y, &#123;x: [<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>, <span class=\"number\">3.0</span>]&#125;))  <span class=\"comment\"># =&gt; \"[1.0, 4.0, 9.0]\"</span></span><br><span class=\"line\">  print(sess.run(y, &#123;x: [<span class=\"number\">0.0</span>, <span class=\"number\">0.0</span>, <span class=\"number\">5.0</span>]&#125;))  <span class=\"comment\"># =&gt; \"[0.0, 0.0, 25.0]\"</span></span><br></pre></td></tr></table></figure>\n"},{"title":"人生--路遥","date":"2018-07-19T15:20:58.000Z","_content":"\n### 故事梗概\n\n小说以改革时期陕北高原的城乡生活为时空背景，描写了高中毕业生高加林回到土地又离开土地，再离开土地，再回到土地这样人生的变化过程构成了其故事构架。高加林同农村姑娘刘巧珍，城市姑娘黄亚萍之间的感情纠葛构成了故事发展的矛盾，也正是体现那种艰难选择的悲剧。\n\n### 内容简介\n\n#### 回到土地\n\n主人公是高加林，他高中毕业回到村里后当上了民办小学的教师，很满足这个既能体现他的才能而又对他充满希望的职业，但是好景不长，他就被有权有势的大队书记高明楼的儿子顶替了，他重新回到了土地。正当他失意无奈，甚至有些绝望的时候，善良美丽的农村姑娘刘巧珍闯进了他的生活，刘巧珍虽然没有文化，但是却真心真意地爱上了高加林这个\n“文化人”，她的爱质朴纯真，她以她的那种充满激情而又实际的作法表白了她的炽烈的爱。而实际上她所得到的爱从一开始就是不平等，高加林在她的眼中是完美的，而她对于高加林来说只是在他失意时找到了精神上的慰藉。当机遇再次降临到了高加林身上，他终于抓住了这次机会，重新回到了城市。\n\n#### 离开土地\n\n城市生活给了高加林大显身手的机会，又让他重新遇到了他的同学黄亚萍。与巧珍相比，黄亚萍无疑是位现代女性，她开朗活泼，却又任性专横，她对高加林的爱炽烈大胆又有一种征服欲。高加林的确与她有许多相似的地方，他们有相同的知识背景，又有许多感兴趣的话题，当他们俩口若悬河、侃侃而谈时，高加林已经进入了一种艰难的选择之中。当高加林隐隐地有了这种想法时，他的念头很快便被另一种感情压下去了，他想起了巧珍那亲切可爱的脸庞，想起了巧珍那种无私而温柔的爱。当巧珍带着狗皮褥子来看他时，巧珍去县城看了好几次加林，加林都有事下乡采访了，终于有一次他俩有机会见面了，加林看到日思夜想的巧珍，心情很是激动，巧珍看他的被褥那么单薄，就说下次去给他带去她自己铺的狗皮褥子，高加林一下子不高兴了，因为城里人没有人用狗皮褥子，而且那狗皮褥子跟他生活的环境一点都不相称，他怕被别人笑话，而当巧珍给他讲的都是些家长里短的小事的时候，他一下子觉得很失落，他跟黄亚萍谈论的都是时事政治、国家大事！那才是他想要的，他的远大抱负。这种反差让高加林很是纠结。他的那种难以言说的复杂的感情一下子表现了出来。在经过反复考虑后，他接受了黄亚萍的爱，可同时意味着这种选择会无情地伤害巧珍，当他委婉地对巧珍表达了他的这种选择后，巧珍含泪接受了，但她却并没有过多地责怪高加林，反而更担心高加林以后的生活，劝他到外地多操心。但是泪水却在她脸上刷刷地淌着。\n\n#### 回到土地\n\n但是好梦难圆，高加林通过关系得到城内工作这件事终于被人告发了，他要面对的是重新回到生他养他的那片土地，他所有的理想和抱负如同过眼云烟难以挽留了。难以承受的是这份打击更难以面对的是生他养他的那片土地，（他本以为村里人都等着看他的笑话呢！可他万万没想到，当他灰头土脸地出现在家乡人面前的时候，家乡人给他的是各种安慰的话语，他感动的不知说什么了，只是拿出他随身带着的烟散给乡亲们。而此时他也得知巧珍已嫁作他人妇，即便如此，她依然去求她姐姐的公公、村支书——高明楼，求他给高加林安排去教学，因为据说家乡的那所学校因为学生增多要新添一个老师。德顺爷爷感慨地说道：“多好的娃娃啊！”此时的高加林已经泣不成声，趴在热情的乡土上大声痛苦......）他褪去了骄傲，认清了现实，接受了德顺爷爷的一番话，而后懊悔的扑倒在了地上。\n\n### 创作背景\n\n20世纪80年代的中国，商品经济的活跃打破了农村的僵持与保守，具有现代文明的城市开始对一直困守在土地的农民产生强烈的诱惑。特别是在青年心中引起巨大的骚动，他们开始对自己的生活及周围的世界产生怀疑与不满。\n\n20世纪80年代，中国户籍制度清晰地将公民分为农业户口和非农业户口，在这种固态格式化的身份制度下，中国社会形成了独特的社会地理景观：乡村景观和城市景观；与这两种景观相对应的是两种截然不同的经济制度和生存方式、文化特征、价值观念。由此导致了中国社会最重要的社会差异；城乡差别。同时，国家还通过各种举措在主观上强化这种差异。臂如在劳动分配制度上，城市工作的工人、教师、职员每月有固定的工资收入，有相对完善的医疗制度、退休制度，同时还可以享受国家各种福利待遇。而在乡村，农民不仅要按时按量向国家交纳粮食，在很长的时期内只能有限度地支配自己的劳动产品。并且，农民还要完成国家规定的各种税费。参与无偿的劳作（例如大规模强制性的农田水利建设）。而国家采取的各种政策将农民强制性地限制在土地上。这些政策的实施直接导致了农民在整个社会发展中长时间处于相对贫困的状态中。因此，可以说在这种基本的身份差异之下，城市和乡村作为两个基本对立的概念被凸显了出来。这是一个作为卑贱农民和一个高贵知识分子的对立，普通百姓和达官显贵的对立。\n\n《人生》就是在城市的场景中展开，似乎一切都处于城市的控制下，甚至乡下人天生就应该在城里人面前低人一等。这种强烈的等级观念、城乡差异在小说中被强化。\n\n当路遥年轻时不停地奔波在城市与乡村时，他最为熟悉的生活即是“城市交叉地带”，充满生气和机遇的城市生活对于像他那样的身处封闭而又贫困的农村知识青年构成了一种双重的刺激，不论在物质还是在精神上。路遥思考并理解了这一现象，在城市化的浪潮汹涌而来的种种冲击中，他提出了农村知识青年该如何做出选择。\n\n早在大学读书时，路遥阅读了大量的经典名著，并对新中国的文学成就进行了一翻巡视。他发现以前的小说带有某种脸谱化的倾向，正如儿童眼中将电影中的人物形象简单分为“好人”和“坏蛋“，而人的思想是复杂的、多变的，绝对不能将复杂的人性这样简单的划分，这种思考体现在《人生》的主人公高加林身上。\n\n### 人物介绍\n\n#### 高加林\n\n高加林是作者着力塑造的复杂的人物。他身上既体现了现代青年那种不断向命运挑战，自信坚毅的品质，又同时具有辛勤、朴实的传统美德。他热爱生活，心性极高，有着远大的理想和抱负。关心国际问题，爱好打篮球，并融入时代的潮流。他不像他的父亲那样忍气吞声、安守本分，而是有更高的精神追求，但是他的现实与他心中的理想总是相差极远，正是这样反差构成了他的复杂的性格特征。\n\n#### 刘巧珍\n\n巧珍美丽善良，爱情真诚。但她把自己置于高加林的附属地位，理想之光幻灭后，她以无爱的婚姻表示对命运的抗争，恰恰重陷传统道德观念的桎梏。\n\n---\n摘自《百度百科词条：人生》\n","source":"_posts/人生-路遥.md","raw":"---\ntitle: 人生--路遥\ndate: 2018-07-19 23:20:58\ntags: 路遥\ncategories: 文学\n---\n\n### 故事梗概\n\n小说以改革时期陕北高原的城乡生活为时空背景，描写了高中毕业生高加林回到土地又离开土地，再离开土地，再回到土地这样人生的变化过程构成了其故事构架。高加林同农村姑娘刘巧珍，城市姑娘黄亚萍之间的感情纠葛构成了故事发展的矛盾，也正是体现那种艰难选择的悲剧。\n\n### 内容简介\n\n#### 回到土地\n\n主人公是高加林，他高中毕业回到村里后当上了民办小学的教师，很满足这个既能体现他的才能而又对他充满希望的职业，但是好景不长，他就被有权有势的大队书记高明楼的儿子顶替了，他重新回到了土地。正当他失意无奈，甚至有些绝望的时候，善良美丽的农村姑娘刘巧珍闯进了他的生活，刘巧珍虽然没有文化，但是却真心真意地爱上了高加林这个\n“文化人”，她的爱质朴纯真，她以她的那种充满激情而又实际的作法表白了她的炽烈的爱。而实际上她所得到的爱从一开始就是不平等，高加林在她的眼中是完美的，而她对于高加林来说只是在他失意时找到了精神上的慰藉。当机遇再次降临到了高加林身上，他终于抓住了这次机会，重新回到了城市。\n\n#### 离开土地\n\n城市生活给了高加林大显身手的机会，又让他重新遇到了他的同学黄亚萍。与巧珍相比，黄亚萍无疑是位现代女性，她开朗活泼，却又任性专横，她对高加林的爱炽烈大胆又有一种征服欲。高加林的确与她有许多相似的地方，他们有相同的知识背景，又有许多感兴趣的话题，当他们俩口若悬河、侃侃而谈时，高加林已经进入了一种艰难的选择之中。当高加林隐隐地有了这种想法时，他的念头很快便被另一种感情压下去了，他想起了巧珍那亲切可爱的脸庞，想起了巧珍那种无私而温柔的爱。当巧珍带着狗皮褥子来看他时，巧珍去县城看了好几次加林，加林都有事下乡采访了，终于有一次他俩有机会见面了，加林看到日思夜想的巧珍，心情很是激动，巧珍看他的被褥那么单薄，就说下次去给他带去她自己铺的狗皮褥子，高加林一下子不高兴了，因为城里人没有人用狗皮褥子，而且那狗皮褥子跟他生活的环境一点都不相称，他怕被别人笑话，而当巧珍给他讲的都是些家长里短的小事的时候，他一下子觉得很失落，他跟黄亚萍谈论的都是时事政治、国家大事！那才是他想要的，他的远大抱负。这种反差让高加林很是纠结。他的那种难以言说的复杂的感情一下子表现了出来。在经过反复考虑后，他接受了黄亚萍的爱，可同时意味着这种选择会无情地伤害巧珍，当他委婉地对巧珍表达了他的这种选择后，巧珍含泪接受了，但她却并没有过多地责怪高加林，反而更担心高加林以后的生活，劝他到外地多操心。但是泪水却在她脸上刷刷地淌着。\n\n#### 回到土地\n\n但是好梦难圆，高加林通过关系得到城内工作这件事终于被人告发了，他要面对的是重新回到生他养他的那片土地，他所有的理想和抱负如同过眼云烟难以挽留了。难以承受的是这份打击更难以面对的是生他养他的那片土地，（他本以为村里人都等着看他的笑话呢！可他万万没想到，当他灰头土脸地出现在家乡人面前的时候，家乡人给他的是各种安慰的话语，他感动的不知说什么了，只是拿出他随身带着的烟散给乡亲们。而此时他也得知巧珍已嫁作他人妇，即便如此，她依然去求她姐姐的公公、村支书——高明楼，求他给高加林安排去教学，因为据说家乡的那所学校因为学生增多要新添一个老师。德顺爷爷感慨地说道：“多好的娃娃啊！”此时的高加林已经泣不成声，趴在热情的乡土上大声痛苦......）他褪去了骄傲，认清了现实，接受了德顺爷爷的一番话，而后懊悔的扑倒在了地上。\n\n### 创作背景\n\n20世纪80年代的中国，商品经济的活跃打破了农村的僵持与保守，具有现代文明的城市开始对一直困守在土地的农民产生强烈的诱惑。特别是在青年心中引起巨大的骚动，他们开始对自己的生活及周围的世界产生怀疑与不满。\n\n20世纪80年代，中国户籍制度清晰地将公民分为农业户口和非农业户口，在这种固态格式化的身份制度下，中国社会形成了独特的社会地理景观：乡村景观和城市景观；与这两种景观相对应的是两种截然不同的经济制度和生存方式、文化特征、价值观念。由此导致了中国社会最重要的社会差异；城乡差别。同时，国家还通过各种举措在主观上强化这种差异。臂如在劳动分配制度上，城市工作的工人、教师、职员每月有固定的工资收入，有相对完善的医疗制度、退休制度，同时还可以享受国家各种福利待遇。而在乡村，农民不仅要按时按量向国家交纳粮食，在很长的时期内只能有限度地支配自己的劳动产品。并且，农民还要完成国家规定的各种税费。参与无偿的劳作（例如大规模强制性的农田水利建设）。而国家采取的各种政策将农民强制性地限制在土地上。这些政策的实施直接导致了农民在整个社会发展中长时间处于相对贫困的状态中。因此，可以说在这种基本的身份差异之下，城市和乡村作为两个基本对立的概念被凸显了出来。这是一个作为卑贱农民和一个高贵知识分子的对立，普通百姓和达官显贵的对立。\n\n《人生》就是在城市的场景中展开，似乎一切都处于城市的控制下，甚至乡下人天生就应该在城里人面前低人一等。这种强烈的等级观念、城乡差异在小说中被强化。\n\n当路遥年轻时不停地奔波在城市与乡村时，他最为熟悉的生活即是“城市交叉地带”，充满生气和机遇的城市生活对于像他那样的身处封闭而又贫困的农村知识青年构成了一种双重的刺激，不论在物质还是在精神上。路遥思考并理解了这一现象，在城市化的浪潮汹涌而来的种种冲击中，他提出了农村知识青年该如何做出选择。\n\n早在大学读书时，路遥阅读了大量的经典名著，并对新中国的文学成就进行了一翻巡视。他发现以前的小说带有某种脸谱化的倾向，正如儿童眼中将电影中的人物形象简单分为“好人”和“坏蛋“，而人的思想是复杂的、多变的，绝对不能将复杂的人性这样简单的划分，这种思考体现在《人生》的主人公高加林身上。\n\n### 人物介绍\n\n#### 高加林\n\n高加林是作者着力塑造的复杂的人物。他身上既体现了现代青年那种不断向命运挑战，自信坚毅的品质，又同时具有辛勤、朴实的传统美德。他热爱生活，心性极高，有着远大的理想和抱负。关心国际问题，爱好打篮球，并融入时代的潮流。他不像他的父亲那样忍气吞声、安守本分，而是有更高的精神追求，但是他的现实与他心中的理想总是相差极远，正是这样反差构成了他的复杂的性格特征。\n\n#### 刘巧珍\n\n巧珍美丽善良，爱情真诚。但她把自己置于高加林的附属地位，理想之光幻灭后，她以无爱的婚姻表示对命运的抗争，恰恰重陷传统道德观念的桎梏。\n\n---\n摘自《百度百科词条：人生》\n","slug":"人生-路遥","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds46001xpcvor6vjil6y","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"故事梗概\"><a href=\"#故事梗概\" class=\"headerlink\" title=\"故事梗概\"></a>故事梗概</h3><p>小说以改革时期陕北高原的城乡生活为时空背景，描写了高中毕业生高加林回到土地又离开土地，再离开土地，再回到土地这样人生的变化过程构成了其故事构架。高加林同农村姑娘刘巧珍，城市姑娘黄亚萍之间的感情纠葛构成了故事发展的矛盾，也正是体现那种艰难选择的悲剧。</p>\n<h3 id=\"内容简介\"><a href=\"#内容简介\" class=\"headerlink\" title=\"内容简介\"></a>内容简介</h3><h4 id=\"回到土地\"><a href=\"#回到土地\" class=\"headerlink\" title=\"回到土地\"></a>回到土地</h4><p>主人公是高加林，他高中毕业回到村里后当上了民办小学的教师，很满足这个既能体现他的才能而又对他充满希望的职业，但是好景不长，他就被有权有势的大队书记高明楼的儿子顶替了，他重新回到了土地。正当他失意无奈，甚至有些绝望的时候，善良美丽的农村姑娘刘巧珍闯进了他的生活，刘巧珍虽然没有文化，但是却真心真意地爱上了高加林这个<br>“文化人”，她的爱质朴纯真，她以她的那种充满激情而又实际的作法表白了她的炽烈的爱。而实际上她所得到的爱从一开始就是不平等，高加林在她的眼中是完美的，而她对于高加林来说只是在他失意时找到了精神上的慰藉。当机遇再次降临到了高加林身上，他终于抓住了这次机会，重新回到了城市。</p>\n<h4 id=\"离开土地\"><a href=\"#离开土地\" class=\"headerlink\" title=\"离开土地\"></a>离开土地</h4><p>城市生活给了高加林大显身手的机会，又让他重新遇到了他的同学黄亚萍。与巧珍相比，黄亚萍无疑是位现代女性，她开朗活泼，却又任性专横，她对高加林的爱炽烈大胆又有一种征服欲。高加林的确与她有许多相似的地方，他们有相同的知识背景，又有许多感兴趣的话题，当他们俩口若悬河、侃侃而谈时，高加林已经进入了一种艰难的选择之中。当高加林隐隐地有了这种想法时，他的念头很快便被另一种感情压下去了，他想起了巧珍那亲切可爱的脸庞，想起了巧珍那种无私而温柔的爱。当巧珍带着狗皮褥子来看他时，巧珍去县城看了好几次加林，加林都有事下乡采访了，终于有一次他俩有机会见面了，加林看到日思夜想的巧珍，心情很是激动，巧珍看他的被褥那么单薄，就说下次去给他带去她自己铺的狗皮褥子，高加林一下子不高兴了，因为城里人没有人用狗皮褥子，而且那狗皮褥子跟他生活的环境一点都不相称，他怕被别人笑话，而当巧珍给他讲的都是些家长里短的小事的时候，他一下子觉得很失落，他跟黄亚萍谈论的都是时事政治、国家大事！那才是他想要的，他的远大抱负。这种反差让高加林很是纠结。他的那种难以言说的复杂的感情一下子表现了出来。在经过反复考虑后，他接受了黄亚萍的爱，可同时意味着这种选择会无情地伤害巧珍，当他委婉地对巧珍表达了他的这种选择后，巧珍含泪接受了，但她却并没有过多地责怪高加林，反而更担心高加林以后的生活，劝他到外地多操心。但是泪水却在她脸上刷刷地淌着。</p>\n<h4 id=\"回到土地-1\"><a href=\"#回到土地-1\" class=\"headerlink\" title=\"回到土地\"></a>回到土地</h4><p>但是好梦难圆，高加林通过关系得到城内工作这件事终于被人告发了，他要面对的是重新回到生他养他的那片土地，他所有的理想和抱负如同过眼云烟难以挽留了。难以承受的是这份打击更难以面对的是生他养他的那片土地，（他本以为村里人都等着看他的笑话呢！可他万万没想到，当他灰头土脸地出现在家乡人面前的时候，家乡人给他的是各种安慰的话语，他感动的不知说什么了，只是拿出他随身带着的烟散给乡亲们。而此时他也得知巧珍已嫁作他人妇，即便如此，她依然去求她姐姐的公公、村支书——高明楼，求他给高加林安排去教学，因为据说家乡的那所学校因为学生增多要新添一个老师。德顺爷爷感慨地说道：“多好的娃娃啊！”此时的高加林已经泣不成声，趴在热情的乡土上大声痛苦……）他褪去了骄傲，认清了现实，接受了德顺爷爷的一番话，而后懊悔的扑倒在了地上。</p>\n<h3 id=\"创作背景\"><a href=\"#创作背景\" class=\"headerlink\" title=\"创作背景\"></a>创作背景</h3><p>20世纪80年代的中国，商品经济的活跃打破了农村的僵持与保守，具有现代文明的城市开始对一直困守在土地的农民产生强烈的诱惑。特别是在青年心中引起巨大的骚动，他们开始对自己的生活及周围的世界产生怀疑与不满。</p>\n<p>20世纪80年代，中国户籍制度清晰地将公民分为农业户口和非农业户口，在这种固态格式化的身份制度下，中国社会形成了独特的社会地理景观：乡村景观和城市景观；与这两种景观相对应的是两种截然不同的经济制度和生存方式、文化特征、价值观念。由此导致了中国社会最重要的社会差异；城乡差别。同时，国家还通过各种举措在主观上强化这种差异。臂如在劳动分配制度上，城市工作的工人、教师、职员每月有固定的工资收入，有相对完善的医疗制度、退休制度，同时还可以享受国家各种福利待遇。而在乡村，农民不仅要按时按量向国家交纳粮食，在很长的时期内只能有限度地支配自己的劳动产品。并且，农民还要完成国家规定的各种税费。参与无偿的劳作（例如大规模强制性的农田水利建设）。而国家采取的各种政策将农民强制性地限制在土地上。这些政策的实施直接导致了农民在整个社会发展中长时间处于相对贫困的状态中。因此，可以说在这种基本的身份差异之下，城市和乡村作为两个基本对立的概念被凸显了出来。这是一个作为卑贱农民和一个高贵知识分子的对立，普通百姓和达官显贵的对立。</p>\n<p>《人生》就是在城市的场景中展开，似乎一切都处于城市的控制下，甚至乡下人天生就应该在城里人面前低人一等。这种强烈的等级观念、城乡差异在小说中被强化。</p>\n<p>当路遥年轻时不停地奔波在城市与乡村时，他最为熟悉的生活即是“城市交叉地带”，充满生气和机遇的城市生活对于像他那样的身处封闭而又贫困的农村知识青年构成了一种双重的刺激，不论在物质还是在精神上。路遥思考并理解了这一现象，在城市化的浪潮汹涌而来的种种冲击中，他提出了农村知识青年该如何做出选择。</p>\n<p>早在大学读书时，路遥阅读了大量的经典名著，并对新中国的文学成就进行了一翻巡视。他发现以前的小说带有某种脸谱化的倾向，正如儿童眼中将电影中的人物形象简单分为“好人”和“坏蛋“，而人的思想是复杂的、多变的，绝对不能将复杂的人性这样简单的划分，这种思考体现在《人生》的主人公高加林身上。</p>\n<h3 id=\"人物介绍\"><a href=\"#人物介绍\" class=\"headerlink\" title=\"人物介绍\"></a>人物介绍</h3><h4 id=\"高加林\"><a href=\"#高加林\" class=\"headerlink\" title=\"高加林\"></a>高加林</h4><p>高加林是作者着力塑造的复杂的人物。他身上既体现了现代青年那种不断向命运挑战，自信坚毅的品质，又同时具有辛勤、朴实的传统美德。他热爱生活，心性极高，有着远大的理想和抱负。关心国际问题，爱好打篮球，并融入时代的潮流。他不像他的父亲那样忍气吞声、安守本分，而是有更高的精神追求，但是他的现实与他心中的理想总是相差极远，正是这样反差构成了他的复杂的性格特征。</p>\n<h4 id=\"刘巧珍\"><a href=\"#刘巧珍\" class=\"headerlink\" title=\"刘巧珍\"></a>刘巧珍</h4><p>巧珍美丽善良，爱情真诚。但她把自己置于高加林的附属地位，理想之光幻灭后，她以无爱的婚姻表示对命运的抗争，恰恰重陷传统道德观念的桎梏。</p>\n<hr>\n<p>摘自《百度百科词条：人生》</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"故事梗概\"><a href=\"#故事梗概\" class=\"headerlink\" title=\"故事梗概\"></a>故事梗概</h3><p>小说以改革时期陕北高原的城乡生活为时空背景，描写了高中毕业生高加林回到土地又离开土地，再离开土地，再回到土地这样人生的变化过程构成了其故事构架。高加林同农村姑娘刘巧珍，城市姑娘黄亚萍之间的感情纠葛构成了故事发展的矛盾，也正是体现那种艰难选择的悲剧。</p>\n<h3 id=\"内容简介\"><a href=\"#内容简介\" class=\"headerlink\" title=\"内容简介\"></a>内容简介</h3><h4 id=\"回到土地\"><a href=\"#回到土地\" class=\"headerlink\" title=\"回到土地\"></a>回到土地</h4><p>主人公是高加林，他高中毕业回到村里后当上了民办小学的教师，很满足这个既能体现他的才能而又对他充满希望的职业，但是好景不长，他就被有权有势的大队书记高明楼的儿子顶替了，他重新回到了土地。正当他失意无奈，甚至有些绝望的时候，善良美丽的农村姑娘刘巧珍闯进了他的生活，刘巧珍虽然没有文化，但是却真心真意地爱上了高加林这个<br>“文化人”，她的爱质朴纯真，她以她的那种充满激情而又实际的作法表白了她的炽烈的爱。而实际上她所得到的爱从一开始就是不平等，高加林在她的眼中是完美的，而她对于高加林来说只是在他失意时找到了精神上的慰藉。当机遇再次降临到了高加林身上，他终于抓住了这次机会，重新回到了城市。</p>\n<h4 id=\"离开土地\"><a href=\"#离开土地\" class=\"headerlink\" title=\"离开土地\"></a>离开土地</h4><p>城市生活给了高加林大显身手的机会，又让他重新遇到了他的同学黄亚萍。与巧珍相比，黄亚萍无疑是位现代女性，她开朗活泼，却又任性专横，她对高加林的爱炽烈大胆又有一种征服欲。高加林的确与她有许多相似的地方，他们有相同的知识背景，又有许多感兴趣的话题，当他们俩口若悬河、侃侃而谈时，高加林已经进入了一种艰难的选择之中。当高加林隐隐地有了这种想法时，他的念头很快便被另一种感情压下去了，他想起了巧珍那亲切可爱的脸庞，想起了巧珍那种无私而温柔的爱。当巧珍带着狗皮褥子来看他时，巧珍去县城看了好几次加林，加林都有事下乡采访了，终于有一次他俩有机会见面了，加林看到日思夜想的巧珍，心情很是激动，巧珍看他的被褥那么单薄，就说下次去给他带去她自己铺的狗皮褥子，高加林一下子不高兴了，因为城里人没有人用狗皮褥子，而且那狗皮褥子跟他生活的环境一点都不相称，他怕被别人笑话，而当巧珍给他讲的都是些家长里短的小事的时候，他一下子觉得很失落，他跟黄亚萍谈论的都是时事政治、国家大事！那才是他想要的，他的远大抱负。这种反差让高加林很是纠结。他的那种难以言说的复杂的感情一下子表现了出来。在经过反复考虑后，他接受了黄亚萍的爱，可同时意味着这种选择会无情地伤害巧珍，当他委婉地对巧珍表达了他的这种选择后，巧珍含泪接受了，但她却并没有过多地责怪高加林，反而更担心高加林以后的生活，劝他到外地多操心。但是泪水却在她脸上刷刷地淌着。</p>\n<h4 id=\"回到土地-1\"><a href=\"#回到土地-1\" class=\"headerlink\" title=\"回到土地\"></a>回到土地</h4><p>但是好梦难圆，高加林通过关系得到城内工作这件事终于被人告发了，他要面对的是重新回到生他养他的那片土地，他所有的理想和抱负如同过眼云烟难以挽留了。难以承受的是这份打击更难以面对的是生他养他的那片土地，（他本以为村里人都等着看他的笑话呢！可他万万没想到，当他灰头土脸地出现在家乡人面前的时候，家乡人给他的是各种安慰的话语，他感动的不知说什么了，只是拿出他随身带着的烟散给乡亲们。而此时他也得知巧珍已嫁作他人妇，即便如此，她依然去求她姐姐的公公、村支书——高明楼，求他给高加林安排去教学，因为据说家乡的那所学校因为学生增多要新添一个老师。德顺爷爷感慨地说道：“多好的娃娃啊！”此时的高加林已经泣不成声，趴在热情的乡土上大声痛苦……）他褪去了骄傲，认清了现实，接受了德顺爷爷的一番话，而后懊悔的扑倒在了地上。</p>\n<h3 id=\"创作背景\"><a href=\"#创作背景\" class=\"headerlink\" title=\"创作背景\"></a>创作背景</h3><p>20世纪80年代的中国，商品经济的活跃打破了农村的僵持与保守，具有现代文明的城市开始对一直困守在土地的农民产生强烈的诱惑。特别是在青年心中引起巨大的骚动，他们开始对自己的生活及周围的世界产生怀疑与不满。</p>\n<p>20世纪80年代，中国户籍制度清晰地将公民分为农业户口和非农业户口，在这种固态格式化的身份制度下，中国社会形成了独特的社会地理景观：乡村景观和城市景观；与这两种景观相对应的是两种截然不同的经济制度和生存方式、文化特征、价值观念。由此导致了中国社会最重要的社会差异；城乡差别。同时，国家还通过各种举措在主观上强化这种差异。臂如在劳动分配制度上，城市工作的工人、教师、职员每月有固定的工资收入，有相对完善的医疗制度、退休制度，同时还可以享受国家各种福利待遇。而在乡村，农民不仅要按时按量向国家交纳粮食，在很长的时期内只能有限度地支配自己的劳动产品。并且，农民还要完成国家规定的各种税费。参与无偿的劳作（例如大规模强制性的农田水利建设）。而国家采取的各种政策将农民强制性地限制在土地上。这些政策的实施直接导致了农民在整个社会发展中长时间处于相对贫困的状态中。因此，可以说在这种基本的身份差异之下，城市和乡村作为两个基本对立的概念被凸显了出来。这是一个作为卑贱农民和一个高贵知识分子的对立，普通百姓和达官显贵的对立。</p>\n<p>《人生》就是在城市的场景中展开，似乎一切都处于城市的控制下，甚至乡下人天生就应该在城里人面前低人一等。这种强烈的等级观念、城乡差异在小说中被强化。</p>\n<p>当路遥年轻时不停地奔波在城市与乡村时，他最为熟悉的生活即是“城市交叉地带”，充满生气和机遇的城市生活对于像他那样的身处封闭而又贫困的农村知识青年构成了一种双重的刺激，不论在物质还是在精神上。路遥思考并理解了这一现象，在城市化的浪潮汹涌而来的种种冲击中，他提出了农村知识青年该如何做出选择。</p>\n<p>早在大学读书时，路遥阅读了大量的经典名著，并对新中国的文学成就进行了一翻巡视。他发现以前的小说带有某种脸谱化的倾向，正如儿童眼中将电影中的人物形象简单分为“好人”和“坏蛋“，而人的思想是复杂的、多变的，绝对不能将复杂的人性这样简单的划分，这种思考体现在《人生》的主人公高加林身上。</p>\n<h3 id=\"人物介绍\"><a href=\"#人物介绍\" class=\"headerlink\" title=\"人物介绍\"></a>人物介绍</h3><h4 id=\"高加林\"><a href=\"#高加林\" class=\"headerlink\" title=\"高加林\"></a>高加林</h4><p>高加林是作者着力塑造的复杂的人物。他身上既体现了现代青年那种不断向命运挑战，自信坚毅的品质，又同时具有辛勤、朴实的传统美德。他热爱生活，心性极高，有着远大的理想和抱负。关心国际问题，爱好打篮球，并融入时代的潮流。他不像他的父亲那样忍气吞声、安守本分，而是有更高的精神追求，但是他的现实与他心中的理想总是相差极远，正是这样反差构成了他的复杂的性格特征。</p>\n<h4 id=\"刘巧珍\"><a href=\"#刘巧珍\" class=\"headerlink\" title=\"刘巧珍\"></a>刘巧珍</h4><p>巧珍美丽善良，爱情真诚。但她把自己置于高加林的附属地位，理想之光幻灭后，她以无爱的婚姻表示对命运的抗争，恰恰重陷传统道德观念的桎梏。</p>\n<hr>\n<p>摘自《百度百科词条：人生》</p>\n"},{"title":"tensorflow variable","date":"2018-09-05T02:50:55.000Z","_content":"A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.\n\n### Create a variable\n\n```python\nmy_int_variable = tf.get_variable(\"my_int_variable\", [1, 2, 3], dtype=tf.int32,\n  initializer=tf.zeros_initializer)\n```\n\n**tf.get_variable**\n\n* 构造函数\n    ```python\n    tf.get_variable(\n    name,\n    shape=None,\n    dtype=None,\n    initializer=None,\n    regularizer=None,\n    trainable=None,\n    collections=None,\n    caching_device=None,\n    partitioner=None,\n    validate_shape=True,\n    use_resource=None,\n    custom_getter=None,\n    constraint=None,\n    synchronization=tf.VariableSynchronization.AUTO,\n    aggregation=tf.VariableAggregation.NONE\n    )\n    ```\n\n* **initializer:** Initializer for the variable if one is created. Can either be an initializer object or a Tensor. If it's a Tensor, its shape must be known unless validate_shape is False.\n\n* **regularizer:** A (Tensor -> Tensor or None) function; the result of applying it on a newly created variable will be added to the collection *tf.GraphKeys.REGULARIZATION_LOSSES* and can be used for regularization.\n\n* **trainable:** If True also add the variable to the graph collection *GraphKeys.TRAINABLE_VARIABLES* (see tf.Variable). collections: List of graph collections keys to add the Variable to. Defaults to *[GraphKeys.GLOBAL_VARIABLES]* (see tf.Variable).\n\n### Variable collections\n\nBecause disconnected parts of a TensorFlow program might want to create variables, it is sometimes useful to have a single way to access all of them.For this reason TensorFlow provides collections, which are named lists of tensors or other objects, such as tf.Variable instances\n\nBy default every tf.Variable gets placed in the following two collections:\n\n    tf.GraphKeys.GLOBAL_VARIABLES --- variables that can be shared across multiple devices,\n    tf.GraphKeys.TRAINABLE_VARIABLES --- variables for which TensorFlow will calculate gradients.\n\nIf you don't want a variable to be trainable, add it to the **tf.GraphKeys.LOCAL_VARIABLES** collection instead.\n\n```python\nmy_local = tf.get_variable(\"my_local\", shape=(),\ncollections=[tf.GraphKeys.LOCAL_VARIABLES])\n\nmy_non_trainable = tf.get_variable(\"my_non_trainable\",\n                                   shape=(),\n                                   trainable=False)\n\ntf.add_to_collection(\"my_collection_name\", my_local)\n#  retrieve a list of all the variables\ntf.get_collection(\"my_collection_name\")                               \n```\n\n### Initializing variables\n\nTo initialize all trainable variables in one go, before training starts, call **tf.global_variables_initializer()**. This function returns a single operation responsible for initializing all variables in the **tf.GraphKeys.GLOBAL_VARIABLES** collection.\n\n```python\nsession.run(tf.global_variables_initializer())\n# Now all variables are initialized.\nsession.run(my_variable.initializer)\n```\n\nNote that by default tf.global_variables_initializer does not specify the order in which variables are initialized. Therefore, if the initial value of a variable depends on another variable's value, it's likely that you'll get an error. Any time you use the value of a variable in a context in which not all variables are initialized (say, if you use a variable's value while initializing another variable), it is best to use **variable.initialized_value()** instead of variable:\n\n```python\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n```\n\n### Using variable\n\nTo use the value of a tf.Variable in a TensorFlow graph, simply treat it like a normal tf.Tensor:\n\n```python\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n           # Any time a variable is used in an expression it gets automatically\n           # converted to a tf.Tensor representing its value.\n```\n\n### Sharing variables\n\nTensorFlow supports two ways of sharing variables:\n\n    Explicitly passing tf.Variable objects around.\n    Implicitly wrapping tf.Variable objects within tf.variable_scope objects.\n\nVariable scopes allow you to control variable reuse when calling functions which implicitly create and use variables. They also allow you to name your variables in a hierarchical and understandable way.\n\n```python\ndef conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name, padding='SAME'):\n    # Get number of input channels\n    input_channels = int(x.get_shape()[-1])\n    # create lambda function for the convolution\n    convolve = lambda i, k: tf.nn.conv2d(i, k, strides=[1, stride_y, stride_x, 1], padding=padding)\n    with tf.variable_scope(name) as scope:\n        weights = tf.get_variable('weights', shape=[filter_height, filter_width, input_channels, num_filters])\n        biases = tf.get_variable('biases', shape=[num_filters])\n        conv = convolve(x, weights)\n        bias = tf.reshape(tf.nn.bias_add(conv, biases))\n        # Apply relu function\n        relu = tf.nn.relu(bias, name=scope.name)\n        return relu\n```\n","source":"_posts/tensorflow-variable.md","raw":"---\ntitle: tensorflow variable\ndate: 2018-09-05 10:50:55\ntags: tensorflow_python_API\ncategories: Tensorflow\n---\nA TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.\n\n### Create a variable\n\n```python\nmy_int_variable = tf.get_variable(\"my_int_variable\", [1, 2, 3], dtype=tf.int32,\n  initializer=tf.zeros_initializer)\n```\n\n**tf.get_variable**\n\n* 构造函数\n    ```python\n    tf.get_variable(\n    name,\n    shape=None,\n    dtype=None,\n    initializer=None,\n    regularizer=None,\n    trainable=None,\n    collections=None,\n    caching_device=None,\n    partitioner=None,\n    validate_shape=True,\n    use_resource=None,\n    custom_getter=None,\n    constraint=None,\n    synchronization=tf.VariableSynchronization.AUTO,\n    aggregation=tf.VariableAggregation.NONE\n    )\n    ```\n\n* **initializer:** Initializer for the variable if one is created. Can either be an initializer object or a Tensor. If it's a Tensor, its shape must be known unless validate_shape is False.\n\n* **regularizer:** A (Tensor -> Tensor or None) function; the result of applying it on a newly created variable will be added to the collection *tf.GraphKeys.REGULARIZATION_LOSSES* and can be used for regularization.\n\n* **trainable:** If True also add the variable to the graph collection *GraphKeys.TRAINABLE_VARIABLES* (see tf.Variable). collections: List of graph collections keys to add the Variable to. Defaults to *[GraphKeys.GLOBAL_VARIABLES]* (see tf.Variable).\n\n### Variable collections\n\nBecause disconnected parts of a TensorFlow program might want to create variables, it is sometimes useful to have a single way to access all of them.For this reason TensorFlow provides collections, which are named lists of tensors or other objects, such as tf.Variable instances\n\nBy default every tf.Variable gets placed in the following two collections:\n\n    tf.GraphKeys.GLOBAL_VARIABLES --- variables that can be shared across multiple devices,\n    tf.GraphKeys.TRAINABLE_VARIABLES --- variables for which TensorFlow will calculate gradients.\n\nIf you don't want a variable to be trainable, add it to the **tf.GraphKeys.LOCAL_VARIABLES** collection instead.\n\n```python\nmy_local = tf.get_variable(\"my_local\", shape=(),\ncollections=[tf.GraphKeys.LOCAL_VARIABLES])\n\nmy_non_trainable = tf.get_variable(\"my_non_trainable\",\n                                   shape=(),\n                                   trainable=False)\n\ntf.add_to_collection(\"my_collection_name\", my_local)\n#  retrieve a list of all the variables\ntf.get_collection(\"my_collection_name\")                               \n```\n\n### Initializing variables\n\nTo initialize all trainable variables in one go, before training starts, call **tf.global_variables_initializer()**. This function returns a single operation responsible for initializing all variables in the **tf.GraphKeys.GLOBAL_VARIABLES** collection.\n\n```python\nsession.run(tf.global_variables_initializer())\n# Now all variables are initialized.\nsession.run(my_variable.initializer)\n```\n\nNote that by default tf.global_variables_initializer does not specify the order in which variables are initialized. Therefore, if the initial value of a variable depends on another variable's value, it's likely that you'll get an error. Any time you use the value of a variable in a context in which not all variables are initialized (say, if you use a variable's value while initializing another variable), it is best to use **variable.initialized_value()** instead of variable:\n\n```python\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n```\n\n### Using variable\n\nTo use the value of a tf.Variable in a TensorFlow graph, simply treat it like a normal tf.Tensor:\n\n```python\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n           # Any time a variable is used in an expression it gets automatically\n           # converted to a tf.Tensor representing its value.\n```\n\n### Sharing variables\n\nTensorFlow supports two ways of sharing variables:\n\n    Explicitly passing tf.Variable objects around.\n    Implicitly wrapping tf.Variable objects within tf.variable_scope objects.\n\nVariable scopes allow you to control variable reuse when calling functions which implicitly create and use variables. They also allow you to name your variables in a hierarchical and understandable way.\n\n```python\ndef conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name, padding='SAME'):\n    # Get number of input channels\n    input_channels = int(x.get_shape()[-1])\n    # create lambda function for the convolution\n    convolve = lambda i, k: tf.nn.conv2d(i, k, strides=[1, stride_y, stride_x, 1], padding=padding)\n    with tf.variable_scope(name) as scope:\n        weights = tf.get_variable('weights', shape=[filter_height, filter_width, input_channels, num_filters])\n        biases = tf.get_variable('biases', shape=[num_filters])\n        conv = convolve(x, weights)\n        bias = tf.reshape(tf.nn.bias_add(conv, biases))\n        # Apply relu function\n        relu = tf.nn.relu(bias, name=scope.name)\n        return relu\n```\n","slug":"tensorflow-variable","published":1,"updated":"2018-09-05T09:57:29.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds460021pcvoadujnupl","content":"<p>A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.</p>\n<h3 id=\"Create-a-variable\"><a href=\"#Create-a-variable\" class=\"headerlink\" title=\"Create a variable\"></a>Create a variable</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my_int_variable = tf.get_variable(<span class=\"string\">\"my_int_variable\"</span>, [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], dtype=tf.int32,</span><br><span class=\"line\">  initializer=tf.zeros_initializer)</span><br></pre></td></tr></table></figure>\n<p><strong>tf.get_variable</strong></p>\n<ul>\n<li><p>构造函数</p>\n  <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.get_variable(</span><br><span class=\"line\">name,</span><br><span class=\"line\">shape=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">dtype=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">initializer=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">regularizer=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">trainable=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">collections=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">caching_device=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">partitioner=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">validate_shape=<span class=\"keyword\">True</span>,</span><br><span class=\"line\">use_resource=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">custom_getter=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">constraint=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">synchronization=tf.VariableSynchronization.AUTO,</span><br><span class=\"line\">aggregation=tf.VariableAggregation.NONE</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>initializer:</strong> Initializer for the variable if one is created. Can either be an initializer object or a Tensor. If it’s a Tensor, its shape must be known unless validate_shape is False.</p>\n</li>\n<li><p><strong>regularizer:</strong> A (Tensor -&gt; Tensor or None) function; the result of applying it on a newly created variable will be added to the collection <em>tf.GraphKeys.REGULARIZATION_LOSSES</em> and can be used for regularization.</p>\n</li>\n<li><p><strong>trainable:</strong> If True also add the variable to the graph collection <em>GraphKeys.TRAINABLE_VARIABLES</em> (see tf.Variable). collections: List of graph collections keys to add the Variable to. Defaults to <em>[GraphKeys.GLOBAL_VARIABLES]</em> (see tf.Variable).</p>\n</li>\n</ul>\n<h3 id=\"Variable-collections\"><a href=\"#Variable-collections\" class=\"headerlink\" title=\"Variable collections\"></a>Variable collections</h3><p>Because disconnected parts of a TensorFlow program might want to create variables, it is sometimes useful to have a single way to access all of them.For this reason TensorFlow provides collections, which are named lists of tensors or other objects, such as tf.Variable instances</p>\n<p>By default every tf.Variable gets placed in the following two collections:</p>\n<pre><code>tf.GraphKeys.GLOBAL_VARIABLES --- variables that can be shared across multiple devices,\ntf.GraphKeys.TRAINABLE_VARIABLES --- variables for which TensorFlow will calculate gradients.\n</code></pre><p>If you don’t want a variable to be trainable, add it to the <strong>tf.GraphKeys.LOCAL_VARIABLES</strong> collection instead.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my_local = tf.get_variable(<span class=\"string\">\"my_local\"</span>, shape=(),</span><br><span class=\"line\">collections=[tf.GraphKeys.LOCAL_VARIABLES])</span><br><span class=\"line\"></span><br><span class=\"line\">my_non_trainable = tf.get_variable(<span class=\"string\">\"my_non_trainable\"</span>,</span><br><span class=\"line\">                                   shape=(),</span><br><span class=\"line\">                                   trainable=<span class=\"keyword\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">tf.add_to_collection(<span class=\"string\">\"my_collection_name\"</span>, my_local)</span><br><span class=\"line\"><span class=\"comment\">#  retrieve a list of all the variables</span></span><br><span class=\"line\">tf.get_collection(<span class=\"string\">\"my_collection_name\"</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Initializing-variables\"><a href=\"#Initializing-variables\" class=\"headerlink\" title=\"Initializing variables\"></a>Initializing variables</h3><p>To initialize all trainable variables in one go, before training starts, call <strong>tf.global_variables_initializer()</strong>. This function returns a single operation responsible for initializing all variables in the <strong>tf.GraphKeys.GLOBAL_VARIABLES</strong> collection.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session.run(tf.global_variables_initializer())</span><br><span class=\"line\"><span class=\"comment\"># Now all variables are initialized.</span></span><br><span class=\"line\">session.run(my_variable.initializer)</span><br></pre></td></tr></table></figure>\n<p>Note that by default tf.global_variables_initializer does not specify the order in which variables are initialized. Therefore, if the initial value of a variable depends on another variable’s value, it’s likely that you’ll get an error. Any time you use the value of a variable in a context in which not all variables are initialized (say, if you use a variable’s value while initializing another variable), it is best to use <strong>variable.initialized_value()</strong> instead of variable:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v = tf.get_variable(<span class=\"string\">\"v\"</span>, shape=(), initializer=tf.zeros_initializer())</span><br><span class=\"line\">w = tf.get_variable(<span class=\"string\">\"w\"</span>, initializer=v.initialized_value() + <span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Using-variable\"><a href=\"#Using-variable\" class=\"headerlink\" title=\"Using variable\"></a>Using variable</h3><p>To use the value of a tf.Variable in a TensorFlow graph, simply treat it like a normal tf.Tensor:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v = tf.get_variable(<span class=\"string\">\"v\"</span>, shape=(), initializer=tf.zeros_initializer())</span><br><span class=\"line\">w = v + <span class=\"number\">1</span>  <span class=\"comment\"># w is a tf.Tensor which is computed based on the value of v.</span></span><br><span class=\"line\">           <span class=\"comment\"># Any time a variable is used in an expression it gets automatically</span></span><br><span class=\"line\">           <span class=\"comment\"># converted to a tf.Tensor representing its value.</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Sharing-variables\"><a href=\"#Sharing-variables\" class=\"headerlink\" title=\"Sharing variables\"></a>Sharing variables</h3><p>TensorFlow supports two ways of sharing variables:</p>\n<pre><code>Explicitly passing tf.Variable objects around.\nImplicitly wrapping tf.Variable objects within tf.variable_scope objects.\n</code></pre><p>Variable scopes allow you to control variable reuse when calling functions which implicitly create and use variables. They also allow you to name your variables in a hierarchical and understandable way.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv</span><span class=\"params\">(x, filter_height, filter_width, num_filters, stride_y, stride_x, name, padding=<span class=\"string\">'SAME'</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># Get number of input channels</span></span><br><span class=\"line\">    input_channels = int(x.get_shape()[<span class=\"number\">-1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># create lambda function for the convolution</span></span><br><span class=\"line\">    convolve = <span class=\"keyword\">lambda</span> i, k: tf.nn.conv2d(i, k, strides=[<span class=\"number\">1</span>, stride_y, stride_x, <span class=\"number\">1</span>], padding=padding)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.variable_scope(name) <span class=\"keyword\">as</span> scope:</span><br><span class=\"line\">        weights = tf.get_variable(<span class=\"string\">'weights'</span>, shape=[filter_height, filter_width, input_channels, num_filters])</span><br><span class=\"line\">        biases = tf.get_variable(<span class=\"string\">'biases'</span>, shape=[num_filters])</span><br><span class=\"line\">        conv = convolve(x, weights)</span><br><span class=\"line\">        bias = tf.reshape(tf.nn.bias_add(conv, biases))</span><br><span class=\"line\">        <span class=\"comment\"># Apply relu function</span></span><br><span class=\"line\">        relu = tf.nn.relu(bias, name=scope.name)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> relu</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.</p>\n<h3 id=\"Create-a-variable\"><a href=\"#Create-a-variable\" class=\"headerlink\" title=\"Create a variable\"></a>Create a variable</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my_int_variable = tf.get_variable(<span class=\"string\">\"my_int_variable\"</span>, [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], dtype=tf.int32,</span><br><span class=\"line\">  initializer=tf.zeros_initializer)</span><br></pre></td></tr></table></figure>\n<p><strong>tf.get_variable</strong></p>\n<ul>\n<li><p>构造函数</p>\n  <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.get_variable(</span><br><span class=\"line\">name,</span><br><span class=\"line\">shape=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">dtype=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">initializer=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">regularizer=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">trainable=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">collections=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">caching_device=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">partitioner=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">validate_shape=<span class=\"keyword\">True</span>,</span><br><span class=\"line\">use_resource=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">custom_getter=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">constraint=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">synchronization=tf.VariableSynchronization.AUTO,</span><br><span class=\"line\">aggregation=tf.VariableAggregation.NONE</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>initializer:</strong> Initializer for the variable if one is created. Can either be an initializer object or a Tensor. If it’s a Tensor, its shape must be known unless validate_shape is False.</p>\n</li>\n<li><p><strong>regularizer:</strong> A (Tensor -&gt; Tensor or None) function; the result of applying it on a newly created variable will be added to the collection <em>tf.GraphKeys.REGULARIZATION_LOSSES</em> and can be used for regularization.</p>\n</li>\n<li><p><strong>trainable:</strong> If True also add the variable to the graph collection <em>GraphKeys.TRAINABLE_VARIABLES</em> (see tf.Variable). collections: List of graph collections keys to add the Variable to. Defaults to <em>[GraphKeys.GLOBAL_VARIABLES]</em> (see tf.Variable).</p>\n</li>\n</ul>\n<h3 id=\"Variable-collections\"><a href=\"#Variable-collections\" class=\"headerlink\" title=\"Variable collections\"></a>Variable collections</h3><p>Because disconnected parts of a TensorFlow program might want to create variables, it is sometimes useful to have a single way to access all of them.For this reason TensorFlow provides collections, which are named lists of tensors or other objects, such as tf.Variable instances</p>\n<p>By default every tf.Variable gets placed in the following two collections:</p>\n<pre><code>tf.GraphKeys.GLOBAL_VARIABLES --- variables that can be shared across multiple devices,\ntf.GraphKeys.TRAINABLE_VARIABLES --- variables for which TensorFlow will calculate gradients.\n</code></pre><p>If you don’t want a variable to be trainable, add it to the <strong>tf.GraphKeys.LOCAL_VARIABLES</strong> collection instead.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my_local = tf.get_variable(<span class=\"string\">\"my_local\"</span>, shape=(),</span><br><span class=\"line\">collections=[tf.GraphKeys.LOCAL_VARIABLES])</span><br><span class=\"line\"></span><br><span class=\"line\">my_non_trainable = tf.get_variable(<span class=\"string\">\"my_non_trainable\"</span>,</span><br><span class=\"line\">                                   shape=(),</span><br><span class=\"line\">                                   trainable=<span class=\"keyword\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">tf.add_to_collection(<span class=\"string\">\"my_collection_name\"</span>, my_local)</span><br><span class=\"line\"><span class=\"comment\">#  retrieve a list of all the variables</span></span><br><span class=\"line\">tf.get_collection(<span class=\"string\">\"my_collection_name\"</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Initializing-variables\"><a href=\"#Initializing-variables\" class=\"headerlink\" title=\"Initializing variables\"></a>Initializing variables</h3><p>To initialize all trainable variables in one go, before training starts, call <strong>tf.global_variables_initializer()</strong>. This function returns a single operation responsible for initializing all variables in the <strong>tf.GraphKeys.GLOBAL_VARIABLES</strong> collection.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session.run(tf.global_variables_initializer())</span><br><span class=\"line\"><span class=\"comment\"># Now all variables are initialized.</span></span><br><span class=\"line\">session.run(my_variable.initializer)</span><br></pre></td></tr></table></figure>\n<p>Note that by default tf.global_variables_initializer does not specify the order in which variables are initialized. Therefore, if the initial value of a variable depends on another variable’s value, it’s likely that you’ll get an error. Any time you use the value of a variable in a context in which not all variables are initialized (say, if you use a variable’s value while initializing another variable), it is best to use <strong>variable.initialized_value()</strong> instead of variable:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v = tf.get_variable(<span class=\"string\">\"v\"</span>, shape=(), initializer=tf.zeros_initializer())</span><br><span class=\"line\">w = tf.get_variable(<span class=\"string\">\"w\"</span>, initializer=v.initialized_value() + <span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Using-variable\"><a href=\"#Using-variable\" class=\"headerlink\" title=\"Using variable\"></a>Using variable</h3><p>To use the value of a tf.Variable in a TensorFlow graph, simply treat it like a normal tf.Tensor:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v = tf.get_variable(<span class=\"string\">\"v\"</span>, shape=(), initializer=tf.zeros_initializer())</span><br><span class=\"line\">w = v + <span class=\"number\">1</span>  <span class=\"comment\"># w is a tf.Tensor which is computed based on the value of v.</span></span><br><span class=\"line\">           <span class=\"comment\"># Any time a variable is used in an expression it gets automatically</span></span><br><span class=\"line\">           <span class=\"comment\"># converted to a tf.Tensor representing its value.</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Sharing-variables\"><a href=\"#Sharing-variables\" class=\"headerlink\" title=\"Sharing variables\"></a>Sharing variables</h3><p>TensorFlow supports two ways of sharing variables:</p>\n<pre><code>Explicitly passing tf.Variable objects around.\nImplicitly wrapping tf.Variable objects within tf.variable_scope objects.\n</code></pre><p>Variable scopes allow you to control variable reuse when calling functions which implicitly create and use variables. They also allow you to name your variables in a hierarchical and understandable way.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv</span><span class=\"params\">(x, filter_height, filter_width, num_filters, stride_y, stride_x, name, padding=<span class=\"string\">'SAME'</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># Get number of input channels</span></span><br><span class=\"line\">    input_channels = int(x.get_shape()[<span class=\"number\">-1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># create lambda function for the convolution</span></span><br><span class=\"line\">    convolve = <span class=\"keyword\">lambda</span> i, k: tf.nn.conv2d(i, k, strides=[<span class=\"number\">1</span>, stride_y, stride_x, <span class=\"number\">1</span>], padding=padding)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.variable_scope(name) <span class=\"keyword\">as</span> scope:</span><br><span class=\"line\">        weights = tf.get_variable(<span class=\"string\">'weights'</span>, shape=[filter_height, filter_width, input_channels, num_filters])</span><br><span class=\"line\">        biases = tf.get_variable(<span class=\"string\">'biases'</span>, shape=[num_filters])</span><br><span class=\"line\">        conv = convolve(x, weights)</span><br><span class=\"line\">        bias = tf.reshape(tf.nn.bias_add(conv, biases))</span><br><span class=\"line\">        <span class=\"comment\"># Apply relu function</span></span><br><span class=\"line\">        relu = tf.nn.relu(bias, name=scope.name)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> relu</span><br></pre></td></tr></table></figure>\n"},{"title":"人脸识别","date":"2018-09-02T13:13:33.000Z","mathjax":true,"_content":"**人脸验证（Face Verification）** 和 **人脸识别（Face Recognition）** 的区别：\n\n* 人脸验证：一般指一个一对一问题，只需要验证输入的人脸图像是否与某个已知的身份信息对应；\n* 人脸识别：一个更为复杂的一对多问题，需要验证输入的人脸图像是否与多个已知身份信息中的某一个匹配。\n\n一般来说，由于需要匹配的身份信息更多导致错误率增加，人脸识别比人脸验证更难一些。\n\n### One-Shot 学习\n\n人脸识别所面临的一个挑战是要求系统只采集某人的一个面部样本，就能快速准确地识别出这个人，即只用一个训练样本来获得准确的预测结果。这被称为 **One-Shot 学习**。\n\n有一种方法是假设数据库中存有 N 个人的身份信息，对于每张输入图像，用 Softmax 输出 N+1 种标签，分别对应每个人以及都不是。然而这种方法的实际效果很差，因为过小的训练集不足以训练出一个稳健的神经网络；并且如果有新的身份信息入库，需要重新训练神经网络，不够灵活。\n\n因此，我们通过学习一个 Similarity 函数来实现 One-Shot 学习过程。Similarity 函数定义了输入的两幅图像的差异度，其公式如下：\n\n$$Similarity  = d(img1, img2)$$\n\n可以设置一个超参数 $τ$ 作为阈值，作为判断两幅图片是否为同一个人的依据。\n\n### Siamese 网络\n\n实现 Similarity 函数的一种方式是使用 **Siamese 网络**，它是一种对两个不同输入运行相同的卷积网络，然后对它们的结果进行比较的神经网络。\n\n![Siamese](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Siamese.png)\n\n如上图示例，将图片 $x^{(1)}$、$x^{(2)}$ 分别输入两个相同的卷积网络中，经过全连接层后不再进行 Softmax，而是得到特征向量 $f(x^{(1)})$、$f(x^{(2)})$。这时，Similarity 函数就被定义为两个特征向量之差的 L2 范数：\n\n$$d(x^{(1)}, x^{(2)}) = ||f(x^{(1)}) - f(x^{(2)})||^2_2$$\n\n相关论文：[Taigman et al., 2014, DeepFace closing the gap to human level performance](http://www.cs.wayne.edu/~mdong/taigman_cvpr14.pdf)\n\n### Triplet 损失\n\n**Triplet 损失函数** 用于训练出合适的参数，以获得高质量的人脸图像编码。“Triplet”一词来源于训练这个神经网络需要大量包含 Anchor（靶目标）、Positive（正例）、Negative（反例）的图片组，其中 Anchor 和 Positive 需要是同一个人的人脸图像。\n\n![Training-set-using-triplet-loss](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Training-set-using-triplet-loss.png)\n\n对于这三张图片，应该有：\n\n$$||f(A) - f(P)||^2_2 + \\alpha \\le ||f(A) - f(N)||^2_2$$\n\n其中，$\\alpha$ 被称为 **间隔（margin）**，用于确保 $f()$ 不会总是输出零向量（或者一个恒定的值）。\n\nTriplet 损失函数的定义：\n\n$$L(A, P, N) = max(||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha, 0)$$\n\n其中，因为 $||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha$ 的值需要小于等于 0，因此取它和 0 的更大值。\n\n对于大小为 $m$ 的训练集，代价函数为：\n\n$$J = \\sum^m_{i=1}L(A^{(i)}, P^{(i)}, N^{(i)})$$\n\n通过梯度下降最小化代价函数。\n\n在选择训练样本时，随机选择容易使 Anchor 和 Positive 极为接近，而 Anchor 和 Negative 相差较大，以致训练出来的模型容易抓不到关键的区别。因此，最好的做法是人为增加 Anchor 和 Positive 的区别，缩小 Anchor 和 Negative 的区别，促使模型去学习不同人脸之间的关键差异。\n\n相关论文：[Schroff et al., 2015,  FaceNet: A unified embedding for face recognition and clustering](https://arxiv.org/pdf/1503.03832.pdf)\n\n### 二分类结构\n\n除了 Triplet 损失函数，二分类结构也可用于学习参数以解决人脸识别问题。其做法是输入一对图片，将两个 Siamese 网络产生的特征向量输入至同一个 Sigmoid 单元，输出 1 则表示是识别为同一人，输出 0 则表示识别为不同的人。\n\nSigmoid 单元对应的表达式为：\n$$\\hat y = \\sigma (\\sum^K_{k=1}w_k|f(x^{(i)})\\_{k} - x^{(j)}_{k}| + b)$$\n\n其中，$w_k$ 和 $b$ 都是通过梯度下降算法迭代训练得到的参数。上述计算表达式也可以用另一种表达式代替：\n\n$$\\hat y = \\sigma (\\sum^K_{k=1}w_k\n\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k} + b)$$\n\n其中，$\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k}$ 被称为 $\\chi$ 方相似度。\n\n无论是对于使用 Triplet 损失函数的网络，还是二分类结构，为了减少计算量，可以提前计算好编码输出 $f(x)$ 并保存。这样就不必存储原始图片，并且每次进行人脸识别时只需要计算测试图片的编码输出。\n","source":"_posts/人脸识别.md","raw":"---\ntitle: 人脸识别\ndate: 2018-09-02 21:13:33\ntags: 计算机视觉\ncategories: 深度学习\nmathjax: true\n---\n**人脸验证（Face Verification）** 和 **人脸识别（Face Recognition）** 的区别：\n\n* 人脸验证：一般指一个一对一问题，只需要验证输入的人脸图像是否与某个已知的身份信息对应；\n* 人脸识别：一个更为复杂的一对多问题，需要验证输入的人脸图像是否与多个已知身份信息中的某一个匹配。\n\n一般来说，由于需要匹配的身份信息更多导致错误率增加，人脸识别比人脸验证更难一些。\n\n### One-Shot 学习\n\n人脸识别所面临的一个挑战是要求系统只采集某人的一个面部样本，就能快速准确地识别出这个人，即只用一个训练样本来获得准确的预测结果。这被称为 **One-Shot 学习**。\n\n有一种方法是假设数据库中存有 N 个人的身份信息，对于每张输入图像，用 Softmax 输出 N+1 种标签，分别对应每个人以及都不是。然而这种方法的实际效果很差，因为过小的训练集不足以训练出一个稳健的神经网络；并且如果有新的身份信息入库，需要重新训练神经网络，不够灵活。\n\n因此，我们通过学习一个 Similarity 函数来实现 One-Shot 学习过程。Similarity 函数定义了输入的两幅图像的差异度，其公式如下：\n\n$$Similarity  = d(img1, img2)$$\n\n可以设置一个超参数 $τ$ 作为阈值，作为判断两幅图片是否为同一个人的依据。\n\n### Siamese 网络\n\n实现 Similarity 函数的一种方式是使用 **Siamese 网络**，它是一种对两个不同输入运行相同的卷积网络，然后对它们的结果进行比较的神经网络。\n\n![Siamese](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Siamese.png)\n\n如上图示例，将图片 $x^{(1)}$、$x^{(2)}$ 分别输入两个相同的卷积网络中，经过全连接层后不再进行 Softmax，而是得到特征向量 $f(x^{(1)})$、$f(x^{(2)})$。这时，Similarity 函数就被定义为两个特征向量之差的 L2 范数：\n\n$$d(x^{(1)}, x^{(2)}) = ||f(x^{(1)}) - f(x^{(2)})||^2_2$$\n\n相关论文：[Taigman et al., 2014, DeepFace closing the gap to human level performance](http://www.cs.wayne.edu/~mdong/taigman_cvpr14.pdf)\n\n### Triplet 损失\n\n**Triplet 损失函数** 用于训练出合适的参数，以获得高质量的人脸图像编码。“Triplet”一词来源于训练这个神经网络需要大量包含 Anchor（靶目标）、Positive（正例）、Negative（反例）的图片组，其中 Anchor 和 Positive 需要是同一个人的人脸图像。\n\n![Training-set-using-triplet-loss](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Training-set-using-triplet-loss.png)\n\n对于这三张图片，应该有：\n\n$$||f(A) - f(P)||^2_2 + \\alpha \\le ||f(A) - f(N)||^2_2$$\n\n其中，$\\alpha$ 被称为 **间隔（margin）**，用于确保 $f()$ 不会总是输出零向量（或者一个恒定的值）。\n\nTriplet 损失函数的定义：\n\n$$L(A, P, N) = max(||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha, 0)$$\n\n其中，因为 $||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha$ 的值需要小于等于 0，因此取它和 0 的更大值。\n\n对于大小为 $m$ 的训练集，代价函数为：\n\n$$J = \\sum^m_{i=1}L(A^{(i)}, P^{(i)}, N^{(i)})$$\n\n通过梯度下降最小化代价函数。\n\n在选择训练样本时，随机选择容易使 Anchor 和 Positive 极为接近，而 Anchor 和 Negative 相差较大，以致训练出来的模型容易抓不到关键的区别。因此，最好的做法是人为增加 Anchor 和 Positive 的区别，缩小 Anchor 和 Negative 的区别，促使模型去学习不同人脸之间的关键差异。\n\n相关论文：[Schroff et al., 2015,  FaceNet: A unified embedding for face recognition and clustering](https://arxiv.org/pdf/1503.03832.pdf)\n\n### 二分类结构\n\n除了 Triplet 损失函数，二分类结构也可用于学习参数以解决人脸识别问题。其做法是输入一对图片，将两个 Siamese 网络产生的特征向量输入至同一个 Sigmoid 单元，输出 1 则表示是识别为同一人，输出 0 则表示识别为不同的人。\n\nSigmoid 单元对应的表达式为：\n$$\\hat y = \\sigma (\\sum^K_{k=1}w_k|f(x^{(i)})\\_{k} - x^{(j)}_{k}| + b)$$\n\n其中，$w_k$ 和 $b$ 都是通过梯度下降算法迭代训练得到的参数。上述计算表达式也可以用另一种表达式代替：\n\n$$\\hat y = \\sigma (\\sum^K_{k=1}w_k\n\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k} + b)$$\n\n其中，$\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k}$ 被称为 $\\chi$ 方相似度。\n\n无论是对于使用 Triplet 损失函数的网络，还是二分类结构，为了减少计算量，可以提前计算好编码输出 $f(x)$ 并保存。这样就不必存储原始图片，并且每次进行人脸识别时只需要计算测试图片的编码输出。\n","slug":"人脸识别","published":1,"updated":"2018-09-05T10:02:01.859Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds460024pcvo4qkm87z0","content":"<p><strong>人脸验证（Face Verification）</strong> 和 <strong>人脸识别（Face Recognition）</strong> 的区别：</p>\n<ul>\n<li>人脸验证：一般指一个一对一问题，只需要验证输入的人脸图像是否与某个已知的身份信息对应；</li>\n<li>人脸识别：一个更为复杂的一对多问题，需要验证输入的人脸图像是否与多个已知身份信息中的某一个匹配。</li>\n</ul>\n<p>一般来说，由于需要匹配的身份信息更多导致错误率增加，人脸识别比人脸验证更难一些。</p>\n<h3 id=\"One-Shot-学习\"><a href=\"#One-Shot-学习\" class=\"headerlink\" title=\"One-Shot 学习\"></a>One-Shot 学习</h3><p>人脸识别所面临的一个挑战是要求系统只采集某人的一个面部样本，就能快速准确地识别出这个人，即只用一个训练样本来获得准确的预测结果。这被称为 <strong>One-Shot 学习</strong>。</p>\n<p>有一种方法是假设数据库中存有 N 个人的身份信息，对于每张输入图像，用 Softmax 输出 N+1 种标签，分别对应每个人以及都不是。然而这种方法的实际效果很差，因为过小的训练集不足以训练出一个稳健的神经网络；并且如果有新的身份信息入库，需要重新训练神经网络，不够灵活。</p>\n<p>因此，我们通过学习一个 Similarity 函数来实现 One-Shot 学习过程。Similarity 函数定义了输入的两幅图像的差异度，其公式如下：</p>\n<p>$$Similarity  = d(img1, img2)$$</p>\n<p>可以设置一个超参数 $τ$ 作为阈值，作为判断两幅图片是否为同一个人的依据。</p>\n<h3 id=\"Siamese-网络\"><a href=\"#Siamese-网络\" class=\"headerlink\" title=\"Siamese 网络\"></a>Siamese 网络</h3><p>实现 Similarity 函数的一种方式是使用 <strong>Siamese 网络</strong>，它是一种对两个不同输入运行相同的卷积网络，然后对它们的结果进行比较的神经网络。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Siamese.png\" alt=\"Siamese\"></p>\n<p>如上图示例，将图片 $x^{(1)}$、$x^{(2)}$ 分别输入两个相同的卷积网络中，经过全连接层后不再进行 Softmax，而是得到特征向量 $f(x^{(1)})$、$f(x^{(2)})$。这时，Similarity 函数就被定义为两个特征向量之差的 L2 范数：</p>\n<p>$$d(x^{(1)}, x^{(2)}) = ||f(x^{(1)}) - f(x^{(2)})||^2_2$$</p>\n<p>相关论文：<a href=\"http://www.cs.wayne.edu/~mdong/taigman_cvpr14.pdf\" target=\"_blank\" rel=\"noopener\">Taigman et al., 2014, DeepFace closing the gap to human level performance</a></p>\n<h3 id=\"Triplet-损失\"><a href=\"#Triplet-损失\" class=\"headerlink\" title=\"Triplet 损失\"></a>Triplet 损失</h3><p><strong>Triplet 损失函数</strong> 用于训练出合适的参数，以获得高质量的人脸图像编码。“Triplet”一词来源于训练这个神经网络需要大量包含 Anchor（靶目标）、Positive（正例）、Negative（反例）的图片组，其中 Anchor 和 Positive 需要是同一个人的人脸图像。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Training-set-using-triplet-loss.png\" alt=\"Training-set-using-triplet-loss\"></p>\n<p>对于这三张图片，应该有：</p>\n<p>$$||f(A) - f(P)||^2_2 + \\alpha \\le ||f(A) - f(N)||^2_2$$</p>\n<p>其中，$\\alpha$ 被称为 <strong>间隔（margin）</strong>，用于确保 $f()$ 不会总是输出零向量（或者一个恒定的值）。</p>\n<p>Triplet 损失函数的定义：</p>\n<p>$$L(A, P, N) = max(||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha, 0)$$</p>\n<p>其中，因为 $||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha$ 的值需要小于等于 0，因此取它和 0 的更大值。</p>\n<p>对于大小为 $m$ 的训练集，代价函数为：</p>\n<p>$$J = \\sum^m_{i=1}L(A^{(i)}, P^{(i)}, N^{(i)})$$</p>\n<p>通过梯度下降最小化代价函数。</p>\n<p>在选择训练样本时，随机选择容易使 Anchor 和 Positive 极为接近，而 Anchor 和 Negative 相差较大，以致训练出来的模型容易抓不到关键的区别。因此，最好的做法是人为增加 Anchor 和 Positive 的区别，缩小 Anchor 和 Negative 的区别，促使模型去学习不同人脸之间的关键差异。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1503.03832.pdf\" target=\"_blank\" rel=\"noopener\">Schroff et al., 2015,  FaceNet: A unified embedding for face recognition and clustering</a></p>\n<h3 id=\"二分类结构\"><a href=\"#二分类结构\" class=\"headerlink\" title=\"二分类结构\"></a>二分类结构</h3><p>除了 Triplet 损失函数，二分类结构也可用于学习参数以解决人脸识别问题。其做法是输入一对图片，将两个 Siamese 网络产生的特征向量输入至同一个 Sigmoid 单元，输出 1 则表示是识别为同一人，输出 0 则表示识别为不同的人。</p>\n<p>Sigmoid 单元对应的表达式为：<br>$$\\hat y = \\sigma (\\sum^K_{k=1}w_k|f(x^{(i)})_{k} - x^{(j)}_{k}| + b)$$</p>\n<p>其中，$w_k$ 和 $b$ 都是通过梯度下降算法迭代训练得到的参数。上述计算表达式也可以用另一种表达式代替：</p>\n<p>$$\\hat y = \\sigma (\\sum^K_{k=1}w_k<br>\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k} + b)$$</p>\n<p>其中，$\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k}$ 被称为 $\\chi$ 方相似度。</p>\n<p>无论是对于使用 Triplet 损失函数的网络，还是二分类结构，为了减少计算量，可以提前计算好编码输出 $f(x)$ 并保存。这样就不必存储原始图片，并且每次进行人脸识别时只需要计算测试图片的编码输出。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>人脸验证（Face Verification）</strong> 和 <strong>人脸识别（Face Recognition）</strong> 的区别：</p>\n<ul>\n<li>人脸验证：一般指一个一对一问题，只需要验证输入的人脸图像是否与某个已知的身份信息对应；</li>\n<li>人脸识别：一个更为复杂的一对多问题，需要验证输入的人脸图像是否与多个已知身份信息中的某一个匹配。</li>\n</ul>\n<p>一般来说，由于需要匹配的身份信息更多导致错误率增加，人脸识别比人脸验证更难一些。</p>\n<h3 id=\"One-Shot-学习\"><a href=\"#One-Shot-学习\" class=\"headerlink\" title=\"One-Shot 学习\"></a>One-Shot 学习</h3><p>人脸识别所面临的一个挑战是要求系统只采集某人的一个面部样本，就能快速准确地识别出这个人，即只用一个训练样本来获得准确的预测结果。这被称为 <strong>One-Shot 学习</strong>。</p>\n<p>有一种方法是假设数据库中存有 N 个人的身份信息，对于每张输入图像，用 Softmax 输出 N+1 种标签，分别对应每个人以及都不是。然而这种方法的实际效果很差，因为过小的训练集不足以训练出一个稳健的神经网络；并且如果有新的身份信息入库，需要重新训练神经网络，不够灵活。</p>\n<p>因此，我们通过学习一个 Similarity 函数来实现 One-Shot 学习过程。Similarity 函数定义了输入的两幅图像的差异度，其公式如下：</p>\n<p>$$Similarity  = d(img1, img2)$$</p>\n<p>可以设置一个超参数 $τ$ 作为阈值，作为判断两幅图片是否为同一个人的依据。</p>\n<h3 id=\"Siamese-网络\"><a href=\"#Siamese-网络\" class=\"headerlink\" title=\"Siamese 网络\"></a>Siamese 网络</h3><p>实现 Similarity 函数的一种方式是使用 <strong>Siamese 网络</strong>，它是一种对两个不同输入运行相同的卷积网络，然后对它们的结果进行比较的神经网络。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Siamese.png\" alt=\"Siamese\"></p>\n<p>如上图示例，将图片 $x^{(1)}$、$x^{(2)}$ 分别输入两个相同的卷积网络中，经过全连接层后不再进行 Softmax，而是得到特征向量 $f(x^{(1)})$、$f(x^{(2)})$。这时，Similarity 函数就被定义为两个特征向量之差的 L2 范数：</p>\n<p>$$d(x^{(1)}, x^{(2)}) = ||f(x^{(1)}) - f(x^{(2)})||^2_2$$</p>\n<p>相关论文：<a href=\"http://www.cs.wayne.edu/~mdong/taigman_cvpr14.pdf\" target=\"_blank\" rel=\"noopener\">Taigman et al., 2014, DeepFace closing the gap to human level performance</a></p>\n<h3 id=\"Triplet-损失\"><a href=\"#Triplet-损失\" class=\"headerlink\" title=\"Triplet 损失\"></a>Triplet 损失</h3><p><strong>Triplet 损失函数</strong> 用于训练出合适的参数，以获得高质量的人脸图像编码。“Triplet”一词来源于训练这个神经网络需要大量包含 Anchor（靶目标）、Positive（正例）、Negative（反例）的图片组，其中 Anchor 和 Positive 需要是同一个人的人脸图像。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Training-set-using-triplet-loss.png\" alt=\"Training-set-using-triplet-loss\"></p>\n<p>对于这三张图片，应该有：</p>\n<p>$$||f(A) - f(P)||^2_2 + \\alpha \\le ||f(A) - f(N)||^2_2$$</p>\n<p>其中，$\\alpha$ 被称为 <strong>间隔（margin）</strong>，用于确保 $f()$ 不会总是输出零向量（或者一个恒定的值）。</p>\n<p>Triplet 损失函数的定义：</p>\n<p>$$L(A, P, N) = max(||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha, 0)$$</p>\n<p>其中，因为 $||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha$ 的值需要小于等于 0，因此取它和 0 的更大值。</p>\n<p>对于大小为 $m$ 的训练集，代价函数为：</p>\n<p>$$J = \\sum^m_{i=1}L(A^{(i)}, P^{(i)}, N^{(i)})$$</p>\n<p>通过梯度下降最小化代价函数。</p>\n<p>在选择训练样本时，随机选择容易使 Anchor 和 Positive 极为接近，而 Anchor 和 Negative 相差较大，以致训练出来的模型容易抓不到关键的区别。因此，最好的做法是人为增加 Anchor 和 Positive 的区别，缩小 Anchor 和 Negative 的区别，促使模型去学习不同人脸之间的关键差异。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1503.03832.pdf\" target=\"_blank\" rel=\"noopener\">Schroff et al., 2015,  FaceNet: A unified embedding for face recognition and clustering</a></p>\n<h3 id=\"二分类结构\"><a href=\"#二分类结构\" class=\"headerlink\" title=\"二分类结构\"></a>二分类结构</h3><p>除了 Triplet 损失函数，二分类结构也可用于学习参数以解决人脸识别问题。其做法是输入一对图片，将两个 Siamese 网络产生的特征向量输入至同一个 Sigmoid 单元，输出 1 则表示是识别为同一人，输出 0 则表示识别为不同的人。</p>\n<p>Sigmoid 单元对应的表达式为：<br>$$\\hat y = \\sigma (\\sum^K_{k=1}w_k|f(x^{(i)})_{k} - x^{(j)}_{k}| + b)$$</p>\n<p>其中，$w_k$ 和 $b$ 都是通过梯度下降算法迭代训练得到的参数。上述计算表达式也可以用另一种表达式代替：</p>\n<p>$$\\hat y = \\sigma (\\sum^K_{k=1}w_k<br>\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k} + b)$$</p>\n<p>其中，$\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k}$ 被称为 $\\chi$ 方相似度。</p>\n<p>无论是对于使用 Triplet 损失函数的网络，还是二分类结构，为了减少计算量，可以提前计算好编码输出 $f(x)$ 并保存。这样就不必存储原始图片，并且每次进行人脸识别时只需要计算测试图片的编码输出。</p>\n"},{"title":"信息简史","date":"2018-09-17T11:46:41.000Z","_content":">通信的基本问题是，在一点精确地或近似地复现在另一点所选取的讯息。这些讯息往往都带有意义。-- 克劳德.香龙, 《通信的数学理论》\n\n生物体中的所有细胞都是一个错综复杂的通信网络中的节点，它们一刻不停地传输和接受信息，不停地编码和解码。进化本身正是生物体与环境之间持续不断的信息交换的具体表现。\n\n>万物源自比特。(It from Bit)。未来我们将用信息的语言去理解和表达全部物理学。--物理学家约翰.阿奇博尔德.惠勒。\n\n当光子、电子以及其他基本粒子发生相互作用时，它们实际在做什么呢？其实是在交换比特、转换量子态以及处理信息，而物理定律就是处理信息时所用的算法。\n\n\n### 会说话的鼓\n\n在非洲，很早以前的一种通信工具是鼓，人们用鼓来传递消息，每个村庄都有鼓。鼓声沿村庄一个接一个地传递，可以传到很远的地方。为什么他们能听出鼓声所代表的消息呢？这要从非洲语言的核心特点说起。就像汉语一样，非洲语言也是一些声调语言，同一个单词不同的声调会带来不同的读音，也代表着不同的意思。鼓语就是借着这样的特点，将不同的音调转换成高低音的不同来编码口语的。然而有一些词的读音相同但意思不同，这又是怎样区分的呢？这就要考虑上下文的语境了。所以人们在表达一个词时，会加上很多修饰来丰富它的语境。这种 **为避免语言歧义而添加冗余信息** 的例子还在很多地方可见，比如另一种专业化的语言--航空通信的语言。\n\n摩尔斯电码的4个基本元素：点（点击），点击之间的停顿，线（电路的闭合时间比发送一个点更长），停顿（用来间隔词与词，句子与句子）\n\n实际上每一种自然语言都内在地包含冗余，这也是为什么人们可以读懂错别字连篇的文章。“if u cn rd ths, u cn gt a gd jb w hi pa!”\n","source":"_posts/信息简史.md","raw":"---\ntitle: 信息简史\ndate: 2018-09-17 19:46:41\ntags: 信息简史\ncategories: 科普读物\n---\n>通信的基本问题是，在一点精确地或近似地复现在另一点所选取的讯息。这些讯息往往都带有意义。-- 克劳德.香龙, 《通信的数学理论》\n\n生物体中的所有细胞都是一个错综复杂的通信网络中的节点，它们一刻不停地传输和接受信息，不停地编码和解码。进化本身正是生物体与环境之间持续不断的信息交换的具体表现。\n\n>万物源自比特。(It from Bit)。未来我们将用信息的语言去理解和表达全部物理学。--物理学家约翰.阿奇博尔德.惠勒。\n\n当光子、电子以及其他基本粒子发生相互作用时，它们实际在做什么呢？其实是在交换比特、转换量子态以及处理信息，而物理定律就是处理信息时所用的算法。\n\n\n### 会说话的鼓\n\n在非洲，很早以前的一种通信工具是鼓，人们用鼓来传递消息，每个村庄都有鼓。鼓声沿村庄一个接一个地传递，可以传到很远的地方。为什么他们能听出鼓声所代表的消息呢？这要从非洲语言的核心特点说起。就像汉语一样，非洲语言也是一些声调语言，同一个单词不同的声调会带来不同的读音，也代表着不同的意思。鼓语就是借着这样的特点，将不同的音调转换成高低音的不同来编码口语的。然而有一些词的读音相同但意思不同，这又是怎样区分的呢？这就要考虑上下文的语境了。所以人们在表达一个词时，会加上很多修饰来丰富它的语境。这种 **为避免语言歧义而添加冗余信息** 的例子还在很多地方可见，比如另一种专业化的语言--航空通信的语言。\n\n摩尔斯电码的4个基本元素：点（点击），点击之间的停顿，线（电路的闭合时间比发送一个点更长），停顿（用来间隔词与词，句子与句子）\n\n实际上每一种自然语言都内在地包含冗余，这也是为什么人们可以读懂错别字连篇的文章。“if u cn rd ths, u cn gt a gd jb w hi pa!”\n","slug":"信息简史","published":1,"updated":"2018-09-22T03:50:09.092Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds460027pcvoy2r0028l","content":"<blockquote>\n<p>通信的基本问题是，在一点精确地或近似地复现在另一点所选取的讯息。这些讯息往往都带有意义。– 克劳德.香龙, 《通信的数学理论》</p>\n</blockquote>\n<p>生物体中的所有细胞都是一个错综复杂的通信网络中的节点，它们一刻不停地传输和接受信息，不停地编码和解码。进化本身正是生物体与环境之间持续不断的信息交换的具体表现。</p>\n<blockquote>\n<p>万物源自比特。(It from Bit)。未来我们将用信息的语言去理解和表达全部物理学。–物理学家约翰.阿奇博尔德.惠勒。</p>\n</blockquote>\n<p>当光子、电子以及其他基本粒子发生相互作用时，它们实际在做什么呢？其实是在交换比特、转换量子态以及处理信息，而物理定律就是处理信息时所用的算法。</p>\n<h3 id=\"会说话的鼓\"><a href=\"#会说话的鼓\" class=\"headerlink\" title=\"会说话的鼓\"></a>会说话的鼓</h3><p>在非洲，很早以前的一种通信工具是鼓，人们用鼓来传递消息，每个村庄都有鼓。鼓声沿村庄一个接一个地传递，可以传到很远的地方。为什么他们能听出鼓声所代表的消息呢？这要从非洲语言的核心特点说起。就像汉语一样，非洲语言也是一些声调语言，同一个单词不同的声调会带来不同的读音，也代表着不同的意思。鼓语就是借着这样的特点，将不同的音调转换成高低音的不同来编码口语的。然而有一些词的读音相同但意思不同，这又是怎样区分的呢？这就要考虑上下文的语境了。所以人们在表达一个词时，会加上很多修饰来丰富它的语境。这种 <strong>为避免语言歧义而添加冗余信息</strong> 的例子还在很多地方可见，比如另一种专业化的语言–航空通信的语言。</p>\n<p>摩尔斯电码的4个基本元素：点（点击），点击之间的停顿，线（电路的闭合时间比发送一个点更长），停顿（用来间隔词与词，句子与句子）</p>\n<p>实际上每一种自然语言都内在地包含冗余，这也是为什么人们可以读懂错别字连篇的文章。“if u cn rd ths, u cn gt a gd jb w hi pa!”</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>通信的基本问题是，在一点精确地或近似地复现在另一点所选取的讯息。这些讯息往往都带有意义。– 克劳德.香龙, 《通信的数学理论》</p>\n</blockquote>\n<p>生物体中的所有细胞都是一个错综复杂的通信网络中的节点，它们一刻不停地传输和接受信息，不停地编码和解码。进化本身正是生物体与环境之间持续不断的信息交换的具体表现。</p>\n<blockquote>\n<p>万物源自比特。(It from Bit)。未来我们将用信息的语言去理解和表达全部物理学。–物理学家约翰.阿奇博尔德.惠勒。</p>\n</blockquote>\n<p>当光子、电子以及其他基本粒子发生相互作用时，它们实际在做什么呢？其实是在交换比特、转换量子态以及处理信息，而物理定律就是处理信息时所用的算法。</p>\n<h3 id=\"会说话的鼓\"><a href=\"#会说话的鼓\" class=\"headerlink\" title=\"会说话的鼓\"></a>会说话的鼓</h3><p>在非洲，很早以前的一种通信工具是鼓，人们用鼓来传递消息，每个村庄都有鼓。鼓声沿村庄一个接一个地传递，可以传到很远的地方。为什么他们能听出鼓声所代表的消息呢？这要从非洲语言的核心特点说起。就像汉语一样，非洲语言也是一些声调语言，同一个单词不同的声调会带来不同的读音，也代表着不同的意思。鼓语就是借着这样的特点，将不同的音调转换成高低音的不同来编码口语的。然而有一些词的读音相同但意思不同，这又是怎样区分的呢？这就要考虑上下文的语境了。所以人们在表达一个词时，会加上很多修饰来丰富它的语境。这种 <strong>为避免语言歧义而添加冗余信息</strong> 的例子还在很多地方可见，比如另一种专业化的语言–航空通信的语言。</p>\n<p>摩尔斯电码的4个基本元素：点（点击），点击之间的停顿，线（电路的闭合时间比发送一个点更长），停顿（用来间隔词与词，句子与句子）</p>\n<p>实际上每一种自然语言都内在地包含冗余，这也是为什么人们可以读懂错别字连篇的文章。“if u cn rd ths, u cn gt a gd jb w hi pa!”</p>\n"},{"title":"动态规划","date":"2018-07-21T14:47:53.000Z","mathjax":true,"_content":"## 动态规划（dynamic programming）\n\n与分治法相似，都是通过组合子问题的解来求解原问题。不同的是，动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题。在这种情况下，动态规划算法对每个子子问题只求解一次，将其保存在一个表格中，减少了计算量。\n\n通常用来求解最优化问题。\n\n我们通常按如下4个步骤来设计一个动态规划算法：\n\n* 刻画一个最优解的结构特征\n* 递归地定义最优解的值\n* 计算最优解的值，通常采用自底向上的方法\n* 利用计算出的信息构造一个最优解\n\n## 钢条切割问题\n\n### 问题定义\n\n给定一段长度为$n$英寸的钢条（长度均为整英寸，切割后也必须是整英寸）和一个价格表$p_i(i=1, 2, ..., n)$, 求解切割钢条的方案（方案也可以是不切割），使收益$r_n$最大。\n\n### 问题分析\n\n长度为$n$英寸的钢条共有$2^{n-1}$种不同的切割方案，如果一个最优解将钢条切割为$k$段，那么最优切割方案为\n\n$$n = i_1 + i_2 + ... + i_k$$\n\n得到的最大收益为\n\n$$r_n = p_{i_1} + p_{i_2} + ... + p_{i_k}$$\n\n当完成首次切割后，我们将两段钢条看成两个独立的钢条切割问题实例。我们通过组合两个相关子问题的最优解，并在所有可能的两段切割方案种选取组合收益最大者，构成原问题的最优解。\n\n则最优切割收益为\n\n$$r_n = max(p_n, r_1 + r_{n-1}, r_2 + r_{n-2}, ..., r_{n-1} + r_1)$$\n\n除上述求解方法外，钢条切割问题还存在一种相似的但更为简单的递归求解方法：我们将钢条从左边切割下长度为$i$的一段，只对右边剩下的长度为$n-i$的一段继续进行切割（递归求解）。\n\n这样我们得到上述式子的简化版本\n\n$$r_n = \\mathop {\\max}_{1 \\le i \\le n}(p_i + r_{n-i})$$\n\n### 代码实现\n\n#### 自顶向下递归实现\n\n```python\ndef cut_rod(p, n):\n    \"\"\"\n    Arguments:\n    p -- the table of prices.\n    n -- the total length of steel rod.\n    \"\"\"\n    if n == 0:\n        return 0\n    q = -1\n    for i in range(1, n+1):\n        q = max(q, p[i] + cut_rod(p, n-i))\n    return q\n```\n\n#### 代码分析\n\n![](/images/动态规划.jpg)\n\n令$T(n)$表示cut_rod的调用次数\n\n$$T(n) = 1 + \\sum_{j=0}^{n-1} T(j) = 2^n$$\n\n第一项“1”表示函数的额第一次调用，$T(j)$为调用cut_rod(p, n-i)所产生的所有调用$(j = n-i)$\n\n#### 使用动态规划求解\n\n朴素递归算法之所以效率低，是因为它反复求解相同的子问题。因此，动态规划方法仔细安排求解顺序，对每个子问题只求解一次，并将结果保存下来。如果随后再次需要此子问题的解，只需查找保存的结果。\n\n动态规划有两种等价的实现。**带备忘的自顶向下**、**自底向上**。这里只给出第二种的代码。\n\n```python\ndef bottom_up_cut_rod(p, n):\n    \"\"\"\n    Arguments:\n    p -- the table of prices.\n    n -- the total length of steel rod.\n    \"\"\"\n    r = list(range(n + 1))  # to save subproblem's result\n    r[0] = 0\n    for j in range(1, n + 1):\n        q = -1\n        for i in range(1, j + 1):\n            q = max(q, p[i] + r[j - i])\n            r[j] = q\n    return r[n]\n```\n\n#### 代码分析\n\n自底向上版本采用子问题的自然顺序，一次求解规模为$j = 0, 1, 2, ..., n$的子问题。时间复杂度为$\\Theta(n^2)$\n\n#### 扩展代码\n\n前文给出的钢条切割问题的动态规划算法返回最优解的收益值，但未返回解本身。我们可以扩展动态规划算法，使之对每个子问题不仅保存最优收益值，还保存对应的切割方案。\n\n```python\ndef externed_bottom_up_cut_rod(p, n):\n    r = list(range(n + 1))  # 长度为j的钢条的最大收益值r_j\n    s = list(range(n + 1))  # 最优解对应的第一条钢条的长度s_j\n    r[0] = 0\n    for j in range(1, n + 1):\n        q = -1\n        for i in range(1, j + 1):\n            if q < p[i] + r[j - i]:\n                q = p[i] + r[j - i]\n                s[j] = i\n        r[j] = q\n    return r[n]\n\ndef print_cut_rod_solution(p, n):\n    (r, s) = externed_bottom_up_cut_rod(p, n)\n    print(r)\n    while n > 0:\n        print(s[n], end=' ')\n        n = n - s[n]\n```\n","source":"_posts/动态规划.md","raw":"---\ntitle: 动态规划\ndate: 2018-07-21 22:47:53\ntags: 动态规划\ncategories: 算法导论\nmathjax: true\n---\n## 动态规划（dynamic programming）\n\n与分治法相似，都是通过组合子问题的解来求解原问题。不同的是，动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题。在这种情况下，动态规划算法对每个子子问题只求解一次，将其保存在一个表格中，减少了计算量。\n\n通常用来求解最优化问题。\n\n我们通常按如下4个步骤来设计一个动态规划算法：\n\n* 刻画一个最优解的结构特征\n* 递归地定义最优解的值\n* 计算最优解的值，通常采用自底向上的方法\n* 利用计算出的信息构造一个最优解\n\n## 钢条切割问题\n\n### 问题定义\n\n给定一段长度为$n$英寸的钢条（长度均为整英寸，切割后也必须是整英寸）和一个价格表$p_i(i=1, 2, ..., n)$, 求解切割钢条的方案（方案也可以是不切割），使收益$r_n$最大。\n\n### 问题分析\n\n长度为$n$英寸的钢条共有$2^{n-1}$种不同的切割方案，如果一个最优解将钢条切割为$k$段，那么最优切割方案为\n\n$$n = i_1 + i_2 + ... + i_k$$\n\n得到的最大收益为\n\n$$r_n = p_{i_1} + p_{i_2} + ... + p_{i_k}$$\n\n当完成首次切割后，我们将两段钢条看成两个独立的钢条切割问题实例。我们通过组合两个相关子问题的最优解，并在所有可能的两段切割方案种选取组合收益最大者，构成原问题的最优解。\n\n则最优切割收益为\n\n$$r_n = max(p_n, r_1 + r_{n-1}, r_2 + r_{n-2}, ..., r_{n-1} + r_1)$$\n\n除上述求解方法外，钢条切割问题还存在一种相似的但更为简单的递归求解方法：我们将钢条从左边切割下长度为$i$的一段，只对右边剩下的长度为$n-i$的一段继续进行切割（递归求解）。\n\n这样我们得到上述式子的简化版本\n\n$$r_n = \\mathop {\\max}_{1 \\le i \\le n}(p_i + r_{n-i})$$\n\n### 代码实现\n\n#### 自顶向下递归实现\n\n```python\ndef cut_rod(p, n):\n    \"\"\"\n    Arguments:\n    p -- the table of prices.\n    n -- the total length of steel rod.\n    \"\"\"\n    if n == 0:\n        return 0\n    q = -1\n    for i in range(1, n+1):\n        q = max(q, p[i] + cut_rod(p, n-i))\n    return q\n```\n\n#### 代码分析\n\n![](/images/动态规划.jpg)\n\n令$T(n)$表示cut_rod的调用次数\n\n$$T(n) = 1 + \\sum_{j=0}^{n-1} T(j) = 2^n$$\n\n第一项“1”表示函数的额第一次调用，$T(j)$为调用cut_rod(p, n-i)所产生的所有调用$(j = n-i)$\n\n#### 使用动态规划求解\n\n朴素递归算法之所以效率低，是因为它反复求解相同的子问题。因此，动态规划方法仔细安排求解顺序，对每个子问题只求解一次，并将结果保存下来。如果随后再次需要此子问题的解，只需查找保存的结果。\n\n动态规划有两种等价的实现。**带备忘的自顶向下**、**自底向上**。这里只给出第二种的代码。\n\n```python\ndef bottom_up_cut_rod(p, n):\n    \"\"\"\n    Arguments:\n    p -- the table of prices.\n    n -- the total length of steel rod.\n    \"\"\"\n    r = list(range(n + 1))  # to save subproblem's result\n    r[0] = 0\n    for j in range(1, n + 1):\n        q = -1\n        for i in range(1, j + 1):\n            q = max(q, p[i] + r[j - i])\n            r[j] = q\n    return r[n]\n```\n\n#### 代码分析\n\n自底向上版本采用子问题的自然顺序，一次求解规模为$j = 0, 1, 2, ..., n$的子问题。时间复杂度为$\\Theta(n^2)$\n\n#### 扩展代码\n\n前文给出的钢条切割问题的动态规划算法返回最优解的收益值，但未返回解本身。我们可以扩展动态规划算法，使之对每个子问题不仅保存最优收益值，还保存对应的切割方案。\n\n```python\ndef externed_bottom_up_cut_rod(p, n):\n    r = list(range(n + 1))  # 长度为j的钢条的最大收益值r_j\n    s = list(range(n + 1))  # 最优解对应的第一条钢条的长度s_j\n    r[0] = 0\n    for j in range(1, n + 1):\n        q = -1\n        for i in range(1, j + 1):\n            if q < p[i] + r[j - i]:\n                q = p[i] + r[j - i]\n                s[j] = i\n        r[j] = q\n    return r[n]\n\ndef print_cut_rod_solution(p, n):\n    (r, s) = externed_bottom_up_cut_rod(p, n)\n    print(r)\n    while n > 0:\n        print(s[n], end=' ')\n        n = n - s[n]\n```\n","slug":"动态规划","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds4m002bpcvo3288fo85","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"动态规划（dynamic-programming）\"><a href=\"#动态规划（dynamic-programming）\" class=\"headerlink\" title=\"动态规划（dynamic programming）\"></a>动态规划（dynamic programming）</h2><p>与分治法相似，都是通过组合子问题的解来求解原问题。不同的是，动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题。在这种情况下，动态规划算法对每个子子问题只求解一次，将其保存在一个表格中，减少了计算量。</p>\n<p>通常用来求解最优化问题。</p>\n<p>我们通常按如下4个步骤来设计一个动态规划算法：</p>\n<ul>\n<li>刻画一个最优解的结构特征</li>\n<li>递归地定义最优解的值</li>\n<li>计算最优解的值，通常采用自底向上的方法</li>\n<li>利用计算出的信息构造一个最优解</li>\n</ul>\n<h2 id=\"钢条切割问题\"><a href=\"#钢条切割问题\" class=\"headerlink\" title=\"钢条切割问题\"></a>钢条切割问题</h2><h3 id=\"问题定义\"><a href=\"#问题定义\" class=\"headerlink\" title=\"问题定义\"></a>问题定义</h3><p>给定一段长度为$n$英寸的钢条（长度均为整英寸，切割后也必须是整英寸）和一个价格表$p_i(i=1, 2, …, n)$, 求解切割钢条的方案（方案也可以是不切割），使收益$r_n$最大。</p>\n<h3 id=\"问题分析\"><a href=\"#问题分析\" class=\"headerlink\" title=\"问题分析\"></a>问题分析</h3><p>长度为$n$英寸的钢条共有$2^{n-1}$种不同的切割方案，如果一个最优解将钢条切割为$k$段，那么最优切割方案为</p>\n<p>$$n = i_1 + i_2 + … + i_k$$</p>\n<p>得到的最大收益为</p>\n<p>$$r_n = p_{i_1} + p_{i_2} + … + p_{i_k}$$</p>\n<p>当完成首次切割后，我们将两段钢条看成两个独立的钢条切割问题实例。我们通过组合两个相关子问题的最优解，并在所有可能的两段切割方案种选取组合收益最大者，构成原问题的最优解。</p>\n<p>则最优切割收益为</p>\n<p>$$r_n = max(p_n, r_1 + r_{n-1}, r_2 + r_{n-2}, …, r_{n-1} + r_1)$$</p>\n<p>除上述求解方法外，钢条切割问题还存在一种相似的但更为简单的递归求解方法：我们将钢条从左边切割下长度为$i$的一段，只对右边剩下的长度为$n-i$的一段继续进行切割（递归求解）。</p>\n<p>这样我们得到上述式子的简化版本</p>\n<p>$$r_n = \\mathop {\\max}_{1 \\le i \\le n}(p_i + r_{n-i})$$</p>\n<h3 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h3><h4 id=\"自顶向下递归实现\"><a href=\"#自顶向下递归实现\" class=\"headerlink\" title=\"自顶向下递归实现\"></a>自顶向下递归实现</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cut_rod</span><span class=\"params\">(p, n)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    p -- the table of prices.</span></span><br><span class=\"line\"><span class=\"string\">    n -- the total length of steel rod.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> n == <span class=\"number\">0</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">    q = <span class=\"number\">-1</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n+<span class=\"number\">1</span>):</span><br><span class=\"line\">        q = max(q, p[i] + cut_rod(p, n-i))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> q</span><br></pre></td></tr></table></figure>\n<h4 id=\"代码分析\"><a href=\"#代码分析\" class=\"headerlink\" title=\"代码分析\"></a>代码分析</h4><p><img src=\"/images/动态规划.jpg\" alt=\"\"></p>\n<p>令$T(n)$表示cut_rod的调用次数</p>\n<p>$$T(n) = 1 + \\sum_{j=0}^{n-1} T(j) = 2^n$$</p>\n<p>第一项“1”表示函数的额第一次调用，$T(j)$为调用cut_rod(p, n-i)所产生的所有调用$(j = n-i)$</p>\n<h4 id=\"使用动态规划求解\"><a href=\"#使用动态规划求解\" class=\"headerlink\" title=\"使用动态规划求解\"></a>使用动态规划求解</h4><p>朴素递归算法之所以效率低，是因为它反复求解相同的子问题。因此，动态规划方法仔细安排求解顺序，对每个子问题只求解一次，并将结果保存下来。如果随后再次需要此子问题的解，只需查找保存的结果。</p>\n<p>动态规划有两种等价的实现。<strong>带备忘的自顶向下</strong>、<strong>自底向上</strong>。这里只给出第二种的代码。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bottom_up_cut_rod</span><span class=\"params\">(p, n)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    p -- the table of prices.</span></span><br><span class=\"line\"><span class=\"string\">    n -- the total length of steel rod.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    r = list(range(n + <span class=\"number\">1</span>))  <span class=\"comment\"># to save subproblem's result</span></span><br><span class=\"line\">    r[<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        q = <span class=\"number\">-1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, j + <span class=\"number\">1</span>):</span><br><span class=\"line\">            q = max(q, p[i] + r[j - i])</span><br><span class=\"line\">            r[j] = q</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r[n]</span><br></pre></td></tr></table></figure>\n<h4 id=\"代码分析-1\"><a href=\"#代码分析-1\" class=\"headerlink\" title=\"代码分析\"></a>代码分析</h4><p>自底向上版本采用子问题的自然顺序，一次求解规模为$j = 0, 1, 2, …, n$的子问题。时间复杂度为$\\Theta(n^2)$</p>\n<h4 id=\"扩展代码\"><a href=\"#扩展代码\" class=\"headerlink\" title=\"扩展代码\"></a>扩展代码</h4><p>前文给出的钢条切割问题的动态规划算法返回最优解的收益值，但未返回解本身。我们可以扩展动态规划算法，使之对每个子问题不仅保存最优收益值，还保存对应的切割方案。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">externed_bottom_up_cut_rod</span><span class=\"params\">(p, n)</span>:</span></span><br><span class=\"line\">    r = list(range(n + <span class=\"number\">1</span>))  <span class=\"comment\"># 长度为j的钢条的最大收益值r_j</span></span><br><span class=\"line\">    s = list(range(n + <span class=\"number\">1</span>))  <span class=\"comment\"># 最优解对应的第一条钢条的长度s_j</span></span><br><span class=\"line\">    r[<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        q = <span class=\"number\">-1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, j + <span class=\"number\">1</span>):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> q &lt; p[i] + r[j - i]:</span><br><span class=\"line\">                q = p[i] + r[j - i]</span><br><span class=\"line\">                s[j] = i</span><br><span class=\"line\">        r[j] = q</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r[n]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">print_cut_rod_solution</span><span class=\"params\">(p, n)</span>:</span></span><br><span class=\"line\">    (r, s) = externed_bottom_up_cut_rod(p, n)</span><br><span class=\"line\">    print(r)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> n &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        print(s[n], end=<span class=\"string\">' '</span>)</span><br><span class=\"line\">        n = n - s[n]</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"动态规划（dynamic-programming）\"><a href=\"#动态规划（dynamic-programming）\" class=\"headerlink\" title=\"动态规划（dynamic programming）\"></a>动态规划（dynamic programming）</h2><p>与分治法相似，都是通过组合子问题的解来求解原问题。不同的是，动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题。在这种情况下，动态规划算法对每个子子问题只求解一次，将其保存在一个表格中，减少了计算量。</p>\n<p>通常用来求解最优化问题。</p>\n<p>我们通常按如下4个步骤来设计一个动态规划算法：</p>\n<ul>\n<li>刻画一个最优解的结构特征</li>\n<li>递归地定义最优解的值</li>\n<li>计算最优解的值，通常采用自底向上的方法</li>\n<li>利用计算出的信息构造一个最优解</li>\n</ul>\n<h2 id=\"钢条切割问题\"><a href=\"#钢条切割问题\" class=\"headerlink\" title=\"钢条切割问题\"></a>钢条切割问题</h2><h3 id=\"问题定义\"><a href=\"#问题定义\" class=\"headerlink\" title=\"问题定义\"></a>问题定义</h3><p>给定一段长度为$n$英寸的钢条（长度均为整英寸，切割后也必须是整英寸）和一个价格表$p_i(i=1, 2, …, n)$, 求解切割钢条的方案（方案也可以是不切割），使收益$r_n$最大。</p>\n<h3 id=\"问题分析\"><a href=\"#问题分析\" class=\"headerlink\" title=\"问题分析\"></a>问题分析</h3><p>长度为$n$英寸的钢条共有$2^{n-1}$种不同的切割方案，如果一个最优解将钢条切割为$k$段，那么最优切割方案为</p>\n<p>$$n = i_1 + i_2 + … + i_k$$</p>\n<p>得到的最大收益为</p>\n<p>$$r_n = p_{i_1} + p_{i_2} + … + p_{i_k}$$</p>\n<p>当完成首次切割后，我们将两段钢条看成两个独立的钢条切割问题实例。我们通过组合两个相关子问题的最优解，并在所有可能的两段切割方案种选取组合收益最大者，构成原问题的最优解。</p>\n<p>则最优切割收益为</p>\n<p>$$r_n = max(p_n, r_1 + r_{n-1}, r_2 + r_{n-2}, …, r_{n-1} + r_1)$$</p>\n<p>除上述求解方法外，钢条切割问题还存在一种相似的但更为简单的递归求解方法：我们将钢条从左边切割下长度为$i$的一段，只对右边剩下的长度为$n-i$的一段继续进行切割（递归求解）。</p>\n<p>这样我们得到上述式子的简化版本</p>\n<p>$$r_n = \\mathop {\\max}_{1 \\le i \\le n}(p_i + r_{n-i})$$</p>\n<h3 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h3><h4 id=\"自顶向下递归实现\"><a href=\"#自顶向下递归实现\" class=\"headerlink\" title=\"自顶向下递归实现\"></a>自顶向下递归实现</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cut_rod</span><span class=\"params\">(p, n)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    p -- the table of prices.</span></span><br><span class=\"line\"><span class=\"string\">    n -- the total length of steel rod.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> n == <span class=\"number\">0</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">    q = <span class=\"number\">-1</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n+<span class=\"number\">1</span>):</span><br><span class=\"line\">        q = max(q, p[i] + cut_rod(p, n-i))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> q</span><br></pre></td></tr></table></figure>\n<h4 id=\"代码分析\"><a href=\"#代码分析\" class=\"headerlink\" title=\"代码分析\"></a>代码分析</h4><p><img src=\"/images/动态规划.jpg\" alt=\"\"></p>\n<p>令$T(n)$表示cut_rod的调用次数</p>\n<p>$$T(n) = 1 + \\sum_{j=0}^{n-1} T(j) = 2^n$$</p>\n<p>第一项“1”表示函数的额第一次调用，$T(j)$为调用cut_rod(p, n-i)所产生的所有调用$(j = n-i)$</p>\n<h4 id=\"使用动态规划求解\"><a href=\"#使用动态规划求解\" class=\"headerlink\" title=\"使用动态规划求解\"></a>使用动态规划求解</h4><p>朴素递归算法之所以效率低，是因为它反复求解相同的子问题。因此，动态规划方法仔细安排求解顺序，对每个子问题只求解一次，并将结果保存下来。如果随后再次需要此子问题的解，只需查找保存的结果。</p>\n<p>动态规划有两种等价的实现。<strong>带备忘的自顶向下</strong>、<strong>自底向上</strong>。这里只给出第二种的代码。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bottom_up_cut_rod</span><span class=\"params\">(p, n)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    p -- the table of prices.</span></span><br><span class=\"line\"><span class=\"string\">    n -- the total length of steel rod.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    r = list(range(n + <span class=\"number\">1</span>))  <span class=\"comment\"># to save subproblem's result</span></span><br><span class=\"line\">    r[<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        q = <span class=\"number\">-1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, j + <span class=\"number\">1</span>):</span><br><span class=\"line\">            q = max(q, p[i] + r[j - i])</span><br><span class=\"line\">            r[j] = q</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r[n]</span><br></pre></td></tr></table></figure>\n<h4 id=\"代码分析-1\"><a href=\"#代码分析-1\" class=\"headerlink\" title=\"代码分析\"></a>代码分析</h4><p>自底向上版本采用子问题的自然顺序，一次求解规模为$j = 0, 1, 2, …, n$的子问题。时间复杂度为$\\Theta(n^2)$</p>\n<h4 id=\"扩展代码\"><a href=\"#扩展代码\" class=\"headerlink\" title=\"扩展代码\"></a>扩展代码</h4><p>前文给出的钢条切割问题的动态规划算法返回最优解的收益值，但未返回解本身。我们可以扩展动态规划算法，使之对每个子问题不仅保存最优收益值，还保存对应的切割方案。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">externed_bottom_up_cut_rod</span><span class=\"params\">(p, n)</span>:</span></span><br><span class=\"line\">    r = list(range(n + <span class=\"number\">1</span>))  <span class=\"comment\"># 长度为j的钢条的最大收益值r_j</span></span><br><span class=\"line\">    s = list(range(n + <span class=\"number\">1</span>))  <span class=\"comment\"># 最优解对应的第一条钢条的长度s_j</span></span><br><span class=\"line\">    r[<span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        q = <span class=\"number\">-1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, j + <span class=\"number\">1</span>):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> q &lt; p[i] + r[j - i]:</span><br><span class=\"line\">                q = p[i] + r[j - i]</span><br><span class=\"line\">                s[j] = i</span><br><span class=\"line\">        r[j] = q</span><br><span class=\"line\">    <span class=\"keyword\">return</span> r[n]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">print_cut_rod_solution</span><span class=\"params\">(p, n)</span>:</span></span><br><span class=\"line\">    (r, s) = externed_bottom_up_cut_rod(p, n)</span><br><span class=\"line\">    print(r)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> n &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        print(s[n], end=<span class=\"string\">' '</span>)</span><br><span class=\"line\">        n = n - s[n]</span><br></pre></td></tr></table></figure>\n"},{"title":"十个策略故事","date":"2018-07-19T16:59:24.000Z","catrgories":"博弈论","_content":"\n### 1. 选数游戏\n\n游戏的参与者：你和一位面试官\n\n游戏的内容：面试官从1到100之间随机挑选一个整数，你有5次机会猜出它。每猜一次，面试官会提供给你所猜数与结果的大小信息\n\n游戏的收益：如果你第一次就猜对，你将获得100元，之后每次收益递减20元。面试官相应地损失这么多收益。\n\n模拟游戏的程序\n\n```python\nimport random\n\nres = random.randint(1, 100)\n\nfor i in range(5):\n    guess = int(input(\"Epoch {}: \".format(i + 1)))\n    if guess < res:\n        print(\"your guess is lower than the key.\")\n    elif guess > res:\n        print(\"your guess is greater than the key.\")\n    else:\n        print(\"Bingo, you will get {} dollars.\".format(100 - 20 * i))\nprint(\"The key is {}\".format(res))\n```\n\n#### 总结\n\n这场游戏揭示了是什么使用得某些事件成为一场博弈：你必须考虑到其他与参与人得目标及策略。在猜测一个随机挑选得数字时，这个数字不会被刻意掩饰。你可以用工程师得思维将区间一分为二，尽可能做得最好。但在博弈对局中，你需要考虑其他参与人将如何行动，以及那些人的决策将如何影响你的策略。\n\n","source":"_posts/十个策略故事.md","raw":"---\ntitle: 十个策略故事\ndate: 2018-07-20 00:59:24\ntags: 策略游戏\ncatrgories: 博弈论\n---\n\n### 1. 选数游戏\n\n游戏的参与者：你和一位面试官\n\n游戏的内容：面试官从1到100之间随机挑选一个整数，你有5次机会猜出它。每猜一次，面试官会提供给你所猜数与结果的大小信息\n\n游戏的收益：如果你第一次就猜对，你将获得100元，之后每次收益递减20元。面试官相应地损失这么多收益。\n\n模拟游戏的程序\n\n```python\nimport random\n\nres = random.randint(1, 100)\n\nfor i in range(5):\n    guess = int(input(\"Epoch {}: \".format(i + 1)))\n    if guess < res:\n        print(\"your guess is lower than the key.\")\n    elif guess > res:\n        print(\"your guess is greater than the key.\")\n    else:\n        print(\"Bingo, you will get {} dollars.\".format(100 - 20 * i))\nprint(\"The key is {}\".format(res))\n```\n\n#### 总结\n\n这场游戏揭示了是什么使用得某些事件成为一场博弈：你必须考虑到其他与参与人得目标及策略。在猜测一个随机挑选得数字时，这个数字不会被刻意掩饰。你可以用工程师得思维将区间一分为二，尽可能做得最好。但在博弈对局中，你需要考虑其他参与人将如何行动，以及那些人的决策将如何影响你的策略。\n\n","slug":"十个策略故事","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds4m002epcvo2wgarlgu","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"1-选数游戏\"><a href=\"#1-选数游戏\" class=\"headerlink\" title=\"1. 选数游戏\"></a>1. 选数游戏</h3><p>游戏的参与者：你和一位面试官</p>\n<p>游戏的内容：面试官从1到100之间随机挑选一个整数，你有5次机会猜出它。每猜一次，面试官会提供给你所猜数与结果的大小信息</p>\n<p>游戏的收益：如果你第一次就猜对，你将获得100元，之后每次收益递减20元。面试官相应地损失这么多收益。</p>\n<p>模拟游戏的程序</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"></span><br><span class=\"line\">res = random.randint(<span class=\"number\">1</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>):</span><br><span class=\"line\">    guess = int(input(<span class=\"string\">\"Epoch &#123;&#125;: \"</span>.format(i + <span class=\"number\">1</span>)))</span><br><span class=\"line\">    <span class=\"keyword\">if</span> guess &lt; res:</span><br><span class=\"line\">        print(<span class=\"string\">\"your guess is lower than the key.\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> guess &gt; res:</span><br><span class=\"line\">        print(<span class=\"string\">\"your guess is greater than the key.\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        print(<span class=\"string\">\"Bingo, you will get &#123;&#125; dollars.\"</span>.format(<span class=\"number\">100</span> - <span class=\"number\">20</span> * i))</span><br><span class=\"line\">print(<span class=\"string\">\"The key is &#123;&#125;\"</span>.format(res))</span><br></pre></td></tr></table></figure>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>这场游戏揭示了是什么使用得某些事件成为一场博弈：你必须考虑到其他与参与人得目标及策略。在猜测一个随机挑选得数字时，这个数字不会被刻意掩饰。你可以用工程师得思维将区间一分为二，尽可能做得最好。但在博弈对局中，你需要考虑其他参与人将如何行动，以及那些人的决策将如何影响你的策略。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-选数游戏\"><a href=\"#1-选数游戏\" class=\"headerlink\" title=\"1. 选数游戏\"></a>1. 选数游戏</h3><p>游戏的参与者：你和一位面试官</p>\n<p>游戏的内容：面试官从1到100之间随机挑选一个整数，你有5次机会猜出它。每猜一次，面试官会提供给你所猜数与结果的大小信息</p>\n<p>游戏的收益：如果你第一次就猜对，你将获得100元，之后每次收益递减20元。面试官相应地损失这么多收益。</p>\n<p>模拟游戏的程序</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"></span><br><span class=\"line\">res = random.randint(<span class=\"number\">1</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>):</span><br><span class=\"line\">    guess = int(input(<span class=\"string\">\"Epoch &#123;&#125;: \"</span>.format(i + <span class=\"number\">1</span>)))</span><br><span class=\"line\">    <span class=\"keyword\">if</span> guess &lt; res:</span><br><span class=\"line\">        print(<span class=\"string\">\"your guess is lower than the key.\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> guess &gt; res:</span><br><span class=\"line\">        print(<span class=\"string\">\"your guess is greater than the key.\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        print(<span class=\"string\">\"Bingo, you will get &#123;&#125; dollars.\"</span>.format(<span class=\"number\">100</span> - <span class=\"number\">20</span> * i))</span><br><span class=\"line\">print(<span class=\"string\">\"The key is &#123;&#125;\"</span>.format(res))</span><br></pre></td></tr></table></figure>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>这场游戏揭示了是什么使用得某些事件成为一场博弈：你必须考虑到其他与参与人得目标及策略。在猜测一个随机挑选得数字时，这个数字不会被刻意掩饰。你可以用工程师得思维将区间一分为二，尽可能做得最好。但在博弈对局中，你需要考虑其他参与人将如何行动，以及那些人的决策将如何影响你的策略。</p>\n"},{"title":"分治策略","date":"2018-09-08T14:46:06.000Z","mathjax":true,"_content":"\n## 最大子数组问题\n\n### 问题描述\n\n给定一数组A, 寻找A的和最大的非空连续子数组。我们称这样的连续子数组为 **最大子数组(maximum subarray)**. 只有当数组中包含负数时，最大子数组问题才有意义。常见的实际问题有股票的买卖，从买入到卖出我们希望股票的价格净变值最大。\n\n### 使用分治策略的求解方法\n\n假定我们要寻找子数组A[low...high]的最大子数组。使用分治技术意味着我们要将子数组划分为两个规模尽量相等的子数组（比如从中央位置划分），然后考虑求解两个子数组A[low...mid]和A[mid+1...high]。A[low...high]的一个任何连续子数组所处的位置必然是这三种情况之一：\n* 完全位于子数组A[low...mid]中，\n$low \\le i \\le j \\le mid$\n* 完全位于子数组A[mid+1...high]中，\n$mid+1 \\le i \\le j \\le high$\n* 跨越了中点，\n$low \\le i \\le mid \\le j \\le high$\n\n实际上，A[low...high]的一个最大子数组必然是上述三种情况的所有子数组中和的最大者。\n\n### 代码实现\n\n**求解跨越中点的最大子数组**\n```python\ndef find_max_crossing_subarray(A, low, mid, high):\n    \"\"\"\n    Arguments:\n        A: a not empty array with index (low mid hight)\n    Return:\n        (i, j, sum): the index of the maximum subarray which crosses the mid.\n    \"\"\"\n    left_sum = -float('inf')\n    sum = 0\n    for i in range(mid, low-1, -1):\n        sum = sum + A[i]\n        if sum > left_sum:\n            left_sum = sum\n            max_left = i\n    right_sum = -float('inf')\n    sum = 0\n    for j in range(mid+1, high+1):\n        sum = sum + A[j]\n        if sum > right_sum:\n            right_sum = sum\n            max_right = j\n    return (max_left, max_right, left_sum + right_sum)\n```\n\n**求解最大子数组**\n```python\ndef find_maximum_subarray(A, low, high):\n    if high == low:\n        return (low, high, A[low])\n    else:\n        mid = round((low + high) / 2)\n        (left_low, left_high, left_sum) = find_maximum_subarray(A, low, mid)\n        (right_low, right_high, right_sum) = find_maximum_subarray(A, mid+1, high)\n        (cross_low, cross_high, cross_sum) = find_max_crossing_subarray(A, low, mid, high)\n        if left_sum >= right_sum and left_sum >= cross_sum:\n            return (left_low, left_high, left_sum)\n        elif right_sum >= left_sum and right_sum >= cross_sum:\n            return (right_low, right_high, right_sum)\n        else:\n            return (cross_low, cross_high, cross_sum)\n```\n\n### 算法分析\n\n假设原问题的规模是2的幂，这样所有子问题的规模均为整数。我们用T(n)表示求解n个元素的最大子数组的运行时间。\n\n$$T(n) = \\begin{cases}\\Theta(1)&& n=1\\\\2T(n/2) + \\Theta(n)&& n>1 \\end{cases}$$\n\n$T(n) = \\Theta(nlgn)$\n","source":"_posts/分治策略.md","raw":"---\ntitle: 分治策略\ndate: 2018-09-08 22:46:06\ntags: 分治策略\ncategories: 算法导论\nmathjax: true\n---\n\n## 最大子数组问题\n\n### 问题描述\n\n给定一数组A, 寻找A的和最大的非空连续子数组。我们称这样的连续子数组为 **最大子数组(maximum subarray)**. 只有当数组中包含负数时，最大子数组问题才有意义。常见的实际问题有股票的买卖，从买入到卖出我们希望股票的价格净变值最大。\n\n### 使用分治策略的求解方法\n\n假定我们要寻找子数组A[low...high]的最大子数组。使用分治技术意味着我们要将子数组划分为两个规模尽量相等的子数组（比如从中央位置划分），然后考虑求解两个子数组A[low...mid]和A[mid+1...high]。A[low...high]的一个任何连续子数组所处的位置必然是这三种情况之一：\n* 完全位于子数组A[low...mid]中，\n$low \\le i \\le j \\le mid$\n* 完全位于子数组A[mid+1...high]中，\n$mid+1 \\le i \\le j \\le high$\n* 跨越了中点，\n$low \\le i \\le mid \\le j \\le high$\n\n实际上，A[low...high]的一个最大子数组必然是上述三种情况的所有子数组中和的最大者。\n\n### 代码实现\n\n**求解跨越中点的最大子数组**\n```python\ndef find_max_crossing_subarray(A, low, mid, high):\n    \"\"\"\n    Arguments:\n        A: a not empty array with index (low mid hight)\n    Return:\n        (i, j, sum): the index of the maximum subarray which crosses the mid.\n    \"\"\"\n    left_sum = -float('inf')\n    sum = 0\n    for i in range(mid, low-1, -1):\n        sum = sum + A[i]\n        if sum > left_sum:\n            left_sum = sum\n            max_left = i\n    right_sum = -float('inf')\n    sum = 0\n    for j in range(mid+1, high+1):\n        sum = sum + A[j]\n        if sum > right_sum:\n            right_sum = sum\n            max_right = j\n    return (max_left, max_right, left_sum + right_sum)\n```\n\n**求解最大子数组**\n```python\ndef find_maximum_subarray(A, low, high):\n    if high == low:\n        return (low, high, A[low])\n    else:\n        mid = round((low + high) / 2)\n        (left_low, left_high, left_sum) = find_maximum_subarray(A, low, mid)\n        (right_low, right_high, right_sum) = find_maximum_subarray(A, mid+1, high)\n        (cross_low, cross_high, cross_sum) = find_max_crossing_subarray(A, low, mid, high)\n        if left_sum >= right_sum and left_sum >= cross_sum:\n            return (left_low, left_high, left_sum)\n        elif right_sum >= left_sum and right_sum >= cross_sum:\n            return (right_low, right_high, right_sum)\n        else:\n            return (cross_low, cross_high, cross_sum)\n```\n\n### 算法分析\n\n假设原问题的规模是2的幂，这样所有子问题的规模均为整数。我们用T(n)表示求解n个元素的最大子数组的运行时间。\n\n$$T(n) = \\begin{cases}\\Theta(1)&& n=1\\\\2T(n/2) + \\Theta(n)&& n>1 \\end{cases}$$\n\n$T(n) = \\Theta(nlgn)$\n","slug":"分治策略","published":1,"updated":"2018-09-22T05:28:29.852Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds4m002ipcvoqpuwqqto","content":"<h2 id=\"最大子数组问题\"><a href=\"#最大子数组问题\" class=\"headerlink\" title=\"最大子数组问题\"></a>最大子数组问题</h2><h3 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h3><p>给定一数组A, 寻找A的和最大的非空连续子数组。我们称这样的连续子数组为 <strong>最大子数组(maximum subarray)</strong>. 只有当数组中包含负数时，最大子数组问题才有意义。常见的实际问题有股票的买卖，从买入到卖出我们希望股票的价格净变值最大。</p>\n<h3 id=\"使用分治策略的求解方法\"><a href=\"#使用分治策略的求解方法\" class=\"headerlink\" title=\"使用分治策略的求解方法\"></a>使用分治策略的求解方法</h3><p>假定我们要寻找子数组A[low…high]的最大子数组。使用分治技术意味着我们要将子数组划分为两个规模尽量相等的子数组（比如从中央位置划分），然后考虑求解两个子数组A[low…mid]和A[mid+1…high]。A[low…high]的一个任何连续子数组所处的位置必然是这三种情况之一：</p>\n<ul>\n<li>完全位于子数组A[low…mid]中，<br>$low \\le i \\le j \\le mid$</li>\n<li>完全位于子数组A[mid+1…high]中，<br>$mid+1 \\le i \\le j \\le high$</li>\n<li>跨越了中点，<br>$low \\le i \\le mid \\le j \\le high$</li>\n</ul>\n<p>实际上，A[low…high]的一个最大子数组必然是上述三种情况的所有子数组中和的最大者。</p>\n<h3 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h3><p><strong>求解跨越中点的最大子数组</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">find_max_crossing_subarray</span><span class=\"params\">(A, low, mid, high)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">        A: a not empty array with index (low mid hight)</span></span><br><span class=\"line\"><span class=\"string\">    Return:</span></span><br><span class=\"line\"><span class=\"string\">        (i, j, sum): the index of the maximum subarray which crosses the mid.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    left_sum = -float(<span class=\"string\">'inf'</span>)</span><br><span class=\"line\">    sum = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(mid, low<span class=\"number\">-1</span>, <span class=\"number\">-1</span>):</span><br><span class=\"line\">        sum = sum + A[i]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> sum &gt; left_sum:</span><br><span class=\"line\">            left_sum = sum</span><br><span class=\"line\">            max_left = i</span><br><span class=\"line\">    right_sum = -float(<span class=\"string\">'inf'</span>)</span><br><span class=\"line\">    sum = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(mid+<span class=\"number\">1</span>, high+<span class=\"number\">1</span>):</span><br><span class=\"line\">        sum = sum + A[j]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> sum &gt; right_sum:</span><br><span class=\"line\">            right_sum = sum</span><br><span class=\"line\">            max_right = j</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (max_left, max_right, left_sum + right_sum)</span><br></pre></td></tr></table></figure></p>\n<p><strong>求解最大子数组</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">find_maximum_subarray</span><span class=\"params\">(A, low, high)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> high == low:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (low, high, A[low])</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        mid = round((low + high) / <span class=\"number\">2</span>)</span><br><span class=\"line\">        (left_low, left_high, left_sum) = find_maximum_subarray(A, low, mid)</span><br><span class=\"line\">        (right_low, right_high, right_sum) = find_maximum_subarray(A, mid+<span class=\"number\">1</span>, high)</span><br><span class=\"line\">        (cross_low, cross_high, cross_sum) = find_max_crossing_subarray(A, low, mid, high)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> left_sum &gt;= right_sum <span class=\"keyword\">and</span> left_sum &gt;= cross_sum:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (left_low, left_high, left_sum)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> right_sum &gt;= left_sum <span class=\"keyword\">and</span> right_sum &gt;= cross_sum:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (right_low, right_high, right_sum)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (cross_low, cross_high, cross_sum)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"算法分析\"><a href=\"#算法分析\" class=\"headerlink\" title=\"算法分析\"></a>算法分析</h3><p>假设原问题的规模是2的幂，这样所有子问题的规模均为整数。我们用T(n)表示求解n个元素的最大子数组的运行时间。</p>\n<p>$$T(n) = \\begin{cases}\\Theta(1)&amp;&amp; n=1\\2T(n/2) + \\Theta(n)&amp;&amp; n&gt;1 \\end{cases}$$</p>\n<p>$T(n) = \\Theta(nlgn)$</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"最大子数组问题\"><a href=\"#最大子数组问题\" class=\"headerlink\" title=\"最大子数组问题\"></a>最大子数组问题</h2><h3 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h3><p>给定一数组A, 寻找A的和最大的非空连续子数组。我们称这样的连续子数组为 <strong>最大子数组(maximum subarray)</strong>. 只有当数组中包含负数时，最大子数组问题才有意义。常见的实际问题有股票的买卖，从买入到卖出我们希望股票的价格净变值最大。</p>\n<h3 id=\"使用分治策略的求解方法\"><a href=\"#使用分治策略的求解方法\" class=\"headerlink\" title=\"使用分治策略的求解方法\"></a>使用分治策略的求解方法</h3><p>假定我们要寻找子数组A[low…high]的最大子数组。使用分治技术意味着我们要将子数组划分为两个规模尽量相等的子数组（比如从中央位置划分），然后考虑求解两个子数组A[low…mid]和A[mid+1…high]。A[low…high]的一个任何连续子数组所处的位置必然是这三种情况之一：</p>\n<ul>\n<li>完全位于子数组A[low…mid]中，<br>$low \\le i \\le j \\le mid$</li>\n<li>完全位于子数组A[mid+1…high]中，<br>$mid+1 \\le i \\le j \\le high$</li>\n<li>跨越了中点，<br>$low \\le i \\le mid \\le j \\le high$</li>\n</ul>\n<p>实际上，A[low…high]的一个最大子数组必然是上述三种情况的所有子数组中和的最大者。</p>\n<h3 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h3><p><strong>求解跨越中点的最大子数组</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">find_max_crossing_subarray</span><span class=\"params\">(A, low, mid, high)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">        A: a not empty array with index (low mid hight)</span></span><br><span class=\"line\"><span class=\"string\">    Return:</span></span><br><span class=\"line\"><span class=\"string\">        (i, j, sum): the index of the maximum subarray which crosses the mid.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    left_sum = -float(<span class=\"string\">'inf'</span>)</span><br><span class=\"line\">    sum = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(mid, low<span class=\"number\">-1</span>, <span class=\"number\">-1</span>):</span><br><span class=\"line\">        sum = sum + A[i]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> sum &gt; left_sum:</span><br><span class=\"line\">            left_sum = sum</span><br><span class=\"line\">            max_left = i</span><br><span class=\"line\">    right_sum = -float(<span class=\"string\">'inf'</span>)</span><br><span class=\"line\">    sum = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(mid+<span class=\"number\">1</span>, high+<span class=\"number\">1</span>):</span><br><span class=\"line\">        sum = sum + A[j]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> sum &gt; right_sum:</span><br><span class=\"line\">            right_sum = sum</span><br><span class=\"line\">            max_right = j</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (max_left, max_right, left_sum + right_sum)</span><br></pre></td></tr></table></figure></p>\n<p><strong>求解最大子数组</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">find_maximum_subarray</span><span class=\"params\">(A, low, high)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> high == low:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (low, high, A[low])</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        mid = round((low + high) / <span class=\"number\">2</span>)</span><br><span class=\"line\">        (left_low, left_high, left_sum) = find_maximum_subarray(A, low, mid)</span><br><span class=\"line\">        (right_low, right_high, right_sum) = find_maximum_subarray(A, mid+<span class=\"number\">1</span>, high)</span><br><span class=\"line\">        (cross_low, cross_high, cross_sum) = find_max_crossing_subarray(A, low, mid, high)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> left_sum &gt;= right_sum <span class=\"keyword\">and</span> left_sum &gt;= cross_sum:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (left_low, left_high, left_sum)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> right_sum &gt;= left_sum <span class=\"keyword\">and</span> right_sum &gt;= cross_sum:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (right_low, right_high, right_sum)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (cross_low, cross_high, cross_sum)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"算法分析\"><a href=\"#算法分析\" class=\"headerlink\" title=\"算法分析\"></a>算法分析</h3><p>假设原问题的规模是2的幂，这样所有子问题的规模均为整数。我们用T(n)表示求解n个元素的最大子数组的运行时间。</p>\n<p>$$T(n) = \\begin{cases}\\Theta(1)&amp;&amp; n=1\\2T(n/2) + \\Theta(n)&amp;&amp; n&gt;1 \\end{cases}$$</p>\n<p>$T(n) = \\Theta(nlgn)$</p>\n"},{"title":"初始化参数","date":"2018-07-22T05:22:45.000Z","_content":"\n## Initialization\n\nTraining your neural network requires specifying an initial value of the weights. A well chosen initialization method will help learning.  \n\nA well chosen initialization can:\n- Speed up the convergence of gradient descent\n- Increase the odds of gradient descent converging to a lower training (and generalization) error\n\n## Random initialization\n\n```python\nparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * 0.01\nparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n```\n\n## He initialization\n\n```python\nparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * np.sqrt(2 / layers_dims[l-1])\nparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n```\n\n\n**What you should remember from this artical**:\n- Different initializations lead to different results\n- Random initialization is used to break symmetry and make sure different hidden units can learn different things\n- Don't intialize to values that are too large\n- He initialization works well for networks with ReLU activations.\n","source":"_posts/初始化参数.md","raw":"---\ntitle: 初始化参数\ndate: 2018-07-22 13:22:45\ntags: 优化算法\ncategories: 深度学习\n---\n\n## Initialization\n\nTraining your neural network requires specifying an initial value of the weights. A well chosen initialization method will help learning.  \n\nA well chosen initialization can:\n- Speed up the convergence of gradient descent\n- Increase the odds of gradient descent converging to a lower training (and generalization) error\n\n## Random initialization\n\n```python\nparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * 0.01\nparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n```\n\n## He initialization\n\n```python\nparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * np.sqrt(2 / layers_dims[l-1])\nparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n```\n\n\n**What you should remember from this artical**:\n- Different initializations lead to different results\n- Random initialization is used to break symmetry and make sure different hidden units can learn different things\n- Don't intialize to values that are too large\n- He initialization works well for networks with ReLU activations.\n","slug":"初始化参数","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds4m002lpcvo8ha7j3lm","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Initialization\"><a href=\"#Initialization\" class=\"headerlink\" title=\"Initialization\"></a>Initialization</h2><p>Training your neural network requires specifying an initial value of the weights. A well chosen initialization method will help learning.  </p>\n<p>A well chosen initialization can:</p>\n<ul>\n<li>Speed up the convergence of gradient descent</li>\n<li>Increase the odds of gradient descent converging to a lower training (and generalization) error</li>\n</ul>\n<h2 id=\"Random-initialization\"><a href=\"#Random-initialization\" class=\"headerlink\" title=\"Random initialization\"></a>Random initialization</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parameters[<span class=\"string\">'W'</span> + str(l)] = np.random.randn(layers_dims[l], layers_dims[l<span class=\"number\">-1</span>]) * <span class=\"number\">0.01</span></span><br><span class=\"line\">parameters[<span class=\"string\">'b'</span> + str(l)] = np.zeros((layers_dims[l], <span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<h2 id=\"He-initialization\"><a href=\"#He-initialization\" class=\"headerlink\" title=\"He initialization\"></a>He initialization</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parameters[<span class=\"string\">'W'</span> + str(l)] = np.random.randn(layers_dims[l], layers_dims[l<span class=\"number\">-1</span>]) * np.sqrt(<span class=\"number\">2</span> / layers_dims[l<span class=\"number\">-1</span>])</span><br><span class=\"line\">parameters[<span class=\"string\">'b'</span> + str(l)] = np.zeros((layers_dims[l], <span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p><strong>What you should remember from this artical</strong>:</p>\n<ul>\n<li>Different initializations lead to different results</li>\n<li>Random initialization is used to break symmetry and make sure different hidden units can learn different things</li>\n<li>Don’t intialize to values that are too large</li>\n<li>He initialization works well for networks with ReLU activations.</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Initialization\"><a href=\"#Initialization\" class=\"headerlink\" title=\"Initialization\"></a>Initialization</h2><p>Training your neural network requires specifying an initial value of the weights. A well chosen initialization method will help learning.  </p>\n<p>A well chosen initialization can:</p>\n<ul>\n<li>Speed up the convergence of gradient descent</li>\n<li>Increase the odds of gradient descent converging to a lower training (and generalization) error</li>\n</ul>\n<h2 id=\"Random-initialization\"><a href=\"#Random-initialization\" class=\"headerlink\" title=\"Random initialization\"></a>Random initialization</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parameters[<span class=\"string\">'W'</span> + str(l)] = np.random.randn(layers_dims[l], layers_dims[l<span class=\"number\">-1</span>]) * <span class=\"number\">0.01</span></span><br><span class=\"line\">parameters[<span class=\"string\">'b'</span> + str(l)] = np.zeros((layers_dims[l], <span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<h2 id=\"He-initialization\"><a href=\"#He-initialization\" class=\"headerlink\" title=\"He initialization\"></a>He initialization</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parameters[<span class=\"string\">'W'</span> + str(l)] = np.random.randn(layers_dims[l], layers_dims[l<span class=\"number\">-1</span>]) * np.sqrt(<span class=\"number\">2</span> / layers_dims[l<span class=\"number\">-1</span>])</span><br><span class=\"line\">parameters[<span class=\"string\">'b'</span> + str(l)] = np.zeros((layers_dims[l], <span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p><strong>What you should remember from this artical</strong>:</p>\n<ul>\n<li>Different initializations lead to different results</li>\n<li>Random initialization is used to break symmetry and make sure different hidden units can learn different things</li>\n<li>Don’t intialize to values that are too large</li>\n<li>He initialization works well for networks with ReLU activations.</li>\n</ul>\n"},{"title":"卷积神经网络","date":"2018-08-26T09:20:05.000Z","mathjax":true,"_content":"\n## Convolution neural network(CNN)\n\n是一种专门用来处理**具有类似网格结构的数据**的神经网络。例如时间序列数据(可以认为在时间轴上有规律的采样形成的一维网格)和图像数据(可以看作二维的像素网格)。\n\n## 卷积运算\n\n数学定义\n$$f(t) = f_1(t) \\ast f_2(t) = \\int_{-\\infty}^{\\infty} f_1(\\tau)f_2(t - \\tau)d\\tau$$\n\n$$y(k) = f(k) \\ast h(k) = \\sum_{i = -\\infty}^{\\infty} f(i) h(k - i)$$\n\n二维图像的卷积表示\n$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(m, n)K(i - m, j - n)$$\n\n神经网络中实现的卷积运算实际上是**互相关函数**\n$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(i + m, j + n)K(m, n)$$\n\n## 三个重要思想\n\n### 稀疏交互(sparse interactions)\n\n**在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。**\n\n![](/images/dl_pic9_2.jpg)\n\n传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。其中，参数矩阵中的每一个单独的参数都描述了一个输入单元与一个输出单元间的交互。这意味着每一个输出单元与每一个输入单元都产生交互。然而卷积网络具有稀疏交互的特征，这是使核的大小远小于输入的大小来达到的。当处理一张图像时，输入的图像可能包含成千上万个像素点，但我们可以通过只占用几十到几百个像素点的核来检测一些小的有意义的特征，例如图像的边缘。\n\n### 参数共享(parameter sharing)\n\n特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。**即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。**\n\n在传统的神经网络中，当计算一层的输出时，权重矩阵的每个元素只使用一次，当它乘以输入的一个元素后就再也不会用到了。在卷积神经网络中，核的每一个元素都作用在输入的每一个位置上。卷积运算中的参数共享保证了我们只需要学习一个参数集合，而不是对每一个位置都需要学习一个单独的参数集合。\n\n![](/images/dl_pic9_5.jpg)\n\n### 等变表示(equivarient representations)\n\n等变的数学概念\n$$如果函数f(x), g(x)满足 f(g(x)) = g(f(x)) 我们就说f(x)对于变换g具有等变性 $$\n\n对于卷积来说，**如果令g是输入的任意平移函数，那么卷积函数对于g具有等变性。**\n在图像处理中，卷积产生了一个二维映射来表明某些特征在输入中出现的位置。如果我们移动输入中的对象，它的表示也会在输出中移动同样的量。\n\n## 池化(pooling)\n\n卷积网络中一个典型层包含三级\n![](/images/dl_pic9_7.jpg)\n\n**池化层**的作用是在卷积后很好地聚合了特征，通过降维来减少运算量, 缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。\n\n**池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。** 例如最大池化函数给出相邻区域内的最大值。\n\n**不管采用什么样的池化函数，当输入做出少量平移时，池化能够帮助输入的表示近似不变**。局部平移不变性是一个很有用的性质，尤其当我们关心某个特征是否出现而不关心它出现的具体位置时。\n\n在很多任务中，池化对于处理不同大小的输入具有重要作用。例如我们想对不同大小的图像进行分类时，分类层的输入必须是固定大小，而这通常通过调整池化区域的偏置大小来实现，这样分类层总是能接收到相同数量的统计特征而不管最初的输入大小。例如最终的池化层可能会输入4组综合统计特征，每组对于着图像的一个象限。\n\n## 卷积与池化作为一种无限强的先验\n\n>先验概率分布。这是一个模型参数的概率分布，它刻画了我们在看到数据之前认为什么样的模型是合理的信念。先验被认为强或者弱取决于先验中概率密度的集中程度。一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值。\n\n我们可以把卷积网络类比成全连接网络，但对于这个全连接网络的权重有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权重必须和它邻居的权重相同，但可以在空间上移动。这个先验也要求那些处于隐藏单元的小的空间连续的接受域内的权重以外，其余权重都为零。\n\n类似地使用池化也是一个无限强的先验：每一个单元都具有对少量平移的不变性。\n\n## 填充(Padding)\n\n假设输入图片的大小为 $n \\times n$，而滤波器的大小为 $f \\times f$，则卷积后的输出图片大小为 $(n-f+1) \\times (n-f+1)$。\n\n这样就有两个问题：\n\n* 每次卷积运算后，输出图片的尺寸缩小；\n* 原始图片的角落、边缘区像素点在输出中采用较少，输出图片丢失边缘位置的很多信息。\n\n为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行 **填充（Padding）**，以增加矩阵的大小。通常将 0 作为填充值。\n\n![](/images/Padding.jpg)\n\n设每个方向扩展像素点数量为 $p$，则填充后原始图片的大小为 $(n+2p) \\times (n+2p)$，滤波器大小保持 $f \\times f$不变，则输出图片大小为 $(n+2p-f+1) \\times (n+2p-f+1)$。\n\n因此，在进行卷积运算时，我们有两种选择：\n\n* **Valid 卷积**：不填充，直接卷积。结果大小为 $(n-f+1) \\times (n-f+1)$；\n* **Same 卷积**：进行填充，并使得卷积后结果大小与输入一致，这样 $p = \\frac{f-1}{2}$。\n\n在计算机视觉领域，$f$通常为奇数。原因包括 Same 卷积中 $p = \\frac{f-1}{2}$ 能得到自然数结果，并且滤波器有一个便于表示其所在位置的中心点。\n\n## 卷积步长(Stride)\n\n卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置 **步长（Stride）** 来压缩一部分信息。\n\n步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。之前，步长被默认为 1。而如果我们设置步长为 2，则卷积过程如下图所示：\n\n![](/images/Stride.jpg)\n\n设步长为 $s$，填充长度为 $p$，输入图片大小为 $n \\times n$，滤波器大小为 $f \\times f$，则卷积后图片的尺寸为：\n\n$$\\biggl\\lfloor \\frac{n+2p-f}{s}+1   \\biggr\\rfloor \\times \\biggl\\lfloor \\frac{n+2p-f}{s}+1 \\biggr\\rfloor$$\n\n## 高维卷积\n\n如果我们想要对三通道的 RGB 图片进行卷积运算，那么其对应的滤波器组也同样是三通道的。过程是将每个单通道（R，G，B）与对应的滤波器进行卷积运算求和，然后再将三个通道的和相加，将 27 个乘积的和作为输出图片的一个像素值。\n\n![](/images/Convolutions-on-RGB-image.png)\n\n设输入图片的尺寸为 $n \\times n \\times n_c$（$n_c$为通道数），滤波器尺寸为 $f \\times f \\times n_c$，则卷积后的输出图片尺寸为 $(n-f+1) \\times (n-f+1) \\times n^{'}_c$，$n^{'}_c$为滤波器组的个数。\n\n### 符号总结\n\n设 $l$ 层为卷积层：\n\n* $f^{[l]}$：**滤波器的高（或宽）**\n* $p^{[l]}$：**填充长度**\n* $s^{[l]}$：**步长**\n* $n^{[l]}_c$：**滤波器组的数量**\n\n* **输入维度**：$n^{[l-1]}_H \\times n^{[l-1]}_W \\times n^{[l-1]}_c$ 。其中 $n^{[l-1]}_H$表示输入图片的高，$n^{[l-1]}_W$表示输入图片的宽。之前的示例中输入图片的高和宽都相同，但是实际中也可能不同，因此加上下标予以区分。\n\n* **输出维度**：$n^{[l]}_H \\times n^{[l]}_W \\times n^{[l]}_c$ 。其中\n\n$$n^{[l]}_H = \\biggl\\lfloor \\frac{n^{[l-1]}_H+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$\n\n$$n^{[l]}_W = \\biggl\\lfloor \\frac{n^{[l-1]}_W+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$\n\n* **每个滤波器组的维度**：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c$ 。其中$n^{[l-1]}_c$ 为输入图片通道数（也称深度）。\n* **权重维度**：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c$\n* **偏置维度**：$1 \\times 1 \\times 1 \\times n^{[l]}_c$\n","source":"_posts/卷积神经网络.md","raw":"---\ntitle: 卷积神经网络\ndate: 2018-08-26 17:20:05\ntags: CNN\ncategories: 深度学习\nmathjax: true\n---\n\n## Convolution neural network(CNN)\n\n是一种专门用来处理**具有类似网格结构的数据**的神经网络。例如时间序列数据(可以认为在时间轴上有规律的采样形成的一维网格)和图像数据(可以看作二维的像素网格)。\n\n## 卷积运算\n\n数学定义\n$$f(t) = f_1(t) \\ast f_2(t) = \\int_{-\\infty}^{\\infty} f_1(\\tau)f_2(t - \\tau)d\\tau$$\n\n$$y(k) = f(k) \\ast h(k) = \\sum_{i = -\\infty}^{\\infty} f(i) h(k - i)$$\n\n二维图像的卷积表示\n$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(m, n)K(i - m, j - n)$$\n\n神经网络中实现的卷积运算实际上是**互相关函数**\n$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(i + m, j + n)K(m, n)$$\n\n## 三个重要思想\n\n### 稀疏交互(sparse interactions)\n\n**在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。**\n\n![](/images/dl_pic9_2.jpg)\n\n传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。其中，参数矩阵中的每一个单独的参数都描述了一个输入单元与一个输出单元间的交互。这意味着每一个输出单元与每一个输入单元都产生交互。然而卷积网络具有稀疏交互的特征，这是使核的大小远小于输入的大小来达到的。当处理一张图像时，输入的图像可能包含成千上万个像素点，但我们可以通过只占用几十到几百个像素点的核来检测一些小的有意义的特征，例如图像的边缘。\n\n### 参数共享(parameter sharing)\n\n特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。**即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。**\n\n在传统的神经网络中，当计算一层的输出时，权重矩阵的每个元素只使用一次，当它乘以输入的一个元素后就再也不会用到了。在卷积神经网络中，核的每一个元素都作用在输入的每一个位置上。卷积运算中的参数共享保证了我们只需要学习一个参数集合，而不是对每一个位置都需要学习一个单独的参数集合。\n\n![](/images/dl_pic9_5.jpg)\n\n### 等变表示(equivarient representations)\n\n等变的数学概念\n$$如果函数f(x), g(x)满足 f(g(x)) = g(f(x)) 我们就说f(x)对于变换g具有等变性 $$\n\n对于卷积来说，**如果令g是输入的任意平移函数，那么卷积函数对于g具有等变性。**\n在图像处理中，卷积产生了一个二维映射来表明某些特征在输入中出现的位置。如果我们移动输入中的对象，它的表示也会在输出中移动同样的量。\n\n## 池化(pooling)\n\n卷积网络中一个典型层包含三级\n![](/images/dl_pic9_7.jpg)\n\n**池化层**的作用是在卷积后很好地聚合了特征，通过降维来减少运算量, 缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。\n\n**池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。** 例如最大池化函数给出相邻区域内的最大值。\n\n**不管采用什么样的池化函数，当输入做出少量平移时，池化能够帮助输入的表示近似不变**。局部平移不变性是一个很有用的性质，尤其当我们关心某个特征是否出现而不关心它出现的具体位置时。\n\n在很多任务中，池化对于处理不同大小的输入具有重要作用。例如我们想对不同大小的图像进行分类时，分类层的输入必须是固定大小，而这通常通过调整池化区域的偏置大小来实现，这样分类层总是能接收到相同数量的统计特征而不管最初的输入大小。例如最终的池化层可能会输入4组综合统计特征，每组对于着图像的一个象限。\n\n## 卷积与池化作为一种无限强的先验\n\n>先验概率分布。这是一个模型参数的概率分布，它刻画了我们在看到数据之前认为什么样的模型是合理的信念。先验被认为强或者弱取决于先验中概率密度的集中程度。一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值。\n\n我们可以把卷积网络类比成全连接网络，但对于这个全连接网络的权重有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权重必须和它邻居的权重相同，但可以在空间上移动。这个先验也要求那些处于隐藏单元的小的空间连续的接受域内的权重以外，其余权重都为零。\n\n类似地使用池化也是一个无限强的先验：每一个单元都具有对少量平移的不变性。\n\n## 填充(Padding)\n\n假设输入图片的大小为 $n \\times n$，而滤波器的大小为 $f \\times f$，则卷积后的输出图片大小为 $(n-f+1) \\times (n-f+1)$。\n\n这样就有两个问题：\n\n* 每次卷积运算后，输出图片的尺寸缩小；\n* 原始图片的角落、边缘区像素点在输出中采用较少，输出图片丢失边缘位置的很多信息。\n\n为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行 **填充（Padding）**，以增加矩阵的大小。通常将 0 作为填充值。\n\n![](/images/Padding.jpg)\n\n设每个方向扩展像素点数量为 $p$，则填充后原始图片的大小为 $(n+2p) \\times (n+2p)$，滤波器大小保持 $f \\times f$不变，则输出图片大小为 $(n+2p-f+1) \\times (n+2p-f+1)$。\n\n因此，在进行卷积运算时，我们有两种选择：\n\n* **Valid 卷积**：不填充，直接卷积。结果大小为 $(n-f+1) \\times (n-f+1)$；\n* **Same 卷积**：进行填充，并使得卷积后结果大小与输入一致，这样 $p = \\frac{f-1}{2}$。\n\n在计算机视觉领域，$f$通常为奇数。原因包括 Same 卷积中 $p = \\frac{f-1}{2}$ 能得到自然数结果，并且滤波器有一个便于表示其所在位置的中心点。\n\n## 卷积步长(Stride)\n\n卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置 **步长（Stride）** 来压缩一部分信息。\n\n步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。之前，步长被默认为 1。而如果我们设置步长为 2，则卷积过程如下图所示：\n\n![](/images/Stride.jpg)\n\n设步长为 $s$，填充长度为 $p$，输入图片大小为 $n \\times n$，滤波器大小为 $f \\times f$，则卷积后图片的尺寸为：\n\n$$\\biggl\\lfloor \\frac{n+2p-f}{s}+1   \\biggr\\rfloor \\times \\biggl\\lfloor \\frac{n+2p-f}{s}+1 \\biggr\\rfloor$$\n\n## 高维卷积\n\n如果我们想要对三通道的 RGB 图片进行卷积运算，那么其对应的滤波器组也同样是三通道的。过程是将每个单通道（R，G，B）与对应的滤波器进行卷积运算求和，然后再将三个通道的和相加，将 27 个乘积的和作为输出图片的一个像素值。\n\n![](/images/Convolutions-on-RGB-image.png)\n\n设输入图片的尺寸为 $n \\times n \\times n_c$（$n_c$为通道数），滤波器尺寸为 $f \\times f \\times n_c$，则卷积后的输出图片尺寸为 $(n-f+1) \\times (n-f+1) \\times n^{'}_c$，$n^{'}_c$为滤波器组的个数。\n\n### 符号总结\n\n设 $l$ 层为卷积层：\n\n* $f^{[l]}$：**滤波器的高（或宽）**\n* $p^{[l]}$：**填充长度**\n* $s^{[l]}$：**步长**\n* $n^{[l]}_c$：**滤波器组的数量**\n\n* **输入维度**：$n^{[l-1]}_H \\times n^{[l-1]}_W \\times n^{[l-1]}_c$ 。其中 $n^{[l-1]}_H$表示输入图片的高，$n^{[l-1]}_W$表示输入图片的宽。之前的示例中输入图片的高和宽都相同，但是实际中也可能不同，因此加上下标予以区分。\n\n* **输出维度**：$n^{[l]}_H \\times n^{[l]}_W \\times n^{[l]}_c$ 。其中\n\n$$n^{[l]}_H = \\biggl\\lfloor \\frac{n^{[l-1]}_H+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$\n\n$$n^{[l]}_W = \\biggl\\lfloor \\frac{n^{[l-1]}_W+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$\n\n* **每个滤波器组的维度**：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c$ 。其中$n^{[l-1]}_c$ 为输入图片通道数（也称深度）。\n* **权重维度**：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c$\n* **偏置维度**：$1 \\times 1 \\times 1 \\times n^{[l]}_c$\n","slug":"卷积神经网络","published":1,"updated":"2018-08-26T09:48:30.935Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds4m002ppcvop7cdaq7n","content":"<h2 id=\"Convolution-neural-network-CNN\"><a href=\"#Convolution-neural-network-CNN\" class=\"headerlink\" title=\"Convolution neural network(CNN)\"></a>Convolution neural network(CNN)</h2><p>是一种专门用来处理<strong>具有类似网格结构的数据</strong>的神经网络。例如时间序列数据(可以认为在时间轴上有规律的采样形成的一维网格)和图像数据(可以看作二维的像素网格)。</p>\n<h2 id=\"卷积运算\"><a href=\"#卷积运算\" class=\"headerlink\" title=\"卷积运算\"></a>卷积运算</h2><p>数学定义<br>$$f(t) = f_1(t) \\ast f_2(t) = \\int_{-\\infty}^{\\infty} f_1(\\tau)f_2(t - \\tau)d\\tau$$</p>\n<p>$$y(k) = f(k) \\ast h(k) = \\sum_{i = -\\infty}^{\\infty} f(i) h(k - i)$$</p>\n<p>二维图像的卷积表示<br>$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(m, n)K(i - m, j - n)$$</p>\n<p>神经网络中实现的卷积运算实际上是<strong>互相关函数</strong><br>$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(i + m, j + n)K(m, n)$$</p>\n<h2 id=\"三个重要思想\"><a href=\"#三个重要思想\" class=\"headerlink\" title=\"三个重要思想\"></a>三个重要思想</h2><h3 id=\"稀疏交互-sparse-interactions\"><a href=\"#稀疏交互-sparse-interactions\" class=\"headerlink\" title=\"稀疏交互(sparse interactions)\"></a>稀疏交互(sparse interactions)</h3><p><strong>在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。</strong></p>\n<p><img src=\"/images/dl_pic9_2.jpg\" alt=\"\"></p>\n<p>传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。其中，参数矩阵中的每一个单独的参数都描述了一个输入单元与一个输出单元间的交互。这意味着每一个输出单元与每一个输入单元都产生交互。然而卷积网络具有稀疏交互的特征，这是使核的大小远小于输入的大小来达到的。当处理一张图像时，输入的图像可能包含成千上万个像素点，但我们可以通过只占用几十到几百个像素点的核来检测一些小的有意义的特征，例如图像的边缘。</p>\n<h3 id=\"参数共享-parameter-sharing\"><a href=\"#参数共享-parameter-sharing\" class=\"headerlink\" title=\"参数共享(parameter sharing)\"></a>参数共享(parameter sharing)</h3><p>特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。<strong>即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。</strong></p>\n<p>在传统的神经网络中，当计算一层的输出时，权重矩阵的每个元素只使用一次，当它乘以输入的一个元素后就再也不会用到了。在卷积神经网络中，核的每一个元素都作用在输入的每一个位置上。卷积运算中的参数共享保证了我们只需要学习一个参数集合，而不是对每一个位置都需要学习一个单独的参数集合。</p>\n<p><img src=\"/images/dl_pic9_5.jpg\" alt=\"\"></p>\n<h3 id=\"等变表示-equivarient-representations\"><a href=\"#等变表示-equivarient-representations\" class=\"headerlink\" title=\"等变表示(equivarient representations)\"></a>等变表示(equivarient representations)</h3><p>等变的数学概念<br>$$如果函数f(x), g(x)满足 f(g(x)) = g(f(x)) 我们就说f(x)对于变换g具有等变性 $$</p>\n<p>对于卷积来说，<strong>如果令g是输入的任意平移函数，那么卷积函数对于g具有等变性。</strong><br>在图像处理中，卷积产生了一个二维映射来表明某些特征在输入中出现的位置。如果我们移动输入中的对象，它的表示也会在输出中移动同样的量。</p>\n<h2 id=\"池化-pooling\"><a href=\"#池化-pooling\" class=\"headerlink\" title=\"池化(pooling)\"></a>池化(pooling)</h2><p>卷积网络中一个典型层包含三级<br><img src=\"/images/dl_pic9_7.jpg\" alt=\"\"></p>\n<p><strong>池化层</strong>的作用是在卷积后很好地聚合了特征，通过降维来减少运算量, 缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。</p>\n<p><strong>池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。</strong> 例如最大池化函数给出相邻区域内的最大值。</p>\n<p><strong>不管采用什么样的池化函数，当输入做出少量平移时，池化能够帮助输入的表示近似不变</strong>。局部平移不变性是一个很有用的性质，尤其当我们关心某个特征是否出现而不关心它出现的具体位置时。</p>\n<p>在很多任务中，池化对于处理不同大小的输入具有重要作用。例如我们想对不同大小的图像进行分类时，分类层的输入必须是固定大小，而这通常通过调整池化区域的偏置大小来实现，这样分类层总是能接收到相同数量的统计特征而不管最初的输入大小。例如最终的池化层可能会输入4组综合统计特征，每组对于着图像的一个象限。</p>\n<h2 id=\"卷积与池化作为一种无限强的先验\"><a href=\"#卷积与池化作为一种无限强的先验\" class=\"headerlink\" title=\"卷积与池化作为一种无限强的先验\"></a>卷积与池化作为一种无限强的先验</h2><blockquote>\n<p>先验概率分布。这是一个模型参数的概率分布，它刻画了我们在看到数据之前认为什么样的模型是合理的信念。先验被认为强或者弱取决于先验中概率密度的集中程度。一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值。</p>\n</blockquote>\n<p>我们可以把卷积网络类比成全连接网络，但对于这个全连接网络的权重有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权重必须和它邻居的权重相同，但可以在空间上移动。这个先验也要求那些处于隐藏单元的小的空间连续的接受域内的权重以外，其余权重都为零。</p>\n<p>类似地使用池化也是一个无限强的先验：每一个单元都具有对少量平移的不变性。</p>\n<h2 id=\"填充-Padding\"><a href=\"#填充-Padding\" class=\"headerlink\" title=\"填充(Padding)\"></a>填充(Padding)</h2><p>假设输入图片的大小为 $n \\times n$，而滤波器的大小为 $f \\times f$，则卷积后的输出图片大小为 $(n-f+1) \\times (n-f+1)$。</p>\n<p>这样就有两个问题：</p>\n<ul>\n<li>每次卷积运算后，输出图片的尺寸缩小；</li>\n<li>原始图片的角落、边缘区像素点在输出中采用较少，输出图片丢失边缘位置的很多信息。</li>\n</ul>\n<p>为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行 <strong>填充（Padding）</strong>，以增加矩阵的大小。通常将 0 作为填充值。</p>\n<p><img src=\"/images/Padding.jpg\" alt=\"\"></p>\n<p>设每个方向扩展像素点数量为 $p$，则填充后原始图片的大小为 $(n+2p) \\times (n+2p)$，滤波器大小保持 $f \\times f$不变，则输出图片大小为 $(n+2p-f+1) \\times (n+2p-f+1)$。</p>\n<p>因此，在进行卷积运算时，我们有两种选择：</p>\n<ul>\n<li><strong>Valid 卷积</strong>：不填充，直接卷积。结果大小为 $(n-f+1) \\times (n-f+1)$；</li>\n<li><strong>Same 卷积</strong>：进行填充，并使得卷积后结果大小与输入一致，这样 $p = \\frac{f-1}{2}$。</li>\n</ul>\n<p>在计算机视觉领域，$f$通常为奇数。原因包括 Same 卷积中 $p = \\frac{f-1}{2}$ 能得到自然数结果，并且滤波器有一个便于表示其所在位置的中心点。</p>\n<h2 id=\"卷积步长-Stride\"><a href=\"#卷积步长-Stride\" class=\"headerlink\" title=\"卷积步长(Stride)\"></a>卷积步长(Stride)</h2><p>卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置 <strong>步长（Stride）</strong> 来压缩一部分信息。</p>\n<p>步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。之前，步长被默认为 1。而如果我们设置步长为 2，则卷积过程如下图所示：</p>\n<p><img src=\"/images/Stride.jpg\" alt=\"\"></p>\n<p>设步长为 $s$，填充长度为 $p$，输入图片大小为 $n \\times n$，滤波器大小为 $f \\times f$，则卷积后图片的尺寸为：</p>\n<p>$$\\biggl\\lfloor \\frac{n+2p-f}{s}+1   \\biggr\\rfloor \\times \\biggl\\lfloor \\frac{n+2p-f}{s}+1 \\biggr\\rfloor$$</p>\n<h2 id=\"高维卷积\"><a href=\"#高维卷积\" class=\"headerlink\" title=\"高维卷积\"></a>高维卷积</h2><p>如果我们想要对三通道的 RGB 图片进行卷积运算，那么其对应的滤波器组也同样是三通道的。过程是将每个单通道（R，G，B）与对应的滤波器进行卷积运算求和，然后再将三个通道的和相加，将 27 个乘积的和作为输出图片的一个像素值。</p>\n<p><img src=\"/images/Convolutions-on-RGB-image.png\" alt=\"\"></p>\n<p>设输入图片的尺寸为 $n \\times n \\times n_c$（$n_c$为通道数），滤波器尺寸为 $f \\times f \\times n_c$，则卷积后的输出图片尺寸为 $(n-f+1) \\times (n-f+1) \\times n^{‘}_c$，$n^{‘}_c$为滤波器组的个数。</p>\n<h3 id=\"符号总结\"><a href=\"#符号总结\" class=\"headerlink\" title=\"符号总结\"></a>符号总结</h3><p>设 $l$ 层为卷积层：</p>\n<ul>\n<li>$f^{[l]}$：<strong>滤波器的高（或宽）</strong></li>\n<li>$p^{[l]}$：<strong>填充长度</strong></li>\n<li>$s^{[l]}$：<strong>步长</strong></li>\n<li><p>$n^{[l]}_c$：<strong>滤波器组的数量</strong></p>\n</li>\n<li><p><strong>输入维度</strong>：$n^{[l-1]}_H \\times n^{[l-1]}_W \\times n^{[l-1]}_c$ 。其中 $n^{[l-1]}_H$表示输入图片的高，$n^{[l-1]}_W$表示输入图片的宽。之前的示例中输入图片的高和宽都相同，但是实际中也可能不同，因此加上下标予以区分。</p>\n</li>\n<li><p><strong>输出维度</strong>：$n^{[l]}_H \\times n^{[l]}_W \\times n^{[l]}_c$ 。其中</p>\n</li>\n</ul>\n<p>$$n^{[l]}_H = \\biggl\\lfloor \\frac{n^{[l-1]}_H+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$</p>\n<p>$$n^{[l]}_W = \\biggl\\lfloor \\frac{n^{[l-1]}_W+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$</p>\n<ul>\n<li><strong>每个滤波器组的维度</strong>：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c$ 。其中$n^{[l-1]}_c$ 为输入图片通道数（也称深度）。</li>\n<li><strong>权重维度</strong>：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c$</li>\n<li><strong>偏置维度</strong>：$1 \\times 1 \\times 1 \\times n^{[l]}_c$</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Convolution-neural-network-CNN\"><a href=\"#Convolution-neural-network-CNN\" class=\"headerlink\" title=\"Convolution neural network(CNN)\"></a>Convolution neural network(CNN)</h2><p>是一种专门用来处理<strong>具有类似网格结构的数据</strong>的神经网络。例如时间序列数据(可以认为在时间轴上有规律的采样形成的一维网格)和图像数据(可以看作二维的像素网格)。</p>\n<h2 id=\"卷积运算\"><a href=\"#卷积运算\" class=\"headerlink\" title=\"卷积运算\"></a>卷积运算</h2><p>数学定义<br>$$f(t) = f_1(t) \\ast f_2(t) = \\int_{-\\infty}^{\\infty} f_1(\\tau)f_2(t - \\tau)d\\tau$$</p>\n<p>$$y(k) = f(k) \\ast h(k) = \\sum_{i = -\\infty}^{\\infty} f(i) h(k - i)$$</p>\n<p>二维图像的卷积表示<br>$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(m, n)K(i - m, j - n)$$</p>\n<p>神经网络中实现的卷积运算实际上是<strong>互相关函数</strong><br>$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(i + m, j + n)K(m, n)$$</p>\n<h2 id=\"三个重要思想\"><a href=\"#三个重要思想\" class=\"headerlink\" title=\"三个重要思想\"></a>三个重要思想</h2><h3 id=\"稀疏交互-sparse-interactions\"><a href=\"#稀疏交互-sparse-interactions\" class=\"headerlink\" title=\"稀疏交互(sparse interactions)\"></a>稀疏交互(sparse interactions)</h3><p><strong>在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。</strong></p>\n<p><img src=\"/images/dl_pic9_2.jpg\" alt=\"\"></p>\n<p>传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。其中，参数矩阵中的每一个单独的参数都描述了一个输入单元与一个输出单元间的交互。这意味着每一个输出单元与每一个输入单元都产生交互。然而卷积网络具有稀疏交互的特征，这是使核的大小远小于输入的大小来达到的。当处理一张图像时，输入的图像可能包含成千上万个像素点，但我们可以通过只占用几十到几百个像素点的核来检测一些小的有意义的特征，例如图像的边缘。</p>\n<h3 id=\"参数共享-parameter-sharing\"><a href=\"#参数共享-parameter-sharing\" class=\"headerlink\" title=\"参数共享(parameter sharing)\"></a>参数共享(parameter sharing)</h3><p>特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。<strong>即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。</strong></p>\n<p>在传统的神经网络中，当计算一层的输出时，权重矩阵的每个元素只使用一次，当它乘以输入的一个元素后就再也不会用到了。在卷积神经网络中，核的每一个元素都作用在输入的每一个位置上。卷积运算中的参数共享保证了我们只需要学习一个参数集合，而不是对每一个位置都需要学习一个单独的参数集合。</p>\n<p><img src=\"/images/dl_pic9_5.jpg\" alt=\"\"></p>\n<h3 id=\"等变表示-equivarient-representations\"><a href=\"#等变表示-equivarient-representations\" class=\"headerlink\" title=\"等变表示(equivarient representations)\"></a>等变表示(equivarient representations)</h3><p>等变的数学概念<br>$$如果函数f(x), g(x)满足 f(g(x)) = g(f(x)) 我们就说f(x)对于变换g具有等变性 $$</p>\n<p>对于卷积来说，<strong>如果令g是输入的任意平移函数，那么卷积函数对于g具有等变性。</strong><br>在图像处理中，卷积产生了一个二维映射来表明某些特征在输入中出现的位置。如果我们移动输入中的对象，它的表示也会在输出中移动同样的量。</p>\n<h2 id=\"池化-pooling\"><a href=\"#池化-pooling\" class=\"headerlink\" title=\"池化(pooling)\"></a>池化(pooling)</h2><p>卷积网络中一个典型层包含三级<br><img src=\"/images/dl_pic9_7.jpg\" alt=\"\"></p>\n<p><strong>池化层</strong>的作用是在卷积后很好地聚合了特征，通过降维来减少运算量, 缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。</p>\n<p><strong>池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。</strong> 例如最大池化函数给出相邻区域内的最大值。</p>\n<p><strong>不管采用什么样的池化函数，当输入做出少量平移时，池化能够帮助输入的表示近似不变</strong>。局部平移不变性是一个很有用的性质，尤其当我们关心某个特征是否出现而不关心它出现的具体位置时。</p>\n<p>在很多任务中，池化对于处理不同大小的输入具有重要作用。例如我们想对不同大小的图像进行分类时，分类层的输入必须是固定大小，而这通常通过调整池化区域的偏置大小来实现，这样分类层总是能接收到相同数量的统计特征而不管最初的输入大小。例如最终的池化层可能会输入4组综合统计特征，每组对于着图像的一个象限。</p>\n<h2 id=\"卷积与池化作为一种无限强的先验\"><a href=\"#卷积与池化作为一种无限强的先验\" class=\"headerlink\" title=\"卷积与池化作为一种无限强的先验\"></a>卷积与池化作为一种无限强的先验</h2><blockquote>\n<p>先验概率分布。这是一个模型参数的概率分布，它刻画了我们在看到数据之前认为什么样的模型是合理的信念。先验被认为强或者弱取决于先验中概率密度的集中程度。一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值。</p>\n</blockquote>\n<p>我们可以把卷积网络类比成全连接网络，但对于这个全连接网络的权重有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权重必须和它邻居的权重相同，但可以在空间上移动。这个先验也要求那些处于隐藏单元的小的空间连续的接受域内的权重以外，其余权重都为零。</p>\n<p>类似地使用池化也是一个无限强的先验：每一个单元都具有对少量平移的不变性。</p>\n<h2 id=\"填充-Padding\"><a href=\"#填充-Padding\" class=\"headerlink\" title=\"填充(Padding)\"></a>填充(Padding)</h2><p>假设输入图片的大小为 $n \\times n$，而滤波器的大小为 $f \\times f$，则卷积后的输出图片大小为 $(n-f+1) \\times (n-f+1)$。</p>\n<p>这样就有两个问题：</p>\n<ul>\n<li>每次卷积运算后，输出图片的尺寸缩小；</li>\n<li>原始图片的角落、边缘区像素点在输出中采用较少，输出图片丢失边缘位置的很多信息。</li>\n</ul>\n<p>为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行 <strong>填充（Padding）</strong>，以增加矩阵的大小。通常将 0 作为填充值。</p>\n<p><img src=\"/images/Padding.jpg\" alt=\"\"></p>\n<p>设每个方向扩展像素点数量为 $p$，则填充后原始图片的大小为 $(n+2p) \\times (n+2p)$，滤波器大小保持 $f \\times f$不变，则输出图片大小为 $(n+2p-f+1) \\times (n+2p-f+1)$。</p>\n<p>因此，在进行卷积运算时，我们有两种选择：</p>\n<ul>\n<li><strong>Valid 卷积</strong>：不填充，直接卷积。结果大小为 $(n-f+1) \\times (n-f+1)$；</li>\n<li><strong>Same 卷积</strong>：进行填充，并使得卷积后结果大小与输入一致，这样 $p = \\frac{f-1}{2}$。</li>\n</ul>\n<p>在计算机视觉领域，$f$通常为奇数。原因包括 Same 卷积中 $p = \\frac{f-1}{2}$ 能得到自然数结果，并且滤波器有一个便于表示其所在位置的中心点。</p>\n<h2 id=\"卷积步长-Stride\"><a href=\"#卷积步长-Stride\" class=\"headerlink\" title=\"卷积步长(Stride)\"></a>卷积步长(Stride)</h2><p>卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置 <strong>步长（Stride）</strong> 来压缩一部分信息。</p>\n<p>步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。之前，步长被默认为 1。而如果我们设置步长为 2，则卷积过程如下图所示：</p>\n<p><img src=\"/images/Stride.jpg\" alt=\"\"></p>\n<p>设步长为 $s$，填充长度为 $p$，输入图片大小为 $n \\times n$，滤波器大小为 $f \\times f$，则卷积后图片的尺寸为：</p>\n<p>$$\\biggl\\lfloor \\frac{n+2p-f}{s}+1   \\biggr\\rfloor \\times \\biggl\\lfloor \\frac{n+2p-f}{s}+1 \\biggr\\rfloor$$</p>\n<h2 id=\"高维卷积\"><a href=\"#高维卷积\" class=\"headerlink\" title=\"高维卷积\"></a>高维卷积</h2><p>如果我们想要对三通道的 RGB 图片进行卷积运算，那么其对应的滤波器组也同样是三通道的。过程是将每个单通道（R，G，B）与对应的滤波器进行卷积运算求和，然后再将三个通道的和相加，将 27 个乘积的和作为输出图片的一个像素值。</p>\n<p><img src=\"/images/Convolutions-on-RGB-image.png\" alt=\"\"></p>\n<p>设输入图片的尺寸为 $n \\times n \\times n_c$（$n_c$为通道数），滤波器尺寸为 $f \\times f \\times n_c$，则卷积后的输出图片尺寸为 $(n-f+1) \\times (n-f+1) \\times n^{‘}_c$，$n^{‘}_c$为滤波器组的个数。</p>\n<h3 id=\"符号总结\"><a href=\"#符号总结\" class=\"headerlink\" title=\"符号总结\"></a>符号总结</h3><p>设 $l$ 层为卷积层：</p>\n<ul>\n<li>$f^{[l]}$：<strong>滤波器的高（或宽）</strong></li>\n<li>$p^{[l]}$：<strong>填充长度</strong></li>\n<li>$s^{[l]}$：<strong>步长</strong></li>\n<li><p>$n^{[l]}_c$：<strong>滤波器组的数量</strong></p>\n</li>\n<li><p><strong>输入维度</strong>：$n^{[l-1]}_H \\times n^{[l-1]}_W \\times n^{[l-1]}_c$ 。其中 $n^{[l-1]}_H$表示输入图片的高，$n^{[l-1]}_W$表示输入图片的宽。之前的示例中输入图片的高和宽都相同，但是实际中也可能不同，因此加上下标予以区分。</p>\n</li>\n<li><p><strong>输出维度</strong>：$n^{[l]}_H \\times n^{[l]}_W \\times n^{[l]}_c$ 。其中</p>\n</li>\n</ul>\n<p>$$n^{[l]}_H = \\biggl\\lfloor \\frac{n^{[l-1]}_H+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$</p>\n<p>$$n^{[l]}_W = \\biggl\\lfloor \\frac{n^{[l-1]}_W+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$</p>\n<ul>\n<li><strong>每个滤波器组的维度</strong>：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c$ 。其中$n^{[l-1]}_c$ 为输入图片通道数（也称深度）。</li>\n<li><strong>权重维度</strong>：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c$</li>\n<li><strong>偏置维度</strong>：$1 \\times 1 \\times 1 \\times n^{[l]}_c$</li>\n</ul>\n"},{"title":"循环神经网络","date":"2018-09-01T09:05:05.000Z","mathjax":true,"_content":"**循环神经网络(Recurrent Neural Network)** 是一类用于处理序列数据的神经网络。如自然语言，音频这类前后关联的数据。\n\n使用RNN实现的应用包括下图所示：\n![Examples-of-Sequence-Model](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-Sequence-Model.png)\n\n## 数学符号\n\n对于一个序列数据 $x$，用符号 $x^{⟨t⟩}$ 来表示这个数据中的第 $t$个元素，用 $y^{⟨t⟩}$ 来表示第 $t$ 个标签，用 $T_x$ 和 $T_y$ 来表示输入和输出的长度。对于一段音频，元素可能是其中的几帧；对于一句话，元素可能是一到多个单词。\n\n第 $i$ 个序列数据的第 $t$ 个元素用符号 $x^{(i)⟨t⟩}$，第 $t$ 个标签即为 $y^{(i)⟨t⟩}$。对应即有 $T^{(i)}_x$ 和 $T^{(i)}_y$。\n\n想要表示一个词语，需要先建立一个 **词汇表（Vocabulary**，或者叫 **字典（Dictionary**。将需要表示的所有词语变为一个列向量，可以根据字母顺序排列，然后根据单词在向量中的位置，用 **one-hot 向量（one-hot vector）** 来表示该单词的标签：将每个单词编码成一个 $R^{|V| \\times 1}$ 向量，其中 $|V|$ 是词汇表中单词的数量。一个单词在词汇表中的索引在该向量对应的元素为 1，其余元素均为 0。\n\n例如，'zebra'排在词汇表的最后一位，因此它的词向量表示为：\n\n$$w^{zebra} = \\left [ 0, 0, 0, ..., 1\\right ]^T$$\n\n## 循环神经网络模型\n\n对于序列数据，使用标准神经网络存在以下问题：\n\n* 对于不同的示例，输入和输出可能有不同的长度，因此输入层和输出层的神经元数量无法固定。\n* 从输入文本的不同位置学到的同一特征无法共享。\n* 模型中的参数太多，计算量太大。\n\n为了解决这些问题，引入 **循环神经网络（Recurrent Neural Network，RNN）**。一种循环神经网络的结构如下图所示：\n\n![Recurrent-Neural-Network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Recurrent-Neural-Network.png)\n\n当元素 $x^{⟨t⟩}$ 输入对应时间步（Time Step）的隐藏层的同时，该隐藏层也会接收来自上一时间步的隐藏层的激活值 $a^{⟨t-1⟩}$，其中 $a^{⟨0⟩}$ 一般直接初始化为零向量。一个时间步输出一个对应的预测结果 $\\hat y^{⟨t⟩}$。\n\n循环神经网络从左向右扫描数据，同时每个时间步的参数也是共享的，输入、激活、输出的参数对应为 $W_{ax}$、$W_{aa}$、$W_{ay}$。\n\n下图是一个 RNN 神经元的结构：\n\n![RNN-cell](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/RNN-cell.png)\n\n前向传播过程的公式如下：\n\n$$a^{⟨0⟩} = \\vec{0}$$\n\n$$a^{⟨t⟩} = g_1(W_{aa}a^{⟨t-1⟩} + W_{ax}x^{⟨t⟩} + b_a)$$\n\n$$\\hat y^{⟨t⟩} = g_2(W_{ya}a^{⟨t⟩} + b_y)$$\n\n激活函数 $g_1$通常选择 tanh，有时也用 ReLU；$g_2$可选 sigmoid 或 softmax，取决于需要的输出类型。\n\n为了进一步简化公式以方便运算，可以将 $W_{ax}$、$W_{aa}$**水平并列** 为一个矩阵 $W_a$，同时 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$ **堆叠** 成一个矩阵。则有：\n\n$$W_a = [W_{ax}, W_{aa}]$$\n\n$$a^{⟨t⟩} = g_1(W_a[a^{⟨t-1⟩}, x^{⟨t⟩}] + b_a)$$\n\n$$\\hat y^{⟨t⟩} = g_2(W_{y}a^{⟨t⟩} + b_y)$$\n\n### 反向传播\n\n为了计算反向传播过程，需要先定义一个损失函数。单个位置上（或者说单个时间步上）某个单词的预测值的损失函数采用**交叉熵损失函数**，如下所示：\n\n$$L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -y^{⟨t⟩}log\\hat y^{⟨t⟩} - (1 - y^{⟨t⟩})log(1-\\hat y^{⟨t⟩})$$\n\n将单个位置上的损失函数相加，得到整个序列的成本函数如下：\n\n$$J = L(\\hat y, y) = \\sum^{T_x}_{t=1} L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$\n\n循环神经网络的反向传播被称为 **通过时间反向传播（Backpropagation through time）**，因为从右向左计算的过程就像是时间倒流。\n\n### 不同结构\n\n某些情况下，输入长度和输出长度不一致。根据所需的输入及输出长度，循环神经网络可分为“一对一”、“多对一”、“多对多”等结构：\n\n![Examples-of-RNN-architectures](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-RNN-architectures.png)\n\n目前我们看到的模型的问题是，只使用了这个序列中之前的信息来做出预测，即后文没有被使用。可以通过 **双向循环神经网络（Bidirectional RNN，BRNN）** 来解决这个问题。\n\n## 语言模型\n\n**语言模型（Language Model）** 是根据语言客观事实而进行的语言抽象数学建模，能够估计某个序列中各元素出现的可能性。例如，在一个语音识别系统中，语言模型能够计算两个读音相近的句子为正确结果的概率，以此为依据作出准确判断。\n\n建立语言模型所采用的训练集是一个大型的 **语料库（Corpus）**，指数量众多的句子组成的文本。建立过程的第一步是 **标记化（Tokenize）**，即建立字典；然后将语料库中的每个词表示为对应的 one-hot 向量。另外，需要增加一个额外的标记 EOS（End of Sentence）来表示一个句子的结尾。标点符号可以忽略，也可以加入字典后用 one-hot 向量表示。\n\n对于语料库中部分特殊的、不包含在字典中的词汇，例如人名、地名，可以不必针对这些具体的词，而是在词典中加入一个 UNK（Unique Token）标记来表示。\n\n将标志化后的训练集用于训练 RNN，过程如下图所示：\n\n![language-model-RNN-example](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/language-model-RNN-example.png)\n\n在第一个时间步中，输入的 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 都是零向量，$\\hat y^{⟨1⟩}$ 是通过 softmax 预测出的字典中每个词作为第一个词出现的概率；在第二个时间步中，输入的 $x^{⟨2⟩}$ 是训练样本的标签中的第一个单词 $y^{⟨1⟩}$（即“cats”）和上一层的激活项 $a^{⟨1⟩}$，输出的 $y^{⟨2⟩}$ 表示的是通过 softmax 预测出的、单词“cats”后面出现字典中的其他每个词的条件概率。以此类推，最后就可以得到整个句子出现的概率。\n\n定义损失函数为：\n\n$$L(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -\\sum_t y_i^{⟨t⟩} log \\hat y^{⟨t⟩}$$\n\n则成本函数为：\n\n$$J = \\sum_t L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$\n\n## 采样\n\n在训练好一个语言模型后，可以通过 **采样（Sample）** 新的序列来了解这个模型中都学习到了一些什么。\n\n![Sampling](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Sampling.png)\n\n在第一个时间步输入 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 为零向量，输出预测出的字典中每个词作为第一个词出现的概率，根据 softmax 的分布进行随机采样（`np.random.choice`），将采样得到的 $\\hat y^{⟨1⟩}$ 作为第二个时间步的输入 $x^{⟨2⟩}$。以此类推，直到采样到 EOS，最后模型会自动生成一些句子，从这些句子中可以发现模型通过语料库学习到的知识。\n\n这里建立的是基于词汇构建的语言模型。根据需要也可以构建基于字符的语言模型，其优点是不必担心出现未知标识（UNK），其缺点是得到的序列过多过长，并且训练成本高昂。因此，基于词汇构建的语言模型更为常用。\n\n## RNN 的梯度消失\n\n$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$\n\n$$The\\ cats, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ were\\ full.$$\n\n对于以上两个句子，后面的动词单复数形式由前面的名词的单复数形式决定。但是 **基本的 RNN 不擅长捕获这种长期依赖关系**。究其原因，由于梯度消失，在反向传播时，后面层的输出误差很难影响到较靠前层的计算，网络很难调整靠前的计算。\n\n在反向传播时，随着层数的增多，梯度不仅可能指数型下降，也有可能指数型上升，即梯度爆炸。不过梯度爆炸比较容易发现，因为参数会急剧膨胀到数值溢出（可能显示为 NaN）。这时可以采用 **梯度修剪（Gradient Clipping）** 来解决：观察梯度向量，如果它大于某个阈值，则缩放梯度向量以保证其不会太大。相比之下，梯度消失问题更难解决。**GRU 和 LSTM 都可以作为缓解梯度消失问题的方案**。\n\n## GRU（门控循环单元）\n\n**GRU（Gated Recurrent Units, 门控循环单元）** 改善了 RNN 的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题。\n\n$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$\n\n当我们从左到右读上面这个句子时，GRU 单元有一个新的变量称为 $c$，代表 **记忆细胞（Memory Cell）**，其作用是提供记忆的能力，记住例如前文主语是单数还是复数等信息。在时间 t，记忆细胞的值 $c^{⟨t⟩}$ 等于输出的激活值 $a^{⟨t⟩}$；$\\tilde c^{⟨t⟩}$ 代表下一个 $c$ 的候选值。$Γ_u$ 代表 **更新门（Update Gate）** ，用于决定什么时候更新记忆细胞的值。以上结构的具体公式为：\n\n$$\\tilde c^{⟨t⟩} = tanh(W_c[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$\n\n$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$\n\n$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$\n\n$$a^{⟨t⟩} = c^{⟨t⟩}$$\n\n当使用 sigmoid 作为激活函数 $\\sigma$ 来得到 $Γ_u$时，$Γ_u$ 的值在 0 到 1 的范围内，且大多数时间非常接近于 0 或 1。当 $Γ_u = 1$时，$c^{⟨t⟩}$ 被更新为 $\\tilde c^{⟨t⟩}$，否则保持为 $c^{⟨t-1⟩}$。因为 $Γ_u$ 可以很接近 0，因此 $c^{⟨t⟩}$ 几乎就等于 $c^{⟨t-1⟩}$。在经过很长的序列后，$c$ 的值依然被维持，从而实现“记忆”的功能。\n\n以上实际上是简化过的 GRU 单元，但是蕴涵了 GRU 最重要的思想。完整的 GRU 单元添加了一个新的**相关门（Relevance Gate）** $Γ_r$，表示 $\\tilde c^{⟨t⟩}$ 和 $c^{⟨t⟩}$ 的相关性。因此，表达式改为如下所示：\n\n$$\\tilde c^{⟨t⟩} = tanh(W_c[Γ_r * c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$\n\n$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$\n\n$$Γ_r = \\sigma(W_r[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_r)$$\n\n$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$\n\n$$a^{⟨t⟩} = c^{⟨t⟩}$$\n\n相关论文：\n\n1. [Cho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches](https://arxiv.org/pdf/1409.1259.pdf)\n2. [Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/pdf/1412.3555.pdf)\n\n## LSTM（长短期记忆）\n\n**LSTM（Long Short Term Memory，长短期记忆）** 网络比 GRU 更加灵活和强大，它额外引入了 **遗忘门（Forget Gate）** $Γ_f$ 和 **输出门（Output Gate）** $Γ_o$。其结构图和公式如下：\n\n![LSTM](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/LSTM.png)\n\n将多个 LSTM 单元按时间次序连接起来，就得到一个 LSTM 网络。\n\n以上是简化版的 LSTM。在更为常用的版本中，几个门值不仅取决于 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$，有时也可以偷窥上一个记忆细胞输入的值 $c^{⟨t-1⟩}$，这被称为 **窥视孔连接（Peephole Connection)**。这时，和 GRU 不同，$c^{⟨t-1⟩}$ 和门值是一对一的。\n\n$c^{0}$ 常被初始化为零向量。\n\n相关论文：[Hochreiter & Schmidhuber 1997. Long short-term memory](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory)\n\n## 双向循环神经网络（BRNN）\n\n单向的循环神经网络在某一时刻的预测结果只能使用之前输入的序列信息。**双向循环神经网络（Bidirectional RNN，BRNN）** 可以在序列的任意位置使用之前和之后的数据。其工作原理是增加一个反向循环层，结构如下图所示：\n\n![BRNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/BRNN.png)\n\n因此，有\n\n$$y^{⟨t⟩} = g(W_y[\\overrightarrow a^{⟨t⟩},  \\overleftarrow a^{⟨t⟩}] + b_y)$$\n\n这个改进的方法不仅能用于基本的 RNN，也可以用于 GRU 或 LSTM。**缺点** 是需要完整的序列数据，才能预测任意位置的结果。例如构建语音识别系统，需要等待用户说完并获取整个语音表达，才能处理这段语音并进一步做语音识别。因此，实际应用会有更加复杂的模块。\n\n## 深度循环神经网络（DRNN)\n\n循环神经网络的每个时间步上也可以包含多个隐藏层，形成 **深度循环神经网络（Deep RNN)** 。结构如下图所示：\n\n![DRNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/DRNN.png)\n\n以 $a^{[2]⟨3⟩}$ 为例，有 $a^{[2]⟨3⟩} = g(W_a^{[2]}[a^{[2]⟨2⟩}, a^{[1]⟨3⟩}] + b_a^{[2]})$。\n","source":"_posts/循环神经网络.md","raw":"---\ntitle: 循环神经网络\ndate: 2018-09-01 17:05:05\ntags: RNN\ncategories: 深度学习\nmathjax: true\n---\n**循环神经网络(Recurrent Neural Network)** 是一类用于处理序列数据的神经网络。如自然语言，音频这类前后关联的数据。\n\n使用RNN实现的应用包括下图所示：\n![Examples-of-Sequence-Model](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-Sequence-Model.png)\n\n## 数学符号\n\n对于一个序列数据 $x$，用符号 $x^{⟨t⟩}$ 来表示这个数据中的第 $t$个元素，用 $y^{⟨t⟩}$ 来表示第 $t$ 个标签，用 $T_x$ 和 $T_y$ 来表示输入和输出的长度。对于一段音频，元素可能是其中的几帧；对于一句话，元素可能是一到多个单词。\n\n第 $i$ 个序列数据的第 $t$ 个元素用符号 $x^{(i)⟨t⟩}$，第 $t$ 个标签即为 $y^{(i)⟨t⟩}$。对应即有 $T^{(i)}_x$ 和 $T^{(i)}_y$。\n\n想要表示一个词语，需要先建立一个 **词汇表（Vocabulary**，或者叫 **字典（Dictionary**。将需要表示的所有词语变为一个列向量，可以根据字母顺序排列，然后根据单词在向量中的位置，用 **one-hot 向量（one-hot vector）** 来表示该单词的标签：将每个单词编码成一个 $R^{|V| \\times 1}$ 向量，其中 $|V|$ 是词汇表中单词的数量。一个单词在词汇表中的索引在该向量对应的元素为 1，其余元素均为 0。\n\n例如，'zebra'排在词汇表的最后一位，因此它的词向量表示为：\n\n$$w^{zebra} = \\left [ 0, 0, 0, ..., 1\\right ]^T$$\n\n## 循环神经网络模型\n\n对于序列数据，使用标准神经网络存在以下问题：\n\n* 对于不同的示例，输入和输出可能有不同的长度，因此输入层和输出层的神经元数量无法固定。\n* 从输入文本的不同位置学到的同一特征无法共享。\n* 模型中的参数太多，计算量太大。\n\n为了解决这些问题，引入 **循环神经网络（Recurrent Neural Network，RNN）**。一种循环神经网络的结构如下图所示：\n\n![Recurrent-Neural-Network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Recurrent-Neural-Network.png)\n\n当元素 $x^{⟨t⟩}$ 输入对应时间步（Time Step）的隐藏层的同时，该隐藏层也会接收来自上一时间步的隐藏层的激活值 $a^{⟨t-1⟩}$，其中 $a^{⟨0⟩}$ 一般直接初始化为零向量。一个时间步输出一个对应的预测结果 $\\hat y^{⟨t⟩}$。\n\n循环神经网络从左向右扫描数据，同时每个时间步的参数也是共享的，输入、激活、输出的参数对应为 $W_{ax}$、$W_{aa}$、$W_{ay}$。\n\n下图是一个 RNN 神经元的结构：\n\n![RNN-cell](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/RNN-cell.png)\n\n前向传播过程的公式如下：\n\n$$a^{⟨0⟩} = \\vec{0}$$\n\n$$a^{⟨t⟩} = g_1(W_{aa}a^{⟨t-1⟩} + W_{ax}x^{⟨t⟩} + b_a)$$\n\n$$\\hat y^{⟨t⟩} = g_2(W_{ya}a^{⟨t⟩} + b_y)$$\n\n激活函数 $g_1$通常选择 tanh，有时也用 ReLU；$g_2$可选 sigmoid 或 softmax，取决于需要的输出类型。\n\n为了进一步简化公式以方便运算，可以将 $W_{ax}$、$W_{aa}$**水平并列** 为一个矩阵 $W_a$，同时 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$ **堆叠** 成一个矩阵。则有：\n\n$$W_a = [W_{ax}, W_{aa}]$$\n\n$$a^{⟨t⟩} = g_1(W_a[a^{⟨t-1⟩}, x^{⟨t⟩}] + b_a)$$\n\n$$\\hat y^{⟨t⟩} = g_2(W_{y}a^{⟨t⟩} + b_y)$$\n\n### 反向传播\n\n为了计算反向传播过程，需要先定义一个损失函数。单个位置上（或者说单个时间步上）某个单词的预测值的损失函数采用**交叉熵损失函数**，如下所示：\n\n$$L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -y^{⟨t⟩}log\\hat y^{⟨t⟩} - (1 - y^{⟨t⟩})log(1-\\hat y^{⟨t⟩})$$\n\n将单个位置上的损失函数相加，得到整个序列的成本函数如下：\n\n$$J = L(\\hat y, y) = \\sum^{T_x}_{t=1} L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$\n\n循环神经网络的反向传播被称为 **通过时间反向传播（Backpropagation through time）**，因为从右向左计算的过程就像是时间倒流。\n\n### 不同结构\n\n某些情况下，输入长度和输出长度不一致。根据所需的输入及输出长度，循环神经网络可分为“一对一”、“多对一”、“多对多”等结构：\n\n![Examples-of-RNN-architectures](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-RNN-architectures.png)\n\n目前我们看到的模型的问题是，只使用了这个序列中之前的信息来做出预测，即后文没有被使用。可以通过 **双向循环神经网络（Bidirectional RNN，BRNN）** 来解决这个问题。\n\n## 语言模型\n\n**语言模型（Language Model）** 是根据语言客观事实而进行的语言抽象数学建模，能够估计某个序列中各元素出现的可能性。例如，在一个语音识别系统中，语言模型能够计算两个读音相近的句子为正确结果的概率，以此为依据作出准确判断。\n\n建立语言模型所采用的训练集是一个大型的 **语料库（Corpus）**，指数量众多的句子组成的文本。建立过程的第一步是 **标记化（Tokenize）**，即建立字典；然后将语料库中的每个词表示为对应的 one-hot 向量。另外，需要增加一个额外的标记 EOS（End of Sentence）来表示一个句子的结尾。标点符号可以忽略，也可以加入字典后用 one-hot 向量表示。\n\n对于语料库中部分特殊的、不包含在字典中的词汇，例如人名、地名，可以不必针对这些具体的词，而是在词典中加入一个 UNK（Unique Token）标记来表示。\n\n将标志化后的训练集用于训练 RNN，过程如下图所示：\n\n![language-model-RNN-example](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/language-model-RNN-example.png)\n\n在第一个时间步中，输入的 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 都是零向量，$\\hat y^{⟨1⟩}$ 是通过 softmax 预测出的字典中每个词作为第一个词出现的概率；在第二个时间步中，输入的 $x^{⟨2⟩}$ 是训练样本的标签中的第一个单词 $y^{⟨1⟩}$（即“cats”）和上一层的激活项 $a^{⟨1⟩}$，输出的 $y^{⟨2⟩}$ 表示的是通过 softmax 预测出的、单词“cats”后面出现字典中的其他每个词的条件概率。以此类推，最后就可以得到整个句子出现的概率。\n\n定义损失函数为：\n\n$$L(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -\\sum_t y_i^{⟨t⟩} log \\hat y^{⟨t⟩}$$\n\n则成本函数为：\n\n$$J = \\sum_t L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$\n\n## 采样\n\n在训练好一个语言模型后，可以通过 **采样（Sample）** 新的序列来了解这个模型中都学习到了一些什么。\n\n![Sampling](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Sampling.png)\n\n在第一个时间步输入 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 为零向量，输出预测出的字典中每个词作为第一个词出现的概率，根据 softmax 的分布进行随机采样（`np.random.choice`），将采样得到的 $\\hat y^{⟨1⟩}$ 作为第二个时间步的输入 $x^{⟨2⟩}$。以此类推，直到采样到 EOS，最后模型会自动生成一些句子，从这些句子中可以发现模型通过语料库学习到的知识。\n\n这里建立的是基于词汇构建的语言模型。根据需要也可以构建基于字符的语言模型，其优点是不必担心出现未知标识（UNK），其缺点是得到的序列过多过长，并且训练成本高昂。因此，基于词汇构建的语言模型更为常用。\n\n## RNN 的梯度消失\n\n$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$\n\n$$The\\ cats, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ were\\ full.$$\n\n对于以上两个句子，后面的动词单复数形式由前面的名词的单复数形式决定。但是 **基本的 RNN 不擅长捕获这种长期依赖关系**。究其原因，由于梯度消失，在反向传播时，后面层的输出误差很难影响到较靠前层的计算，网络很难调整靠前的计算。\n\n在反向传播时，随着层数的增多，梯度不仅可能指数型下降，也有可能指数型上升，即梯度爆炸。不过梯度爆炸比较容易发现，因为参数会急剧膨胀到数值溢出（可能显示为 NaN）。这时可以采用 **梯度修剪（Gradient Clipping）** 来解决：观察梯度向量，如果它大于某个阈值，则缩放梯度向量以保证其不会太大。相比之下，梯度消失问题更难解决。**GRU 和 LSTM 都可以作为缓解梯度消失问题的方案**。\n\n## GRU（门控循环单元）\n\n**GRU（Gated Recurrent Units, 门控循环单元）** 改善了 RNN 的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题。\n\n$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$\n\n当我们从左到右读上面这个句子时，GRU 单元有一个新的变量称为 $c$，代表 **记忆细胞（Memory Cell）**，其作用是提供记忆的能力，记住例如前文主语是单数还是复数等信息。在时间 t，记忆细胞的值 $c^{⟨t⟩}$ 等于输出的激活值 $a^{⟨t⟩}$；$\\tilde c^{⟨t⟩}$ 代表下一个 $c$ 的候选值。$Γ_u$ 代表 **更新门（Update Gate）** ，用于决定什么时候更新记忆细胞的值。以上结构的具体公式为：\n\n$$\\tilde c^{⟨t⟩} = tanh(W_c[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$\n\n$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$\n\n$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$\n\n$$a^{⟨t⟩} = c^{⟨t⟩}$$\n\n当使用 sigmoid 作为激活函数 $\\sigma$ 来得到 $Γ_u$时，$Γ_u$ 的值在 0 到 1 的范围内，且大多数时间非常接近于 0 或 1。当 $Γ_u = 1$时，$c^{⟨t⟩}$ 被更新为 $\\tilde c^{⟨t⟩}$，否则保持为 $c^{⟨t-1⟩}$。因为 $Γ_u$ 可以很接近 0，因此 $c^{⟨t⟩}$ 几乎就等于 $c^{⟨t-1⟩}$。在经过很长的序列后，$c$ 的值依然被维持，从而实现“记忆”的功能。\n\n以上实际上是简化过的 GRU 单元，但是蕴涵了 GRU 最重要的思想。完整的 GRU 单元添加了一个新的**相关门（Relevance Gate）** $Γ_r$，表示 $\\tilde c^{⟨t⟩}$ 和 $c^{⟨t⟩}$ 的相关性。因此，表达式改为如下所示：\n\n$$\\tilde c^{⟨t⟩} = tanh(W_c[Γ_r * c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$\n\n$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$\n\n$$Γ_r = \\sigma(W_r[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_r)$$\n\n$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$\n\n$$a^{⟨t⟩} = c^{⟨t⟩}$$\n\n相关论文：\n\n1. [Cho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches](https://arxiv.org/pdf/1409.1259.pdf)\n2. [Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/pdf/1412.3555.pdf)\n\n## LSTM（长短期记忆）\n\n**LSTM（Long Short Term Memory，长短期记忆）** 网络比 GRU 更加灵活和强大，它额外引入了 **遗忘门（Forget Gate）** $Γ_f$ 和 **输出门（Output Gate）** $Γ_o$。其结构图和公式如下：\n\n![LSTM](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/LSTM.png)\n\n将多个 LSTM 单元按时间次序连接起来，就得到一个 LSTM 网络。\n\n以上是简化版的 LSTM。在更为常用的版本中，几个门值不仅取决于 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$，有时也可以偷窥上一个记忆细胞输入的值 $c^{⟨t-1⟩}$，这被称为 **窥视孔连接（Peephole Connection)**。这时，和 GRU 不同，$c^{⟨t-1⟩}$ 和门值是一对一的。\n\n$c^{0}$ 常被初始化为零向量。\n\n相关论文：[Hochreiter & Schmidhuber 1997. Long short-term memory](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory)\n\n## 双向循环神经网络（BRNN）\n\n单向的循环神经网络在某一时刻的预测结果只能使用之前输入的序列信息。**双向循环神经网络（Bidirectional RNN，BRNN）** 可以在序列的任意位置使用之前和之后的数据。其工作原理是增加一个反向循环层，结构如下图所示：\n\n![BRNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/BRNN.png)\n\n因此，有\n\n$$y^{⟨t⟩} = g(W_y[\\overrightarrow a^{⟨t⟩},  \\overleftarrow a^{⟨t⟩}] + b_y)$$\n\n这个改进的方法不仅能用于基本的 RNN，也可以用于 GRU 或 LSTM。**缺点** 是需要完整的序列数据，才能预测任意位置的结果。例如构建语音识别系统，需要等待用户说完并获取整个语音表达，才能处理这段语音并进一步做语音识别。因此，实际应用会有更加复杂的模块。\n\n## 深度循环神经网络（DRNN)\n\n循环神经网络的每个时间步上也可以包含多个隐藏层，形成 **深度循环神经网络（Deep RNN)** 。结构如下图所示：\n\n![DRNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/DRNN.png)\n\n以 $a^{[2]⟨3⟩}$ 为例，有 $a^{[2]⟨3⟩} = g(W_a^{[2]}[a^{[2]⟨2⟩}, a^{[1]⟨3⟩}] + b_a^{[2]})$。\n","slug":"循环神经网络","published":1,"updated":"2018-09-01T14:15:14.770Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds52002spcvoew94a24z","content":"<p><strong>循环神经网络(Recurrent Neural Network)</strong> 是一类用于处理序列数据的神经网络。如自然语言，音频这类前后关联的数据。</p>\n<p>使用RNN实现的应用包括下图所示：<br><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-Sequence-Model.png\" alt=\"Examples-of-Sequence-Model\"></p>\n<h2 id=\"数学符号\"><a href=\"#数学符号\" class=\"headerlink\" title=\"数学符号\"></a>数学符号</h2><p>对于一个序列数据 $x$，用符号 $x^{⟨t⟩}$ 来表示这个数据中的第 $t$个元素，用 $y^{⟨t⟩}$ 来表示第 $t$ 个标签，用 $T_x$ 和 $T_y$ 来表示输入和输出的长度。对于一段音频，元素可能是其中的几帧；对于一句话，元素可能是一到多个单词。</p>\n<p>第 $i$ 个序列数据的第 $t$ 个元素用符号 $x^{(i)⟨t⟩}$，第 $t$ 个标签即为 $y^{(i)⟨t⟩}$。对应即有 $T^{(i)}_x$ 和 $T^{(i)}_y$。</p>\n<p>想要表示一个词语，需要先建立一个 <strong>词汇表（Vocabulary</strong>，或者叫 <strong>字典（Dictionary</strong>。将需要表示的所有词语变为一个列向量，可以根据字母顺序排列，然后根据单词在向量中的位置，用 <strong>one-hot 向量（one-hot vector）</strong> 来表示该单词的标签：将每个单词编码成一个 $R^{|V| \\times 1}$ 向量，其中 $|V|$ 是词汇表中单词的数量。一个单词在词汇表中的索引在该向量对应的元素为 1，其余元素均为 0。</p>\n<p>例如，’zebra’排在词汇表的最后一位，因此它的词向量表示为：</p>\n<p>$$w^{zebra} = \\left [ 0, 0, 0, …, 1\\right ]^T$$</p>\n<h2 id=\"循环神经网络模型\"><a href=\"#循环神经网络模型\" class=\"headerlink\" title=\"循环神经网络模型\"></a>循环神经网络模型</h2><p>对于序列数据，使用标准神经网络存在以下问题：</p>\n<ul>\n<li>对于不同的示例，输入和输出可能有不同的长度，因此输入层和输出层的神经元数量无法固定。</li>\n<li>从输入文本的不同位置学到的同一特征无法共享。</li>\n<li>模型中的参数太多，计算量太大。</li>\n</ul>\n<p>为了解决这些问题，引入 <strong>循环神经网络（Recurrent Neural Network，RNN）</strong>。一种循环神经网络的结构如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Recurrent-Neural-Network.png\" alt=\"Recurrent-Neural-Network\"></p>\n<p>当元素 $x^{⟨t⟩}$ 输入对应时间步（Time Step）的隐藏层的同时，该隐藏层也会接收来自上一时间步的隐藏层的激活值 $a^{⟨t-1⟩}$，其中 $a^{⟨0⟩}$ 一般直接初始化为零向量。一个时间步输出一个对应的预测结果 $\\hat y^{⟨t⟩}$。</p>\n<p>循环神经网络从左向右扫描数据，同时每个时间步的参数也是共享的，输入、激活、输出的参数对应为 $W_{ax}$、$W_{aa}$、$W_{ay}$。</p>\n<p>下图是一个 RNN 神经元的结构：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/RNN-cell.png\" alt=\"RNN-cell\"></p>\n<p>前向传播过程的公式如下：</p>\n<p>$$a^{⟨0⟩} = \\vec{0}$$</p>\n<p>$$a^{⟨t⟩} = g_1(W_{aa}a^{⟨t-1⟩} + W_{ax}x^{⟨t⟩} + b_a)$$</p>\n<p>$$\\hat y^{⟨t⟩} = g_2(W_{ya}a^{⟨t⟩} + b_y)$$</p>\n<p>激活函数 $g_1$通常选择 tanh，有时也用 ReLU；$g_2$可选 sigmoid 或 softmax，取决于需要的输出类型。</p>\n<p>为了进一步简化公式以方便运算，可以将 $W_{ax}$、$W_{aa}$<strong>水平并列</strong> 为一个矩阵 $W_a$，同时 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$ <strong>堆叠</strong> 成一个矩阵。则有：</p>\n<p>$$W_a = [W_{ax}, W_{aa}]$$</p>\n<p>$$a^{⟨t⟩} = g_1(W_a[a^{⟨t-1⟩}, x^{⟨t⟩}] + b_a)$$</p>\n<p>$$\\hat y^{⟨t⟩} = g_2(W_{y}a^{⟨t⟩} + b_y)$$</p>\n<h3 id=\"反向传播\"><a href=\"#反向传播\" class=\"headerlink\" title=\"反向传播\"></a>反向传播</h3><p>为了计算反向传播过程，需要先定义一个损失函数。单个位置上（或者说单个时间步上）某个单词的预测值的损失函数采用<strong>交叉熵损失函数</strong>，如下所示：</p>\n<p>$$L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -y^{⟨t⟩}log\\hat y^{⟨t⟩} - (1 - y^{⟨t⟩})log(1-\\hat y^{⟨t⟩})$$</p>\n<p>将单个位置上的损失函数相加，得到整个序列的成本函数如下：</p>\n<p>$$J = L(\\hat y, y) = \\sum^{T_x}_{t=1} L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$</p>\n<p>循环神经网络的反向传播被称为 <strong>通过时间反向传播（Backpropagation through time）</strong>，因为从右向左计算的过程就像是时间倒流。</p>\n<h3 id=\"不同结构\"><a href=\"#不同结构\" class=\"headerlink\" title=\"不同结构\"></a>不同结构</h3><p>某些情况下，输入长度和输出长度不一致。根据所需的输入及输出长度，循环神经网络可分为“一对一”、“多对一”、“多对多”等结构：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-RNN-architectures.png\" alt=\"Examples-of-RNN-architectures\"></p>\n<p>目前我们看到的模型的问题是，只使用了这个序列中之前的信息来做出预测，即后文没有被使用。可以通过 <strong>双向循环神经网络（Bidirectional RNN，BRNN）</strong> 来解决这个问题。</p>\n<h2 id=\"语言模型\"><a href=\"#语言模型\" class=\"headerlink\" title=\"语言模型\"></a>语言模型</h2><p><strong>语言模型（Language Model）</strong> 是根据语言客观事实而进行的语言抽象数学建模，能够估计某个序列中各元素出现的可能性。例如，在一个语音识别系统中，语言模型能够计算两个读音相近的句子为正确结果的概率，以此为依据作出准确判断。</p>\n<p>建立语言模型所采用的训练集是一个大型的 <strong>语料库（Corpus）</strong>，指数量众多的句子组成的文本。建立过程的第一步是 <strong>标记化（Tokenize）</strong>，即建立字典；然后将语料库中的每个词表示为对应的 one-hot 向量。另外，需要增加一个额外的标记 EOS（End of Sentence）来表示一个句子的结尾。标点符号可以忽略，也可以加入字典后用 one-hot 向量表示。</p>\n<p>对于语料库中部分特殊的、不包含在字典中的词汇，例如人名、地名，可以不必针对这些具体的词，而是在词典中加入一个 UNK（Unique Token）标记来表示。</p>\n<p>将标志化后的训练集用于训练 RNN，过程如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/language-model-RNN-example.png\" alt=\"language-model-RNN-example\"></p>\n<p>在第一个时间步中，输入的 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 都是零向量，$\\hat y^{⟨1⟩}$ 是通过 softmax 预测出的字典中每个词作为第一个词出现的概率；在第二个时间步中，输入的 $x^{⟨2⟩}$ 是训练样本的标签中的第一个单词 $y^{⟨1⟩}$（即“cats”）和上一层的激活项 $a^{⟨1⟩}$，输出的 $y^{⟨2⟩}$ 表示的是通过 softmax 预测出的、单词“cats”后面出现字典中的其他每个词的条件概率。以此类推，最后就可以得到整个句子出现的概率。</p>\n<p>定义损失函数为：</p>\n<p>$$L(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -\\sum_t y_i^{⟨t⟩} log \\hat y^{⟨t⟩}$$</p>\n<p>则成本函数为：</p>\n<p>$$J = \\sum_t L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$</p>\n<h2 id=\"采样\"><a href=\"#采样\" class=\"headerlink\" title=\"采样\"></a>采样</h2><p>在训练好一个语言模型后，可以通过 <strong>采样（Sample）</strong> 新的序列来了解这个模型中都学习到了一些什么。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Sampling.png\" alt=\"Sampling\"></p>\n<p>在第一个时间步输入 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 为零向量，输出预测出的字典中每个词作为第一个词出现的概率，根据 softmax 的分布进行随机采样（<code>np.random.choice</code>），将采样得到的 $\\hat y^{⟨1⟩}$ 作为第二个时间步的输入 $x^{⟨2⟩}$。以此类推，直到采样到 EOS，最后模型会自动生成一些句子，从这些句子中可以发现模型通过语料库学习到的知识。</p>\n<p>这里建立的是基于词汇构建的语言模型。根据需要也可以构建基于字符的语言模型，其优点是不必担心出现未知标识（UNK），其缺点是得到的序列过多过长，并且训练成本高昂。因此，基于词汇构建的语言模型更为常用。</p>\n<h2 id=\"RNN-的梯度消失\"><a href=\"#RNN-的梯度消失\" class=\"headerlink\" title=\"RNN 的梯度消失\"></a>RNN 的梯度消失</h2><p>$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$</p>\n<p>$$The\\ cats, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ were\\ full.$$</p>\n<p>对于以上两个句子，后面的动词单复数形式由前面的名词的单复数形式决定。但是 <strong>基本的 RNN 不擅长捕获这种长期依赖关系</strong>。究其原因，由于梯度消失，在反向传播时，后面层的输出误差很难影响到较靠前层的计算，网络很难调整靠前的计算。</p>\n<p>在反向传播时，随着层数的增多，梯度不仅可能指数型下降，也有可能指数型上升，即梯度爆炸。不过梯度爆炸比较容易发现，因为参数会急剧膨胀到数值溢出（可能显示为 NaN）。这时可以采用 <strong>梯度修剪（Gradient Clipping）</strong> 来解决：观察梯度向量，如果它大于某个阈值，则缩放梯度向量以保证其不会太大。相比之下，梯度消失问题更难解决。<strong>GRU 和 LSTM 都可以作为缓解梯度消失问题的方案</strong>。</p>\n<h2 id=\"GRU（门控循环单元）\"><a href=\"#GRU（门控循环单元）\" class=\"headerlink\" title=\"GRU（门控循环单元）\"></a>GRU（门控循环单元）</h2><p><strong>GRU（Gated Recurrent Units, 门控循环单元）</strong> 改善了 RNN 的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题。</p>\n<p>$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$</p>\n<p>当我们从左到右读上面这个句子时，GRU 单元有一个新的变量称为 $c$，代表 <strong>记忆细胞（Memory Cell）</strong>，其作用是提供记忆的能力，记住例如前文主语是单数还是复数等信息。在时间 t，记忆细胞的值 $c^{⟨t⟩}$ 等于输出的激活值 $a^{⟨t⟩}$；$\\tilde c^{⟨t⟩}$ 代表下一个 $c$ 的候选值。$Γ_u$ 代表 <strong>更新门（Update Gate）</strong> ，用于决定什么时候更新记忆细胞的值。以上结构的具体公式为：</p>\n<p>$$\\tilde c^{⟨t⟩} = tanh(W_c[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$</p>\n<p>$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$</p>\n<p>$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$</p>\n<p>$$a^{⟨t⟩} = c^{⟨t⟩}$$</p>\n<p>当使用 sigmoid 作为激活函数 $\\sigma$ 来得到 $Γ_u$时，$Γ_u$ 的值在 0 到 1 的范围内，且大多数时间非常接近于 0 或 1。当 $Γ_u = 1$时，$c^{⟨t⟩}$ 被更新为 $\\tilde c^{⟨t⟩}$，否则保持为 $c^{⟨t-1⟩}$。因为 $Γ_u$ 可以很接近 0，因此 $c^{⟨t⟩}$ 几乎就等于 $c^{⟨t-1⟩}$。在经过很长的序列后，$c$ 的值依然被维持，从而实现“记忆”的功能。</p>\n<p>以上实际上是简化过的 GRU 单元，但是蕴涵了 GRU 最重要的思想。完整的 GRU 单元添加了一个新的<strong>相关门（Relevance Gate）</strong> $Γ_r$，表示 $\\tilde c^{⟨t⟩}$ 和 $c^{⟨t⟩}$ 的相关性。因此，表达式改为如下所示：</p>\n<p>$$\\tilde c^{⟨t⟩} = tanh(W_c[Γ_r * c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$</p>\n<p>$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$</p>\n<p>$$Γ_r = \\sigma(W_r[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_r)$$</p>\n<p>$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$</p>\n<p>$$a^{⟨t⟩} = c^{⟨t⟩}$$</p>\n<p>相关论文：</p>\n<ol>\n<li><a href=\"https://arxiv.org/pdf/1409.1259.pdf\" target=\"_blank\" rel=\"noopener\">Cho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches</a></li>\n<li><a href=\"https://arxiv.org/pdf/1412.3555.pdf\" target=\"_blank\" rel=\"noopener\">Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</a></li>\n</ol>\n<h2 id=\"LSTM（长短期记忆）\"><a href=\"#LSTM（长短期记忆）\" class=\"headerlink\" title=\"LSTM（长短期记忆）\"></a>LSTM（长短期记忆）</h2><p><strong>LSTM（Long Short Term Memory，长短期记忆）</strong> 网络比 GRU 更加灵活和强大，它额外引入了 <strong>遗忘门（Forget Gate）</strong> $Γ_f$ 和 <strong>输出门（Output Gate）</strong> $Γ_o$。其结构图和公式如下：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/LSTM.png\" alt=\"LSTM\"></p>\n<p>将多个 LSTM 单元按时间次序连接起来，就得到一个 LSTM 网络。</p>\n<p>以上是简化版的 LSTM。在更为常用的版本中，几个门值不仅取决于 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$，有时也可以偷窥上一个记忆细胞输入的值 $c^{⟨t-1⟩}$，这被称为 <strong>窥视孔连接（Peephole Connection)</strong>。这时，和 GRU 不同，$c^{⟨t-1⟩}$ 和门值是一对一的。</p>\n<p>$c^{0}$ 常被初始化为零向量。</p>\n<p>相关论文：<a href=\"https://www.researchgate.net/publication/13853244_Long_Short-term_Memory\" target=\"_blank\" rel=\"noopener\">Hochreiter &amp; Schmidhuber 1997. Long short-term memory</a></p>\n<h2 id=\"双向循环神经网络（BRNN）\"><a href=\"#双向循环神经网络（BRNN）\" class=\"headerlink\" title=\"双向循环神经网络（BRNN）\"></a>双向循环神经网络（BRNN）</h2><p>单向的循环神经网络在某一时刻的预测结果只能使用之前输入的序列信息。<strong>双向循环神经网络（Bidirectional RNN，BRNN）</strong> 可以在序列的任意位置使用之前和之后的数据。其工作原理是增加一个反向循环层，结构如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/BRNN.png\" alt=\"BRNN\"></p>\n<p>因此，有</p>\n<p>$$y^{⟨t⟩} = g(W_y[\\overrightarrow a^{⟨t⟩},  \\overleftarrow a^{⟨t⟩}] + b_y)$$</p>\n<p>这个改进的方法不仅能用于基本的 RNN，也可以用于 GRU 或 LSTM。<strong>缺点</strong> 是需要完整的序列数据，才能预测任意位置的结果。例如构建语音识别系统，需要等待用户说完并获取整个语音表达，才能处理这段语音并进一步做语音识别。因此，实际应用会有更加复杂的模块。</p>\n<h2 id=\"深度循环神经网络（DRNN\"><a href=\"#深度循环神经网络（DRNN\" class=\"headerlink\" title=\"深度循环神经网络（DRNN)\"></a>深度循环神经网络（DRNN)</h2><p>循环神经网络的每个时间步上也可以包含多个隐藏层，形成 <strong>深度循环神经网络（Deep RNN)</strong> 。结构如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/DRNN.png\" alt=\"DRNN\"></p>\n<p>以 $a^{[2]⟨3⟩}$ 为例，有 $a^{[2]⟨3⟩} = g(W_a^{[2]}[a^{[2]⟨2⟩}, a^{[1]⟨3⟩}] + b_a^{[2]})$。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>循环神经网络(Recurrent Neural Network)</strong> 是一类用于处理序列数据的神经网络。如自然语言，音频这类前后关联的数据。</p>\n<p>使用RNN实现的应用包括下图所示：<br><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-Sequence-Model.png\" alt=\"Examples-of-Sequence-Model\"></p>\n<h2 id=\"数学符号\"><a href=\"#数学符号\" class=\"headerlink\" title=\"数学符号\"></a>数学符号</h2><p>对于一个序列数据 $x$，用符号 $x^{⟨t⟩}$ 来表示这个数据中的第 $t$个元素，用 $y^{⟨t⟩}$ 来表示第 $t$ 个标签，用 $T_x$ 和 $T_y$ 来表示输入和输出的长度。对于一段音频，元素可能是其中的几帧；对于一句话，元素可能是一到多个单词。</p>\n<p>第 $i$ 个序列数据的第 $t$ 个元素用符号 $x^{(i)⟨t⟩}$，第 $t$ 个标签即为 $y^{(i)⟨t⟩}$。对应即有 $T^{(i)}_x$ 和 $T^{(i)}_y$。</p>\n<p>想要表示一个词语，需要先建立一个 <strong>词汇表（Vocabulary</strong>，或者叫 <strong>字典（Dictionary</strong>。将需要表示的所有词语变为一个列向量，可以根据字母顺序排列，然后根据单词在向量中的位置，用 <strong>one-hot 向量（one-hot vector）</strong> 来表示该单词的标签：将每个单词编码成一个 $R^{|V| \\times 1}$ 向量，其中 $|V|$ 是词汇表中单词的数量。一个单词在词汇表中的索引在该向量对应的元素为 1，其余元素均为 0。</p>\n<p>例如，’zebra’排在词汇表的最后一位，因此它的词向量表示为：</p>\n<p>$$w^{zebra} = \\left [ 0, 0, 0, …, 1\\right ]^T$$</p>\n<h2 id=\"循环神经网络模型\"><a href=\"#循环神经网络模型\" class=\"headerlink\" title=\"循环神经网络模型\"></a>循环神经网络模型</h2><p>对于序列数据，使用标准神经网络存在以下问题：</p>\n<ul>\n<li>对于不同的示例，输入和输出可能有不同的长度，因此输入层和输出层的神经元数量无法固定。</li>\n<li>从输入文本的不同位置学到的同一特征无法共享。</li>\n<li>模型中的参数太多，计算量太大。</li>\n</ul>\n<p>为了解决这些问题，引入 <strong>循环神经网络（Recurrent Neural Network，RNN）</strong>。一种循环神经网络的结构如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Recurrent-Neural-Network.png\" alt=\"Recurrent-Neural-Network\"></p>\n<p>当元素 $x^{⟨t⟩}$ 输入对应时间步（Time Step）的隐藏层的同时，该隐藏层也会接收来自上一时间步的隐藏层的激活值 $a^{⟨t-1⟩}$，其中 $a^{⟨0⟩}$ 一般直接初始化为零向量。一个时间步输出一个对应的预测结果 $\\hat y^{⟨t⟩}$。</p>\n<p>循环神经网络从左向右扫描数据，同时每个时间步的参数也是共享的，输入、激活、输出的参数对应为 $W_{ax}$、$W_{aa}$、$W_{ay}$。</p>\n<p>下图是一个 RNN 神经元的结构：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/RNN-cell.png\" alt=\"RNN-cell\"></p>\n<p>前向传播过程的公式如下：</p>\n<p>$$a^{⟨0⟩} = \\vec{0}$$</p>\n<p>$$a^{⟨t⟩} = g_1(W_{aa}a^{⟨t-1⟩} + W_{ax}x^{⟨t⟩} + b_a)$$</p>\n<p>$$\\hat y^{⟨t⟩} = g_2(W_{ya}a^{⟨t⟩} + b_y)$$</p>\n<p>激活函数 $g_1$通常选择 tanh，有时也用 ReLU；$g_2$可选 sigmoid 或 softmax，取决于需要的输出类型。</p>\n<p>为了进一步简化公式以方便运算，可以将 $W_{ax}$、$W_{aa}$<strong>水平并列</strong> 为一个矩阵 $W_a$，同时 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$ <strong>堆叠</strong> 成一个矩阵。则有：</p>\n<p>$$W_a = [W_{ax}, W_{aa}]$$</p>\n<p>$$a^{⟨t⟩} = g_1(W_a[a^{⟨t-1⟩}, x^{⟨t⟩}] + b_a)$$</p>\n<p>$$\\hat y^{⟨t⟩} = g_2(W_{y}a^{⟨t⟩} + b_y)$$</p>\n<h3 id=\"反向传播\"><a href=\"#反向传播\" class=\"headerlink\" title=\"反向传播\"></a>反向传播</h3><p>为了计算反向传播过程，需要先定义一个损失函数。单个位置上（或者说单个时间步上）某个单词的预测值的损失函数采用<strong>交叉熵损失函数</strong>，如下所示：</p>\n<p>$$L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -y^{⟨t⟩}log\\hat y^{⟨t⟩} - (1 - y^{⟨t⟩})log(1-\\hat y^{⟨t⟩})$$</p>\n<p>将单个位置上的损失函数相加，得到整个序列的成本函数如下：</p>\n<p>$$J = L(\\hat y, y) = \\sum^{T_x}_{t=1} L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$</p>\n<p>循环神经网络的反向传播被称为 <strong>通过时间反向传播（Backpropagation through time）</strong>，因为从右向左计算的过程就像是时间倒流。</p>\n<h3 id=\"不同结构\"><a href=\"#不同结构\" class=\"headerlink\" title=\"不同结构\"></a>不同结构</h3><p>某些情况下，输入长度和输出长度不一致。根据所需的输入及输出长度，循环神经网络可分为“一对一”、“多对一”、“多对多”等结构：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-RNN-architectures.png\" alt=\"Examples-of-RNN-architectures\"></p>\n<p>目前我们看到的模型的问题是，只使用了这个序列中之前的信息来做出预测，即后文没有被使用。可以通过 <strong>双向循环神经网络（Bidirectional RNN，BRNN）</strong> 来解决这个问题。</p>\n<h2 id=\"语言模型\"><a href=\"#语言模型\" class=\"headerlink\" title=\"语言模型\"></a>语言模型</h2><p><strong>语言模型（Language Model）</strong> 是根据语言客观事实而进行的语言抽象数学建模，能够估计某个序列中各元素出现的可能性。例如，在一个语音识别系统中，语言模型能够计算两个读音相近的句子为正确结果的概率，以此为依据作出准确判断。</p>\n<p>建立语言模型所采用的训练集是一个大型的 <strong>语料库（Corpus）</strong>，指数量众多的句子组成的文本。建立过程的第一步是 <strong>标记化（Tokenize）</strong>，即建立字典；然后将语料库中的每个词表示为对应的 one-hot 向量。另外，需要增加一个额外的标记 EOS（End of Sentence）来表示一个句子的结尾。标点符号可以忽略，也可以加入字典后用 one-hot 向量表示。</p>\n<p>对于语料库中部分特殊的、不包含在字典中的词汇，例如人名、地名，可以不必针对这些具体的词，而是在词典中加入一个 UNK（Unique Token）标记来表示。</p>\n<p>将标志化后的训练集用于训练 RNN，过程如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/language-model-RNN-example.png\" alt=\"language-model-RNN-example\"></p>\n<p>在第一个时间步中，输入的 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 都是零向量，$\\hat y^{⟨1⟩}$ 是通过 softmax 预测出的字典中每个词作为第一个词出现的概率；在第二个时间步中，输入的 $x^{⟨2⟩}$ 是训练样本的标签中的第一个单词 $y^{⟨1⟩}$（即“cats”）和上一层的激活项 $a^{⟨1⟩}$，输出的 $y^{⟨2⟩}$ 表示的是通过 softmax 预测出的、单词“cats”后面出现字典中的其他每个词的条件概率。以此类推，最后就可以得到整个句子出现的概率。</p>\n<p>定义损失函数为：</p>\n<p>$$L(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -\\sum_t y_i^{⟨t⟩} log \\hat y^{⟨t⟩}$$</p>\n<p>则成本函数为：</p>\n<p>$$J = \\sum_t L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$</p>\n<h2 id=\"采样\"><a href=\"#采样\" class=\"headerlink\" title=\"采样\"></a>采样</h2><p>在训练好一个语言模型后，可以通过 <strong>采样（Sample）</strong> 新的序列来了解这个模型中都学习到了一些什么。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Sampling.png\" alt=\"Sampling\"></p>\n<p>在第一个时间步输入 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 为零向量，输出预测出的字典中每个词作为第一个词出现的概率，根据 softmax 的分布进行随机采样（<code>np.random.choice</code>），将采样得到的 $\\hat y^{⟨1⟩}$ 作为第二个时间步的输入 $x^{⟨2⟩}$。以此类推，直到采样到 EOS，最后模型会自动生成一些句子，从这些句子中可以发现模型通过语料库学习到的知识。</p>\n<p>这里建立的是基于词汇构建的语言模型。根据需要也可以构建基于字符的语言模型，其优点是不必担心出现未知标识（UNK），其缺点是得到的序列过多过长，并且训练成本高昂。因此，基于词汇构建的语言模型更为常用。</p>\n<h2 id=\"RNN-的梯度消失\"><a href=\"#RNN-的梯度消失\" class=\"headerlink\" title=\"RNN 的梯度消失\"></a>RNN 的梯度消失</h2><p>$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$</p>\n<p>$$The\\ cats, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ were\\ full.$$</p>\n<p>对于以上两个句子，后面的动词单复数形式由前面的名词的单复数形式决定。但是 <strong>基本的 RNN 不擅长捕获这种长期依赖关系</strong>。究其原因，由于梯度消失，在反向传播时，后面层的输出误差很难影响到较靠前层的计算，网络很难调整靠前的计算。</p>\n<p>在反向传播时，随着层数的增多，梯度不仅可能指数型下降，也有可能指数型上升，即梯度爆炸。不过梯度爆炸比较容易发现，因为参数会急剧膨胀到数值溢出（可能显示为 NaN）。这时可以采用 <strong>梯度修剪（Gradient Clipping）</strong> 来解决：观察梯度向量，如果它大于某个阈值，则缩放梯度向量以保证其不会太大。相比之下，梯度消失问题更难解决。<strong>GRU 和 LSTM 都可以作为缓解梯度消失问题的方案</strong>。</p>\n<h2 id=\"GRU（门控循环单元）\"><a href=\"#GRU（门控循环单元）\" class=\"headerlink\" title=\"GRU（门控循环单元）\"></a>GRU（门控循环单元）</h2><p><strong>GRU（Gated Recurrent Units, 门控循环单元）</strong> 改善了 RNN 的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题。</p>\n<p>$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$</p>\n<p>当我们从左到右读上面这个句子时，GRU 单元有一个新的变量称为 $c$，代表 <strong>记忆细胞（Memory Cell）</strong>，其作用是提供记忆的能力，记住例如前文主语是单数还是复数等信息。在时间 t，记忆细胞的值 $c^{⟨t⟩}$ 等于输出的激活值 $a^{⟨t⟩}$；$\\tilde c^{⟨t⟩}$ 代表下一个 $c$ 的候选值。$Γ_u$ 代表 <strong>更新门（Update Gate）</strong> ，用于决定什么时候更新记忆细胞的值。以上结构的具体公式为：</p>\n<p>$$\\tilde c^{⟨t⟩} = tanh(W_c[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$</p>\n<p>$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$</p>\n<p>$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$</p>\n<p>$$a^{⟨t⟩} = c^{⟨t⟩}$$</p>\n<p>当使用 sigmoid 作为激活函数 $\\sigma$ 来得到 $Γ_u$时，$Γ_u$ 的值在 0 到 1 的范围内，且大多数时间非常接近于 0 或 1。当 $Γ_u = 1$时，$c^{⟨t⟩}$ 被更新为 $\\tilde c^{⟨t⟩}$，否则保持为 $c^{⟨t-1⟩}$。因为 $Γ_u$ 可以很接近 0，因此 $c^{⟨t⟩}$ 几乎就等于 $c^{⟨t-1⟩}$。在经过很长的序列后，$c$ 的值依然被维持，从而实现“记忆”的功能。</p>\n<p>以上实际上是简化过的 GRU 单元，但是蕴涵了 GRU 最重要的思想。完整的 GRU 单元添加了一个新的<strong>相关门（Relevance Gate）</strong> $Γ_r$，表示 $\\tilde c^{⟨t⟩}$ 和 $c^{⟨t⟩}$ 的相关性。因此，表达式改为如下所示：</p>\n<p>$$\\tilde c^{⟨t⟩} = tanh(W_c[Γ_r * c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$</p>\n<p>$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$</p>\n<p>$$Γ_r = \\sigma(W_r[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_r)$$</p>\n<p>$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$</p>\n<p>$$a^{⟨t⟩} = c^{⟨t⟩}$$</p>\n<p>相关论文：</p>\n<ol>\n<li><a href=\"https://arxiv.org/pdf/1409.1259.pdf\" target=\"_blank\" rel=\"noopener\">Cho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches</a></li>\n<li><a href=\"https://arxiv.org/pdf/1412.3555.pdf\" target=\"_blank\" rel=\"noopener\">Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</a></li>\n</ol>\n<h2 id=\"LSTM（长短期记忆）\"><a href=\"#LSTM（长短期记忆）\" class=\"headerlink\" title=\"LSTM（长短期记忆）\"></a>LSTM（长短期记忆）</h2><p><strong>LSTM（Long Short Term Memory，长短期记忆）</strong> 网络比 GRU 更加灵活和强大，它额外引入了 <strong>遗忘门（Forget Gate）</strong> $Γ_f$ 和 <strong>输出门（Output Gate）</strong> $Γ_o$。其结构图和公式如下：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/LSTM.png\" alt=\"LSTM\"></p>\n<p>将多个 LSTM 单元按时间次序连接起来，就得到一个 LSTM 网络。</p>\n<p>以上是简化版的 LSTM。在更为常用的版本中，几个门值不仅取决于 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$，有时也可以偷窥上一个记忆细胞输入的值 $c^{⟨t-1⟩}$，这被称为 <strong>窥视孔连接（Peephole Connection)</strong>。这时，和 GRU 不同，$c^{⟨t-1⟩}$ 和门值是一对一的。</p>\n<p>$c^{0}$ 常被初始化为零向量。</p>\n<p>相关论文：<a href=\"https://www.researchgate.net/publication/13853244_Long_Short-term_Memory\" target=\"_blank\" rel=\"noopener\">Hochreiter &amp; Schmidhuber 1997. Long short-term memory</a></p>\n<h2 id=\"双向循环神经网络（BRNN）\"><a href=\"#双向循环神经网络（BRNN）\" class=\"headerlink\" title=\"双向循环神经网络（BRNN）\"></a>双向循环神经网络（BRNN）</h2><p>单向的循环神经网络在某一时刻的预测结果只能使用之前输入的序列信息。<strong>双向循环神经网络（Bidirectional RNN，BRNN）</strong> 可以在序列的任意位置使用之前和之后的数据。其工作原理是增加一个反向循环层，结构如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/BRNN.png\" alt=\"BRNN\"></p>\n<p>因此，有</p>\n<p>$$y^{⟨t⟩} = g(W_y[\\overrightarrow a^{⟨t⟩},  \\overleftarrow a^{⟨t⟩}] + b_y)$$</p>\n<p>这个改进的方法不仅能用于基本的 RNN，也可以用于 GRU 或 LSTM。<strong>缺点</strong> 是需要完整的序列数据，才能预测任意位置的结果。例如构建语音识别系统，需要等待用户说完并获取整个语音表达，才能处理这段语音并进一步做语音识别。因此，实际应用会有更加复杂的模块。</p>\n<h2 id=\"深度循环神经网络（DRNN\"><a href=\"#深度循环神经网络（DRNN\" class=\"headerlink\" title=\"深度循环神经网络（DRNN)\"></a>深度循环神经网络（DRNN)</h2><p>循环神经网络的每个时间步上也可以包含多个隐藏层，形成 <strong>深度循环神经网络（Deep RNN)</strong> 。结构如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/DRNN.png\" alt=\"DRNN\"></p>\n<p>以 $a^{[2]⟨3⟩}$ 为例，有 $a^{[2]⟨3⟩} = g(W_a^{[2]}[a^{[2]⟨2⟩}, a^{[1]⟨3⟩}] + b_a^{[2]})$。</p>\n"},{"title":"恋爱领域中普遍存在的贬低倾向","date":"2018-07-19T13:03:37.000Z","_content":"\n## 心理阳痿\n\n### 症状\n\n受该障碍困扰者，力比多的活动强烈而旺盛，然而在发作时，执行性欲之器官却无法实行性行为。只有在与某些人做爱时才会失败，与其他人则不会。\n\n### 成因\n\n实际上，这是由于主体的某些心理情结尚未得到认识而产生出的抑制力。他未能克服对母亲或姐妹的乱伦固着，这一点在病因中十分显著，且普遍存在于受此障碍困扰的人身上。此外，主体在婴幼儿时期的性活动中意外获得的某些受挫印象所产生的影响力从总体上削减了理应导向女性性对象的力比多。该障碍的基础在于，在力比多的发展获得我们所谓的正常的最终形态之前，其发展历程中出现了一种抑制，而这或许也是所有神经官能障碍的基础。有两种因素的结合保证了完全正确的爱情态度，即 **情感趋向**和 **肉欲趋向**。这一发展上的抑制有两个来源：一是童年期的强烈固着，二是在反乱伦壁垒的干涉下个体在现实中遭遇了挫折。\n\n### 措施\n\n从心理上贬低性对象，而正常情况在对性对象的过高评价，在这里则会被留给了乱伦对象及其代表。一旦完成心理上的贬低，便能自由地表达性欲。\n\n----\n摘自弗洛伊德的《爱情心理学》第二章\n","source":"_posts/恋爱领域中普遍存在的贬低倾向.md","raw":"---\ntitle: 恋爱领域中普遍存在的贬低倾向\ndate: 2018-07-19 21:03:37\ntags: 爱情心理学\ncategories: 心理学\n---\n\n## 心理阳痿\n\n### 症状\n\n受该障碍困扰者，力比多的活动强烈而旺盛，然而在发作时，执行性欲之器官却无法实行性行为。只有在与某些人做爱时才会失败，与其他人则不会。\n\n### 成因\n\n实际上，这是由于主体的某些心理情结尚未得到认识而产生出的抑制力。他未能克服对母亲或姐妹的乱伦固着，这一点在病因中十分显著，且普遍存在于受此障碍困扰的人身上。此外，主体在婴幼儿时期的性活动中意外获得的某些受挫印象所产生的影响力从总体上削减了理应导向女性性对象的力比多。该障碍的基础在于，在力比多的发展获得我们所谓的正常的最终形态之前，其发展历程中出现了一种抑制，而这或许也是所有神经官能障碍的基础。有两种因素的结合保证了完全正确的爱情态度，即 **情感趋向**和 **肉欲趋向**。这一发展上的抑制有两个来源：一是童年期的强烈固着，二是在反乱伦壁垒的干涉下个体在现实中遭遇了挫折。\n\n### 措施\n\n从心理上贬低性对象，而正常情况在对性对象的过高评价，在这里则会被留给了乱伦对象及其代表。一旦完成心理上的贬低，便能自由地表达性欲。\n\n----\n摘自弗洛伊德的《爱情心理学》第二章\n","slug":"恋爱领域中普遍存在的贬低倾向","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds52002wpcvoehm7vggp","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"心理阳痿\"><a href=\"#心理阳痿\" class=\"headerlink\" title=\"心理阳痿\"></a>心理阳痿</h2><h3 id=\"症状\"><a href=\"#症状\" class=\"headerlink\" title=\"症状\"></a>症状</h3><p>受该障碍困扰者，力比多的活动强烈而旺盛，然而在发作时，执行性欲之器官却无法实行性行为。只有在与某些人做爱时才会失败，与其他人则不会。</p>\n<h3 id=\"成因\"><a href=\"#成因\" class=\"headerlink\" title=\"成因\"></a>成因</h3><p>实际上，这是由于主体的某些心理情结尚未得到认识而产生出的抑制力。他未能克服对母亲或姐妹的乱伦固着，这一点在病因中十分显著，且普遍存在于受此障碍困扰的人身上。此外，主体在婴幼儿时期的性活动中意外获得的某些受挫印象所产生的影响力从总体上削减了理应导向女性性对象的力比多。该障碍的基础在于，在力比多的发展获得我们所谓的正常的最终形态之前，其发展历程中出现了一种抑制，而这或许也是所有神经官能障碍的基础。有两种因素的结合保证了完全正确的爱情态度，即 <strong>情感趋向</strong>和 <strong>肉欲趋向</strong>。这一发展上的抑制有两个来源：一是童年期的强烈固着，二是在反乱伦壁垒的干涉下个体在现实中遭遇了挫折。</p>\n<h3 id=\"措施\"><a href=\"#措施\" class=\"headerlink\" title=\"措施\"></a>措施</h3><p>从心理上贬低性对象，而正常情况在对性对象的过高评价，在这里则会被留给了乱伦对象及其代表。一旦完成心理上的贬低，便能自由地表达性欲。</p>\n<hr>\n<p>摘自弗洛伊德的《爱情心理学》第二章</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"心理阳痿\"><a href=\"#心理阳痿\" class=\"headerlink\" title=\"心理阳痿\"></a>心理阳痿</h2><h3 id=\"症状\"><a href=\"#症状\" class=\"headerlink\" title=\"症状\"></a>症状</h3><p>受该障碍困扰者，力比多的活动强烈而旺盛，然而在发作时，执行性欲之器官却无法实行性行为。只有在与某些人做爱时才会失败，与其他人则不会。</p>\n<h3 id=\"成因\"><a href=\"#成因\" class=\"headerlink\" title=\"成因\"></a>成因</h3><p>实际上，这是由于主体的某些心理情结尚未得到认识而产生出的抑制力。他未能克服对母亲或姐妹的乱伦固着，这一点在病因中十分显著，且普遍存在于受此障碍困扰的人身上。此外，主体在婴幼儿时期的性活动中意外获得的某些受挫印象所产生的影响力从总体上削减了理应导向女性性对象的力比多。该障碍的基础在于，在力比多的发展获得我们所谓的正常的最终形态之前，其发展历程中出现了一种抑制，而这或许也是所有神经官能障碍的基础。有两种因素的结合保证了完全正确的爱情态度，即 <strong>情感趋向</strong>和 <strong>肉欲趋向</strong>。这一发展上的抑制有两个来源：一是童年期的强烈固着，二是在反乱伦壁垒的干涉下个体在现实中遭遇了挫折。</p>\n<h3 id=\"措施\"><a href=\"#措施\" class=\"headerlink\" title=\"措施\"></a>措施</h3><p>从心理上贬低性对象，而正常情况在对性对象的过高评价，在这里则会被留给了乱伦对象及其代表。一旦完成心理上的贬低，便能自由地表达性欲。</p>\n<hr>\n<p>摘自弗洛伊德的《爱情心理学》第二章</p>\n"},{"title":"数据的加载-预处理-可视化","date":"2018-07-21T09:33:49.000Z","_content":"## 图片操作\n\n### 把图片转换为向量\n\n```python\ndef image2vector(image):\n    \"\"\"\n    Argument:\n    image -- a numpy array of shape (length, height, depth)\n\n    Returns:\n    v -- a vector of shape (length*height*depth, 1)\n    \"\"\"\n    v = image.reshape((image.shape[0] * image.shape[1] * image.shape[2], 1))    \n    return v\n```\n### 读入图片\n\n```python\nmy_image = \"my_image.jpg\" # change this to the name of your image file\nmy_label_y = [1] # the true class of your image (1 -> cat, 0 -> non-cat)\nfname = \"images/\" + my_image\nimage = np.array(ndimage.imread(fname, flatten=False))\nmy_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))\nmy_predicted_image = predict(my_image, my_label_y, parameters)\n\nplt.imshow(image)\nprint (\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")\n```\n\n## 矩阵的正则化\n\n```python\ndef normalize(x):\n    \"\"\"\n    Implement a function that normalizes each row of the matrix x (to have unit length).\n\n    Argument:\n    x -- A numpy matrix of shape (n, m)\n\n    Returns:\n    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n    \"\"\"\n    x_norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)  # column: axis=0\n    x = x / x_norm\n    return x\n```\n\n## 猫的数据集\n\n```python\ndef load_dataset():\n    \"\"\"\n    Returns:\n    train_set_x_orig -- shape of (209, 64, 64, 3)\n    train_set_y_orig -- shape of (1, 209)\n    test_set_x_orig -- shape of (50, 64, 64, 3)\n    test_set_y_orig -- shape of (1, 50)\n    \"\"\"\n    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n\n    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n\n    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n\n    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n\n    return train_set_x_orig, train_set_y_orig, test_set_x_origtest_set_x_orig, test_set_y_orig, classes\n```\n\n### 可视化\n\n```python\nindex = 23\nplt.imshow(train_set_x_orig[index])\nprint (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")\nplt.show()\n```\n\n### 向量化\n\n```python\ntrain_x_set_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\ntest_x_set_flatten = train_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n```\n\n### 标准化\n\n```python\ntrain_x_set = train_x_set_flatten / 255\ntest_x_set = test_x_set_flatten / 255\n```\n\n## 二维数据的一般操作\n\n### 加载\n\n```python\ndef load_planar_dataset():\n    \"\"\"\n    Returns:\n    X -- a numpy array shaped (2, 400) that contains features (x1, x2)\n    Y -- a numpy array shaped (1, 400) that contains labels (0, 1)\n    \"\"\"\n    np.random.seed(1)\n    m = 400  # number of examples\n    N = int(m / 2)  # number of points per class\n    D = 2  # dimensionality\n    X = np.zeros((m, D))  # data matrix where each row is a single example\n    # labels vector (0 for red, 1 for blue)\n    Y = np.zeros((m, 1), dtype='uint8')\n    a = 4  # maximum ray of the flower\n    for j in range(2):\n        ix = range(N * j, N * (j + 1))\n        t = np.linspace(j * 3.12, (j + 1) * 3.12, N) + \\\n            np.random.randn(N) * 0.2  # theta\n        r = a * np.sin(4 * t) + np.random.randn(N) * 0.2  # radius\n        X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n        Y[ix] = j\n    X = X.T\n    Y = Y.T\n    return X, Y\n```\n\n### 可视化\n\n```python\nplt.scatter(X[0, :], X[1, :], c=Y.flatten(), s=40, cmp=plt.cm.Spectral)\nplt.show()\n```\n\n### 可视化决策边界\n\n```python\ndef plot_decision_boundary(model, X, y):\n    # Set min and max values and give it some padding\n    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n    h = 0.01\n    # Generate a grid of points with distance h between them\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    # Predict the function value for the whole grid\n    Z = model(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    # Plot the contour and training examples\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n    plt.ylabel('x2')\n    plt.xlabel('x1')\n    plt.scatter(X[0, :], X[1, :], c=y.flatten(), cmap=plt.cm.Spectral)\n```\n\n\n## Sklearn中的其他数据集\n\n```python\ndef load_extra_datasets():\n    N = 200\n    noisy_circles = sklearn.datasets.make_circles(\n        n_samples=N, factor=.5, noise=.3)\n    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n    blobs = sklearn.datasets.make_blobs(\n        n_samples=N, random_state=5, n_features=2, centers=6)\n    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(\n        mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n\n    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure\n```\n","source":"_posts/数据的加载-预处理-可视化.md","raw":"---\ntitle: 数据的加载-预处理-可视化\ndate: 2018-07-21 17:33:49\ntags: 数据\ncategories: 深度学习\n---\n## 图片操作\n\n### 把图片转换为向量\n\n```python\ndef image2vector(image):\n    \"\"\"\n    Argument:\n    image -- a numpy array of shape (length, height, depth)\n\n    Returns:\n    v -- a vector of shape (length*height*depth, 1)\n    \"\"\"\n    v = image.reshape((image.shape[0] * image.shape[1] * image.shape[2], 1))    \n    return v\n```\n### 读入图片\n\n```python\nmy_image = \"my_image.jpg\" # change this to the name of your image file\nmy_label_y = [1] # the true class of your image (1 -> cat, 0 -> non-cat)\nfname = \"images/\" + my_image\nimage = np.array(ndimage.imread(fname, flatten=False))\nmy_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))\nmy_predicted_image = predict(my_image, my_label_y, parameters)\n\nplt.imshow(image)\nprint (\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")\n```\n\n## 矩阵的正则化\n\n```python\ndef normalize(x):\n    \"\"\"\n    Implement a function that normalizes each row of the matrix x (to have unit length).\n\n    Argument:\n    x -- A numpy matrix of shape (n, m)\n\n    Returns:\n    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n    \"\"\"\n    x_norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)  # column: axis=0\n    x = x / x_norm\n    return x\n```\n\n## 猫的数据集\n\n```python\ndef load_dataset():\n    \"\"\"\n    Returns:\n    train_set_x_orig -- shape of (209, 64, 64, 3)\n    train_set_y_orig -- shape of (1, 209)\n    test_set_x_orig -- shape of (50, 64, 64, 3)\n    test_set_y_orig -- shape of (1, 50)\n    \"\"\"\n    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n\n    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n\n    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n\n    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n\n    return train_set_x_orig, train_set_y_orig, test_set_x_origtest_set_x_orig, test_set_y_orig, classes\n```\n\n### 可视化\n\n```python\nindex = 23\nplt.imshow(train_set_x_orig[index])\nprint (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")\nplt.show()\n```\n\n### 向量化\n\n```python\ntrain_x_set_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\ntest_x_set_flatten = train_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n```\n\n### 标准化\n\n```python\ntrain_x_set = train_x_set_flatten / 255\ntest_x_set = test_x_set_flatten / 255\n```\n\n## 二维数据的一般操作\n\n### 加载\n\n```python\ndef load_planar_dataset():\n    \"\"\"\n    Returns:\n    X -- a numpy array shaped (2, 400) that contains features (x1, x2)\n    Y -- a numpy array shaped (1, 400) that contains labels (0, 1)\n    \"\"\"\n    np.random.seed(1)\n    m = 400  # number of examples\n    N = int(m / 2)  # number of points per class\n    D = 2  # dimensionality\n    X = np.zeros((m, D))  # data matrix where each row is a single example\n    # labels vector (0 for red, 1 for blue)\n    Y = np.zeros((m, 1), dtype='uint8')\n    a = 4  # maximum ray of the flower\n    for j in range(2):\n        ix = range(N * j, N * (j + 1))\n        t = np.linspace(j * 3.12, (j + 1) * 3.12, N) + \\\n            np.random.randn(N) * 0.2  # theta\n        r = a * np.sin(4 * t) + np.random.randn(N) * 0.2  # radius\n        X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n        Y[ix] = j\n    X = X.T\n    Y = Y.T\n    return X, Y\n```\n\n### 可视化\n\n```python\nplt.scatter(X[0, :], X[1, :], c=Y.flatten(), s=40, cmp=plt.cm.Spectral)\nplt.show()\n```\n\n### 可视化决策边界\n\n```python\ndef plot_decision_boundary(model, X, y):\n    # Set min and max values and give it some padding\n    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n    h = 0.01\n    # Generate a grid of points with distance h between them\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    # Predict the function value for the whole grid\n    Z = model(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    # Plot the contour and training examples\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n    plt.ylabel('x2')\n    plt.xlabel('x1')\n    plt.scatter(X[0, :], X[1, :], c=y.flatten(), cmap=plt.cm.Spectral)\n```\n\n\n## Sklearn中的其他数据集\n\n```python\ndef load_extra_datasets():\n    N = 200\n    noisy_circles = sklearn.datasets.make_circles(\n        n_samples=N, factor=.5, noise=.3)\n    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n    blobs = sklearn.datasets.make_blobs(\n        n_samples=N, random_state=5, n_features=2, centers=6)\n    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(\n        mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n\n    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure\n```\n","slug":"数据的加载-预处理-可视化","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds520030pcvosm83t500","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"图片操作\"><a href=\"#图片操作\" class=\"headerlink\" title=\"图片操作\"></a>图片操作</h2><h3 id=\"把图片转换为向量\"><a href=\"#把图片转换为向量\" class=\"headerlink\" title=\"把图片转换为向量\"></a>把图片转换为向量</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">image2vector</span><span class=\"params\">(image)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Argument:</span></span><br><span class=\"line\"><span class=\"string\">    image -- a numpy array of shape (length, height, depth)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    v -- a vector of shape (length*height*depth, 1)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    v = image.reshape((image.shape[<span class=\"number\">0</span>] * image.shape[<span class=\"number\">1</span>] * image.shape[<span class=\"number\">2</span>], <span class=\"number\">1</span>))    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> v</span><br></pre></td></tr></table></figure>\n<h3 id=\"读入图片\"><a href=\"#读入图片\" class=\"headerlink\" title=\"读入图片\"></a>读入图片</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my_image = <span class=\"string\">\"my_image.jpg\"</span> <span class=\"comment\"># change this to the name of your image file</span></span><br><span class=\"line\">my_label_y = [<span class=\"number\">1</span>] <span class=\"comment\"># the true class of your image (1 -&gt; cat, 0 -&gt; non-cat)</span></span><br><span class=\"line\">fname = <span class=\"string\">\"images/\"</span> + my_image</span><br><span class=\"line\">image = np.array(ndimage.imread(fname, flatten=<span class=\"keyword\">False</span>))</span><br><span class=\"line\">my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*<span class=\"number\">3</span>,<span class=\"number\">1</span>))</span><br><span class=\"line\">my_predicted_image = predict(my_image, my_label_y, parameters)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.imshow(image)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"y = \"</span> + str(np.squeeze(my_predicted_image)) + <span class=\"string\">\", your L-layer model predicts a \\\"\"</span> + classes[int(np.squeeze(my_predicted_image)),].decode(<span class=\"string\">\"utf-8\"</span>) +  <span class=\"string\">\"\\\" picture.\"</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"矩阵的正则化\"><a href=\"#矩阵的正则化\" class=\"headerlink\" title=\"矩阵的正则化\"></a>矩阵的正则化</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">normalize</span><span class=\"params\">(x)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement a function that normalizes each row of the matrix x (to have unit length).</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Argument:</span></span><br><span class=\"line\"><span class=\"string\">    x -- A numpy matrix of shape (n, m)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    x -- The normalized (by row) numpy matrix. You are allowed to modify x.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    x_norm = np.linalg.norm(x, ord=<span class=\"number\">2</span>, axis=<span class=\"number\">1</span>, keepdims=<span class=\"keyword\">True</span>)  <span class=\"comment\"># column: axis=0</span></span><br><span class=\"line\">    x = x / x_norm</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br></pre></td></tr></table></figure>\n<h2 id=\"猫的数据集\"><a href=\"#猫的数据集\" class=\"headerlink\" title=\"猫的数据集\"></a>猫的数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_dataset</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    train_set_x_orig -- shape of (209, 64, 64, 3)</span></span><br><span class=\"line\"><span class=\"string\">    train_set_y_orig -- shape of (1, 209)</span></span><br><span class=\"line\"><span class=\"string\">    test_set_x_orig -- shape of (50, 64, 64, 3)</span></span><br><span class=\"line\"><span class=\"string\">    test_set_y_orig -- shape of (1, 50)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    train_dataset = h5py.File(<span class=\"string\">'datasets/train_catvnoncat.h5'</span>, <span class=\"string\">\"r\"</span>)</span><br><span class=\"line\">    train_set_x_orig = np.array(train_dataset[<span class=\"string\">\"train_set_x\"</span>][:]) <span class=\"comment\"># your train set features</span></span><br><span class=\"line\">    train_set_y_orig = np.array(train_dataset[<span class=\"string\">\"train_set_y\"</span>][:]) <span class=\"comment\"># your train set labels</span></span><br><span class=\"line\"></span><br><span class=\"line\">    test_dataset = h5py.File(<span class=\"string\">'datasets/test_catvnoncat.h5'</span>, <span class=\"string\">\"r\"</span>)</span><br><span class=\"line\">    test_set_x_orig = np.array(test_dataset[<span class=\"string\">\"test_set_x\"</span>][:]) <span class=\"comment\"># your test set features</span></span><br><span class=\"line\">    test_set_y_orig = np.array(test_dataset[<span class=\"string\">\"test_set_y\"</span>][:]) <span class=\"comment\"># your test set labels</span></span><br><span class=\"line\"></span><br><span class=\"line\">    classes = np.array(test_dataset[<span class=\"string\">\"list_classes\"</span>][:]) <span class=\"comment\"># the list of classes</span></span><br><span class=\"line\"></span><br><span class=\"line\">    train_set_y_orig = train_set_y_orig.reshape((<span class=\"number\">1</span>, train_set_y_orig.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">    test_set_y_orig = test_set_y_orig.reshape((<span class=\"number\">1</span>, test_set_y_orig.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_set_x_orig, train_set_y_orig, test_set_x_origtest_set_x_orig, test_set_y_orig, classes</span><br></pre></td></tr></table></figure>\n<h3 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">index = <span class=\"number\">23</span></span><br><span class=\"line\">plt.imshow(train_set_x_orig[index])</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"y = \"</span> + str(train_set_y[:, index]) + <span class=\"string\">\", it's a '\"</span> + classes[np.squeeze(train_set_y[:, index])].decode(<span class=\"string\">\"utf-8\"</span>) +  <span class=\"string\">\"' picture.\"</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h3 id=\"向量化\"><a href=\"#向量化\" class=\"headerlink\" title=\"向量化\"></a>向量化</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_x_set_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[<span class=\"number\">0</span>], <span class=\"number\">-1</span>).T</span><br><span class=\"line\">test_x_set_flatten = train_set_x_orig.reshape(test_set_x_orig.shape[<span class=\"number\">0</span>], <span class=\"number\">-1</span>).T</span><br></pre></td></tr></table></figure>\n<h3 id=\"标准化\"><a href=\"#标准化\" class=\"headerlink\" title=\"标准化\"></a>标准化</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_x_set = train_x_set_flatten / <span class=\"number\">255</span></span><br><span class=\"line\">test_x_set = test_x_set_flatten / <span class=\"number\">255</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"二维数据的一般操作\"><a href=\"#二维数据的一般操作\" class=\"headerlink\" title=\"二维数据的一般操作\"></a>二维数据的一般操作</h2><h3 id=\"加载\"><a href=\"#加载\" class=\"headerlink\" title=\"加载\"></a>加载</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_planar_dataset</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    X -- a numpy array shaped (2, 400) that contains features (x1, x2)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- a numpy array shaped (1, 400) that contains labels (0, 1)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    np.random.seed(<span class=\"number\">1</span>)</span><br><span class=\"line\">    m = <span class=\"number\">400</span>  <span class=\"comment\"># number of examples</span></span><br><span class=\"line\">    N = int(m / <span class=\"number\">2</span>)  <span class=\"comment\"># number of points per class</span></span><br><span class=\"line\">    D = <span class=\"number\">2</span>  <span class=\"comment\"># dimensionality</span></span><br><span class=\"line\">    X = np.zeros((m, D))  <span class=\"comment\"># data matrix where each row is a single example</span></span><br><span class=\"line\">    <span class=\"comment\"># labels vector (0 for red, 1 for blue)</span></span><br><span class=\"line\">    Y = np.zeros((m, <span class=\"number\">1</span>), dtype=<span class=\"string\">'uint8'</span>)</span><br><span class=\"line\">    a = <span class=\"number\">4</span>  <span class=\"comment\"># maximum ray of the flower</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">2</span>):</span><br><span class=\"line\">        ix = range(N * j, N * (j + <span class=\"number\">1</span>))</span><br><span class=\"line\">        t = np.linspace(j * <span class=\"number\">3.12</span>, (j + <span class=\"number\">1</span>) * <span class=\"number\">3.12</span>, N) + \\</span><br><span class=\"line\">            np.random.randn(N) * <span class=\"number\">0.2</span>  <span class=\"comment\"># theta</span></span><br><span class=\"line\">        r = a * np.sin(<span class=\"number\">4</span> * t) + np.random.randn(N) * <span class=\"number\">0.2</span>  <span class=\"comment\"># radius</span></span><br><span class=\"line\">        X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]</span><br><span class=\"line\">        Y[ix] = j</span><br><span class=\"line\">    X = X.T</span><br><span class=\"line\">    Y = Y.T</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X, Y</span><br></pre></td></tr></table></figure>\n<h3 id=\"可视化-1\"><a href=\"#可视化-1\" class=\"headerlink\" title=\"可视化\"></a>可视化</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.scatter(X[<span class=\"number\">0</span>, :], X[<span class=\"number\">1</span>, :], c=Y.flatten(), s=<span class=\"number\">40</span>, cmp=plt.cm.Spectral)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h3 id=\"可视化决策边界\"><a href=\"#可视化决策边界\" class=\"headerlink\" title=\"可视化决策边界\"></a>可视化决策边界</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_decision_boundary</span><span class=\"params\">(model, X, y)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># Set min and max values and give it some padding</span></span><br><span class=\"line\">    x_min, x_max = X[<span class=\"number\">0</span>, :].min() - <span class=\"number\">1</span>, X[<span class=\"number\">0</span>, :].max() + <span class=\"number\">1</span></span><br><span class=\"line\">    y_min, y_max = X[<span class=\"number\">1</span>, :].min() - <span class=\"number\">1</span>, X[<span class=\"number\">1</span>, :].max() + <span class=\"number\">1</span></span><br><span class=\"line\">    h = <span class=\"number\">0.01</span></span><br><span class=\"line\">    <span class=\"comment\"># Generate a grid of points with distance h between them</span></span><br><span class=\"line\">    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),</span><br><span class=\"line\">                         np.arange(y_min, y_max, h))</span><br><span class=\"line\">    <span class=\"comment\"># Predict the function value for the whole grid</span></span><br><span class=\"line\">    Z = model(np.c_[xx.ravel(), yy.ravel()])</span><br><span class=\"line\">    Z = Z.reshape(xx.shape)</span><br><span class=\"line\">    <span class=\"comment\"># Plot the contour and training examples</span></span><br><span class=\"line\">    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">'x2'</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">'x1'</span>)</span><br><span class=\"line\">    plt.scatter(X[<span class=\"number\">0</span>, :], X[<span class=\"number\">1</span>, :], c=y.flatten(), cmap=plt.cm.Spectral)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Sklearn中的其他数据集\"><a href=\"#Sklearn中的其他数据集\" class=\"headerlink\" title=\"Sklearn中的其他数据集\"></a>Sklearn中的其他数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_extra_datasets</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    N = <span class=\"number\">200</span></span><br><span class=\"line\">    noisy_circles = sklearn.datasets.make_circles(</span><br><span class=\"line\">        n_samples=N, factor=<span class=\"number\">.5</span>, noise=<span class=\"number\">.3</span>)</span><br><span class=\"line\">    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=<span class=\"number\">.2</span>)</span><br><span class=\"line\">    blobs = sklearn.datasets.make_blobs(</span><br><span class=\"line\">        n_samples=N, random_state=<span class=\"number\">5</span>, n_features=<span class=\"number\">2</span>, centers=<span class=\"number\">6</span>)</span><br><span class=\"line\">    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(</span><br><span class=\"line\">        mean=<span class=\"keyword\">None</span>, cov=<span class=\"number\">0.5</span>, n_samples=N, n_features=<span class=\"number\">2</span>, n_classes=<span class=\"number\">2</span>, shuffle=<span class=\"keyword\">True</span>, random_state=<span class=\"keyword\">None</span>)</span><br><span class=\"line\">    no_structure = np.random.rand(N, <span class=\"number\">2</span>), np.random.rand(N, <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"图片操作\"><a href=\"#图片操作\" class=\"headerlink\" title=\"图片操作\"></a>图片操作</h2><h3 id=\"把图片转换为向量\"><a href=\"#把图片转换为向量\" class=\"headerlink\" title=\"把图片转换为向量\"></a>把图片转换为向量</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">image2vector</span><span class=\"params\">(image)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Argument:</span></span><br><span class=\"line\"><span class=\"string\">    image -- a numpy array of shape (length, height, depth)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    v -- a vector of shape (length*height*depth, 1)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    v = image.reshape((image.shape[<span class=\"number\">0</span>] * image.shape[<span class=\"number\">1</span>] * image.shape[<span class=\"number\">2</span>], <span class=\"number\">1</span>))    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> v</span><br></pre></td></tr></table></figure>\n<h3 id=\"读入图片\"><a href=\"#读入图片\" class=\"headerlink\" title=\"读入图片\"></a>读入图片</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my_image = <span class=\"string\">\"my_image.jpg\"</span> <span class=\"comment\"># change this to the name of your image file</span></span><br><span class=\"line\">my_label_y = [<span class=\"number\">1</span>] <span class=\"comment\"># the true class of your image (1 -&gt; cat, 0 -&gt; non-cat)</span></span><br><span class=\"line\">fname = <span class=\"string\">\"images/\"</span> + my_image</span><br><span class=\"line\">image = np.array(ndimage.imread(fname, flatten=<span class=\"keyword\">False</span>))</span><br><span class=\"line\">my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*<span class=\"number\">3</span>,<span class=\"number\">1</span>))</span><br><span class=\"line\">my_predicted_image = predict(my_image, my_label_y, parameters)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.imshow(image)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"y = \"</span> + str(np.squeeze(my_predicted_image)) + <span class=\"string\">\", your L-layer model predicts a \\\"\"</span> + classes[int(np.squeeze(my_predicted_image)),].decode(<span class=\"string\">\"utf-8\"</span>) +  <span class=\"string\">\"\\\" picture.\"</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"矩阵的正则化\"><a href=\"#矩阵的正则化\" class=\"headerlink\" title=\"矩阵的正则化\"></a>矩阵的正则化</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">normalize</span><span class=\"params\">(x)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement a function that normalizes each row of the matrix x (to have unit length).</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Argument:</span></span><br><span class=\"line\"><span class=\"string\">    x -- A numpy matrix of shape (n, m)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    x -- The normalized (by row) numpy matrix. You are allowed to modify x.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    x_norm = np.linalg.norm(x, ord=<span class=\"number\">2</span>, axis=<span class=\"number\">1</span>, keepdims=<span class=\"keyword\">True</span>)  <span class=\"comment\"># column: axis=0</span></span><br><span class=\"line\">    x = x / x_norm</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br></pre></td></tr></table></figure>\n<h2 id=\"猫的数据集\"><a href=\"#猫的数据集\" class=\"headerlink\" title=\"猫的数据集\"></a>猫的数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_dataset</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    train_set_x_orig -- shape of (209, 64, 64, 3)</span></span><br><span class=\"line\"><span class=\"string\">    train_set_y_orig -- shape of (1, 209)</span></span><br><span class=\"line\"><span class=\"string\">    test_set_x_orig -- shape of (50, 64, 64, 3)</span></span><br><span class=\"line\"><span class=\"string\">    test_set_y_orig -- shape of (1, 50)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    train_dataset = h5py.File(<span class=\"string\">'datasets/train_catvnoncat.h5'</span>, <span class=\"string\">\"r\"</span>)</span><br><span class=\"line\">    train_set_x_orig = np.array(train_dataset[<span class=\"string\">\"train_set_x\"</span>][:]) <span class=\"comment\"># your train set features</span></span><br><span class=\"line\">    train_set_y_orig = np.array(train_dataset[<span class=\"string\">\"train_set_y\"</span>][:]) <span class=\"comment\"># your train set labels</span></span><br><span class=\"line\"></span><br><span class=\"line\">    test_dataset = h5py.File(<span class=\"string\">'datasets/test_catvnoncat.h5'</span>, <span class=\"string\">\"r\"</span>)</span><br><span class=\"line\">    test_set_x_orig = np.array(test_dataset[<span class=\"string\">\"test_set_x\"</span>][:]) <span class=\"comment\"># your test set features</span></span><br><span class=\"line\">    test_set_y_orig = np.array(test_dataset[<span class=\"string\">\"test_set_y\"</span>][:]) <span class=\"comment\"># your test set labels</span></span><br><span class=\"line\"></span><br><span class=\"line\">    classes = np.array(test_dataset[<span class=\"string\">\"list_classes\"</span>][:]) <span class=\"comment\"># the list of classes</span></span><br><span class=\"line\"></span><br><span class=\"line\">    train_set_y_orig = train_set_y_orig.reshape((<span class=\"number\">1</span>, train_set_y_orig.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">    test_set_y_orig = test_set_y_orig.reshape((<span class=\"number\">1</span>, test_set_y_orig.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_set_x_orig, train_set_y_orig, test_set_x_origtest_set_x_orig, test_set_y_orig, classes</span><br></pre></td></tr></table></figure>\n<h3 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">index = <span class=\"number\">23</span></span><br><span class=\"line\">plt.imshow(train_set_x_orig[index])</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"y = \"</span> + str(train_set_y[:, index]) + <span class=\"string\">\", it's a '\"</span> + classes[np.squeeze(train_set_y[:, index])].decode(<span class=\"string\">\"utf-8\"</span>) +  <span class=\"string\">\"' picture.\"</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h3 id=\"向量化\"><a href=\"#向量化\" class=\"headerlink\" title=\"向量化\"></a>向量化</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_x_set_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[<span class=\"number\">0</span>], <span class=\"number\">-1</span>).T</span><br><span class=\"line\">test_x_set_flatten = train_set_x_orig.reshape(test_set_x_orig.shape[<span class=\"number\">0</span>], <span class=\"number\">-1</span>).T</span><br></pre></td></tr></table></figure>\n<h3 id=\"标准化\"><a href=\"#标准化\" class=\"headerlink\" title=\"标准化\"></a>标准化</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_x_set = train_x_set_flatten / <span class=\"number\">255</span></span><br><span class=\"line\">test_x_set = test_x_set_flatten / <span class=\"number\">255</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"二维数据的一般操作\"><a href=\"#二维数据的一般操作\" class=\"headerlink\" title=\"二维数据的一般操作\"></a>二维数据的一般操作</h2><h3 id=\"加载\"><a href=\"#加载\" class=\"headerlink\" title=\"加载\"></a>加载</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_planar_dataset</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    X -- a numpy array shaped (2, 400) that contains features (x1, x2)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- a numpy array shaped (1, 400) that contains labels (0, 1)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    np.random.seed(<span class=\"number\">1</span>)</span><br><span class=\"line\">    m = <span class=\"number\">400</span>  <span class=\"comment\"># number of examples</span></span><br><span class=\"line\">    N = int(m / <span class=\"number\">2</span>)  <span class=\"comment\"># number of points per class</span></span><br><span class=\"line\">    D = <span class=\"number\">2</span>  <span class=\"comment\"># dimensionality</span></span><br><span class=\"line\">    X = np.zeros((m, D))  <span class=\"comment\"># data matrix where each row is a single example</span></span><br><span class=\"line\">    <span class=\"comment\"># labels vector (0 for red, 1 for blue)</span></span><br><span class=\"line\">    Y = np.zeros((m, <span class=\"number\">1</span>), dtype=<span class=\"string\">'uint8'</span>)</span><br><span class=\"line\">    a = <span class=\"number\">4</span>  <span class=\"comment\"># maximum ray of the flower</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">2</span>):</span><br><span class=\"line\">        ix = range(N * j, N * (j + <span class=\"number\">1</span>))</span><br><span class=\"line\">        t = np.linspace(j * <span class=\"number\">3.12</span>, (j + <span class=\"number\">1</span>) * <span class=\"number\">3.12</span>, N) + \\</span><br><span class=\"line\">            np.random.randn(N) * <span class=\"number\">0.2</span>  <span class=\"comment\"># theta</span></span><br><span class=\"line\">        r = a * np.sin(<span class=\"number\">4</span> * t) + np.random.randn(N) * <span class=\"number\">0.2</span>  <span class=\"comment\"># radius</span></span><br><span class=\"line\">        X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]</span><br><span class=\"line\">        Y[ix] = j</span><br><span class=\"line\">    X = X.T</span><br><span class=\"line\">    Y = Y.T</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X, Y</span><br></pre></td></tr></table></figure>\n<h3 id=\"可视化-1\"><a href=\"#可视化-1\" class=\"headerlink\" title=\"可视化\"></a>可视化</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.scatter(X[<span class=\"number\">0</span>, :], X[<span class=\"number\">1</span>, :], c=Y.flatten(), s=<span class=\"number\">40</span>, cmp=plt.cm.Spectral)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h3 id=\"可视化决策边界\"><a href=\"#可视化决策边界\" class=\"headerlink\" title=\"可视化决策边界\"></a>可视化决策边界</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_decision_boundary</span><span class=\"params\">(model, X, y)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># Set min and max values and give it some padding</span></span><br><span class=\"line\">    x_min, x_max = X[<span class=\"number\">0</span>, :].min() - <span class=\"number\">1</span>, X[<span class=\"number\">0</span>, :].max() + <span class=\"number\">1</span></span><br><span class=\"line\">    y_min, y_max = X[<span class=\"number\">1</span>, :].min() - <span class=\"number\">1</span>, X[<span class=\"number\">1</span>, :].max() + <span class=\"number\">1</span></span><br><span class=\"line\">    h = <span class=\"number\">0.01</span></span><br><span class=\"line\">    <span class=\"comment\"># Generate a grid of points with distance h between them</span></span><br><span class=\"line\">    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),</span><br><span class=\"line\">                         np.arange(y_min, y_max, h))</span><br><span class=\"line\">    <span class=\"comment\"># Predict the function value for the whole grid</span></span><br><span class=\"line\">    Z = model(np.c_[xx.ravel(), yy.ravel()])</span><br><span class=\"line\">    Z = Z.reshape(xx.shape)</span><br><span class=\"line\">    <span class=\"comment\"># Plot the contour and training examples</span></span><br><span class=\"line\">    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">'x2'</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">'x1'</span>)</span><br><span class=\"line\">    plt.scatter(X[<span class=\"number\">0</span>, :], X[<span class=\"number\">1</span>, :], c=y.flatten(), cmap=plt.cm.Spectral)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Sklearn中的其他数据集\"><a href=\"#Sklearn中的其他数据集\" class=\"headerlink\" title=\"Sklearn中的其他数据集\"></a>Sklearn中的其他数据集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_extra_datasets</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    N = <span class=\"number\">200</span></span><br><span class=\"line\">    noisy_circles = sklearn.datasets.make_circles(</span><br><span class=\"line\">        n_samples=N, factor=<span class=\"number\">.5</span>, noise=<span class=\"number\">.3</span>)</span><br><span class=\"line\">    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=<span class=\"number\">.2</span>)</span><br><span class=\"line\">    blobs = sklearn.datasets.make_blobs(</span><br><span class=\"line\">        n_samples=N, random_state=<span class=\"number\">5</span>, n_features=<span class=\"number\">2</span>, centers=<span class=\"number\">6</span>)</span><br><span class=\"line\">    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(</span><br><span class=\"line\">        mean=<span class=\"keyword\">None</span>, cov=<span class=\"number\">0.5</span>, n_samples=N, n_features=<span class=\"number\">2</span>, n_classes=<span class=\"number\">2</span>, shuffle=<span class=\"keyword\">True</span>, random_state=<span class=\"keyword\">None</span>)</span><br><span class=\"line\">    no_structure = np.random.rand(N, <span class=\"number\">2</span>), np.random.rand(N, <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure</span><br></pre></td></tr></table></figure>\n"},{"title":"数据划分：训练 / 验证 / 测试集","date":"2018-07-20T06:52:44.000Z","_content":"\n## 数据划分：训练 / 验证 / 测试集\n\n应用深度学习是一个典型的迭代过程。\n\n对于一个需要解决的问题的样本数据，在建立模型的过程中，数据会被划分为以下几个部分：\n\n* 训练集（train set）：用训练集对算法或模型进行**训练**过程；\n* 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行**交叉验证**，**选择出最好的模型**；\n* 测试集（test set）：最后利用测试集对模型进行测试，**获取模型运行的无偏估计**（对学习方法进行评估）。\n\n在**小数据量**的时代，如 100、1000、10000 的数据量大小，可以将数据集按照以下比例进行划分：\n\n* 无验证集的情况：70% / 30%；\n* 有验证集的情况：60% / 20% / 20%；\n\n而在如今的**大数据时代**，对于一个问题，我们拥有的数据集的规模可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。\n\n验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大到能够验证大约 2-10 种算法哪种更好，而不需要使用 20% 的数据作为验证集。如百万数据中抽取 1 万的数据作为验证集就可以了。\n\n测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中 1000 条数据足以评估单个模型的效果。\n\n* 100 万数据量：98% / 1% / 1%；\n* 超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）\n\n### 建议\n\n建议**验证集要和训练集来自于同一个分布**（数据来源一致），可以使得机器学习算法变得更快并获得更好的效果。\n\n如果不需要用**无偏估计**来评估模型的性能，则可以不需要测试集。\n\n### 补充：交叉验证（cross validation）\n\n交叉验证的基本思想是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。\n\n### 参考资料\n\n[无偏估计_百度百科](https://baike.baidu.com/item/%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1/3370664?fr=aladdin)\n","source":"_posts/数据划分.md","raw":"---\ntitle: 数据划分：训练 / 验证 / 测试集\ndate: 2018-07-20 14:52:44\ntags: 数据\ncategories: 深度学习\n---\n\n## 数据划分：训练 / 验证 / 测试集\n\n应用深度学习是一个典型的迭代过程。\n\n对于一个需要解决的问题的样本数据，在建立模型的过程中，数据会被划分为以下几个部分：\n\n* 训练集（train set）：用训练集对算法或模型进行**训练**过程；\n* 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行**交叉验证**，**选择出最好的模型**；\n* 测试集（test set）：最后利用测试集对模型进行测试，**获取模型运行的无偏估计**（对学习方法进行评估）。\n\n在**小数据量**的时代，如 100、1000、10000 的数据量大小，可以将数据集按照以下比例进行划分：\n\n* 无验证集的情况：70% / 30%；\n* 有验证集的情况：60% / 20% / 20%；\n\n而在如今的**大数据时代**，对于一个问题，我们拥有的数据集的规模可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。\n\n验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大到能够验证大约 2-10 种算法哪种更好，而不需要使用 20% 的数据作为验证集。如百万数据中抽取 1 万的数据作为验证集就可以了。\n\n测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中 1000 条数据足以评估单个模型的效果。\n\n* 100 万数据量：98% / 1% / 1%；\n* 超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）\n\n### 建议\n\n建议**验证集要和训练集来自于同一个分布**（数据来源一致），可以使得机器学习算法变得更快并获得更好的效果。\n\n如果不需要用**无偏估计**来评估模型的性能，则可以不需要测试集。\n\n### 补充：交叉验证（cross validation）\n\n交叉验证的基本思想是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。\n\n### 参考资料\n\n[无偏估计_百度百科](https://baike.baidu.com/item/%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1/3370664?fr=aladdin)\n","slug":"数据划分","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds520033pcvokom36u84","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"数据划分：训练-验证-测试集\"><a href=\"#数据划分：训练-验证-测试集\" class=\"headerlink\" title=\"数据划分：训练 / 验证 / 测试集\"></a>数据划分：训练 / 验证 / 测试集</h2><p>应用深度学习是一个典型的迭代过程。</p>\n<p>对于一个需要解决的问题的样本数据，在建立模型的过程中，数据会被划分为以下几个部分：</p>\n<ul>\n<li>训练集（train set）：用训练集对算法或模型进行<strong>训练</strong>过程；</li>\n<li>验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行<strong>交叉验证</strong>，<strong>选择出最好的模型</strong>；</li>\n<li>测试集（test set）：最后利用测试集对模型进行测试，<strong>获取模型运行的无偏估计</strong>（对学习方法进行评估）。</li>\n</ul>\n<p>在<strong>小数据量</strong>的时代，如 100、1000、10000 的数据量大小，可以将数据集按照以下比例进行划分：</p>\n<ul>\n<li>无验证集的情况：70% / 30%；</li>\n<li>有验证集的情况：60% / 20% / 20%；</li>\n</ul>\n<p>而在如今的<strong>大数据时代</strong>，对于一个问题，我们拥有的数据集的规模可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。</p>\n<p>验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大到能够验证大约 2-10 种算法哪种更好，而不需要使用 20% 的数据作为验证集。如百万数据中抽取 1 万的数据作为验证集就可以了。</p>\n<p>测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中 1000 条数据足以评估单个模型的效果。</p>\n<ul>\n<li>100 万数据量：98% / 1% / 1%；</li>\n<li>超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）</li>\n</ul>\n<h3 id=\"建议\"><a href=\"#建议\" class=\"headerlink\" title=\"建议\"></a>建议</h3><p>建议<strong>验证集要和训练集来自于同一个分布</strong>（数据来源一致），可以使得机器学习算法变得更快并获得更好的效果。</p>\n<p>如果不需要用<strong>无偏估计</strong>来评估模型的性能，则可以不需要测试集。</p>\n<h3 id=\"补充：交叉验证（cross-validation）\"><a href=\"#补充：交叉验证（cross-validation）\" class=\"headerlink\" title=\"补充：交叉验证（cross validation）\"></a>补充：交叉验证（cross validation）</h3><p>交叉验证的基本思想是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><p><a href=\"https://baike.baidu.com/item/%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1/3370664?fr=aladdin\" target=\"_blank\" rel=\"noopener\">无偏估计_百度百科</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"数据划分：训练-验证-测试集\"><a href=\"#数据划分：训练-验证-测试集\" class=\"headerlink\" title=\"数据划分：训练 / 验证 / 测试集\"></a>数据划分：训练 / 验证 / 测试集</h2><p>应用深度学习是一个典型的迭代过程。</p>\n<p>对于一个需要解决的问题的样本数据，在建立模型的过程中，数据会被划分为以下几个部分：</p>\n<ul>\n<li>训练集（train set）：用训练集对算法或模型进行<strong>训练</strong>过程；</li>\n<li>验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行<strong>交叉验证</strong>，<strong>选择出最好的模型</strong>；</li>\n<li>测试集（test set）：最后利用测试集对模型进行测试，<strong>获取模型运行的无偏估计</strong>（对学习方法进行评估）。</li>\n</ul>\n<p>在<strong>小数据量</strong>的时代，如 100、1000、10000 的数据量大小，可以将数据集按照以下比例进行划分：</p>\n<ul>\n<li>无验证集的情况：70% / 30%；</li>\n<li>有验证集的情况：60% / 20% / 20%；</li>\n</ul>\n<p>而在如今的<strong>大数据时代</strong>，对于一个问题，我们拥有的数据集的规模可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。</p>\n<p>验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大到能够验证大约 2-10 种算法哪种更好，而不需要使用 20% 的数据作为验证集。如百万数据中抽取 1 万的数据作为验证集就可以了。</p>\n<p>测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中 1000 条数据足以评估单个模型的效果。</p>\n<ul>\n<li>100 万数据量：98% / 1% / 1%；</li>\n<li>超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）</li>\n</ul>\n<h3 id=\"建议\"><a href=\"#建议\" class=\"headerlink\" title=\"建议\"></a>建议</h3><p>建议<strong>验证集要和训练集来自于同一个分布</strong>（数据来源一致），可以使得机器学习算法变得更快并获得更好的效果。</p>\n<p>如果不需要用<strong>无偏估计</strong>来评估模型的性能，则可以不需要测试集。</p>\n<h3 id=\"补充：交叉验证（cross-validation）\"><a href=\"#补充：交叉验证（cross-validation）\" class=\"headerlink\" title=\"补充：交叉验证（cross validation）\"></a>补充：交叉验证（cross validation）</h3><p>交叉验证的基本思想是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><p><a href=\"https://baike.baidu.com/item/%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1/3370664?fr=aladdin\" target=\"_blank\" rel=\"noopener\">无偏估计_百度百科</a></p>\n"},{"title":"标准化输入","date":"2018-07-20T08:27:20.000Z","mathjax":true,"_content":"## 标准化输入\n\n使用标准化处理输入 X 能够有效加速收敛。\n\n### 标准化公式\n\n$$x = \\frac{x - \\mu}{\\sigma}$$\n\n其中，\n\n$$\\mu = \\frac{1}{m}\\sum^m\\_{i=1}x^{(i)}$$\n\n$$\\sigma = \\sqrt{\\frac{1}{m}\\sum^m\\_{i=1}{x^{(i)}}^2}$$\n\n（注意，课程上对应内容中的标准化公式疑似有误，将标准差写成了方差，此处进行修正）\n\n### 使用标准化的原因\n\n![why_normalize](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/why_normalize.png)\n\n有图可知，使用标准化前后，成本函数的形状有较大差别。\n\n在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。\n","source":"_posts/标准化输入.md","raw":"---\ntitle: 标准化输入\ndate: 2018-07-20 16:27:20\ntags: 优化算法\ncategories: 深度学习\nmathjax: true\n---\n## 标准化输入\n\n使用标准化处理输入 X 能够有效加速收敛。\n\n### 标准化公式\n\n$$x = \\frac{x - \\mu}{\\sigma}$$\n\n其中，\n\n$$\\mu = \\frac{1}{m}\\sum^m\\_{i=1}x^{(i)}$$\n\n$$\\sigma = \\sqrt{\\frac{1}{m}\\sum^m\\_{i=1}{x^{(i)}}^2}$$\n\n（注意，课程上对应内容中的标准化公式疑似有误，将标准差写成了方差，此处进行修正）\n\n### 使用标准化的原因\n\n![why_normalize](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/why_normalize.png)\n\n有图可知，使用标准化前后，成本函数的形状有较大差别。\n\n在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。\n","slug":"标准化输入","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds5h0037pcvo528wkpl3","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"标准化输入\"><a href=\"#标准化输入\" class=\"headerlink\" title=\"标准化输入\"></a>标准化输入</h2><p>使用标准化处理输入 X 能够有效加速收敛。</p>\n<h3 id=\"标准化公式\"><a href=\"#标准化公式\" class=\"headerlink\" title=\"标准化公式\"></a>标准化公式</h3><p>$$x = \\frac{x - \\mu}{\\sigma}$$</p>\n<p>其中，</p>\n<p>$$\\mu = \\frac{1}{m}\\sum^m_{i=1}x^{(i)}$$</p>\n<p>$$\\sigma = \\sqrt{\\frac{1}{m}\\sum^m_{i=1}{x^{(i)}}^2}$$</p>\n<p>（注意，课程上对应内容中的标准化公式疑似有误，将标准差写成了方差，此处进行修正）</p>\n<h3 id=\"使用标准化的原因\"><a href=\"#使用标准化的原因\" class=\"headerlink\" title=\"使用标准化的原因\"></a>使用标准化的原因</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/why_normalize.png\" alt=\"why_normalize\"></p>\n<p>有图可知，使用标准化前后，成本函数的形状有较大差别。</p>\n<p>在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"标准化输入\"><a href=\"#标准化输入\" class=\"headerlink\" title=\"标准化输入\"></a>标准化输入</h2><p>使用标准化处理输入 X 能够有效加速收敛。</p>\n<h3 id=\"标准化公式\"><a href=\"#标准化公式\" class=\"headerlink\" title=\"标准化公式\"></a>标准化公式</h3><p>$$x = \\frac{x - \\mu}{\\sigma}$$</p>\n<p>其中，</p>\n<p>$$\\mu = \\frac{1}{m}\\sum^m_{i=1}x^{(i)}$$</p>\n<p>$$\\sigma = \\sqrt{\\frac{1}{m}\\sum^m_{i=1}{x^{(i)}}^2}$$</p>\n<p>（注意，课程上对应内容中的标准化公式疑似有误，将标准差写成了方差，此处进行修正）</p>\n<h3 id=\"使用标准化的原因\"><a href=\"#使用标准化的原因\" class=\"headerlink\" title=\"使用标准化的原因\"></a>使用标准化的原因</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/why_normalize.png\" alt=\"why_normalize\"></p>\n<p>有图可知，使用标准化前后，成本函数的形状有较大差别。</p>\n<p>在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。</p>\n"},{"title":"梯度检验","date":"2018-07-20T08:31:29.000Z","mathjax":true,"_content":"## 梯度检验（Gradient checking）\n\n### 梯度的数值逼近\n\n使用双边误差的方法去逼近导数，精度要高于单边误差。\n\n* 单边误差：\n\n![one-sided-difference](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/one-sided-difference.png)\n\n$$f'(\\theta) = \\lim\\_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta)}{\\varepsilon}$$\n\n误差：$O(\\varepsilon)$\n\n* 双边误差求导（即导数的定义）：\n\n![two-sided-difference](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/two-sided-difference.png)\n\n$$f'(\\theta) = \\lim\\_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta - \\varepsilon)}{2\\varepsilon}$$\n\n误差：$O(\\varepsilon^2)$\n\n当 ε 越小时，结果越接近真实的导数，也就是梯度值。可以使用这种方法来判断反向传播进行梯度下降时，是否出现了错误。\n\n### 梯度检验的实施\n\n#### 连接参数\n\n将 $W^{[1]}$，$b^{[1]}$，...，$W^{[L]}$，$b^{[L]}$全部连接出来，成为一个巨型向量 θ。这样，\n\n$$J(W^{[1]}, b^{[1]}, ..., W^{[L]}，b^{[L]}) = J(\\theta)$$\n\n同时，对 $dW^{[1]}$，$db^{[1]}$，...，$dW^{[L]}$，$db^{[L]}$执行同样的操作得到巨型向量 dθ，它和 θ 有同样的维度。\n\n![dictionary_to_vector](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dictionary_to_vector.png)\n\n现在，我们需要找到 dθ 和代价函数 J 的梯度的关系。\n\n#### 进行梯度检验\n\n求得一个梯度逼近值\n\n$$d\\theta_{approx}[i] ＝ \\frac{J(\\theta\\_1, \\theta\\_2, ..., \\theta\\_i+\\varepsilon, ...) - J(\\theta\\_1, \\theta\\_2, ..., \\theta\\_i-\\varepsilon, ...)}{2\\varepsilon}$$\n\n应该\n\n$$\\approx{d\\theta[i]} = \\frac{\\partial J}{\\partial \\theta_i}$$\n\n因此，我们用梯度检验值\n\n$$\\frac{||d\\theta\\_{approx} - d\\theta||\\_2}{||d\\theta\\_{approx}||\\_2+||d\\theta||\\_2}$$\n\n检验反向传播的实施是否正确。其中，\n\n$${||x||}\\_2 = \\sum^N\\_{i=1}{|x_i|}^2$$\n\n表示向量 x 的 2-范数（也称“欧几里德范数”）。\n\n如果梯度检验值和 ε 的值相近，说明神经网络的实施是正确的，否则要去检查代码是否存在 bug。\n\n### 在神经网络实施梯度检验的实用技巧和注意事项\n\n1. 不要在训练中使用梯度检验，它只用于调试（debug）。使用完毕关闭梯度检验的功能；\n2. 如果算法的梯度检验失败，要检查所有项，并试着找出 bug，即确定哪个 dθapprox[i] 与 dθ 的值相差比较大；\n3. 当成本函数包含正则项时，也需要带上正则项进行检验；\n4. 梯度检验不能与 dropout 同时使用。因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的成本函数 J。建议关闭 dropout，用梯度检验进行双重检查，确定在没有 dropout 的情况下算法正确，然后打开 dropout；\n","source":"_posts/梯度检验.md","raw":"---\ntitle: 梯度检验\ndate: 2018-07-20 16:31:29\ntags: 优化算法\ncategories: 深度学习\nmathjax: true\n---\n## 梯度检验（Gradient checking）\n\n### 梯度的数值逼近\n\n使用双边误差的方法去逼近导数，精度要高于单边误差。\n\n* 单边误差：\n\n![one-sided-difference](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/one-sided-difference.png)\n\n$$f'(\\theta) = \\lim\\_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta)}{\\varepsilon}$$\n\n误差：$O(\\varepsilon)$\n\n* 双边误差求导（即导数的定义）：\n\n![two-sided-difference](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/two-sided-difference.png)\n\n$$f'(\\theta) = \\lim\\_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta - \\varepsilon)}{2\\varepsilon}$$\n\n误差：$O(\\varepsilon^2)$\n\n当 ε 越小时，结果越接近真实的导数，也就是梯度值。可以使用这种方法来判断反向传播进行梯度下降时，是否出现了错误。\n\n### 梯度检验的实施\n\n#### 连接参数\n\n将 $W^{[1]}$，$b^{[1]}$，...，$W^{[L]}$，$b^{[L]}$全部连接出来，成为一个巨型向量 θ。这样，\n\n$$J(W^{[1]}, b^{[1]}, ..., W^{[L]}，b^{[L]}) = J(\\theta)$$\n\n同时，对 $dW^{[1]}$，$db^{[1]}$，...，$dW^{[L]}$，$db^{[L]}$执行同样的操作得到巨型向量 dθ，它和 θ 有同样的维度。\n\n![dictionary_to_vector](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dictionary_to_vector.png)\n\n现在，我们需要找到 dθ 和代价函数 J 的梯度的关系。\n\n#### 进行梯度检验\n\n求得一个梯度逼近值\n\n$$d\\theta_{approx}[i] ＝ \\frac{J(\\theta\\_1, \\theta\\_2, ..., \\theta\\_i+\\varepsilon, ...) - J(\\theta\\_1, \\theta\\_2, ..., \\theta\\_i-\\varepsilon, ...)}{2\\varepsilon}$$\n\n应该\n\n$$\\approx{d\\theta[i]} = \\frac{\\partial J}{\\partial \\theta_i}$$\n\n因此，我们用梯度检验值\n\n$$\\frac{||d\\theta\\_{approx} - d\\theta||\\_2}{||d\\theta\\_{approx}||\\_2+||d\\theta||\\_2}$$\n\n检验反向传播的实施是否正确。其中，\n\n$${||x||}\\_2 = \\sum^N\\_{i=1}{|x_i|}^2$$\n\n表示向量 x 的 2-范数（也称“欧几里德范数”）。\n\n如果梯度检验值和 ε 的值相近，说明神经网络的实施是正确的，否则要去检查代码是否存在 bug。\n\n### 在神经网络实施梯度检验的实用技巧和注意事项\n\n1. 不要在训练中使用梯度检验，它只用于调试（debug）。使用完毕关闭梯度检验的功能；\n2. 如果算法的梯度检验失败，要检查所有项，并试着找出 bug，即确定哪个 dθapprox[i] 与 dθ 的值相差比较大；\n3. 当成本函数包含正则项时，也需要带上正则项进行检验；\n4. 梯度检验不能与 dropout 同时使用。因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的成本函数 J。建议关闭 dropout，用梯度检验进行双重检查，确定在没有 dropout 的情况下算法正确，然后打开 dropout；\n","slug":"梯度检验","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds5h003apcvo9cvrlmpb","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"梯度检验（Gradient-checking）\"><a href=\"#梯度检验（Gradient-checking）\" class=\"headerlink\" title=\"梯度检验（Gradient checking）\"></a>梯度检验（Gradient checking）</h2><h3 id=\"梯度的数值逼近\"><a href=\"#梯度的数值逼近\" class=\"headerlink\" title=\"梯度的数值逼近\"></a>梯度的数值逼近</h3><p>使用双边误差的方法去逼近导数，精度要高于单边误差。</p>\n<ul>\n<li>单边误差：</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/one-sided-difference.png\" alt=\"one-sided-difference\"></p>\n<p>$$f’(\\theta) = \\lim_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta)}{\\varepsilon}$$</p>\n<p>误差：$O(\\varepsilon)$</p>\n<ul>\n<li>双边误差求导（即导数的定义）：</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/two-sided-difference.png\" alt=\"two-sided-difference\"></p>\n<p>$$f’(\\theta) = \\lim_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta - \\varepsilon)}{2\\varepsilon}$$</p>\n<p>误差：$O(\\varepsilon^2)$</p>\n<p>当 ε 越小时，结果越接近真实的导数，也就是梯度值。可以使用这种方法来判断反向传播进行梯度下降时，是否出现了错误。</p>\n<h3 id=\"梯度检验的实施\"><a href=\"#梯度检验的实施\" class=\"headerlink\" title=\"梯度检验的实施\"></a>梯度检验的实施</h3><h4 id=\"连接参数\"><a href=\"#连接参数\" class=\"headerlink\" title=\"连接参数\"></a>连接参数</h4><p>将 $W^{[1]}$，$b^{[1]}$，…，$W^{[L]}$，$b^{[L]}$全部连接出来，成为一个巨型向量 θ。这样，</p>\n<p>$$J(W^{[1]}, b^{[1]}, …, W^{[L]}，b^{[L]}) = J(\\theta)$$</p>\n<p>同时，对 $dW^{[1]}$，$db^{[1]}$，…，$dW^{[L]}$，$db^{[L]}$执行同样的操作得到巨型向量 dθ，它和 θ 有同样的维度。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dictionary_to_vector.png\" alt=\"dictionary_to_vector\"></p>\n<p>现在，我们需要找到 dθ 和代价函数 J 的梯度的关系。</p>\n<h4 id=\"进行梯度检验\"><a href=\"#进行梯度检验\" class=\"headerlink\" title=\"进行梯度检验\"></a>进行梯度检验</h4><p>求得一个梯度逼近值</p>\n<p>$$d\\theta_{approx}[i] ＝ \\frac{J(\\theta_1, \\theta_2, …, \\theta_i+\\varepsilon, …) - J(\\theta_1, \\theta_2, …, \\theta_i-\\varepsilon, …)}{2\\varepsilon}$$</p>\n<p>应该</p>\n<p>$$\\approx{d\\theta[i]} = \\frac{\\partial J}{\\partial \\theta_i}$$</p>\n<p>因此，我们用梯度检验值</p>\n<p>$$\\frac{||d\\theta_{approx} - d\\theta||_2}{||d\\theta_{approx}||_2+||d\\theta||_2}$$</p>\n<p>检验反向传播的实施是否正确。其中，</p>\n<p>$${||x||}_2 = \\sum^N_{i=1}{|x_i|}^2$$</p>\n<p>表示向量 x 的 2-范数（也称“欧几里德范数”）。</p>\n<p>如果梯度检验值和 ε 的值相近，说明神经网络的实施是正确的，否则要去检查代码是否存在 bug。</p>\n<h3 id=\"在神经网络实施梯度检验的实用技巧和注意事项\"><a href=\"#在神经网络实施梯度检验的实用技巧和注意事项\" class=\"headerlink\" title=\"在神经网络实施梯度检验的实用技巧和注意事项\"></a>在神经网络实施梯度检验的实用技巧和注意事项</h3><ol>\n<li>不要在训练中使用梯度检验，它只用于调试（debug）。使用完毕关闭梯度检验的功能；</li>\n<li>如果算法的梯度检验失败，要检查所有项，并试着找出 bug，即确定哪个 dθapprox[i] 与 dθ 的值相差比较大；</li>\n<li>当成本函数包含正则项时，也需要带上正则项进行检验；</li>\n<li>梯度检验不能与 dropout 同时使用。因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的成本函数 J。建议关闭 dropout，用梯度检验进行双重检查，确定在没有 dropout 的情况下算法正确，然后打开 dropout；</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"梯度检验（Gradient-checking）\"><a href=\"#梯度检验（Gradient-checking）\" class=\"headerlink\" title=\"梯度检验（Gradient checking）\"></a>梯度检验（Gradient checking）</h2><h3 id=\"梯度的数值逼近\"><a href=\"#梯度的数值逼近\" class=\"headerlink\" title=\"梯度的数值逼近\"></a>梯度的数值逼近</h3><p>使用双边误差的方法去逼近导数，精度要高于单边误差。</p>\n<ul>\n<li>单边误差：</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/one-sided-difference.png\" alt=\"one-sided-difference\"></p>\n<p>$$f’(\\theta) = \\lim_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta)}{\\varepsilon}$$</p>\n<p>误差：$O(\\varepsilon)$</p>\n<ul>\n<li>双边误差求导（即导数的定义）：</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/two-sided-difference.png\" alt=\"two-sided-difference\"></p>\n<p>$$f’(\\theta) = \\lim_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta - \\varepsilon)}{2\\varepsilon}$$</p>\n<p>误差：$O(\\varepsilon^2)$</p>\n<p>当 ε 越小时，结果越接近真实的导数，也就是梯度值。可以使用这种方法来判断反向传播进行梯度下降时，是否出现了错误。</p>\n<h3 id=\"梯度检验的实施\"><a href=\"#梯度检验的实施\" class=\"headerlink\" title=\"梯度检验的实施\"></a>梯度检验的实施</h3><h4 id=\"连接参数\"><a href=\"#连接参数\" class=\"headerlink\" title=\"连接参数\"></a>连接参数</h4><p>将 $W^{[1]}$，$b^{[1]}$，…，$W^{[L]}$，$b^{[L]}$全部连接出来，成为一个巨型向量 θ。这样，</p>\n<p>$$J(W^{[1]}, b^{[1]}, …, W^{[L]}，b^{[L]}) = J(\\theta)$$</p>\n<p>同时，对 $dW^{[1]}$，$db^{[1]}$，…，$dW^{[L]}$，$db^{[L]}$执行同样的操作得到巨型向量 dθ，它和 θ 有同样的维度。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dictionary_to_vector.png\" alt=\"dictionary_to_vector\"></p>\n<p>现在，我们需要找到 dθ 和代价函数 J 的梯度的关系。</p>\n<h4 id=\"进行梯度检验\"><a href=\"#进行梯度检验\" class=\"headerlink\" title=\"进行梯度检验\"></a>进行梯度检验</h4><p>求得一个梯度逼近值</p>\n<p>$$d\\theta_{approx}[i] ＝ \\frac{J(\\theta_1, \\theta_2, …, \\theta_i+\\varepsilon, …) - J(\\theta_1, \\theta_2, …, \\theta_i-\\varepsilon, …)}{2\\varepsilon}$$</p>\n<p>应该</p>\n<p>$$\\approx{d\\theta[i]} = \\frac{\\partial J}{\\partial \\theta_i}$$</p>\n<p>因此，我们用梯度检验值</p>\n<p>$$\\frac{||d\\theta_{approx} - d\\theta||_2}{||d\\theta_{approx}||_2+||d\\theta||_2}$$</p>\n<p>检验反向传播的实施是否正确。其中，</p>\n<p>$${||x||}_2 = \\sum^N_{i=1}{|x_i|}^2$$</p>\n<p>表示向量 x 的 2-范数（也称“欧几里德范数”）。</p>\n<p>如果梯度检验值和 ε 的值相近，说明神经网络的实施是正确的，否则要去检查代码是否存在 bug。</p>\n<h3 id=\"在神经网络实施梯度检验的实用技巧和注意事项\"><a href=\"#在神经网络实施梯度检验的实用技巧和注意事项\" class=\"headerlink\" title=\"在神经网络实施梯度检验的实用技巧和注意事项\"></a>在神经网络实施梯度检验的实用技巧和注意事项</h3><ol>\n<li>不要在训练中使用梯度检验，它只用于调试（debug）。使用完毕关闭梯度检验的功能；</li>\n<li>如果算法的梯度检验失败，要检查所有项，并试着找出 bug，即确定哪个 dθapprox[i] 与 dθ 的值相差比较大；</li>\n<li>当成本函数包含正则项时，也需要带上正则项进行检验；</li>\n<li>梯度检验不能与 dropout 同时使用。因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的成本函数 J。建议关闭 dropout，用梯度检验进行双重检查，确定在没有 dropout 的情况下算法正确，然后打开 dropout；</li>\n</ol>\n"},{"title":"梯度消失和梯度爆炸","date":"2018-07-20T08:25:16.000Z","categroies":"深度学习","mathjax":true,"_content":"\n## 梯度消失和梯度爆炸\n\n在梯度函数上出现的以指数级递增或者递减的情况分别称为**梯度爆炸**或者**梯度消失**。\n\n假定 $g(z) = z, b^{[l]} = 0$，对于目标输出有：\n\n$$\\hat{y} = W^{[L]}W^{[L-1]}...W^{[2]}W^{[1]}X$$\n\n* 对于 $W^{[l]}$的值大于 1 的情况，激活函数的值将以指数级递增；\n* 对于 $W^{[l]}$的值小于 1 的情况，激活函数的值将以指数级递减。\n\n对于导数同理。因此，在计算梯度时，根据不同情况梯度函数会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。\n\n### 利用初始化缓解梯度消失和爆炸\n\n根据\n\n$$z={w}_1{x}\\_1+{w}\\_2{x}\\_2 + ... + {w}\\_n{x}\\_n + b$$\n\n可知，当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。\n\n为了得到较小的 wi，设置`Var(wi)=1/n`，这里称为 **Xavier initialization**。\n\n```python\nWL = np.random.randn(WL.shape[0], WL.shape[1]) * np.sqrt(1/n)\n```\n\n其中 n 是输入的神经元个数，即`WL.shape[1]`。\n\n这样，激活函数的输入 x 近似设置成均值为 0，标准方差为 1，神经元输出 z 的方差就正则化到 1 了。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。\n\n同理，也有 **He Initialization**。它和  Xavier initialization 唯一的区别是`Var(wi)=2/n`，适用于 **ReLU** 作为激活函数时。\n\n当激活函数使用 ReLU 时，`Var(wi)=2/n`；当激活函数使用 tanh 时，`Var(wi)=1/n`。\n","source":"_posts/梯度消失和梯度爆炸.md","raw":"---\ntitle: 梯度消失和梯度爆炸\ndate: 2018-07-20 16:25:16\ntags: 优化算法\ncategroies: 深度学习\nmathjax: true\n---\n\n## 梯度消失和梯度爆炸\n\n在梯度函数上出现的以指数级递增或者递减的情况分别称为**梯度爆炸**或者**梯度消失**。\n\n假定 $g(z) = z, b^{[l]} = 0$，对于目标输出有：\n\n$$\\hat{y} = W^{[L]}W^{[L-1]}...W^{[2]}W^{[1]}X$$\n\n* 对于 $W^{[l]}$的值大于 1 的情况，激活函数的值将以指数级递增；\n* 对于 $W^{[l]}$的值小于 1 的情况，激活函数的值将以指数级递减。\n\n对于导数同理。因此，在计算梯度时，根据不同情况梯度函数会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。\n\n### 利用初始化缓解梯度消失和爆炸\n\n根据\n\n$$z={w}_1{x}\\_1+{w}\\_2{x}\\_2 + ... + {w}\\_n{x}\\_n + b$$\n\n可知，当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。\n\n为了得到较小的 wi，设置`Var(wi)=1/n`，这里称为 **Xavier initialization**。\n\n```python\nWL = np.random.randn(WL.shape[0], WL.shape[1]) * np.sqrt(1/n)\n```\n\n其中 n 是输入的神经元个数，即`WL.shape[1]`。\n\n这样，激活函数的输入 x 近似设置成均值为 0，标准方差为 1，神经元输出 z 的方差就正则化到 1 了。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。\n\n同理，也有 **He Initialization**。它和  Xavier initialization 唯一的区别是`Var(wi)=2/n`，适用于 **ReLU** 作为激活函数时。\n\n当激活函数使用 ReLU 时，`Var(wi)=2/n`；当激活函数使用 tanh 时，`Var(wi)=1/n`。\n","slug":"梯度消失和梯度爆炸","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds5h003epcvondqcendx","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"梯度消失和梯度爆炸\"><a href=\"#梯度消失和梯度爆炸\" class=\"headerlink\" title=\"梯度消失和梯度爆炸\"></a>梯度消失和梯度爆炸</h2><p>在梯度函数上出现的以指数级递增或者递减的情况分别称为<strong>梯度爆炸</strong>或者<strong>梯度消失</strong>。</p>\n<p>假定 $g(z) = z, b^{[l]} = 0$，对于目标输出有：</p>\n<p>$$\\hat{y} = W^{[L]}W^{[L-1]}…W^{[2]}W^{[1]}X$$</p>\n<ul>\n<li>对于 $W^{[l]}$的值大于 1 的情况，激活函数的值将以指数级递增；</li>\n<li>对于 $W^{[l]}$的值小于 1 的情况，激活函数的值将以指数级递减。</li>\n</ul>\n<p>对于导数同理。因此，在计算梯度时，根据不同情况梯度函数会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。</p>\n<h3 id=\"利用初始化缓解梯度消失和爆炸\"><a href=\"#利用初始化缓解梯度消失和爆炸\" class=\"headerlink\" title=\"利用初始化缓解梯度消失和爆炸\"></a>利用初始化缓解梯度消失和爆炸</h3><p>根据</p>\n<p>$$z={w}_1{x}_1+{w}_2{x}_2 + … + {w}_n{x}_n + b$$</p>\n<p>可知，当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。</p>\n<p>为了得到较小的 wi，设置<code>Var(wi)=1/n</code>，这里称为 <strong>Xavier initialization</strong>。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WL = np.random.randn(WL.shape[<span class=\"number\">0</span>], WL.shape[<span class=\"number\">1</span>]) * np.sqrt(<span class=\"number\">1</span>/n)</span><br></pre></td></tr></table></figure>\n<p>其中 n 是输入的神经元个数，即<code>WL.shape[1]</code>。</p>\n<p>这样，激活函数的输入 x 近似设置成均值为 0，标准方差为 1，神经元输出 z 的方差就正则化到 1 了。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。</p>\n<p>同理，也有 <strong>He Initialization</strong>。它和  Xavier initialization 唯一的区别是<code>Var(wi)=2/n</code>，适用于 <strong>ReLU</strong> 作为激活函数时。</p>\n<p>当激活函数使用 ReLU 时，<code>Var(wi)=2/n</code>；当激活函数使用 tanh 时，<code>Var(wi)=1/n</code>。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"梯度消失和梯度爆炸\"><a href=\"#梯度消失和梯度爆炸\" class=\"headerlink\" title=\"梯度消失和梯度爆炸\"></a>梯度消失和梯度爆炸</h2><p>在梯度函数上出现的以指数级递增或者递减的情况分别称为<strong>梯度爆炸</strong>或者<strong>梯度消失</strong>。</p>\n<p>假定 $g(z) = z, b^{[l]} = 0$，对于目标输出有：</p>\n<p>$$\\hat{y} = W^{[L]}W^{[L-1]}…W^{[2]}W^{[1]}X$$</p>\n<ul>\n<li>对于 $W^{[l]}$的值大于 1 的情况，激活函数的值将以指数级递增；</li>\n<li>对于 $W^{[l]}$的值小于 1 的情况，激活函数的值将以指数级递减。</li>\n</ul>\n<p>对于导数同理。因此，在计算梯度时，根据不同情况梯度函数会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。</p>\n<h3 id=\"利用初始化缓解梯度消失和爆炸\"><a href=\"#利用初始化缓解梯度消失和爆炸\" class=\"headerlink\" title=\"利用初始化缓解梯度消失和爆炸\"></a>利用初始化缓解梯度消失和爆炸</h3><p>根据</p>\n<p>$$z={w}_1{x}_1+{w}_2{x}_2 + … + {w}_n{x}_n + b$$</p>\n<p>可知，当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。</p>\n<p>为了得到较小的 wi，设置<code>Var(wi)=1/n</code>，这里称为 <strong>Xavier initialization</strong>。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WL = np.random.randn(WL.shape[<span class=\"number\">0</span>], WL.shape[<span class=\"number\">1</span>]) * np.sqrt(<span class=\"number\">1</span>/n)</span><br></pre></td></tr></table></figure>\n<p>其中 n 是输入的神经元个数，即<code>WL.shape[1]</code>。</p>\n<p>这样，激活函数的输入 x 近似设置成均值为 0，标准方差为 1，神经元输出 z 的方差就正则化到 1 了。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。</p>\n<p>同理，也有 <strong>He Initialization</strong>。它和  Xavier initialization 唯一的区别是<code>Var(wi)=2/n</code>，适用于 <strong>ReLU</strong> 作为激活函数时。</p>\n<p>当激活函数使用 ReLU 时，<code>Var(wi)=2/n</code>；当激活函数使用 tanh 时，<code>Var(wi)=1/n</code>。</p>\n"},{"title":"深度卷积神经网络:实例探究","date":"2018-08-26T09:33:47.000Z","mathjax":true,"_content":"## 经典卷积网络\n\n### LeNet-5\n\n![LeNet-5](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/LeNet-5.png)\n\n特点：\n\n* LeNet-5 针对灰度图像而训练，因此输入图片的通道数为 1。\n* 该模型总共包含了约 6 万个参数，远少于标准神经网络所需。\n* 典型的 LeNet-5 结构包含卷积层（CONV layer），池化层（POOL layer）和全连接层（FC layer），排列顺序一般为 CONV layer->POOL layer->CONV layer->POOL layer->FC layer->FC layer->OUTPUT layer。一个或多个卷积层后面跟着一个池化层的模式至今仍十分常用。\n* 当 LeNet-5模型被提出时，其池化层使用的是平均池化，而且各层激活函数一般选用 Sigmoid 和 tanh。现在，我们可以根据需要，做出改进，使用最大池化并选用 ReLU 作为激活函数。\n\n相关论文：[LeCun et.al., 1998. Gradient-based learning applied to document recognition](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791&tag=1)。\n\n### AlexNet\n\n![AlexNet](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/AlexNet.png)\n\n特点：\n\n* AlexNet 模型与 LeNet-5 模型类似，但是更复杂，包含约 6000 万个参数。另外，AlexNet 模型使用了 ReLU 函数。\n* 当用于训练图像和数据集时，AlexNet 能够处理非常相似的基本构造模块，这些模块往往包含大量的隐藏单元或数据。\n\n相关论文：[Krizhevsky et al.,2012. ImageNet classification with deep convolutional neural networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。这是一篇易于理解并且影响巨大的论文，计算机视觉群体自此开始重视深度学习。\n\n### VGG\n\n![VGG](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/VGG.png)\n\n特点：\n\n* VGG 又称 VGG-16 网络，“16”指网络中包含 16 个卷积层和全连接层。\n* 超参数较少，只需要专注于构建卷积层。\n* 结构不复杂且规整，在每一组卷积层进行滤波器翻倍操作。\n* VGG 需要训练的特征数量巨大，包含多达约 1.38 亿个参数。\n\n相关论文：[Simonvan & Zisserman 2015. Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556.pdf)。\n\n## 残差网络\n\n因为存在梯度消失和梯度爆炸问题，网络越深，就越难以训练成功。**残差网络（Residual Networks，简称为 ResNets）** 可以有效解决这个问题。\n\n![Residual-block](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-block.jpg)\n\n上图的结构被称为 **残差块（Residual block**。 通过 **捷径（Short cut，或者称跳远连接，Skip connections）** 可以将 $a^{[l]}$ 添加到第二个 ReLU 过程中，直接建立 $a^{[l]}$ 与 $a^{[l+2]}$ 之间的隔层联系。表达式如下：\n\n$$z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$$\n\n$$a^{[l+1]} = g(z^{[l+1]})$$\n\n$$z^{[l+2]} = W^{[l+2]}a^{[l+1]} + b^{[l+2]}$$\n\n$$a^{[l+2]} = g(z^{[l+2]} + a^{[l]})$$\n\n构建一个残差网络就是将许多残差块堆积在一起，形成一个深度网络。\n\n![Residual-Network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-Network.jpg)\n\n为了便于区分，在 ResNets 的论文[He et al., 2015. Deep residual networks for image recognition](https://arxiv.org/pdf/1512.03385.pdf)中，非残差网络被称为 **普通网络（Plain Network）**。 将它变为残差网络的方法是加上所有的跳远连接。\n\n在理论上，随着网络深度的增加，性能应该越来越好。但实际上，对于一个普通网络，随着神经网络层数增加，训练错误会先减少，然后开始增多。但残差网络的训练效果显示，即使网络再深，其在训练集上的表现也会越来越好。\n\n![ResNet-Training-Error](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Training-Error.jpg)\n\n残差网络有助于解决梯度消失和梯度爆炸问题，使得在训练更深的网络的同时，又能保证良好的性能。\n\n### 残差网络有效的原因\n\n假设有一个大型神经网络，其输入为 $X$，输出为 $a^{[l]}$。给这个神经网络额外增加两层，输出为 $a^{[l+2]}$。将这两层看作一个具有跳远连接的残差块。为了方便说明，假设整个网络中都选用 ReLU 作为激活函数，因此输出的所有激活值都大于等于 0。\n\n![Why-do-residual-networks-work](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Why-do-residual-networks-work.jpg)\n\n则有：\n\n$$\n\\begin{equation}\n\\begin{split}\n a^{[l+2]} &= g(z^{[l+2]}+a^{[l]})\n     \\\\\\ &= g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})\n\\end{split}\n\\end{equation}\n$$\n\n当发生梯度消失时，$W^{[l+2]}\\approx0$，$b^{[l+2]}\\approx0$，则有：\n\n$$a^{[l+2]} = g(a^{[l]}) = ReLU(a^{[l]}) = a^{[l]}$$\n\n因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。\n\n注意，如果 $a^{[l]}$ 与 $a^{[l+2]}$ 的维度不同，需要引入矩阵 $W\\_s$ 与 $a^{[l]}$ 相乘，使得二者的维度相匹配。参数矩阵 $W\\_s$ 既可以通过模型训练得到，也可以作为固定值，仅使 $a^{[l]}$ 截断或者补零。\n\n![ResNet-Paper](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Paper.png)\n\n上图是论文提供的 CNN 中 ResNet 的一个典型结构。卷积层通常使用 Same 卷积以保持维度相同，而不同类型层之间的连接（例如卷积层和池化层），如果维度不同，则需要引入矩阵 $W_s$。\n\n## 1x1 卷积\n\n1x1 卷积（1x1 convolution，或称为 Network in Network）指滤波器的尺寸为 1。当通道数为 1 时，1x1 卷积意味着卷积操作等同于乘积操作。\n\n![1x1-Conv-1](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-1.png)\n\n而当通道数更多时，1x1 卷积的作用实际上类似全连接层的神经网络结构，从而降低（或升高，取决于滤波器组数）数据的维度。\n\n池化能压缩数据的高度（$n_H$）及宽度（$n_W$），而 1×1 卷积能压缩数据的通道数（$n_C$）。在如下图所示的例子中，用 32 个大小为 1×1×192 的滤波器进行卷积，就能使原先数据包含的 192 个通道压缩为 32 个。\n\n![1x1-Conv-2](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-2.png)\n\n虽然论文[Lin et al., 2013. Network in network](https://arxiv.org/pdf/1312.4400.pdf)中关于架构的详细内容并没有得到广泛应用，但是 1x1 卷积的理念十分有影响力，许多神经网络架构（包括 Inception 网络）都受到它的影响。\n\n## Inception 网络\n\n在之前的卷积网络中，我们只能选择单一尺寸和类型的滤波器。而 **Inception 网络的作用**即是代替人工来确定卷积层中的滤波器尺寸与类型，或者确定是否需要创建卷积层或池化层。\n\n![Motivation-for-inception-network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Motivation-for-inception-network.jpg)\n\n如图，Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。\n\n相关论文：[Szegedy et al., 2014, Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842.pdf)\n\n### 计算成本问题\n\n在提升性能的同时，Inception 网络有着较大的计算成本。下图是一个例子：\n\n![The-problem-of-computational-cost](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/The-problem-of-computational-cost.png)\n\n图中有 32 个滤波器，每个滤波器的大小为 5x5x192。输出大小为 28x28x32，所以需要计算 28x28x32 个数字，对于每个数，都要执行 5x5x192 次乘法运算。加法运算次数与乘法运算次数近似相等。因此，可以看作这一层的计算量为 28x28x32x5x5x192 = 1.2亿。\n\n为了解决计算量大的问题，可以引入 1x1 卷积来减少其计算量。\n\n![Using-1x1-convolution](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Using-1x1-convolution.png)\n\n对于同一个例子，我们使用 1x1 卷积把输入数据从 192 个通道减少到 16 个通道，然后对这个较小层运行 5x5 卷积，得到最终输出。这个 1x1 的卷积层通常被称作**瓶颈层（Bottleneck layer）**。\n\n改进后的计算量为 28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。\n\n只要合理构建瓶颈层，就可以既显著缩小计算规模，又不会降低网络性能。\n\n### 完整的 Inception 网络\n\n![Inception-module](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-module.jpg)\n\n上图是引入 1x1 卷积后的 Inception 模块。值得注意的是，为了将所有的输出组合起来，红色的池化层使用 Same 类型的填充（padding）来池化使得输出的宽高不变，通道数也不变。\n\n多个 Inception 模块组成一个完整的 Inception 网络（被称为 GoogLeNet，以向 LeNet 致敬），如下图所示：\n\n![Inception-network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-network.jpg)\n\n注意黑色椭圆圈出的隐藏层，这些分支都是 Softmax 的输出层，可以用来参与特征的计算及结果预测，起到调整并防止发生过拟合的效果。\n\n经过研究者们的不断发展，Inception 模型的 V2、V3、V4 以及引入残差网络的版本被提出，这些变体都基于 Inception V1 版本的基础思想上。顺便一提，Inception 模型的名字来自电影《盗梦空间》。\n\n## 使用开源的实现方案\n\n很多神经网络复杂细致，并充斥着参数调节的细节问题，因而很难仅通过阅读论文来重现他人的成果。想要搭建一个同样的神经网络，查看开源的实现方案会快很多。\n\n## 迁移学习\n\n在“搭建机器学习项目”课程中，[迁移学习](http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Structuring_Machine_Learning_Projects/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89?id=%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0)已经被提到过。计算机视觉是一个经常用到迁移学习的领域。在搭建计算机视觉的应用时，相比于从头训练权重，下载别人已经训练好的网络结构的权重，用其做**预训练**，然后转换到自己感兴趣的任务上，有助于加速开发。\n\n对于已训练好的卷积神经网络，可以将所有层都看作是**冻结的**，只需要训练与你的 Softmax 层有关的参数即可。大多数深度学习框架都允许用户指定是否训练特定层的权重。\n\n而冻结的层由于不需要改变和训练，可以看作一个固定函数。可以将这个固定函数存入硬盘，以便后续使用，而不必每次再使用训练集进行训练了。\n\n上述的做法适用于你只有一个较小的数据集。如果你有一个更大的数据集，应该冻结更少的层，然后训练后面的层。越多的数据意味着冻结越少的层，训练更多的层。如果有一个极大的数据集，你可以将开源的网络和它的权重整个当作初始化（代替随机初始化），然后训练整个网络。\n\n## 数据扩增\n\n计算机视觉领域的应用都需要大量的数据。当数据不够时，**数据扩增（Data Augmentation）**就有帮助。常用的数据扩增包括镜像翻转、随机裁剪、色彩转换。\n\n其中，色彩转换是对图片的 RGB 通道数值进行随意增加或者减少，改变图片色调。另外，**PCA 颜色增强**指更有针对性地对图片的 RGB 通道进行主成分分析（Principles Components Analysis，PCA），对主要的通道颜色进行增加或减少，可以采用高斯扰动做法来增加有效的样本数量。具体的 PCA 颜色增强做法可以查阅 AlexNet 的相关论文或者开源代码。\n\n在构建大型神经网络的时候，数据扩增和模型训练可以由两个或多个不同的线程并行来实现。\n\n## 计算机视觉现状\n\n通常，学习算法有两种知识来源：\n\n* 被标记的数据\n* 手工工程\n\n**手工工程（Hand-engineering，又称 hacks）** 指精心设计的特性、网络体系结构或是系统的其他组件。手工工程是一项非常重要也比较困难的工作。在数据量不多的情况下，手工工程是获得良好表现的最佳方式。正因为数据量不能满足需要，历史上计算机视觉领域更多地依赖于手工工程。近几年数据量急剧增加，因此手工工程量大幅减少。\n\n另外，在模型研究或者竞赛方面，有一些方法能够有助于提升神经网络模型的性能：\n\n* 集成（Ensembling）：独立地训练几个神经网络，并平均输出它们的输出\n* Multi-crop at test time：将数据扩增应用到测试集，对结果进行平均\n\n但是由于这些方法计算和内存成本较大，一般不适用于构建实际的生产项目。\n","source":"_posts/深度卷积神经网络-实例探究.md","raw":"---\ntitle: 深度卷积神经网络:实例探究\ndate: 2018-08-26 17:33:47\ntags: CNN\ncategories: 深度学习\nmathjax: true\n---\n## 经典卷积网络\n\n### LeNet-5\n\n![LeNet-5](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/LeNet-5.png)\n\n特点：\n\n* LeNet-5 针对灰度图像而训练，因此输入图片的通道数为 1。\n* 该模型总共包含了约 6 万个参数，远少于标准神经网络所需。\n* 典型的 LeNet-5 结构包含卷积层（CONV layer），池化层（POOL layer）和全连接层（FC layer），排列顺序一般为 CONV layer->POOL layer->CONV layer->POOL layer->FC layer->FC layer->OUTPUT layer。一个或多个卷积层后面跟着一个池化层的模式至今仍十分常用。\n* 当 LeNet-5模型被提出时，其池化层使用的是平均池化，而且各层激活函数一般选用 Sigmoid 和 tanh。现在，我们可以根据需要，做出改进，使用最大池化并选用 ReLU 作为激活函数。\n\n相关论文：[LeCun et.al., 1998. Gradient-based learning applied to document recognition](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791&tag=1)。\n\n### AlexNet\n\n![AlexNet](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/AlexNet.png)\n\n特点：\n\n* AlexNet 模型与 LeNet-5 模型类似，但是更复杂，包含约 6000 万个参数。另外，AlexNet 模型使用了 ReLU 函数。\n* 当用于训练图像和数据集时，AlexNet 能够处理非常相似的基本构造模块，这些模块往往包含大量的隐藏单元或数据。\n\n相关论文：[Krizhevsky et al.,2012. ImageNet classification with deep convolutional neural networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。这是一篇易于理解并且影响巨大的论文，计算机视觉群体自此开始重视深度学习。\n\n### VGG\n\n![VGG](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/VGG.png)\n\n特点：\n\n* VGG 又称 VGG-16 网络，“16”指网络中包含 16 个卷积层和全连接层。\n* 超参数较少，只需要专注于构建卷积层。\n* 结构不复杂且规整，在每一组卷积层进行滤波器翻倍操作。\n* VGG 需要训练的特征数量巨大，包含多达约 1.38 亿个参数。\n\n相关论文：[Simonvan & Zisserman 2015. Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556.pdf)。\n\n## 残差网络\n\n因为存在梯度消失和梯度爆炸问题，网络越深，就越难以训练成功。**残差网络（Residual Networks，简称为 ResNets）** 可以有效解决这个问题。\n\n![Residual-block](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-block.jpg)\n\n上图的结构被称为 **残差块（Residual block**。 通过 **捷径（Short cut，或者称跳远连接，Skip connections）** 可以将 $a^{[l]}$ 添加到第二个 ReLU 过程中，直接建立 $a^{[l]}$ 与 $a^{[l+2]}$ 之间的隔层联系。表达式如下：\n\n$$z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$$\n\n$$a^{[l+1]} = g(z^{[l+1]})$$\n\n$$z^{[l+2]} = W^{[l+2]}a^{[l+1]} + b^{[l+2]}$$\n\n$$a^{[l+2]} = g(z^{[l+2]} + a^{[l]})$$\n\n构建一个残差网络就是将许多残差块堆积在一起，形成一个深度网络。\n\n![Residual-Network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-Network.jpg)\n\n为了便于区分，在 ResNets 的论文[He et al., 2015. Deep residual networks for image recognition](https://arxiv.org/pdf/1512.03385.pdf)中，非残差网络被称为 **普通网络（Plain Network）**。 将它变为残差网络的方法是加上所有的跳远连接。\n\n在理论上，随着网络深度的增加，性能应该越来越好。但实际上，对于一个普通网络，随着神经网络层数增加，训练错误会先减少，然后开始增多。但残差网络的训练效果显示，即使网络再深，其在训练集上的表现也会越来越好。\n\n![ResNet-Training-Error](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Training-Error.jpg)\n\n残差网络有助于解决梯度消失和梯度爆炸问题，使得在训练更深的网络的同时，又能保证良好的性能。\n\n### 残差网络有效的原因\n\n假设有一个大型神经网络，其输入为 $X$，输出为 $a^{[l]}$。给这个神经网络额外增加两层，输出为 $a^{[l+2]}$。将这两层看作一个具有跳远连接的残差块。为了方便说明，假设整个网络中都选用 ReLU 作为激活函数，因此输出的所有激活值都大于等于 0。\n\n![Why-do-residual-networks-work](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Why-do-residual-networks-work.jpg)\n\n则有：\n\n$$\n\\begin{equation}\n\\begin{split}\n a^{[l+2]} &= g(z^{[l+2]}+a^{[l]})\n     \\\\\\ &= g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})\n\\end{split}\n\\end{equation}\n$$\n\n当发生梯度消失时，$W^{[l+2]}\\approx0$，$b^{[l+2]}\\approx0$，则有：\n\n$$a^{[l+2]} = g(a^{[l]}) = ReLU(a^{[l]}) = a^{[l]}$$\n\n因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。\n\n注意，如果 $a^{[l]}$ 与 $a^{[l+2]}$ 的维度不同，需要引入矩阵 $W\\_s$ 与 $a^{[l]}$ 相乘，使得二者的维度相匹配。参数矩阵 $W\\_s$ 既可以通过模型训练得到，也可以作为固定值，仅使 $a^{[l]}$ 截断或者补零。\n\n![ResNet-Paper](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Paper.png)\n\n上图是论文提供的 CNN 中 ResNet 的一个典型结构。卷积层通常使用 Same 卷积以保持维度相同，而不同类型层之间的连接（例如卷积层和池化层），如果维度不同，则需要引入矩阵 $W_s$。\n\n## 1x1 卷积\n\n1x1 卷积（1x1 convolution，或称为 Network in Network）指滤波器的尺寸为 1。当通道数为 1 时，1x1 卷积意味着卷积操作等同于乘积操作。\n\n![1x1-Conv-1](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-1.png)\n\n而当通道数更多时，1x1 卷积的作用实际上类似全连接层的神经网络结构，从而降低（或升高，取决于滤波器组数）数据的维度。\n\n池化能压缩数据的高度（$n_H$）及宽度（$n_W$），而 1×1 卷积能压缩数据的通道数（$n_C$）。在如下图所示的例子中，用 32 个大小为 1×1×192 的滤波器进行卷积，就能使原先数据包含的 192 个通道压缩为 32 个。\n\n![1x1-Conv-2](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-2.png)\n\n虽然论文[Lin et al., 2013. Network in network](https://arxiv.org/pdf/1312.4400.pdf)中关于架构的详细内容并没有得到广泛应用，但是 1x1 卷积的理念十分有影响力，许多神经网络架构（包括 Inception 网络）都受到它的影响。\n\n## Inception 网络\n\n在之前的卷积网络中，我们只能选择单一尺寸和类型的滤波器。而 **Inception 网络的作用**即是代替人工来确定卷积层中的滤波器尺寸与类型，或者确定是否需要创建卷积层或池化层。\n\n![Motivation-for-inception-network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Motivation-for-inception-network.jpg)\n\n如图，Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。\n\n相关论文：[Szegedy et al., 2014, Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842.pdf)\n\n### 计算成本问题\n\n在提升性能的同时，Inception 网络有着较大的计算成本。下图是一个例子：\n\n![The-problem-of-computational-cost](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/The-problem-of-computational-cost.png)\n\n图中有 32 个滤波器，每个滤波器的大小为 5x5x192。输出大小为 28x28x32，所以需要计算 28x28x32 个数字，对于每个数，都要执行 5x5x192 次乘法运算。加法运算次数与乘法运算次数近似相等。因此，可以看作这一层的计算量为 28x28x32x5x5x192 = 1.2亿。\n\n为了解决计算量大的问题，可以引入 1x1 卷积来减少其计算量。\n\n![Using-1x1-convolution](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Using-1x1-convolution.png)\n\n对于同一个例子，我们使用 1x1 卷积把输入数据从 192 个通道减少到 16 个通道，然后对这个较小层运行 5x5 卷积，得到最终输出。这个 1x1 的卷积层通常被称作**瓶颈层（Bottleneck layer）**。\n\n改进后的计算量为 28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。\n\n只要合理构建瓶颈层，就可以既显著缩小计算规模，又不会降低网络性能。\n\n### 完整的 Inception 网络\n\n![Inception-module](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-module.jpg)\n\n上图是引入 1x1 卷积后的 Inception 模块。值得注意的是，为了将所有的输出组合起来，红色的池化层使用 Same 类型的填充（padding）来池化使得输出的宽高不变，通道数也不变。\n\n多个 Inception 模块组成一个完整的 Inception 网络（被称为 GoogLeNet，以向 LeNet 致敬），如下图所示：\n\n![Inception-network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-network.jpg)\n\n注意黑色椭圆圈出的隐藏层，这些分支都是 Softmax 的输出层，可以用来参与特征的计算及结果预测，起到调整并防止发生过拟合的效果。\n\n经过研究者们的不断发展，Inception 模型的 V2、V3、V4 以及引入残差网络的版本被提出，这些变体都基于 Inception V1 版本的基础思想上。顺便一提，Inception 模型的名字来自电影《盗梦空间》。\n\n## 使用开源的实现方案\n\n很多神经网络复杂细致，并充斥着参数调节的细节问题，因而很难仅通过阅读论文来重现他人的成果。想要搭建一个同样的神经网络，查看开源的实现方案会快很多。\n\n## 迁移学习\n\n在“搭建机器学习项目”课程中，[迁移学习](http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Structuring_Machine_Learning_Projects/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89?id=%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0)已经被提到过。计算机视觉是一个经常用到迁移学习的领域。在搭建计算机视觉的应用时，相比于从头训练权重，下载别人已经训练好的网络结构的权重，用其做**预训练**，然后转换到自己感兴趣的任务上，有助于加速开发。\n\n对于已训练好的卷积神经网络，可以将所有层都看作是**冻结的**，只需要训练与你的 Softmax 层有关的参数即可。大多数深度学习框架都允许用户指定是否训练特定层的权重。\n\n而冻结的层由于不需要改变和训练，可以看作一个固定函数。可以将这个固定函数存入硬盘，以便后续使用，而不必每次再使用训练集进行训练了。\n\n上述的做法适用于你只有一个较小的数据集。如果你有一个更大的数据集，应该冻结更少的层，然后训练后面的层。越多的数据意味着冻结越少的层，训练更多的层。如果有一个极大的数据集，你可以将开源的网络和它的权重整个当作初始化（代替随机初始化），然后训练整个网络。\n\n## 数据扩增\n\n计算机视觉领域的应用都需要大量的数据。当数据不够时，**数据扩增（Data Augmentation）**就有帮助。常用的数据扩增包括镜像翻转、随机裁剪、色彩转换。\n\n其中，色彩转换是对图片的 RGB 通道数值进行随意增加或者减少，改变图片色调。另外，**PCA 颜色增强**指更有针对性地对图片的 RGB 通道进行主成分分析（Principles Components Analysis，PCA），对主要的通道颜色进行增加或减少，可以采用高斯扰动做法来增加有效的样本数量。具体的 PCA 颜色增强做法可以查阅 AlexNet 的相关论文或者开源代码。\n\n在构建大型神经网络的时候，数据扩增和模型训练可以由两个或多个不同的线程并行来实现。\n\n## 计算机视觉现状\n\n通常，学习算法有两种知识来源：\n\n* 被标记的数据\n* 手工工程\n\n**手工工程（Hand-engineering，又称 hacks）** 指精心设计的特性、网络体系结构或是系统的其他组件。手工工程是一项非常重要也比较困难的工作。在数据量不多的情况下，手工工程是获得良好表现的最佳方式。正因为数据量不能满足需要，历史上计算机视觉领域更多地依赖于手工工程。近几年数据量急剧增加，因此手工工程量大幅减少。\n\n另外，在模型研究或者竞赛方面，有一些方法能够有助于提升神经网络模型的性能：\n\n* 集成（Ensembling）：独立地训练几个神经网络，并平均输出它们的输出\n* Multi-crop at test time：将数据扩增应用到测试集，对结果进行平均\n\n但是由于这些方法计算和内存成本较大，一般不适用于构建实际的生产项目。\n","slug":"深度卷积神经网络-实例探究","published":1,"updated":"2018-08-26T09:48:38.084Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds5h003ipcvoce83xwfn","content":"<h2 id=\"经典卷积网络\"><a href=\"#经典卷积网络\" class=\"headerlink\" title=\"经典卷积网络\"></a>经典卷积网络</h2><h3 id=\"LeNet-5\"><a href=\"#LeNet-5\" class=\"headerlink\" title=\"LeNet-5\"></a>LeNet-5</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/LeNet-5.png\" alt=\"LeNet-5\"></p>\n<p>特点：</p>\n<ul>\n<li>LeNet-5 针对灰度图像而训练，因此输入图片的通道数为 1。</li>\n<li>该模型总共包含了约 6 万个参数，远少于标准神经网络所需。</li>\n<li>典型的 LeNet-5 结构包含卷积层（CONV layer），池化层（POOL layer）和全连接层（FC layer），排列顺序一般为 CONV layer-&gt;POOL layer-&gt;CONV layer-&gt;POOL layer-&gt;FC layer-&gt;FC layer-&gt;OUTPUT layer。一个或多个卷积层后面跟着一个池化层的模式至今仍十分常用。</li>\n<li>当 LeNet-5模型被提出时，其池化层使用的是平均池化，而且各层激活函数一般选用 Sigmoid 和 tanh。现在，我们可以根据需要，做出改进，使用最大池化并选用 ReLU 作为激活函数。</li>\n</ul>\n<p>相关论文：<a href=\"http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791&amp;tag=1\" target=\"_blank\" rel=\"noopener\">LeCun et.al., 1998. Gradient-based learning applied to document recognition</a>。</p>\n<h3 id=\"AlexNet\"><a href=\"#AlexNet\" class=\"headerlink\" title=\"AlexNet\"></a>AlexNet</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/AlexNet.png\" alt=\"AlexNet\"></p>\n<p>特点：</p>\n<ul>\n<li>AlexNet 模型与 LeNet-5 模型类似，但是更复杂，包含约 6000 万个参数。另外，AlexNet 模型使用了 ReLU 函数。</li>\n<li>当用于训练图像和数据集时，AlexNet 能够处理非常相似的基本构造模块，这些模块往往包含大量的隐藏单元或数据。</li>\n</ul>\n<p>相关论文：<a href=\"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" target=\"_blank\" rel=\"noopener\">Krizhevsky et al.,2012. ImageNet classification with deep convolutional neural networks</a>。这是一篇易于理解并且影响巨大的论文，计算机视觉群体自此开始重视深度学习。</p>\n<h3 id=\"VGG\"><a href=\"#VGG\" class=\"headerlink\" title=\"VGG\"></a>VGG</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/VGG.png\" alt=\"VGG\"></p>\n<p>特点：</p>\n<ul>\n<li>VGG 又称 VGG-16 网络，“16”指网络中包含 16 个卷积层和全连接层。</li>\n<li>超参数较少，只需要专注于构建卷积层。</li>\n<li>结构不复杂且规整，在每一组卷积层进行滤波器翻倍操作。</li>\n<li>VGG 需要训练的特征数量巨大，包含多达约 1.38 亿个参数。</li>\n</ul>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1409.1556.pdf\" target=\"_blank\" rel=\"noopener\">Simonvan &amp; Zisserman 2015. Very deep convolutional networks for large-scale image recognition</a>。</p>\n<h2 id=\"残差网络\"><a href=\"#残差网络\" class=\"headerlink\" title=\"残差网络\"></a>残差网络</h2><p>因为存在梯度消失和梯度爆炸问题，网络越深，就越难以训练成功。<strong>残差网络（Residual Networks，简称为 ResNets）</strong> 可以有效解决这个问题。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-block.jpg\" alt=\"Residual-block\"></p>\n<p>上图的结构被称为 <strong>残差块（Residual block</strong>。 通过 <strong>捷径（Short cut，或者称跳远连接，Skip connections）</strong> 可以将 $a^{[l]}$ 添加到第二个 ReLU 过程中，直接建立 $a^{[l]}$ 与 $a^{[l+2]}$ 之间的隔层联系。表达式如下：</p>\n<p>$$z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$$</p>\n<p>$$a^{[l+1]} = g(z^{[l+1]})$$</p>\n<p>$$z^{[l+2]} = W^{[l+2]}a^{[l+1]} + b^{[l+2]}$$</p>\n<p>$$a^{[l+2]} = g(z^{[l+2]} + a^{[l]})$$</p>\n<p>构建一个残差网络就是将许多残差块堆积在一起，形成一个深度网络。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-Network.jpg\" alt=\"Residual-Network\"></p>\n<p>为了便于区分，在 ResNets 的论文<a href=\"https://arxiv.org/pdf/1512.03385.pdf\" target=\"_blank\" rel=\"noopener\">He et al., 2015. Deep residual networks for image recognition</a>中，非残差网络被称为 <strong>普通网络（Plain Network）</strong>。 将它变为残差网络的方法是加上所有的跳远连接。</p>\n<p>在理论上，随着网络深度的增加，性能应该越来越好。但实际上，对于一个普通网络，随着神经网络层数增加，训练错误会先减少，然后开始增多。但残差网络的训练效果显示，即使网络再深，其在训练集上的表现也会越来越好。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Training-Error.jpg\" alt=\"ResNet-Training-Error\"></p>\n<p>残差网络有助于解决梯度消失和梯度爆炸问题，使得在训练更深的网络的同时，又能保证良好的性能。</p>\n<h3 id=\"残差网络有效的原因\"><a href=\"#残差网络有效的原因\" class=\"headerlink\" title=\"残差网络有效的原因\"></a>残差网络有效的原因</h3><p>假设有一个大型神经网络，其输入为 $X$，输出为 $a^{[l]}$。给这个神经网络额外增加两层，输出为 $a^{[l+2]}$。将这两层看作一个具有跳远连接的残差块。为了方便说明，假设整个网络中都选用 ReLU 作为激活函数，因此输出的所有激活值都大于等于 0。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Why-do-residual-networks-work.jpg\" alt=\"Why-do-residual-networks-work\"></p>\n<p>则有：</p>\n<p>$$<br>\\begin{equation}<br>\\begin{split}<br> a^{[l+2]} &amp;= g(z^{[l+2]}+a^{[l]})<br>     \\\\ &amp;= g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})<br>\\end{split}<br>\\end{equation}<br>$$</p>\n<p>当发生梯度消失时，$W^{[l+2]}\\approx0$，$b^{[l+2]}\\approx0$，则有：</p>\n<p>$$a^{[l+2]} = g(a^{[l]}) = ReLU(a^{[l]}) = a^{[l]}$$</p>\n<p>因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。</p>\n<p>注意，如果 $a^{[l]}$ 与 $a^{[l+2]}$ 的维度不同，需要引入矩阵 $W_s$ 与 $a^{[l]}$ 相乘，使得二者的维度相匹配。参数矩阵 $W_s$ 既可以通过模型训练得到，也可以作为固定值，仅使 $a^{[l]}$ 截断或者补零。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Paper.png\" alt=\"ResNet-Paper\"></p>\n<p>上图是论文提供的 CNN 中 ResNet 的一个典型结构。卷积层通常使用 Same 卷积以保持维度相同，而不同类型层之间的连接（例如卷积层和池化层），如果维度不同，则需要引入矩阵 $W_s$。</p>\n<h2 id=\"1x1-卷积\"><a href=\"#1x1-卷积\" class=\"headerlink\" title=\"1x1 卷积\"></a>1x1 卷积</h2><p>1x1 卷积（1x1 convolution，或称为 Network in Network）指滤波器的尺寸为 1。当通道数为 1 时，1x1 卷积意味着卷积操作等同于乘积操作。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-1.png\" alt=\"1x1-Conv-1\"></p>\n<p>而当通道数更多时，1x1 卷积的作用实际上类似全连接层的神经网络结构，从而降低（或升高，取决于滤波器组数）数据的维度。</p>\n<p>池化能压缩数据的高度（$n_H$）及宽度（$n_W$），而 1×1 卷积能压缩数据的通道数（$n_C$）。在如下图所示的例子中，用 32 个大小为 1×1×192 的滤波器进行卷积，就能使原先数据包含的 192 个通道压缩为 32 个。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-2.png\" alt=\"1x1-Conv-2\"></p>\n<p>虽然论文<a href=\"https://arxiv.org/pdf/1312.4400.pdf\" target=\"_blank\" rel=\"noopener\">Lin et al., 2013. Network in network</a>中关于架构的详细内容并没有得到广泛应用，但是 1x1 卷积的理念十分有影响力，许多神经网络架构（包括 Inception 网络）都受到它的影响。</p>\n<h2 id=\"Inception-网络\"><a href=\"#Inception-网络\" class=\"headerlink\" title=\"Inception 网络\"></a>Inception 网络</h2><p>在之前的卷积网络中，我们只能选择单一尺寸和类型的滤波器。而 <strong>Inception 网络的作用</strong>即是代替人工来确定卷积层中的滤波器尺寸与类型，或者确定是否需要创建卷积层或池化层。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Motivation-for-inception-network.jpg\" alt=\"Motivation-for-inception-network\"></p>\n<p>如图，Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1409.4842.pdf\" target=\"_blank\" rel=\"noopener\">Szegedy et al., 2014, Going Deeper with Convolutions</a></p>\n<h3 id=\"计算成本问题\"><a href=\"#计算成本问题\" class=\"headerlink\" title=\"计算成本问题\"></a>计算成本问题</h3><p>在提升性能的同时，Inception 网络有着较大的计算成本。下图是一个例子：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/The-problem-of-computational-cost.png\" alt=\"The-problem-of-computational-cost\"></p>\n<p>图中有 32 个滤波器，每个滤波器的大小为 5x5x192。输出大小为 28x28x32，所以需要计算 28x28x32 个数字，对于每个数，都要执行 5x5x192 次乘法运算。加法运算次数与乘法运算次数近似相等。因此，可以看作这一层的计算量为 28x28x32x5x5x192 = 1.2亿。</p>\n<p>为了解决计算量大的问题，可以引入 1x1 卷积来减少其计算量。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Using-1x1-convolution.png\" alt=\"Using-1x1-convolution\"></p>\n<p>对于同一个例子，我们使用 1x1 卷积把输入数据从 192 个通道减少到 16 个通道，然后对这个较小层运行 5x5 卷积，得到最终输出。这个 1x1 的卷积层通常被称作<strong>瓶颈层（Bottleneck layer）</strong>。</p>\n<p>改进后的计算量为 28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。</p>\n<p>只要合理构建瓶颈层，就可以既显著缩小计算规模，又不会降低网络性能。</p>\n<h3 id=\"完整的-Inception-网络\"><a href=\"#完整的-Inception-网络\" class=\"headerlink\" title=\"完整的 Inception 网络\"></a>完整的 Inception 网络</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-module.jpg\" alt=\"Inception-module\"></p>\n<p>上图是引入 1x1 卷积后的 Inception 模块。值得注意的是，为了将所有的输出组合起来，红色的池化层使用 Same 类型的填充（padding）来池化使得输出的宽高不变，通道数也不变。</p>\n<p>多个 Inception 模块组成一个完整的 Inception 网络（被称为 GoogLeNet，以向 LeNet 致敬），如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-network.jpg\" alt=\"Inception-network\"></p>\n<p>注意黑色椭圆圈出的隐藏层，这些分支都是 Softmax 的输出层，可以用来参与特征的计算及结果预测，起到调整并防止发生过拟合的效果。</p>\n<p>经过研究者们的不断发展，Inception 模型的 V2、V3、V4 以及引入残差网络的版本被提出，这些变体都基于 Inception V1 版本的基础思想上。顺便一提，Inception 模型的名字来自电影《盗梦空间》。</p>\n<h2 id=\"使用开源的实现方案\"><a href=\"#使用开源的实现方案\" class=\"headerlink\" title=\"使用开源的实现方案\"></a>使用开源的实现方案</h2><p>很多神经网络复杂细致，并充斥着参数调节的细节问题，因而很难仅通过阅读论文来重现他人的成果。想要搭建一个同样的神经网络，查看开源的实现方案会快很多。</p>\n<h2 id=\"迁移学习\"><a href=\"#迁移学习\" class=\"headerlink\" title=\"迁移学习\"></a>迁移学习</h2><p>在“搭建机器学习项目”课程中，<a href=\"http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Structuring_Machine_Learning_Projects/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89?id=%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0\" target=\"_blank\" rel=\"noopener\">迁移学习</a>已经被提到过。计算机视觉是一个经常用到迁移学习的领域。在搭建计算机视觉的应用时，相比于从头训练权重，下载别人已经训练好的网络结构的权重，用其做<strong>预训练</strong>，然后转换到自己感兴趣的任务上，有助于加速开发。</p>\n<p>对于已训练好的卷积神经网络，可以将所有层都看作是<strong>冻结的</strong>，只需要训练与你的 Softmax 层有关的参数即可。大多数深度学习框架都允许用户指定是否训练特定层的权重。</p>\n<p>而冻结的层由于不需要改变和训练，可以看作一个固定函数。可以将这个固定函数存入硬盘，以便后续使用，而不必每次再使用训练集进行训练了。</p>\n<p>上述的做法适用于你只有一个较小的数据集。如果你有一个更大的数据集，应该冻结更少的层，然后训练后面的层。越多的数据意味着冻结越少的层，训练更多的层。如果有一个极大的数据集，你可以将开源的网络和它的权重整个当作初始化（代替随机初始化），然后训练整个网络。</p>\n<h2 id=\"数据扩增\"><a href=\"#数据扩增\" class=\"headerlink\" title=\"数据扩增\"></a>数据扩增</h2><p>计算机视觉领域的应用都需要大量的数据。当数据不够时，<strong>数据扩增（Data Augmentation）</strong>就有帮助。常用的数据扩增包括镜像翻转、随机裁剪、色彩转换。</p>\n<p>其中，色彩转换是对图片的 RGB 通道数值进行随意增加或者减少，改变图片色调。另外，<strong>PCA 颜色增强</strong>指更有针对性地对图片的 RGB 通道进行主成分分析（Principles Components Analysis，PCA），对主要的通道颜色进行增加或减少，可以采用高斯扰动做法来增加有效的样本数量。具体的 PCA 颜色增强做法可以查阅 AlexNet 的相关论文或者开源代码。</p>\n<p>在构建大型神经网络的时候，数据扩增和模型训练可以由两个或多个不同的线程并行来实现。</p>\n<h2 id=\"计算机视觉现状\"><a href=\"#计算机视觉现状\" class=\"headerlink\" title=\"计算机视觉现状\"></a>计算机视觉现状</h2><p>通常，学习算法有两种知识来源：</p>\n<ul>\n<li>被标记的数据</li>\n<li>手工工程</li>\n</ul>\n<p><strong>手工工程（Hand-engineering，又称 hacks）</strong> 指精心设计的特性、网络体系结构或是系统的其他组件。手工工程是一项非常重要也比较困难的工作。在数据量不多的情况下，手工工程是获得良好表现的最佳方式。正因为数据量不能满足需要，历史上计算机视觉领域更多地依赖于手工工程。近几年数据量急剧增加，因此手工工程量大幅减少。</p>\n<p>另外，在模型研究或者竞赛方面，有一些方法能够有助于提升神经网络模型的性能：</p>\n<ul>\n<li>集成（Ensembling）：独立地训练几个神经网络，并平均输出它们的输出</li>\n<li>Multi-crop at test time：将数据扩增应用到测试集，对结果进行平均</li>\n</ul>\n<p>但是由于这些方法计算和内存成本较大，一般不适用于构建实际的生产项目。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"经典卷积网络\"><a href=\"#经典卷积网络\" class=\"headerlink\" title=\"经典卷积网络\"></a>经典卷积网络</h2><h3 id=\"LeNet-5\"><a href=\"#LeNet-5\" class=\"headerlink\" title=\"LeNet-5\"></a>LeNet-5</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/LeNet-5.png\" alt=\"LeNet-5\"></p>\n<p>特点：</p>\n<ul>\n<li>LeNet-5 针对灰度图像而训练，因此输入图片的通道数为 1。</li>\n<li>该模型总共包含了约 6 万个参数，远少于标准神经网络所需。</li>\n<li>典型的 LeNet-5 结构包含卷积层（CONV layer），池化层（POOL layer）和全连接层（FC layer），排列顺序一般为 CONV layer-&gt;POOL layer-&gt;CONV layer-&gt;POOL layer-&gt;FC layer-&gt;FC layer-&gt;OUTPUT layer。一个或多个卷积层后面跟着一个池化层的模式至今仍十分常用。</li>\n<li>当 LeNet-5模型被提出时，其池化层使用的是平均池化，而且各层激活函数一般选用 Sigmoid 和 tanh。现在，我们可以根据需要，做出改进，使用最大池化并选用 ReLU 作为激活函数。</li>\n</ul>\n<p>相关论文：<a href=\"http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791&amp;tag=1\" target=\"_blank\" rel=\"noopener\">LeCun et.al., 1998. Gradient-based learning applied to document recognition</a>。</p>\n<h3 id=\"AlexNet\"><a href=\"#AlexNet\" class=\"headerlink\" title=\"AlexNet\"></a>AlexNet</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/AlexNet.png\" alt=\"AlexNet\"></p>\n<p>特点：</p>\n<ul>\n<li>AlexNet 模型与 LeNet-5 模型类似，但是更复杂，包含约 6000 万个参数。另外，AlexNet 模型使用了 ReLU 函数。</li>\n<li>当用于训练图像和数据集时，AlexNet 能够处理非常相似的基本构造模块，这些模块往往包含大量的隐藏单元或数据。</li>\n</ul>\n<p>相关论文：<a href=\"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" target=\"_blank\" rel=\"noopener\">Krizhevsky et al.,2012. ImageNet classification with deep convolutional neural networks</a>。这是一篇易于理解并且影响巨大的论文，计算机视觉群体自此开始重视深度学习。</p>\n<h3 id=\"VGG\"><a href=\"#VGG\" class=\"headerlink\" title=\"VGG\"></a>VGG</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/VGG.png\" alt=\"VGG\"></p>\n<p>特点：</p>\n<ul>\n<li>VGG 又称 VGG-16 网络，“16”指网络中包含 16 个卷积层和全连接层。</li>\n<li>超参数较少，只需要专注于构建卷积层。</li>\n<li>结构不复杂且规整，在每一组卷积层进行滤波器翻倍操作。</li>\n<li>VGG 需要训练的特征数量巨大，包含多达约 1.38 亿个参数。</li>\n</ul>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1409.1556.pdf\" target=\"_blank\" rel=\"noopener\">Simonvan &amp; Zisserman 2015. Very deep convolutional networks for large-scale image recognition</a>。</p>\n<h2 id=\"残差网络\"><a href=\"#残差网络\" class=\"headerlink\" title=\"残差网络\"></a>残差网络</h2><p>因为存在梯度消失和梯度爆炸问题，网络越深，就越难以训练成功。<strong>残差网络（Residual Networks，简称为 ResNets）</strong> 可以有效解决这个问题。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-block.jpg\" alt=\"Residual-block\"></p>\n<p>上图的结构被称为 <strong>残差块（Residual block</strong>。 通过 <strong>捷径（Short cut，或者称跳远连接，Skip connections）</strong> 可以将 $a^{[l]}$ 添加到第二个 ReLU 过程中，直接建立 $a^{[l]}$ 与 $a^{[l+2]}$ 之间的隔层联系。表达式如下：</p>\n<p>$$z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$$</p>\n<p>$$a^{[l+1]} = g(z^{[l+1]})$$</p>\n<p>$$z^{[l+2]} = W^{[l+2]}a^{[l+1]} + b^{[l+2]}$$</p>\n<p>$$a^{[l+2]} = g(z^{[l+2]} + a^{[l]})$$</p>\n<p>构建一个残差网络就是将许多残差块堆积在一起，形成一个深度网络。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-Network.jpg\" alt=\"Residual-Network\"></p>\n<p>为了便于区分，在 ResNets 的论文<a href=\"https://arxiv.org/pdf/1512.03385.pdf\" target=\"_blank\" rel=\"noopener\">He et al., 2015. Deep residual networks for image recognition</a>中，非残差网络被称为 <strong>普通网络（Plain Network）</strong>。 将它变为残差网络的方法是加上所有的跳远连接。</p>\n<p>在理论上，随着网络深度的增加，性能应该越来越好。但实际上，对于一个普通网络，随着神经网络层数增加，训练错误会先减少，然后开始增多。但残差网络的训练效果显示，即使网络再深，其在训练集上的表现也会越来越好。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Training-Error.jpg\" alt=\"ResNet-Training-Error\"></p>\n<p>残差网络有助于解决梯度消失和梯度爆炸问题，使得在训练更深的网络的同时，又能保证良好的性能。</p>\n<h3 id=\"残差网络有效的原因\"><a href=\"#残差网络有效的原因\" class=\"headerlink\" title=\"残差网络有效的原因\"></a>残差网络有效的原因</h3><p>假设有一个大型神经网络，其输入为 $X$，输出为 $a^{[l]}$。给这个神经网络额外增加两层，输出为 $a^{[l+2]}$。将这两层看作一个具有跳远连接的残差块。为了方便说明，假设整个网络中都选用 ReLU 作为激活函数，因此输出的所有激活值都大于等于 0。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Why-do-residual-networks-work.jpg\" alt=\"Why-do-residual-networks-work\"></p>\n<p>则有：</p>\n<p>$$<br>\\begin{equation}<br>\\begin{split}<br> a^{[l+2]} &amp;= g(z^{[l+2]}+a^{[l]})<br>     \\\\ &amp;= g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})<br>\\end{split}<br>\\end{equation}<br>$$</p>\n<p>当发生梯度消失时，$W^{[l+2]}\\approx0$，$b^{[l+2]}\\approx0$，则有：</p>\n<p>$$a^{[l+2]} = g(a^{[l]}) = ReLU(a^{[l]}) = a^{[l]}$$</p>\n<p>因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。</p>\n<p>注意，如果 $a^{[l]}$ 与 $a^{[l+2]}$ 的维度不同，需要引入矩阵 $W_s$ 与 $a^{[l]}$ 相乘，使得二者的维度相匹配。参数矩阵 $W_s$ 既可以通过模型训练得到，也可以作为固定值，仅使 $a^{[l]}$ 截断或者补零。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Paper.png\" alt=\"ResNet-Paper\"></p>\n<p>上图是论文提供的 CNN 中 ResNet 的一个典型结构。卷积层通常使用 Same 卷积以保持维度相同，而不同类型层之间的连接（例如卷积层和池化层），如果维度不同，则需要引入矩阵 $W_s$。</p>\n<h2 id=\"1x1-卷积\"><a href=\"#1x1-卷积\" class=\"headerlink\" title=\"1x1 卷积\"></a>1x1 卷积</h2><p>1x1 卷积（1x1 convolution，或称为 Network in Network）指滤波器的尺寸为 1。当通道数为 1 时，1x1 卷积意味着卷积操作等同于乘积操作。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-1.png\" alt=\"1x1-Conv-1\"></p>\n<p>而当通道数更多时，1x1 卷积的作用实际上类似全连接层的神经网络结构，从而降低（或升高，取决于滤波器组数）数据的维度。</p>\n<p>池化能压缩数据的高度（$n_H$）及宽度（$n_W$），而 1×1 卷积能压缩数据的通道数（$n_C$）。在如下图所示的例子中，用 32 个大小为 1×1×192 的滤波器进行卷积，就能使原先数据包含的 192 个通道压缩为 32 个。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-2.png\" alt=\"1x1-Conv-2\"></p>\n<p>虽然论文<a href=\"https://arxiv.org/pdf/1312.4400.pdf\" target=\"_blank\" rel=\"noopener\">Lin et al., 2013. Network in network</a>中关于架构的详细内容并没有得到广泛应用，但是 1x1 卷积的理念十分有影响力，许多神经网络架构（包括 Inception 网络）都受到它的影响。</p>\n<h2 id=\"Inception-网络\"><a href=\"#Inception-网络\" class=\"headerlink\" title=\"Inception 网络\"></a>Inception 网络</h2><p>在之前的卷积网络中，我们只能选择单一尺寸和类型的滤波器。而 <strong>Inception 网络的作用</strong>即是代替人工来确定卷积层中的滤波器尺寸与类型，或者确定是否需要创建卷积层或池化层。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Motivation-for-inception-network.jpg\" alt=\"Motivation-for-inception-network\"></p>\n<p>如图，Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1409.4842.pdf\" target=\"_blank\" rel=\"noopener\">Szegedy et al., 2014, Going Deeper with Convolutions</a></p>\n<h3 id=\"计算成本问题\"><a href=\"#计算成本问题\" class=\"headerlink\" title=\"计算成本问题\"></a>计算成本问题</h3><p>在提升性能的同时，Inception 网络有着较大的计算成本。下图是一个例子：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/The-problem-of-computational-cost.png\" alt=\"The-problem-of-computational-cost\"></p>\n<p>图中有 32 个滤波器，每个滤波器的大小为 5x5x192。输出大小为 28x28x32，所以需要计算 28x28x32 个数字，对于每个数，都要执行 5x5x192 次乘法运算。加法运算次数与乘法运算次数近似相等。因此，可以看作这一层的计算量为 28x28x32x5x5x192 = 1.2亿。</p>\n<p>为了解决计算量大的问题，可以引入 1x1 卷积来减少其计算量。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Using-1x1-convolution.png\" alt=\"Using-1x1-convolution\"></p>\n<p>对于同一个例子，我们使用 1x1 卷积把输入数据从 192 个通道减少到 16 个通道，然后对这个较小层运行 5x5 卷积，得到最终输出。这个 1x1 的卷积层通常被称作<strong>瓶颈层（Bottleneck layer）</strong>。</p>\n<p>改进后的计算量为 28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。</p>\n<p>只要合理构建瓶颈层，就可以既显著缩小计算规模，又不会降低网络性能。</p>\n<h3 id=\"完整的-Inception-网络\"><a href=\"#完整的-Inception-网络\" class=\"headerlink\" title=\"完整的 Inception 网络\"></a>完整的 Inception 网络</h3><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-module.jpg\" alt=\"Inception-module\"></p>\n<p>上图是引入 1x1 卷积后的 Inception 模块。值得注意的是，为了将所有的输出组合起来，红色的池化层使用 Same 类型的填充（padding）来池化使得输出的宽高不变，通道数也不变。</p>\n<p>多个 Inception 模块组成一个完整的 Inception 网络（被称为 GoogLeNet，以向 LeNet 致敬），如下图所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-network.jpg\" alt=\"Inception-network\"></p>\n<p>注意黑色椭圆圈出的隐藏层，这些分支都是 Softmax 的输出层，可以用来参与特征的计算及结果预测，起到调整并防止发生过拟合的效果。</p>\n<p>经过研究者们的不断发展，Inception 模型的 V2、V3、V4 以及引入残差网络的版本被提出，这些变体都基于 Inception V1 版本的基础思想上。顺便一提，Inception 模型的名字来自电影《盗梦空间》。</p>\n<h2 id=\"使用开源的实现方案\"><a href=\"#使用开源的实现方案\" class=\"headerlink\" title=\"使用开源的实现方案\"></a>使用开源的实现方案</h2><p>很多神经网络复杂细致，并充斥着参数调节的细节问题，因而很难仅通过阅读论文来重现他人的成果。想要搭建一个同样的神经网络，查看开源的实现方案会快很多。</p>\n<h2 id=\"迁移学习\"><a href=\"#迁移学习\" class=\"headerlink\" title=\"迁移学习\"></a>迁移学习</h2><p>在“搭建机器学习项目”课程中，<a href=\"http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Structuring_Machine_Learning_Projects/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89?id=%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0\" target=\"_blank\" rel=\"noopener\">迁移学习</a>已经被提到过。计算机视觉是一个经常用到迁移学习的领域。在搭建计算机视觉的应用时，相比于从头训练权重，下载别人已经训练好的网络结构的权重，用其做<strong>预训练</strong>，然后转换到自己感兴趣的任务上，有助于加速开发。</p>\n<p>对于已训练好的卷积神经网络，可以将所有层都看作是<strong>冻结的</strong>，只需要训练与你的 Softmax 层有关的参数即可。大多数深度学习框架都允许用户指定是否训练特定层的权重。</p>\n<p>而冻结的层由于不需要改变和训练，可以看作一个固定函数。可以将这个固定函数存入硬盘，以便后续使用，而不必每次再使用训练集进行训练了。</p>\n<p>上述的做法适用于你只有一个较小的数据集。如果你有一个更大的数据集，应该冻结更少的层，然后训练后面的层。越多的数据意味着冻结越少的层，训练更多的层。如果有一个极大的数据集，你可以将开源的网络和它的权重整个当作初始化（代替随机初始化），然后训练整个网络。</p>\n<h2 id=\"数据扩增\"><a href=\"#数据扩增\" class=\"headerlink\" title=\"数据扩增\"></a>数据扩增</h2><p>计算机视觉领域的应用都需要大量的数据。当数据不够时，<strong>数据扩增（Data Augmentation）</strong>就有帮助。常用的数据扩增包括镜像翻转、随机裁剪、色彩转换。</p>\n<p>其中，色彩转换是对图片的 RGB 通道数值进行随意增加或者减少，改变图片色调。另外，<strong>PCA 颜色增强</strong>指更有针对性地对图片的 RGB 通道进行主成分分析（Principles Components Analysis，PCA），对主要的通道颜色进行增加或减少，可以采用高斯扰动做法来增加有效的样本数量。具体的 PCA 颜色增强做法可以查阅 AlexNet 的相关论文或者开源代码。</p>\n<p>在构建大型神经网络的时候，数据扩增和模型训练可以由两个或多个不同的线程并行来实现。</p>\n<h2 id=\"计算机视觉现状\"><a href=\"#计算机视觉现状\" class=\"headerlink\" title=\"计算机视觉现状\"></a>计算机视觉现状</h2><p>通常，学习算法有两种知识来源：</p>\n<ul>\n<li>被标记的数据</li>\n<li>手工工程</li>\n</ul>\n<p><strong>手工工程（Hand-engineering，又称 hacks）</strong> 指精心设计的特性、网络体系结构或是系统的其他组件。手工工程是一项非常重要也比较困难的工作。在数据量不多的情况下，手工工程是获得良好表现的最佳方式。正因为数据量不能满足需要，历史上计算机视觉领域更多地依赖于手工工程。近几年数据量急剧增加，因此手工工程量大幅减少。</p>\n<p>另外，在模型研究或者竞赛方面，有一些方法能够有助于提升神经网络模型的性能：</p>\n<ul>\n<li>集成（Ensembling）：独立地训练几个神经网络，并平均输出它们的输出</li>\n<li>Multi-crop at test time：将数据扩增应用到测试集，对结果进行平均</li>\n</ul>\n<p>但是由于这些方法计算和内存成本较大，一般不适用于构建实际的生产项目。</p>\n"},{"title":"模型估计：偏差 / 方差","date":"2018-07-20T07:56:17.000Z","_content":"## 模型估计：偏差 / 方差\n\n**“偏差-方差分解”（bias-variance decomposition）**是解释学习算法泛化性能的一种重要工具。\n\n泛化误差可分解为偏差、方差与噪声之和：\n\n* **偏差**：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了**学习算法本身的拟合能力**；\n* **方差**：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了**数据扰动所造成的影响**；\n* **噪声**：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了**学习问题本身的难度**。\n\n偏差-方差分解说明，**泛化性能**是由**学习算法的能力**、**数据的充分性**以及**学习任务本身的难度**所共同决定的。给定学习任务，为了取得好的泛化性能，则需要使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。\n\n<!-- 以上摘自周志华《机器学习》 -->\n\n在**欠拟合（underfitting）**的情况下，出现**高偏差（high bias）**的情况，即不能很好地对数据进行分类。\n\n当模型设置的太复杂时，训练集中的一些噪声没有被排除，使得模型出现**过拟合（overfitting）**的情况，在验证集上出现**高方差（high variance）**的现象。\n\n当训练出一个模型以后，如果：\n\n* 训练集的错误率较小，而验证集的错误率却较大，说明模型存在较大方差，可能出现了过拟合；\n* 训练集和开发集的错误率都较大，且两者相当，说明模型存在较大偏差，可能出现了欠拟合；\n* 训练集错误率较大，且开发集的错误率远较训练集大，说明方差和偏差都较大，模型很差；\n* 训练集和开发集的错误率都较小，且两者的相差也较小，说明方差和偏差都较小，这个模型效果比较好。\n\n偏差和方差的权衡问题对于模型来说十分重要。\n\n最优误差通常也称为“贝叶斯误差”。\n\n### 应对方法\n\n存在高偏差：\n\n* 扩大网络规模，如添加隐藏层或隐藏单元数目；\n* 寻找合适的网络架构，使用更大的 NN 结构；\n* 花费更长时间训练。\n\n存在高方差：\n\n* 获取更多的数据；\n* 正则化（regularization）；\n* 寻找更合适的网络结构。\n\n不断尝试，直到找到低偏差、低方差的框架。\n\n在深度学习的早期阶段，没有太多方法能做到只减少偏差或方差而不影响到另外一方。而在大数据时代，深度学习对监督式学习大有裨益，使得我们不用像以前一样太过关注如何平衡偏差和方差的权衡问题，通过以上方法可以在不增加某一方的前提下减少另一方的值。\n","source":"_posts/模型估计.md","raw":"---\ntitle: 模型估计：偏差 / 方差\ndate: 2018-07-20 15:56:17\ntags: 模型估计\ncategories: 深度学习\n---\n## 模型估计：偏差 / 方差\n\n**“偏差-方差分解”（bias-variance decomposition）**是解释学习算法泛化性能的一种重要工具。\n\n泛化误差可分解为偏差、方差与噪声之和：\n\n* **偏差**：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了**学习算法本身的拟合能力**；\n* **方差**：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了**数据扰动所造成的影响**；\n* **噪声**：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了**学习问题本身的难度**。\n\n偏差-方差分解说明，**泛化性能**是由**学习算法的能力**、**数据的充分性**以及**学习任务本身的难度**所共同决定的。给定学习任务，为了取得好的泛化性能，则需要使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。\n\n<!-- 以上摘自周志华《机器学习》 -->\n\n在**欠拟合（underfitting）**的情况下，出现**高偏差（high bias）**的情况，即不能很好地对数据进行分类。\n\n当模型设置的太复杂时，训练集中的一些噪声没有被排除，使得模型出现**过拟合（overfitting）**的情况，在验证集上出现**高方差（high variance）**的现象。\n\n当训练出一个模型以后，如果：\n\n* 训练集的错误率较小，而验证集的错误率却较大，说明模型存在较大方差，可能出现了过拟合；\n* 训练集和开发集的错误率都较大，且两者相当，说明模型存在较大偏差，可能出现了欠拟合；\n* 训练集错误率较大，且开发集的错误率远较训练集大，说明方差和偏差都较大，模型很差；\n* 训练集和开发集的错误率都较小，且两者的相差也较小，说明方差和偏差都较小，这个模型效果比较好。\n\n偏差和方差的权衡问题对于模型来说十分重要。\n\n最优误差通常也称为“贝叶斯误差”。\n\n### 应对方法\n\n存在高偏差：\n\n* 扩大网络规模，如添加隐藏层或隐藏单元数目；\n* 寻找合适的网络架构，使用更大的 NN 结构；\n* 花费更长时间训练。\n\n存在高方差：\n\n* 获取更多的数据；\n* 正则化（regularization）；\n* 寻找更合适的网络结构。\n\n不断尝试，直到找到低偏差、低方差的框架。\n\n在深度学习的早期阶段，没有太多方法能做到只减少偏差或方差而不影响到另外一方。而在大数据时代，深度学习对监督式学习大有裨益，使得我们不用像以前一样太过关注如何平衡偏差和方差的权衡问题，通过以上方法可以在不增加某一方的前提下减少另一方的值。\n","slug":"模型估计","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds5x003lpcvo95t42d21","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"模型估计：偏差-方差\"><a href=\"#模型估计：偏差-方差\" class=\"headerlink\" title=\"模型估计：偏差 / 方差\"></a>模型估计：偏差 / 方差</h2><p><strong>“偏差-方差分解”（bias-variance decomposition）</strong>是解释学习算法泛化性能的一种重要工具。</p>\n<p>泛化误差可分解为偏差、方差与噪声之和：</p>\n<ul>\n<li><strong>偏差</strong>：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了<strong>学习算法本身的拟合能力</strong>；</li>\n<li><strong>方差</strong>：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了<strong>数据扰动所造成的影响</strong>；</li>\n<li><strong>噪声</strong>：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了<strong>学习问题本身的难度</strong>。</li>\n</ul>\n<p>偏差-方差分解说明，<strong>泛化性能</strong>是由<strong>学习算法的能力</strong>、<strong>数据的充分性</strong>以及<strong>学习任务本身的难度</strong>所共同决定的。给定学习任务，为了取得好的泛化性能，则需要使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。</p>\n<!-- 以上摘自周志华《机器学习》 -->\n<p>在<strong>欠拟合（underfitting）</strong>的情况下，出现<strong>高偏差（high bias）</strong>的情况，即不能很好地对数据进行分类。</p>\n<p>当模型设置的太复杂时，训练集中的一些噪声没有被排除，使得模型出现<strong>过拟合（overfitting）</strong>的情况，在验证集上出现<strong>高方差（high variance）</strong>的现象。</p>\n<p>当训练出一个模型以后，如果：</p>\n<ul>\n<li>训练集的错误率较小，而验证集的错误率却较大，说明模型存在较大方差，可能出现了过拟合；</li>\n<li>训练集和开发集的错误率都较大，且两者相当，说明模型存在较大偏差，可能出现了欠拟合；</li>\n<li>训练集错误率较大，且开发集的错误率远较训练集大，说明方差和偏差都较大，模型很差；</li>\n<li>训练集和开发集的错误率都较小，且两者的相差也较小，说明方差和偏差都较小，这个模型效果比较好。</li>\n</ul>\n<p>偏差和方差的权衡问题对于模型来说十分重要。</p>\n<p>最优误差通常也称为“贝叶斯误差”。</p>\n<h3 id=\"应对方法\"><a href=\"#应对方法\" class=\"headerlink\" title=\"应对方法\"></a>应对方法</h3><p>存在高偏差：</p>\n<ul>\n<li>扩大网络规模，如添加隐藏层或隐藏单元数目；</li>\n<li>寻找合适的网络架构，使用更大的 NN 结构；</li>\n<li>花费更长时间训练。</li>\n</ul>\n<p>存在高方差：</p>\n<ul>\n<li>获取更多的数据；</li>\n<li>正则化（regularization）；</li>\n<li>寻找更合适的网络结构。</li>\n</ul>\n<p>不断尝试，直到找到低偏差、低方差的框架。</p>\n<p>在深度学习的早期阶段，没有太多方法能做到只减少偏差或方差而不影响到另外一方。而在大数据时代，深度学习对监督式学习大有裨益，使得我们不用像以前一样太过关注如何平衡偏差和方差的权衡问题，通过以上方法可以在不增加某一方的前提下减少另一方的值。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"模型估计：偏差-方差\"><a href=\"#模型估计：偏差-方差\" class=\"headerlink\" title=\"模型估计：偏差 / 方差\"></a>模型估计：偏差 / 方差</h2><p><strong>“偏差-方差分解”（bias-variance decomposition）</strong>是解释学习算法泛化性能的一种重要工具。</p>\n<p>泛化误差可分解为偏差、方差与噪声之和：</p>\n<ul>\n<li><strong>偏差</strong>：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了<strong>学习算法本身的拟合能力</strong>；</li>\n<li><strong>方差</strong>：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了<strong>数据扰动所造成的影响</strong>；</li>\n<li><strong>噪声</strong>：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了<strong>学习问题本身的难度</strong>。</li>\n</ul>\n<p>偏差-方差分解说明，<strong>泛化性能</strong>是由<strong>学习算法的能力</strong>、<strong>数据的充分性</strong>以及<strong>学习任务本身的难度</strong>所共同决定的。给定学习任务，为了取得好的泛化性能，则需要使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。</p>\n<!-- 以上摘自周志华《机器学习》 -->\n<p>在<strong>欠拟合（underfitting）</strong>的情况下，出现<strong>高偏差（high bias）</strong>的情况，即不能很好地对数据进行分类。</p>\n<p>当模型设置的太复杂时，训练集中的一些噪声没有被排除，使得模型出现<strong>过拟合（overfitting）</strong>的情况，在验证集上出现<strong>高方差（high variance）</strong>的现象。</p>\n<p>当训练出一个模型以后，如果：</p>\n<ul>\n<li>训练集的错误率较小，而验证集的错误率却较大，说明模型存在较大方差，可能出现了过拟合；</li>\n<li>训练集和开发集的错误率都较大，且两者相当，说明模型存在较大偏差，可能出现了欠拟合；</li>\n<li>训练集错误率较大，且开发集的错误率远较训练集大，说明方差和偏差都较大，模型很差；</li>\n<li>训练集和开发集的错误率都较小，且两者的相差也较小，说明方差和偏差都较小，这个模型效果比较好。</li>\n</ul>\n<p>偏差和方差的权衡问题对于模型来说十分重要。</p>\n<p>最优误差通常也称为“贝叶斯误差”。</p>\n<h3 id=\"应对方法\"><a href=\"#应对方法\" class=\"headerlink\" title=\"应对方法\"></a>应对方法</h3><p>存在高偏差：</p>\n<ul>\n<li>扩大网络规模，如添加隐藏层或隐藏单元数目；</li>\n<li>寻找合适的网络架构，使用更大的 NN 结构；</li>\n<li>花费更长时间训练。</li>\n</ul>\n<p>存在高方差：</p>\n<ul>\n<li>获取更多的数据；</li>\n<li>正则化（regularization）；</li>\n<li>寻找更合适的网络结构。</li>\n</ul>\n<p>不断尝试，直到找到低偏差、低方差的框架。</p>\n<p>在深度学习的早期阶段，没有太多方法能做到只减少偏差或方差而不影响到另外一方。而在大数据时代，深度学习对监督式学习大有裨益，使得我们不用像以前一样太过关注如何平衡偏差和方差的权衡问题，通过以上方法可以在不增加某一方的前提下减少另一方的值。</p>\n"},{"title":"正则化（regularization）","date":"2018-07-20T07:58:06.000Z","mathjax":true,"_content":"## 正则化（regularization）\n\n**正则化**是在成本函数中加入一个正则化项，惩罚模型的复杂度。正则化可以用于解决高方差的问题。\n\n### Logistic 回归中的正则化\n\n对于 Logistic 回归，加入 L2 正则化（也称“L2 范数”）的成本函数：\n\n$$J(w,b) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}{||w||}^2\\_2$$\n\n* L2 正则化：\n\n$$\\frac{\\lambda}{2m}{||w||}^2\\_2 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n\\_x}w^2\\_j = \\frac{\\lambda}{2m}w^Tw$$\n\n* L1 正则化：\n\n$$\\frac{\\lambda}{2m}{||w||}\\_1 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n\\_x}{|w\\_j|}$$\n\n其中，λ 为**正则化因子**，是**超参数**。\n\n由于 L1 正则化最后得到 w 向量中将存在大量的 0，使模型变得稀疏化，因此 L2 正则化更加常用。\n\n**注意**，`lambda`在 Python 中属于保留字，所以在编程的时候，用`lambd`代替这里的正则化因子。\n\n### 神经网络中的正则化\n\n对于神经网络，加入正则化的成本函数：\n\n$$J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum_{l=1}^L{||w^{[l]}||}^2_F$$\n\n因为 w 的大小为 ($n^{[l−1]}$, $n^{[l]}$)，因此\n\n$${||w^{[l]}||}^2\\_F = \\sum^{n^{[l-1]}}\\_{i=1}\\sum^{n^{[l]}}\\_{j=1}(w^{[l]}\\_{ij})^2$$\n\n```python\nL2_regularization_cost = 1./m * lambd/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)))\ncost = cross_entropy_cost + L2_regularization_cost\n```\n\n该矩阵范数被称为**弗罗贝尼乌斯范数（Frobenius Norm）**，所以神经网络中的正则化项被称为弗罗贝尼乌斯范数矩阵。\n\n#### 权重衰减（Weight decay）\n\n**在加入正则化项后，梯度变为**（反向传播要按这个计算）：\n\n$$dW^{[l]}= \\frac{\\partial L}{\\partial w^{[l]}} +\\frac{\\lambda}{m}W^{[l]}$$\n\n```python\ndW = 1./m * np.dot(dZ, A_prev.T) + lambd / m * W\n```\n\n代入梯度更新公式：\n\n$$W^{[l]} := W^{[l]}-\\alpha dW^{[l]}$$\n\n可得：\n\n$$W^{[l]} := W^{[l]} - \\alpha [\\frac{\\partial L}{\\partial w^{[l]}} + \\frac{\\lambda}{m}W^{[l]}]$$\n\n$$= W^{[l]} - \\alpha \\frac{\\lambda}{m}W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n\n$$= (1 - \\frac{\\alpha\\lambda}{m})W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n\n其中，因为 $1 - \\frac{\\alpha\\lambda}{m}<1$，会给原来的 $W^{[l]}$一个衰减的参数，因此 L2 正则化项也被称为**权重衰减（Weight Decay）**。\n\n### 正则化可以减小过拟合的原因\n\n#### 直观解释\n\n正则化因子设置的足够大的情况下，为了使成本函数最小化，权重矩阵 W 就会被设置为接近于 0 的值，**直观上**相当于消除了很多神经元的影响，那么大的神经网络就会变成一个较小的网络。当然，实际上隐藏层的神经元依然存在，但是其影响减弱了，便不会导致过拟合。\n\n#### 数学解释\n\n假设神经元中使用的激活函数为`g(z) = tanh(z)`（sigmoid 同理）。\n\n![regularization_prevent_overfitting](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/regularization_prevent_overfitting.png)\n\n在加入正则化项后，当 λ  增大，导致 $W^{[l]}$减小，$Z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$便会减小。由上图可知，在 z 较小（接近于 0）的区域里，`tanh(z)`函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，因此不会发生过拟合。\n\n#### 其他解释\n\n在权值 $w^{[L]}$变小之下，输入样本 X 随机的变化不会对神经网络模造成过大的影响，神经网络受局部噪音的影响的可能性变小。这就是正则化能够降低模型方差的原因。\n","source":"_posts/正则化.md","raw":"---\ntitle: 正则化（regularization）\ndate: 2018-07-20 15:58:06\ntags: 正则化\ncategories: 深度学习\nmathjax: true\n---\n## 正则化（regularization）\n\n**正则化**是在成本函数中加入一个正则化项，惩罚模型的复杂度。正则化可以用于解决高方差的问题。\n\n### Logistic 回归中的正则化\n\n对于 Logistic 回归，加入 L2 正则化（也称“L2 范数”）的成本函数：\n\n$$J(w,b) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}{||w||}^2\\_2$$\n\n* L2 正则化：\n\n$$\\frac{\\lambda}{2m}{||w||}^2\\_2 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n\\_x}w^2\\_j = \\frac{\\lambda}{2m}w^Tw$$\n\n* L1 正则化：\n\n$$\\frac{\\lambda}{2m}{||w||}\\_1 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n\\_x}{|w\\_j|}$$\n\n其中，λ 为**正则化因子**，是**超参数**。\n\n由于 L1 正则化最后得到 w 向量中将存在大量的 0，使模型变得稀疏化，因此 L2 正则化更加常用。\n\n**注意**，`lambda`在 Python 中属于保留字，所以在编程的时候，用`lambd`代替这里的正则化因子。\n\n### 神经网络中的正则化\n\n对于神经网络，加入正则化的成本函数：\n\n$$J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum_{l=1}^L{||w^{[l]}||}^2_F$$\n\n因为 w 的大小为 ($n^{[l−1]}$, $n^{[l]}$)，因此\n\n$${||w^{[l]}||}^2\\_F = \\sum^{n^{[l-1]}}\\_{i=1}\\sum^{n^{[l]}}\\_{j=1}(w^{[l]}\\_{ij})^2$$\n\n```python\nL2_regularization_cost = 1./m * lambd/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)))\ncost = cross_entropy_cost + L2_regularization_cost\n```\n\n该矩阵范数被称为**弗罗贝尼乌斯范数（Frobenius Norm）**，所以神经网络中的正则化项被称为弗罗贝尼乌斯范数矩阵。\n\n#### 权重衰减（Weight decay）\n\n**在加入正则化项后，梯度变为**（反向传播要按这个计算）：\n\n$$dW^{[l]}= \\frac{\\partial L}{\\partial w^{[l]}} +\\frac{\\lambda}{m}W^{[l]}$$\n\n```python\ndW = 1./m * np.dot(dZ, A_prev.T) + lambd / m * W\n```\n\n代入梯度更新公式：\n\n$$W^{[l]} := W^{[l]}-\\alpha dW^{[l]}$$\n\n可得：\n\n$$W^{[l]} := W^{[l]} - \\alpha [\\frac{\\partial L}{\\partial w^{[l]}} + \\frac{\\lambda}{m}W^{[l]}]$$\n\n$$= W^{[l]} - \\alpha \\frac{\\lambda}{m}W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n\n$$= (1 - \\frac{\\alpha\\lambda}{m})W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n\n其中，因为 $1 - \\frac{\\alpha\\lambda}{m}<1$，会给原来的 $W^{[l]}$一个衰减的参数，因此 L2 正则化项也被称为**权重衰减（Weight Decay）**。\n\n### 正则化可以减小过拟合的原因\n\n#### 直观解释\n\n正则化因子设置的足够大的情况下，为了使成本函数最小化，权重矩阵 W 就会被设置为接近于 0 的值，**直观上**相当于消除了很多神经元的影响，那么大的神经网络就会变成一个较小的网络。当然，实际上隐藏层的神经元依然存在，但是其影响减弱了，便不会导致过拟合。\n\n#### 数学解释\n\n假设神经元中使用的激活函数为`g(z) = tanh(z)`（sigmoid 同理）。\n\n![regularization_prevent_overfitting](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/regularization_prevent_overfitting.png)\n\n在加入正则化项后，当 λ  增大，导致 $W^{[l]}$减小，$Z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$便会减小。由上图可知，在 z 较小（接近于 0）的区域里，`tanh(z)`函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，因此不会发生过拟合。\n\n#### 其他解释\n\n在权值 $w^{[L]}$变小之下，输入样本 X 随机的变化不会对神经网络模造成过大的影响，神经网络受局部噪音的影响的可能性变小。这就是正则化能够降低模型方差的原因。\n","slug":"正则化","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds5x003ppcvorwljm923","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"正则化（regularization）\"><a href=\"#正则化（regularization）\" class=\"headerlink\" title=\"正则化（regularization）\"></a>正则化（regularization）</h2><p><strong>正则化</strong>是在成本函数中加入一个正则化项，惩罚模型的复杂度。正则化可以用于解决高方差的问题。</p>\n<h3 id=\"Logistic-回归中的正则化\"><a href=\"#Logistic-回归中的正则化\" class=\"headerlink\" title=\"Logistic 回归中的正则化\"></a>Logistic 回归中的正则化</h3><p>对于 Logistic 回归，加入 L2 正则化（也称“L2 范数”）的成本函数：</p>\n<p>$$J(w,b) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}{||w||}^2_2$$</p>\n<ul>\n<li>L2 正则化：</li>\n</ul>\n<p>$$\\frac{\\lambda}{2m}{||w||}^2_2 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}w^2_j = \\frac{\\lambda}{2m}w^Tw$$</p>\n<ul>\n<li>L1 正则化：</li>\n</ul>\n<p>$$\\frac{\\lambda}{2m}{||w||}_1 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}{|w_j|}$$</p>\n<p>其中，λ 为<strong>正则化因子</strong>，是<strong>超参数</strong>。</p>\n<p>由于 L1 正则化最后得到 w 向量中将存在大量的 0，使模型变得稀疏化，因此 L2 正则化更加常用。</p>\n<p><strong>注意</strong>，<code>lambda</code>在 Python 中属于保留字，所以在编程的时候，用<code>lambd</code>代替这里的正则化因子。</p>\n<h3 id=\"神经网络中的正则化\"><a href=\"#神经网络中的正则化\" class=\"headerlink\" title=\"神经网络中的正则化\"></a>神经网络中的正则化</h3><p>对于神经网络，加入正则化的成本函数：</p>\n<p>$$J(w^{[1]}, b^{[1]}, …, w^{[L]}, b^{[L]}) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum_{l=1}^L{||w^{[l]}||}^2_F$$</p>\n<p>因为 w 的大小为 ($n^{[l−1]}$, $n^{[l]}$)，因此</p>\n<p>$${||w^{[l]}||}^2_F = \\sum^{n^{[l-1]}}_{i=1}\\sum^{n^{[l]}}_{j=1}(w^{[l]}_{ij})^2$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">L2_regularization_cost = <span class=\"number\">1.</span>/m * lambd/<span class=\"number\">2</span> * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)))</span><br><span class=\"line\">cost = cross_entropy_cost + L2_regularization_cost</span><br></pre></td></tr></table></figure>\n<p>该矩阵范数被称为<strong>弗罗贝尼乌斯范数（Frobenius Norm）</strong>，所以神经网络中的正则化项被称为弗罗贝尼乌斯范数矩阵。</p>\n<h4 id=\"权重衰减（Weight-decay）\"><a href=\"#权重衰减（Weight-decay）\" class=\"headerlink\" title=\"权重衰减（Weight decay）\"></a>权重衰减（Weight decay）</h4><p><strong>在加入正则化项后，梯度变为</strong>（反向传播要按这个计算）：</p>\n<p>$$dW^{[l]}= \\frac{\\partial L}{\\partial w^{[l]}} +\\frac{\\lambda}{m}W^{[l]}$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dW = <span class=\"number\">1.</span>/m * np.dot(dZ, A_prev.T) + lambd / m * W</span><br></pre></td></tr></table></figure>\n<p>代入梯度更新公式：</p>\n<p>$$W^{[l]} := W^{[l]}-\\alpha dW^{[l]}$$</p>\n<p>可得：</p>\n<p>$$W^{[l]} := W^{[l]} - \\alpha [\\frac{\\partial L}{\\partial w^{[l]}} + \\frac{\\lambda}{m}W^{[l]}]$$</p>\n<p>$$= W^{[l]} - \\alpha \\frac{\\lambda}{m}W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$</p>\n<p>$$= (1 - \\frac{\\alpha\\lambda}{m})W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$</p>\n<p>其中，因为 $1 - \\frac{\\alpha\\lambda}{m}&lt;1$，会给原来的 $W^{[l]}$一个衰减的参数，因此 L2 正则化项也被称为<strong>权重衰减（Weight Decay）</strong>。</p>\n<h3 id=\"正则化可以减小过拟合的原因\"><a href=\"#正则化可以减小过拟合的原因\" class=\"headerlink\" title=\"正则化可以减小过拟合的原因\"></a>正则化可以减小过拟合的原因</h3><h4 id=\"直观解释\"><a href=\"#直观解释\" class=\"headerlink\" title=\"直观解释\"></a>直观解释</h4><p>正则化因子设置的足够大的情况下，为了使成本函数最小化，权重矩阵 W 就会被设置为接近于 0 的值，<strong>直观上</strong>相当于消除了很多神经元的影响，那么大的神经网络就会变成一个较小的网络。当然，实际上隐藏层的神经元依然存在，但是其影响减弱了，便不会导致过拟合。</p>\n<h4 id=\"数学解释\"><a href=\"#数学解释\" class=\"headerlink\" title=\"数学解释\"></a>数学解释</h4><p>假设神经元中使用的激活函数为<code>g(z) = tanh(z)</code>（sigmoid 同理）。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/regularization_prevent_overfitting.png\" alt=\"regularization_prevent_overfitting\"></p>\n<p>在加入正则化项后，当 λ  增大，导致 $W^{[l]}$减小，$Z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$便会减小。由上图可知，在 z 较小（接近于 0）的区域里，<code>tanh(z)</code>函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，因此不会发生过拟合。</p>\n<h4 id=\"其他解释\"><a href=\"#其他解释\" class=\"headerlink\" title=\"其他解释\"></a>其他解释</h4><p>在权值 $w^{[L]}$变小之下，输入样本 X 随机的变化不会对神经网络模造成过大的影响，神经网络受局部噪音的影响的可能性变小。这就是正则化能够降低模型方差的原因。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"正则化（regularization）\"><a href=\"#正则化（regularization）\" class=\"headerlink\" title=\"正则化（regularization）\"></a>正则化（regularization）</h2><p><strong>正则化</strong>是在成本函数中加入一个正则化项，惩罚模型的复杂度。正则化可以用于解决高方差的问题。</p>\n<h3 id=\"Logistic-回归中的正则化\"><a href=\"#Logistic-回归中的正则化\" class=\"headerlink\" title=\"Logistic 回归中的正则化\"></a>Logistic 回归中的正则化</h3><p>对于 Logistic 回归，加入 L2 正则化（也称“L2 范数”）的成本函数：</p>\n<p>$$J(w,b) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}{||w||}^2_2$$</p>\n<ul>\n<li>L2 正则化：</li>\n</ul>\n<p>$$\\frac{\\lambda}{2m}{||w||}^2_2 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}w^2_j = \\frac{\\lambda}{2m}w^Tw$$</p>\n<ul>\n<li>L1 正则化：</li>\n</ul>\n<p>$$\\frac{\\lambda}{2m}{||w||}_1 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}{|w_j|}$$</p>\n<p>其中，λ 为<strong>正则化因子</strong>，是<strong>超参数</strong>。</p>\n<p>由于 L1 正则化最后得到 w 向量中将存在大量的 0，使模型变得稀疏化，因此 L2 正则化更加常用。</p>\n<p><strong>注意</strong>，<code>lambda</code>在 Python 中属于保留字，所以在编程的时候，用<code>lambd</code>代替这里的正则化因子。</p>\n<h3 id=\"神经网络中的正则化\"><a href=\"#神经网络中的正则化\" class=\"headerlink\" title=\"神经网络中的正则化\"></a>神经网络中的正则化</h3><p>对于神经网络，加入正则化的成本函数：</p>\n<p>$$J(w^{[1]}, b^{[1]}, …, w^{[L]}, b^{[L]}) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum_{l=1}^L{||w^{[l]}||}^2_F$$</p>\n<p>因为 w 的大小为 ($n^{[l−1]}$, $n^{[l]}$)，因此</p>\n<p>$${||w^{[l]}||}^2_F = \\sum^{n^{[l-1]}}_{i=1}\\sum^{n^{[l]}}_{j=1}(w^{[l]}_{ij})^2$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">L2_regularization_cost = <span class=\"number\">1.</span>/m * lambd/<span class=\"number\">2</span> * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)))</span><br><span class=\"line\">cost = cross_entropy_cost + L2_regularization_cost</span><br></pre></td></tr></table></figure>\n<p>该矩阵范数被称为<strong>弗罗贝尼乌斯范数（Frobenius Norm）</strong>，所以神经网络中的正则化项被称为弗罗贝尼乌斯范数矩阵。</p>\n<h4 id=\"权重衰减（Weight-decay）\"><a href=\"#权重衰减（Weight-decay）\" class=\"headerlink\" title=\"权重衰减（Weight decay）\"></a>权重衰减（Weight decay）</h4><p><strong>在加入正则化项后，梯度变为</strong>（反向传播要按这个计算）：</p>\n<p>$$dW^{[l]}= \\frac{\\partial L}{\\partial w^{[l]}} +\\frac{\\lambda}{m}W^{[l]}$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dW = <span class=\"number\">1.</span>/m * np.dot(dZ, A_prev.T) + lambd / m * W</span><br></pre></td></tr></table></figure>\n<p>代入梯度更新公式：</p>\n<p>$$W^{[l]} := W^{[l]}-\\alpha dW^{[l]}$$</p>\n<p>可得：</p>\n<p>$$W^{[l]} := W^{[l]} - \\alpha [\\frac{\\partial L}{\\partial w^{[l]}} + \\frac{\\lambda}{m}W^{[l]}]$$</p>\n<p>$$= W^{[l]} - \\alpha \\frac{\\lambda}{m}W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$</p>\n<p>$$= (1 - \\frac{\\alpha\\lambda}{m})W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$</p>\n<p>其中，因为 $1 - \\frac{\\alpha\\lambda}{m}&lt;1$，会给原来的 $W^{[l]}$一个衰减的参数，因此 L2 正则化项也被称为<strong>权重衰减（Weight Decay）</strong>。</p>\n<h3 id=\"正则化可以减小过拟合的原因\"><a href=\"#正则化可以减小过拟合的原因\" class=\"headerlink\" title=\"正则化可以减小过拟合的原因\"></a>正则化可以减小过拟合的原因</h3><h4 id=\"直观解释\"><a href=\"#直观解释\" class=\"headerlink\" title=\"直观解释\"></a>直观解释</h4><p>正则化因子设置的足够大的情况下，为了使成本函数最小化，权重矩阵 W 就会被设置为接近于 0 的值，<strong>直观上</strong>相当于消除了很多神经元的影响，那么大的神经网络就会变成一个较小的网络。当然，实际上隐藏层的神经元依然存在，但是其影响减弱了，便不会导致过拟合。</p>\n<h4 id=\"数学解释\"><a href=\"#数学解释\" class=\"headerlink\" title=\"数学解释\"></a>数学解释</h4><p>假设神经元中使用的激活函数为<code>g(z) = tanh(z)</code>（sigmoid 同理）。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/regularization_prevent_overfitting.png\" alt=\"regularization_prevent_overfitting\"></p>\n<p>在加入正则化项后，当 λ  增大，导致 $W^{[l]}$减小，$Z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$便会减小。由上图可知，在 z 较小（接近于 0）的区域里，<code>tanh(z)</code>函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，因此不会发生过拟合。</p>\n<h4 id=\"其他解释\"><a href=\"#其他解释\" class=\"headerlink\" title=\"其他解释\"></a>其他解释</h4><p>在权值 $w^{[L]}$变小之下，输入样本 X 随机的变化不会对神经网络模造成过大的影响，神经网络受局部噪音的影响的可能性变小。这就是正则化能够降低模型方差的原因。</p>\n"},{"title":"特征值与特征向量","date":"2018-09-23T07:34:27.000Z","_content":"\n## 特征向量(eigenvector)与特征值(eigenvalue)\n\n$\\mathbf A$为$n \\times n$矩阵，对非零向量 $\\vec x$, 若存在某个数量 $\\lambda$. 使得 $\\mathbf Ax = \\lambda x$ 则称 $\\vec x$ 为 $\\mathbf A$ 的 **特征向量**. 如果方程有非平凡解，则数量 $\\lambda$ 为 $\\mathbf A$ 的 **特征值**。\n\n$\\lambda$ 是 $\\mathbf A$ 的特征值当且仅当方程(1)有非平凡解，即 $(\\mathbf A - \\lambda \\mathbf I)$ 不可逆。\n$$(\\mathbf A - \\lambda \\mathbf I)\\vec x = \\mathbf 0 \\tag{1}$$\n\n(1)所有解的集合恰好是矩阵 $(\\mathbf A - \\lambda \\mathbf I)$ 的零空间，所以这个集合是 $\\mathbf R^n$ 的子空间，我们将它称为 $\\mathbf A$ 的对应于 $\\lambda$ 的 **特征空间(eigenspace)**。\n\n定理一： 三角矩阵的特征值为其主对角线上的元素。\n\n定理二：若 $\\vec v_1, ... \\vec v_r$ 为 $n \\times n$ 矩阵 $\\mathbf A$ 的对应于不同特征值 $\\lambda_1, ..., \\lambda_r$ 的特征向量，则集合 $\\{\\vec v_1, ... \\vec v_r\\}$ 线性无关。\n\n## 特征向量和差分方程\n\n$$\\vec x_{k+1} = \\mathbf A\\vec x_k \\qquad k=(0,1,2...) \\tag{2}$$\n\n如果 $\\mathbf A$ 为 $n \\times n$ 矩阵，则(2)是 $\\mathbf R^n$ 中序列的一个递归描述。它的一个解是{$\\vec x_k$}的一个显示表示。构造(2)的解最简单的方法是取一个特征向量 $\\vec x_0$ 以及对应的特征值 $\\lambda$, 令\n$$\\vec x_k = \\lambda^k \\vec x_0 \\qquad k=(1,2,..)$$\n该序列即为(2)的解。因为：\n$$\\mathbf A\\vec x_k = \\mathbf A(\\lambda^k \\vec x_0) = \\lambda^k(\\mathbf A\\vec x_0)\\\\ = \\lambda^k(\\lambda\\vec x_0) = \\lambda^{k+1}\\vec x_0 = \\vec x_{k+1}$$\n\n\n## 特征方程\n\n数量 $\\lambda$ 是 $\\mathbf A$ 的特征值当 $\\lambda$ 满足特征方程：\n$$det(\\mathbf A - \\lambda \\mathbf I) = 0 \\tag{3}$$\n\n### 相似\n\n设$A$和$B$是$n*n$矩阵，如果存在一个可逆矩阵P使得$P^{-1}AP = B$, 或等价地$A=P^{-1}BP$, 则称$A$相似于$B$, 令$Q=P^{-1}$, 则$Q^{-1}BQ = A$, 所以$B$也相似于$A$. 我们简称$A$和$B$相似。将$A$转换为$P^{-1}AP$称为相似变换。\n\n定理4：如果$n*n$矩阵$A$和$B$相似，则他们有相同的特征多项式，从而有相同的特征值。\n\n## 对角化\n\n定理5：可对角化定理\n\n$n*n$矩阵$A$可对角化当且仅当$A$有$n$个线性无关的特征向量。事实上，$A=PDP^{-1}$, 其中$D$为对角矩阵，当且仅当$P$的列向量是$A$的$n$个线性无关的特征向量，此时$D$的对角线元素是$A$的特征值，并且它们分别对应于$P$的特征向量。\n\n换言之，$A$可对角化当且仅当$A$有足够多的特征向量可以构成$R^n$的一组基，这样的一组基称为**特征向量基**.\n","source":"_posts/特征值与特征向量.md","raw":"---\ntitle: 特征值与特征向量\ndate: 2018-09-23 15:34:27\ntags: 线性代数\ncategories: 机器学习\n---\n\n## 特征向量(eigenvector)与特征值(eigenvalue)\n\n$\\mathbf A$为$n \\times n$矩阵，对非零向量 $\\vec x$, 若存在某个数量 $\\lambda$. 使得 $\\mathbf Ax = \\lambda x$ 则称 $\\vec x$ 为 $\\mathbf A$ 的 **特征向量**. 如果方程有非平凡解，则数量 $\\lambda$ 为 $\\mathbf A$ 的 **特征值**。\n\n$\\lambda$ 是 $\\mathbf A$ 的特征值当且仅当方程(1)有非平凡解，即 $(\\mathbf A - \\lambda \\mathbf I)$ 不可逆。\n$$(\\mathbf A - \\lambda \\mathbf I)\\vec x = \\mathbf 0 \\tag{1}$$\n\n(1)所有解的集合恰好是矩阵 $(\\mathbf A - \\lambda \\mathbf I)$ 的零空间，所以这个集合是 $\\mathbf R^n$ 的子空间，我们将它称为 $\\mathbf A$ 的对应于 $\\lambda$ 的 **特征空间(eigenspace)**。\n\n定理一： 三角矩阵的特征值为其主对角线上的元素。\n\n定理二：若 $\\vec v_1, ... \\vec v_r$ 为 $n \\times n$ 矩阵 $\\mathbf A$ 的对应于不同特征值 $\\lambda_1, ..., \\lambda_r$ 的特征向量，则集合 $\\{\\vec v_1, ... \\vec v_r\\}$ 线性无关。\n\n## 特征向量和差分方程\n\n$$\\vec x_{k+1} = \\mathbf A\\vec x_k \\qquad k=(0,1,2...) \\tag{2}$$\n\n如果 $\\mathbf A$ 为 $n \\times n$ 矩阵，则(2)是 $\\mathbf R^n$ 中序列的一个递归描述。它的一个解是{$\\vec x_k$}的一个显示表示。构造(2)的解最简单的方法是取一个特征向量 $\\vec x_0$ 以及对应的特征值 $\\lambda$, 令\n$$\\vec x_k = \\lambda^k \\vec x_0 \\qquad k=(1,2,..)$$\n该序列即为(2)的解。因为：\n$$\\mathbf A\\vec x_k = \\mathbf A(\\lambda^k \\vec x_0) = \\lambda^k(\\mathbf A\\vec x_0)\\\\ = \\lambda^k(\\lambda\\vec x_0) = \\lambda^{k+1}\\vec x_0 = \\vec x_{k+1}$$\n\n\n## 特征方程\n\n数量 $\\lambda$ 是 $\\mathbf A$ 的特征值当 $\\lambda$ 满足特征方程：\n$$det(\\mathbf A - \\lambda \\mathbf I) = 0 \\tag{3}$$\n\n### 相似\n\n设$A$和$B$是$n*n$矩阵，如果存在一个可逆矩阵P使得$P^{-1}AP = B$, 或等价地$A=P^{-1}BP$, 则称$A$相似于$B$, 令$Q=P^{-1}$, 则$Q^{-1}BQ = A$, 所以$B$也相似于$A$. 我们简称$A$和$B$相似。将$A$转换为$P^{-1}AP$称为相似变换。\n\n定理4：如果$n*n$矩阵$A$和$B$相似，则他们有相同的特征多项式，从而有相同的特征值。\n\n## 对角化\n\n定理5：可对角化定理\n\n$n*n$矩阵$A$可对角化当且仅当$A$有$n$个线性无关的特征向量。事实上，$A=PDP^{-1}$, 其中$D$为对角矩阵，当且仅当$P$的列向量是$A$的$n$个线性无关的特征向量，此时$D$的对角线元素是$A$的特征值，并且它们分别对应于$P$的特征向量。\n\n换言之，$A$可对角化当且仅当$A$有足够多的特征向量可以构成$R^n$的一组基，这样的一组基称为**特征向量基**.\n","slug":"特征值与特征向量","published":1,"updated":"2018-09-23T09:14:56.165Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds5x003spcvofcn7dpvg","content":"<h2 id=\"特征向量-eigenvector-与特征值-eigenvalue\"><a href=\"#特征向量-eigenvector-与特征值-eigenvalue\" class=\"headerlink\" title=\"特征向量(eigenvector)与特征值(eigenvalue)\"></a>特征向量(eigenvector)与特征值(eigenvalue)</h2><p>$\\mathbf A$为$n \\times n$矩阵，对非零向量 $\\vec x$, 若存在某个数量 $\\lambda$. 使得 $\\mathbf Ax = \\lambda x$ 则称 $\\vec x$ 为 $\\mathbf A$ 的 <strong>特征向量</strong>. 如果方程有非平凡解，则数量 $\\lambda$ 为 $\\mathbf A$ 的 <strong>特征值</strong>。</p>\n<p>$\\lambda$ 是 $\\mathbf A$ 的特征值当且仅当方程(1)有非平凡解，即 $(\\mathbf A - \\lambda \\mathbf I)$ 不可逆。<br>$$(\\mathbf A - \\lambda \\mathbf I)\\vec x = \\mathbf 0 \\tag{1}$$</p>\n<p>(1)所有解的集合恰好是矩阵 $(\\mathbf A - \\lambda \\mathbf I)$ 的零空间，所以这个集合是 $\\mathbf R^n$ 的子空间，我们将它称为 $\\mathbf A$ 的对应于 $\\lambda$ 的 <strong>特征空间(eigenspace)</strong>。</p>\n<p>定理一： 三角矩阵的特征值为其主对角线上的元素。</p>\n<p>定理二：若 $\\vec v_1, … \\vec v_r$ 为 $n \\times n$ 矩阵 $\\mathbf A$ 的对应于不同特征值 $\\lambda_1, …, \\lambda_r$ 的特征向量，则集合 ${\\vec v_1, … \\vec v_r}$ 线性无关。</p>\n<h2 id=\"特征向量和差分方程\"><a href=\"#特征向量和差分方程\" class=\"headerlink\" title=\"特征向量和差分方程\"></a>特征向量和差分方程</h2><p>$$\\vec x_{k+1} = \\mathbf A\\vec x_k \\qquad k=(0,1,2…) \\tag{2}$$</p>\n<p>如果 $\\mathbf A$ 为 $n \\times n$ 矩阵，则(2)是 $\\mathbf R^n$ 中序列的一个递归描述。它的一个解是{$\\vec x_k$}的一个显示表示。构造(2)的解最简单的方法是取一个特征向量 $\\vec x_0$ 以及对应的特征值 $\\lambda$, 令<br>$$\\vec x_k = \\lambda^k \\vec x_0 \\qquad k=(1,2,..)$$<br>该序列即为(2)的解。因为：<br>$$\\mathbf A\\vec x_k = \\mathbf A(\\lambda^k \\vec x_0) = \\lambda^k(\\mathbf A\\vec x_0)\\ = \\lambda^k(\\lambda\\vec x_0) = \\lambda^{k+1}\\vec x_0 = \\vec x_{k+1}$$</p>\n<h2 id=\"特征方程\"><a href=\"#特征方程\" class=\"headerlink\" title=\"特征方程\"></a>特征方程</h2><p>数量 $\\lambda$ 是 $\\mathbf A$ 的特征值当 $\\lambda$ 满足特征方程：<br>$$det(\\mathbf A - \\lambda \\mathbf I) = 0 \\tag{3}$$</p>\n<h3 id=\"相似\"><a href=\"#相似\" class=\"headerlink\" title=\"相似\"></a>相似</h3><p>设$A$和$B$是$n*n$矩阵，如果存在一个可逆矩阵P使得$P^{-1}AP = B$, 或等价地$A=P^{-1}BP$, 则称$A$相似于$B$, 令$Q=P^{-1}$, 则$Q^{-1}BQ = A$, 所以$B$也相似于$A$. 我们简称$A$和$B$相似。将$A$转换为$P^{-1}AP$称为相似变换。</p>\n<p>定理4：如果$n*n$矩阵$A$和$B$相似，则他们有相同的特征多项式，从而有相同的特征值。</p>\n<h2 id=\"对角化\"><a href=\"#对角化\" class=\"headerlink\" title=\"对角化\"></a>对角化</h2><p>定理5：可对角化定理</p>\n<p>$n*n$矩阵$A$可对角化当且仅当$A$有$n$个线性无关的特征向量。事实上，$A=PDP^{-1}$, 其中$D$为对角矩阵，当且仅当$P$的列向量是$A$的$n$个线性无关的特征向量，此时$D$的对角线元素是$A$的特征值，并且它们分别对应于$P$的特征向量。</p>\n<p>换言之，$A$可对角化当且仅当$A$有足够多的特征向量可以构成$R^n$的一组基，这样的一组基称为<strong>特征向量基</strong>.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"特征向量-eigenvector-与特征值-eigenvalue\"><a href=\"#特征向量-eigenvector-与特征值-eigenvalue\" class=\"headerlink\" title=\"特征向量(eigenvector)与特征值(eigenvalue)\"></a>特征向量(eigenvector)与特征值(eigenvalue)</h2><p>$\\mathbf A$为$n \\times n$矩阵，对非零向量 $\\vec x$, 若存在某个数量 $\\lambda$. 使得 $\\mathbf Ax = \\lambda x$ 则称 $\\vec x$ 为 $\\mathbf A$ 的 <strong>特征向量</strong>. 如果方程有非平凡解，则数量 $\\lambda$ 为 $\\mathbf A$ 的 <strong>特征值</strong>。</p>\n<p>$\\lambda$ 是 $\\mathbf A$ 的特征值当且仅当方程(1)有非平凡解，即 $(\\mathbf A - \\lambda \\mathbf I)$ 不可逆。<br>$$(\\mathbf A - \\lambda \\mathbf I)\\vec x = \\mathbf 0 \\tag{1}$$</p>\n<p>(1)所有解的集合恰好是矩阵 $(\\mathbf A - \\lambda \\mathbf I)$ 的零空间，所以这个集合是 $\\mathbf R^n$ 的子空间，我们将它称为 $\\mathbf A$ 的对应于 $\\lambda$ 的 <strong>特征空间(eigenspace)</strong>。</p>\n<p>定理一： 三角矩阵的特征值为其主对角线上的元素。</p>\n<p>定理二：若 $\\vec v_1, … \\vec v_r$ 为 $n \\times n$ 矩阵 $\\mathbf A$ 的对应于不同特征值 $\\lambda_1, …, \\lambda_r$ 的特征向量，则集合 ${\\vec v_1, … \\vec v_r}$ 线性无关。</p>\n<h2 id=\"特征向量和差分方程\"><a href=\"#特征向量和差分方程\" class=\"headerlink\" title=\"特征向量和差分方程\"></a>特征向量和差分方程</h2><p>$$\\vec x_{k+1} = \\mathbf A\\vec x_k \\qquad k=(0,1,2…) \\tag{2}$$</p>\n<p>如果 $\\mathbf A$ 为 $n \\times n$ 矩阵，则(2)是 $\\mathbf R^n$ 中序列的一个递归描述。它的一个解是{$\\vec x_k$}的一个显示表示。构造(2)的解最简单的方法是取一个特征向量 $\\vec x_0$ 以及对应的特征值 $\\lambda$, 令<br>$$\\vec x_k = \\lambda^k \\vec x_0 \\qquad k=(1,2,..)$$<br>该序列即为(2)的解。因为：<br>$$\\mathbf A\\vec x_k = \\mathbf A(\\lambda^k \\vec x_0) = \\lambda^k(\\mathbf A\\vec x_0)\\ = \\lambda^k(\\lambda\\vec x_0) = \\lambda^{k+1}\\vec x_0 = \\vec x_{k+1}$$</p>\n<h2 id=\"特征方程\"><a href=\"#特征方程\" class=\"headerlink\" title=\"特征方程\"></a>特征方程</h2><p>数量 $\\lambda$ 是 $\\mathbf A$ 的特征值当 $\\lambda$ 满足特征方程：<br>$$det(\\mathbf A - \\lambda \\mathbf I) = 0 \\tag{3}$$</p>\n<h3 id=\"相似\"><a href=\"#相似\" class=\"headerlink\" title=\"相似\"></a>相似</h3><p>设$A$和$B$是$n*n$矩阵，如果存在一个可逆矩阵P使得$P^{-1}AP = B$, 或等价地$A=P^{-1}BP$, 则称$A$相似于$B$, 令$Q=P^{-1}$, 则$Q^{-1}BQ = A$, 所以$B$也相似于$A$. 我们简称$A$和$B$相似。将$A$转换为$P^{-1}AP$称为相似变换。</p>\n<p>定理4：如果$n*n$矩阵$A$和$B$相似，则他们有相同的特征多项式，从而有相同的特征值。</p>\n<h2 id=\"对角化\"><a href=\"#对角化\" class=\"headerlink\" title=\"对角化\"></a>对角化</h2><p>定理5：可对角化定理</p>\n<p>$n*n$矩阵$A$可对角化当且仅当$A$有$n$个线性无关的特征向量。事实上，$A=PDP^{-1}$, 其中$D$为对角矩阵，当且仅当$P$的列向量是$A$的$n$个线性无关的特征向量，此时$D$的对角线元素是$A$的特征值，并且它们分别对应于$P$的特征向量。</p>\n<p>换言之，$A$可对角化当且仅当$A$有足够多的特征向量可以构成$R^n$的一组基，这样的一组基称为<strong>特征向量基</strong>.</p>\n"},{"title":"男人的对象选择中的一种特殊类型","date":"2018-07-19T10:15:03.000Z","_content":"\n首先我将描述一种对象选择类型--选择的主体是男人--特点是设定一系列的“恋爱的必要条件”。\n\n1. 在这些恋爱的先决条件中，有一条是通行的：只要你在一个人身上发现了它，就能在他身上找到这个类型的其他特点。这个先决条件就是得有 **“受到伤害的第三方”；也就是说，这类男人永远不会选择没有归属的女人--如未婚少女或心无所系的已婚妇女--他只会选择已被其他男人占有的女人，这个其他男人可以是丈夫、未婚夫或朋友。** 这个先决条件的作用十分强大，以至于只要一个女人不属于某个男人，那么在对象选择中，她就会遭到该类型的男人的忽视或拒绝；而一旦她与另一个男人确立了关系，就会立刻成为该类男人发泄激情的对象。\n2. 第二个先决条件或许不像第一条那样，在该类型的每个男人身上都能找到，不过它也同样引人瞩目。第二条就是，**名声无可指责的纯洁女人永远无法成为被选择的对象，只有在性方面声名狼藉、忠诚度和可信度都受到怀疑的女人才能激起该类男人的兴趣。** 不过他们选择的范围也相当大，从并不厌恶调情、略有丑闻的已婚女子到性生活淫乱的妓女或深谙爱情艺术的熟女，不一而足。\n\n现在让我们审视一番这种类型的人的不同特征：所爱之女人必须有所归属并像个妓女；他对这样的女人评价极高；他有体验嫉妒的需要；他对这样的女人忠贞不二，而又可与多个女人更替地保持和谐之爱；他有拯救女人的强烈愿望。表面看来，这很难来自同一根源。然而，精神分析关于这种人生活史的探讨却可以轻松地找到这种单一根源。这种人对象选择的奇怪条件及示爱的单一方式，与正常人的爱具有相同的心理根源。**它们源于对母亲柔情的婴儿固着，其表现乃是这种固着的结果。**\n\n---\n\n摘自弗洛伊德的《爱情心理学》第一章\n","source":"_posts/男人的对象选择中的一种特殊类型.md","raw":"---\ntitle: 男人的对象选择中的一种特殊类型\ndate: 2018-07-19 18:15:03\ntags: 爱情心理学\ncategories: 心理学\n---\n\n首先我将描述一种对象选择类型--选择的主体是男人--特点是设定一系列的“恋爱的必要条件”。\n\n1. 在这些恋爱的先决条件中，有一条是通行的：只要你在一个人身上发现了它，就能在他身上找到这个类型的其他特点。这个先决条件就是得有 **“受到伤害的第三方”；也就是说，这类男人永远不会选择没有归属的女人--如未婚少女或心无所系的已婚妇女--他只会选择已被其他男人占有的女人，这个其他男人可以是丈夫、未婚夫或朋友。** 这个先决条件的作用十分强大，以至于只要一个女人不属于某个男人，那么在对象选择中，她就会遭到该类型的男人的忽视或拒绝；而一旦她与另一个男人确立了关系，就会立刻成为该类男人发泄激情的对象。\n2. 第二个先决条件或许不像第一条那样，在该类型的每个男人身上都能找到，不过它也同样引人瞩目。第二条就是，**名声无可指责的纯洁女人永远无法成为被选择的对象，只有在性方面声名狼藉、忠诚度和可信度都受到怀疑的女人才能激起该类男人的兴趣。** 不过他们选择的范围也相当大，从并不厌恶调情、略有丑闻的已婚女子到性生活淫乱的妓女或深谙爱情艺术的熟女，不一而足。\n\n现在让我们审视一番这种类型的人的不同特征：所爱之女人必须有所归属并像个妓女；他对这样的女人评价极高；他有体验嫉妒的需要；他对这样的女人忠贞不二，而又可与多个女人更替地保持和谐之爱；他有拯救女人的强烈愿望。表面看来，这很难来自同一根源。然而，精神分析关于这种人生活史的探讨却可以轻松地找到这种单一根源。这种人对象选择的奇怪条件及示爱的单一方式，与正常人的爱具有相同的心理根源。**它们源于对母亲柔情的婴儿固着，其表现乃是这种固着的结果。**\n\n---\n\n摘自弗洛伊德的《爱情心理学》第一章\n","slug":"男人的对象选择中的一种特殊类型","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds5x003vpcvoodlqserk","comments":1,"layout":"post","photos":[],"link":"","content":"<p>首先我将描述一种对象选择类型–选择的主体是男人–特点是设定一系列的“恋爱的必要条件”。</p>\n<ol>\n<li>在这些恋爱的先决条件中，有一条是通行的：只要你在一个人身上发现了它，就能在他身上找到这个类型的其他特点。这个先决条件就是得有 <strong>“受到伤害的第三方”；也就是说，这类男人永远不会选择没有归属的女人–如未婚少女或心无所系的已婚妇女–他只会选择已被其他男人占有的女人，这个其他男人可以是丈夫、未婚夫或朋友。</strong> 这个先决条件的作用十分强大，以至于只要一个女人不属于某个男人，那么在对象选择中，她就会遭到该类型的男人的忽视或拒绝；而一旦她与另一个男人确立了关系，就会立刻成为该类男人发泄激情的对象。</li>\n<li>第二个先决条件或许不像第一条那样，在该类型的每个男人身上都能找到，不过它也同样引人瞩目。第二条就是，<strong>名声无可指责的纯洁女人永远无法成为被选择的对象，只有在性方面声名狼藉、忠诚度和可信度都受到怀疑的女人才能激起该类男人的兴趣。</strong> 不过他们选择的范围也相当大，从并不厌恶调情、略有丑闻的已婚女子到性生活淫乱的妓女或深谙爱情艺术的熟女，不一而足。</li>\n</ol>\n<p>现在让我们审视一番这种类型的人的不同特征：所爱之女人必须有所归属并像个妓女；他对这样的女人评价极高；他有体验嫉妒的需要；他对这样的女人忠贞不二，而又可与多个女人更替地保持和谐之爱；他有拯救女人的强烈愿望。表面看来，这很难来自同一根源。然而，精神分析关于这种人生活史的探讨却可以轻松地找到这种单一根源。这种人对象选择的奇怪条件及示爱的单一方式，与正常人的爱具有相同的心理根源。<strong>它们源于对母亲柔情的婴儿固着，其表现乃是这种固着的结果。</strong></p>\n<hr>\n<p>摘自弗洛伊德的《爱情心理学》第一章</p>\n","site":{"data":{}},"excerpt":"","more":"<p>首先我将描述一种对象选择类型–选择的主体是男人–特点是设定一系列的“恋爱的必要条件”。</p>\n<ol>\n<li>在这些恋爱的先决条件中，有一条是通行的：只要你在一个人身上发现了它，就能在他身上找到这个类型的其他特点。这个先决条件就是得有 <strong>“受到伤害的第三方”；也就是说，这类男人永远不会选择没有归属的女人–如未婚少女或心无所系的已婚妇女–他只会选择已被其他男人占有的女人，这个其他男人可以是丈夫、未婚夫或朋友。</strong> 这个先决条件的作用十分强大，以至于只要一个女人不属于某个男人，那么在对象选择中，她就会遭到该类型的男人的忽视或拒绝；而一旦她与另一个男人确立了关系，就会立刻成为该类男人发泄激情的对象。</li>\n<li>第二个先决条件或许不像第一条那样，在该类型的每个男人身上都能找到，不过它也同样引人瞩目。第二条就是，<strong>名声无可指责的纯洁女人永远无法成为被选择的对象，只有在性方面声名狼藉、忠诚度和可信度都受到怀疑的女人才能激起该类男人的兴趣。</strong> 不过他们选择的范围也相当大，从并不厌恶调情、略有丑闻的已婚女子到性生活淫乱的妓女或深谙爱情艺术的熟女，不一而足。</li>\n</ol>\n<p>现在让我们审视一番这种类型的人的不同特征：所爱之女人必须有所归属并像个妓女；他对这样的女人评价极高；他有体验嫉妒的需要；他对这样的女人忠贞不二，而又可与多个女人更替地保持和谐之爱；他有拯救女人的强烈愿望。表面看来，这很难来自同一根源。然而，精神分析关于这种人生活史的探讨却可以轻松地找到这种单一根源。这种人对象选择的奇怪条件及示爱的单一方式，与正常人的爱具有相同的心理根源。<strong>它们源于对母亲柔情的婴儿固着，其表现乃是这种固着的结果。</strong></p>\n<hr>\n<p>摘自弗洛伊德的《爱情心理学》第一章</p>\n"},{"title":"布雷默曼极限","date":"2018-08-05T13:38:25.000Z","mathjax":true,"_content":"\n**以Hans-Joachim Bremermann命名的 Bremermann极限是物质世界中独立系统的最大计算速度**由爱因斯坦的质能效应和海森堡测不准原理得到。\n\n$$\\frac{c^2}{h} \\approx 1.36 \\times 10^{50} bits/s\\cdot kg$$\n\n在设计加密算法时，此值很重要，因为它可用于确定加密密钥的最小大小或创建一个永远不会被暴力搜索破解的算法所需的哈希值。例如，在Bremermann极限下运行整个地球质量的计算机每秒可执行大约$10^{75}$次数学计算。如果假设只使用一个操作可以测试加密密钥，那么典型的128位密钥可以在$10^{36}$秒内被破解。但是，256位密钥（已在某些系统中使用）将需要大约两分钟才能破解。使用512位密钥会将破解时间增加到接近$10^{72}$年，而不会将加密时间增加超过常数因子（取决于所使用的加密算法）。\n","source":"_posts/布雷默曼极限.md","raw":"---\ntitle: 布雷默曼极限\ndate: 2018-08-05 21:38:25\ntags: 物理\ncategories: 计算机科学\nmathjax: true\n---\n\n**以Hans-Joachim Bremermann命名的 Bremermann极限是物质世界中独立系统的最大计算速度**由爱因斯坦的质能效应和海森堡测不准原理得到。\n\n$$\\frac{c^2}{h} \\approx 1.36 \\times 10^{50} bits/s\\cdot kg$$\n\n在设计加密算法时，此值很重要，因为它可用于确定加密密钥的最小大小或创建一个永远不会被暴力搜索破解的算法所需的哈希值。例如，在Bremermann极限下运行整个地球质量的计算机每秒可执行大约$10^{75}$次数学计算。如果假设只使用一个操作可以测试加密密钥，那么典型的128位密钥可以在$10^{36}$秒内被破解。但是，256位密钥（已在某些系统中使用）将需要大约两分钟才能破解。使用512位密钥会将破解时间增加到接近$10^{72}$年，而不会将加密时间增加超过常数因子（取决于所使用的加密算法）。\n","slug":"布雷默曼极限","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds6c003zpcvowteh0pib","comments":1,"layout":"post","photos":[],"link":"","content":"<p><strong>以Hans-Joachim Bremermann命名的 Bremermann极限是物质世界中独立系统的最大计算速度</strong>由爱因斯坦的质能效应和海森堡测不准原理得到。</p>\n<p>$$\\frac{c^2}{h} \\approx 1.36 \\times 10^{50} bits/s\\cdot kg$$</p>\n<p>在设计加密算法时，此值很重要，因为它可用于确定加密密钥的最小大小或创建一个永远不会被暴力搜索破解的算法所需的哈希值。例如，在Bremermann极限下运行整个地球质量的计算机每秒可执行大约$10^{75}$次数学计算。如果假设只使用一个操作可以测试加密密钥，那么典型的128位密钥可以在$10^{36}$秒内被破解。但是，256位密钥（已在某些系统中使用）将需要大约两分钟才能破解。使用512位密钥会将破解时间增加到接近$10^{72}$年，而不会将加密时间增加超过常数因子（取决于所使用的加密算法）。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>以Hans-Joachim Bremermann命名的 Bremermann极限是物质世界中独立系统的最大计算速度</strong>由爱因斯坦的质能效应和海森堡测不准原理得到。</p>\n<p>$$\\frac{c^2}{h} \\approx 1.36 \\times 10^{50} bits/s\\cdot kg$$</p>\n<p>在设计加密算法时，此值很重要，因为它可用于确定加密密钥的最小大小或创建一个永远不会被暴力搜索破解的算法所需的哈希值。例如，在Bremermann极限下运行整个地球质量的计算机每秒可执行大约$10^{75}$次数学计算。如果假设只使用一个操作可以测试加密密钥，那么典型的128位密钥可以在$10^{36}$秒内被破解。但是，256位密钥（已在某些系统中使用）将需要大约两分钟才能破解。使用512位密钥会将破解时间增加到接近$10^{72}$年，而不会将加密时间增加超过常数因子（取决于所使用的加密算法）。</p>\n"},{"title":"矩阵链乘法","date":"2018-09-01T14:12:29.000Z","mathjax":true,"_content":"### 问题描述\n\n给定一个n个矩阵的序列（矩阵链）$<A_1, A_2, ..., A_n>$, 为了计算它们的乘积 $A_1A_2...A_n$，可以先用括号明确它们的计算次序，然后利用标准的矩阵相乘算法进行计算。\n\n我们称有如下性质的矩阵乘积链为完全括号化的：它是单一矩阵，或者是两个完全括号化的矩阵乘积链的积，且以外加括号。如 $((A_1A_2)(A_3A_4))$.\n\n对矩阵链加括号的方式会对乘积运算的代价产生巨大影响。矩阵链乘法问题可描述如下：**给定n个矩阵的链 $<A_1, A_2, ..., A_n>$ ，矩阵 $A_i$ 的规模为 $p_{i-1} \\times p_i$, 求完全括号化方案，使得计算乘积 $A_1A_2...A_n$ 所需标量乘法次数最少。**\n\n### 计算括号化方案的数量\n\n令 $P(n)$ 表示n个矩阵的链可供选择的括号化方案的数量。则：\n$$P(n) = \\begin{cases} 1, \\qquad where \\quad n = 1 \\\\ \\sum_{k=1}^{n-1} P(k)P(n - k)\\quad where \\quad n \\ge 2\\end{cases}$$\n\n### 应用动态规划方法\n\n对矩阵链乘法问题，我们可以将对所有 $i \\le i \\le j \\le n$ 确定 $A_1A_2...A_n$ 的最小代价括号化方案作为子问题。令 $m[i,j]$ 表示计算矩阵 $A_{i,j}$ 所需要标量乘法次数的最小值，那么原问题的最优解--计算 $A_{1...n}$ 所需要的最低代价就是 $m[1, n]$.\n$$m[i, j] = \\begin{cases}0 \\qquad i = j\\\\ min_{i \\le k \\lt j} \\{m[i, k] + m[k+1, j] + p_{i-1}p_kp_j\\} \\qquad i < j\\end{cases}$$\n\n为得到最优括号化方案，我们用 $s[i, j]$ 保存 $A_1A_2...A_n$ 最优括号化方案的分割点k\n\n### 代码实现\n\n```python\ndef matrix_chain_order(p):\n    \"\"\"\n    p: 假定矩阵A_i的规模是(p_{i-1}, p_i), p是矩阵链规模的序列\n    \"\"\"\n    n = len(p) - 1\n    # m[i, j]表示计算矩阵A_{i..j} i,j = {1...n}所需的标量乘法次数的最小值\n    m = [[j for j in range(n + 1)] for i in range(n + 1)]\n    # s[i, j]表示A_{i..j} i = {1, n-1}, j={2, n}最优括号化方案的分割点位置\n    s = [[j for j in range(n + 1)] for i in range(n)]\n    for i in range(n + 1):\n        m[i][i] = 0\n    for l in range(2, n + 1):\n        for i in range(1, n - l + 2):\n            j = i + l - 1\n            m[i][j] = float('inf')\n            for k in range(i, j):\n                q = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j]\n                if q < m[i][j]:\n                    m[i][j] = q\n                    s[i][j] = k\n    return m, s\n\ndef print_optimal_solution(s, i, j):\n    global optimal_solution\n    if i == j:\n        optimal_solution.append(\"A\" + str(i))\n    else:\n        optimal_solution.append('(')\n        print_optimal_solution(s, i, s[i][j])\n        print_optimal_solution(s, s[i][j] + 1, j)\n        optimal_solution.append(')')\n\n\nif __name__ == '__main__':\n    optimal_solution = []\n    p = [5, 10, 3, 12, 5, 50, 6]\n    m, s = matrix_chain_order(p)\n    print_optimal_solution(s, 1, 6)\n    print('optimal: ', m[1][6])\n    print(''.join(optimal_solution))\n```\n","source":"_posts/矩阵链乘法.md","raw":"---\ntitle: 矩阵链乘法\ndate: 2018-09-01 22:12:29\ntags: 动态规划\ncategories: 算法导论\nmathjax: true\n---\n### 问题描述\n\n给定一个n个矩阵的序列（矩阵链）$<A_1, A_2, ..., A_n>$, 为了计算它们的乘积 $A_1A_2...A_n$，可以先用括号明确它们的计算次序，然后利用标准的矩阵相乘算法进行计算。\n\n我们称有如下性质的矩阵乘积链为完全括号化的：它是单一矩阵，或者是两个完全括号化的矩阵乘积链的积，且以外加括号。如 $((A_1A_2)(A_3A_4))$.\n\n对矩阵链加括号的方式会对乘积运算的代价产生巨大影响。矩阵链乘法问题可描述如下：**给定n个矩阵的链 $<A_1, A_2, ..., A_n>$ ，矩阵 $A_i$ 的规模为 $p_{i-1} \\times p_i$, 求完全括号化方案，使得计算乘积 $A_1A_2...A_n$ 所需标量乘法次数最少。**\n\n### 计算括号化方案的数量\n\n令 $P(n)$ 表示n个矩阵的链可供选择的括号化方案的数量。则：\n$$P(n) = \\begin{cases} 1, \\qquad where \\quad n = 1 \\\\ \\sum_{k=1}^{n-1} P(k)P(n - k)\\quad where \\quad n \\ge 2\\end{cases}$$\n\n### 应用动态规划方法\n\n对矩阵链乘法问题，我们可以将对所有 $i \\le i \\le j \\le n$ 确定 $A_1A_2...A_n$ 的最小代价括号化方案作为子问题。令 $m[i,j]$ 表示计算矩阵 $A_{i,j}$ 所需要标量乘法次数的最小值，那么原问题的最优解--计算 $A_{1...n}$ 所需要的最低代价就是 $m[1, n]$.\n$$m[i, j] = \\begin{cases}0 \\qquad i = j\\\\ min_{i \\le k \\lt j} \\{m[i, k] + m[k+1, j] + p_{i-1}p_kp_j\\} \\qquad i < j\\end{cases}$$\n\n为得到最优括号化方案，我们用 $s[i, j]$ 保存 $A_1A_2...A_n$ 最优括号化方案的分割点k\n\n### 代码实现\n\n```python\ndef matrix_chain_order(p):\n    \"\"\"\n    p: 假定矩阵A_i的规模是(p_{i-1}, p_i), p是矩阵链规模的序列\n    \"\"\"\n    n = len(p) - 1\n    # m[i, j]表示计算矩阵A_{i..j} i,j = {1...n}所需的标量乘法次数的最小值\n    m = [[j for j in range(n + 1)] for i in range(n + 1)]\n    # s[i, j]表示A_{i..j} i = {1, n-1}, j={2, n}最优括号化方案的分割点位置\n    s = [[j for j in range(n + 1)] for i in range(n)]\n    for i in range(n + 1):\n        m[i][i] = 0\n    for l in range(2, n + 1):\n        for i in range(1, n - l + 2):\n            j = i + l - 1\n            m[i][j] = float('inf')\n            for k in range(i, j):\n                q = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j]\n                if q < m[i][j]:\n                    m[i][j] = q\n                    s[i][j] = k\n    return m, s\n\ndef print_optimal_solution(s, i, j):\n    global optimal_solution\n    if i == j:\n        optimal_solution.append(\"A\" + str(i))\n    else:\n        optimal_solution.append('(')\n        print_optimal_solution(s, i, s[i][j])\n        print_optimal_solution(s, s[i][j] + 1, j)\n        optimal_solution.append(')')\n\n\nif __name__ == '__main__':\n    optimal_solution = []\n    p = [5, 10, 3, 12, 5, 50, 6]\n    m, s = matrix_chain_order(p)\n    print_optimal_solution(s, 1, 6)\n    print('optimal: ', m[1][6])\n    print(''.join(optimal_solution))\n```\n","slug":"矩阵链乘法","published":1,"updated":"2018-09-02T01:38:46.520Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds6c0042pcvokftlunnh","content":"<h3 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h3><p>给定一个n个矩阵的序列（矩阵链）$&lt;A_1, A_2, …, A_n&gt;$, 为了计算它们的乘积 $A_1A_2…A_n$，可以先用括号明确它们的计算次序，然后利用标准的矩阵相乘算法进行计算。</p>\n<p>我们称有如下性质的矩阵乘积链为完全括号化的：它是单一矩阵，或者是两个完全括号化的矩阵乘积链的积，且以外加括号。如 $((A_1A_2)(A_3A_4))$.</p>\n<p>对矩阵链加括号的方式会对乘积运算的代价产生巨大影响。矩阵链乘法问题可描述如下：<strong>给定n个矩阵的链 $&lt;A_1, A_2, …, A_n&gt;$ ，矩阵 $A_i$ 的规模为 $p_{i-1} \\times p_i$, 求完全括号化方案，使得计算乘积 $A_1A_2…A_n$ 所需标量乘法次数最少。</strong></p>\n<h3 id=\"计算括号化方案的数量\"><a href=\"#计算括号化方案的数量\" class=\"headerlink\" title=\"计算括号化方案的数量\"></a>计算括号化方案的数量</h3><p>令 $P(n)$ 表示n个矩阵的链可供选择的括号化方案的数量。则：<br>$$P(n) = \\begin{cases} 1, \\qquad where \\quad n = 1 \\ \\sum_{k=1}^{n-1} P(k)P(n - k)\\quad where \\quad n \\ge 2\\end{cases}$$</p>\n<h3 id=\"应用动态规划方法\"><a href=\"#应用动态规划方法\" class=\"headerlink\" title=\"应用动态规划方法\"></a>应用动态规划方法</h3><p>对矩阵链乘法问题，我们可以将对所有 $i \\le i \\le j \\le n$ 确定 $A_1A_2…A_n$ 的最小代价括号化方案作为子问题。令 $m[i,j]$ 表示计算矩阵 $A_{i,j}$ 所需要标量乘法次数的最小值，那么原问题的最优解–计算 $A_{1…n}$ 所需要的最低代价就是 $m[1, n]$.<br>$$m[i, j] = \\begin{cases}0 \\qquad i = j\\ min_{i \\le k \\lt j} {m[i, k] + m[k+1, j] + p_{i-1}p_kp_j} \\qquad i &lt; j\\end{cases}$$</p>\n<p>为得到最优括号化方案，我们用 $s[i, j]$ 保存 $A_1A_2…A_n$ 最优括号化方案的分割点k</p>\n<h3 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">matrix_chain_order</span><span class=\"params\">(p)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    p: 假定矩阵A_i的规模是(p_&#123;i-1&#125;, p_i), p是矩阵链规模的序列</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    n = len(p) - <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\"># m[i, j]表示计算矩阵A_&#123;i..j&#125; i,j = &#123;1...n&#125;所需的标量乘法次数的最小值</span></span><br><span class=\"line\">    m = [[j <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(n + <span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n + <span class=\"number\">1</span>)]</span><br><span class=\"line\">    <span class=\"comment\"># s[i, j]表示A_&#123;i..j&#125; i = &#123;1, n-1&#125;, j=&#123;2, n&#125;最优括号化方案的分割点位置</span></span><br><span class=\"line\">    s = [[j <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(n + <span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n)]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        m[i][i] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(<span class=\"number\">2</span>, n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n - l + <span class=\"number\">2</span>):</span><br><span class=\"line\">            j = i + l - <span class=\"number\">1</span></span><br><span class=\"line\">            m[i][j] = float(<span class=\"string\">'inf'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> range(i, j):</span><br><span class=\"line\">                q = m[i][k] + m[k + <span class=\"number\">1</span>][j] + p[i - <span class=\"number\">1</span>] * p[k] * p[j]</span><br><span class=\"line\">                <span class=\"keyword\">if</span> q &lt; m[i][j]:</span><br><span class=\"line\">                    m[i][j] = q</span><br><span class=\"line\">                    s[i][j] = k</span><br><span class=\"line\">    <span class=\"keyword\">return</span> m, s</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">print_optimal_solution</span><span class=\"params\">(s, i, j)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">global</span> optimal_solution</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i == j:</span><br><span class=\"line\">        optimal_solution.append(<span class=\"string\">\"A\"</span> + str(i))</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        optimal_solution.append(<span class=\"string\">'('</span>)</span><br><span class=\"line\">        print_optimal_solution(s, i, s[i][j])</span><br><span class=\"line\">        print_optimal_solution(s, s[i][j] + <span class=\"number\">1</span>, j)</span><br><span class=\"line\">        optimal_solution.append(<span class=\"string\">')'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    optimal_solution = []</span><br><span class=\"line\">    p = [<span class=\"number\">5</span>, <span class=\"number\">10</span>, <span class=\"number\">3</span>, <span class=\"number\">12</span>, <span class=\"number\">5</span>, <span class=\"number\">50</span>, <span class=\"number\">6</span>]</span><br><span class=\"line\">    m, s = matrix_chain_order(p)</span><br><span class=\"line\">    print_optimal_solution(s, <span class=\"number\">1</span>, <span class=\"number\">6</span>)</span><br><span class=\"line\">    print(<span class=\"string\">'optimal: '</span>, m[<span class=\"number\">1</span>][<span class=\"number\">6</span>])</span><br><span class=\"line\">    print(<span class=\"string\">''</span>.join(optimal_solution))</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h3><p>给定一个n个矩阵的序列（矩阵链）$&lt;A_1, A_2, …, A_n&gt;$, 为了计算它们的乘积 $A_1A_2…A_n$，可以先用括号明确它们的计算次序，然后利用标准的矩阵相乘算法进行计算。</p>\n<p>我们称有如下性质的矩阵乘积链为完全括号化的：它是单一矩阵，或者是两个完全括号化的矩阵乘积链的积，且以外加括号。如 $((A_1A_2)(A_3A_4))$.</p>\n<p>对矩阵链加括号的方式会对乘积运算的代价产生巨大影响。矩阵链乘法问题可描述如下：<strong>给定n个矩阵的链 $&lt;A_1, A_2, …, A_n&gt;$ ，矩阵 $A_i$ 的规模为 $p_{i-1} \\times p_i$, 求完全括号化方案，使得计算乘积 $A_1A_2…A_n$ 所需标量乘法次数最少。</strong></p>\n<h3 id=\"计算括号化方案的数量\"><a href=\"#计算括号化方案的数量\" class=\"headerlink\" title=\"计算括号化方案的数量\"></a>计算括号化方案的数量</h3><p>令 $P(n)$ 表示n个矩阵的链可供选择的括号化方案的数量。则：<br>$$P(n) = \\begin{cases} 1, \\qquad where \\quad n = 1 \\ \\sum_{k=1}^{n-1} P(k)P(n - k)\\quad where \\quad n \\ge 2\\end{cases}$$</p>\n<h3 id=\"应用动态规划方法\"><a href=\"#应用动态规划方法\" class=\"headerlink\" title=\"应用动态规划方法\"></a>应用动态规划方法</h3><p>对矩阵链乘法问题，我们可以将对所有 $i \\le i \\le j \\le n$ 确定 $A_1A_2…A_n$ 的最小代价括号化方案作为子问题。令 $m[i,j]$ 表示计算矩阵 $A_{i,j}$ 所需要标量乘法次数的最小值，那么原问题的最优解–计算 $A_{1…n}$ 所需要的最低代价就是 $m[1, n]$.<br>$$m[i, j] = \\begin{cases}0 \\qquad i = j\\ min_{i \\le k \\lt j} {m[i, k] + m[k+1, j] + p_{i-1}p_kp_j} \\qquad i &lt; j\\end{cases}$$</p>\n<p>为得到最优括号化方案，我们用 $s[i, j]$ 保存 $A_1A_2…A_n$ 最优括号化方案的分割点k</p>\n<h3 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">matrix_chain_order</span><span class=\"params\">(p)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    p: 假定矩阵A_i的规模是(p_&#123;i-1&#125;, p_i), p是矩阵链规模的序列</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    n = len(p) - <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\"># m[i, j]表示计算矩阵A_&#123;i..j&#125; i,j = &#123;1...n&#125;所需的标量乘法次数的最小值</span></span><br><span class=\"line\">    m = [[j <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(n + <span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n + <span class=\"number\">1</span>)]</span><br><span class=\"line\">    <span class=\"comment\"># s[i, j]表示A_&#123;i..j&#125; i = &#123;1, n-1&#125;, j=&#123;2, n&#125;最优括号化方案的分割点位置</span></span><br><span class=\"line\">    s = [[j <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(n + <span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n)]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        m[i][i] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(<span class=\"number\">2</span>, n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n - l + <span class=\"number\">2</span>):</span><br><span class=\"line\">            j = i + l - <span class=\"number\">1</span></span><br><span class=\"line\">            m[i][j] = float(<span class=\"string\">'inf'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> range(i, j):</span><br><span class=\"line\">                q = m[i][k] + m[k + <span class=\"number\">1</span>][j] + p[i - <span class=\"number\">1</span>] * p[k] * p[j]</span><br><span class=\"line\">                <span class=\"keyword\">if</span> q &lt; m[i][j]:</span><br><span class=\"line\">                    m[i][j] = q</span><br><span class=\"line\">                    s[i][j] = k</span><br><span class=\"line\">    <span class=\"keyword\">return</span> m, s</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">print_optimal_solution</span><span class=\"params\">(s, i, j)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">global</span> optimal_solution</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i == j:</span><br><span class=\"line\">        optimal_solution.append(<span class=\"string\">\"A\"</span> + str(i))</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        optimal_solution.append(<span class=\"string\">'('</span>)</span><br><span class=\"line\">        print_optimal_solution(s, i, s[i][j])</span><br><span class=\"line\">        print_optimal_solution(s, s[i][j] + <span class=\"number\">1</span>, j)</span><br><span class=\"line\">        optimal_solution.append(<span class=\"string\">')'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    optimal_solution = []</span><br><span class=\"line\">    p = [<span class=\"number\">5</span>, <span class=\"number\">10</span>, <span class=\"number\">3</span>, <span class=\"number\">12</span>, <span class=\"number\">5</span>, <span class=\"number\">50</span>, <span class=\"number\">6</span>]</span><br><span class=\"line\">    m, s = matrix_chain_order(p)</span><br><span class=\"line\">    print_optimal_solution(s, <span class=\"number\">1</span>, <span class=\"number\">6</span>)</span><br><span class=\"line\">    print(<span class=\"string\">'optimal: '</span>, m[<span class=\"number\">1</span>][<span class=\"number\">6</span>])</span><br><span class=\"line\">    print(<span class=\"string\">''</span>.join(optimal_solution))</span><br></pre></td></tr></table></figure>\n"},{"title":"短诗三首","date":"2018-07-19T02:25:47.000Z","_content":"\n### 确认过眼神\n\n```\n它，睁开朦胧的双眼\n看见天空\n穿着蓝色的裙子\n在微风中跳舞\n红了脸\n害羞地躲到云朵中\n\n它，热烈地燃烧\n想带给天空温暖\n却抵挡不了黑夜的到来\n黑夜一无所有\n却能给天空安慰\n\n它，裹在云朵中哭泣\n眼泪在泥土上溅起水花\n弄脏了天空的裙子\n又停止哭泣\n给天空画上了美丽的彩虹\n```\n\n### 1900\n```\n冬天来了\n你迫不及待地等待夏天\n夏天来了\n你还活在死寂的冬天\n```\n\n### 远方的山\n```\n有些情\n像远方的山\n不知所起，亦不知所终\n隔着呼啸的海浪\n任心被激打\n激打出沉默的浪花\n何不做那海燕\n到山那边歇歇脚\n```\n","source":"_posts/短诗三首.md","raw":"---\ntitle: 短诗三首\ndate: 2018-07-19 10:25:47\ntags: 现代诗\ncategories: 文学\n---\n\n### 确认过眼神\n\n```\n它，睁开朦胧的双眼\n看见天空\n穿着蓝色的裙子\n在微风中跳舞\n红了脸\n害羞地躲到云朵中\n\n它，热烈地燃烧\n想带给天空温暖\n却抵挡不了黑夜的到来\n黑夜一无所有\n却能给天空安慰\n\n它，裹在云朵中哭泣\n眼泪在泥土上溅起水花\n弄脏了天空的裙子\n又停止哭泣\n给天空画上了美丽的彩虹\n```\n\n### 1900\n```\n冬天来了\n你迫不及待地等待夏天\n夏天来了\n你还活在死寂的冬天\n```\n\n### 远方的山\n```\n有些情\n像远方的山\n不知所起，亦不知所终\n隔着呼啸的海浪\n任心被激打\n激打出沉默的浪花\n何不做那海燕\n到山那边歇歇脚\n```\n","slug":"短诗三首","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds6c0047pcvolhdvlrpn","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"确认过眼神\"><a href=\"#确认过眼神\" class=\"headerlink\" title=\"确认过眼神\"></a>确认过眼神</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">它，睁开朦胧的双眼</span><br><span class=\"line\">看见天空</span><br><span class=\"line\">穿着蓝色的裙子</span><br><span class=\"line\">在微风中跳舞</span><br><span class=\"line\">红了脸</span><br><span class=\"line\">害羞地躲到云朵中</span><br><span class=\"line\"></span><br><span class=\"line\">它，热烈地燃烧</span><br><span class=\"line\">想带给天空温暖</span><br><span class=\"line\">却抵挡不了黑夜的到来</span><br><span class=\"line\">黑夜一无所有</span><br><span class=\"line\">却能给天空安慰</span><br><span class=\"line\"></span><br><span class=\"line\">它，裹在云朵中哭泣</span><br><span class=\"line\">眼泪在泥土上溅起水花</span><br><span class=\"line\">弄脏了天空的裙子</span><br><span class=\"line\">又停止哭泣</span><br><span class=\"line\">给天空画上了美丽的彩虹</span><br></pre></td></tr></table></figure>\n<h3 id=\"1900\"><a href=\"#1900\" class=\"headerlink\" title=\"1900\"></a>1900</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">冬天来了</span><br><span class=\"line\">你迫不及待地等待夏天</span><br><span class=\"line\">夏天来了</span><br><span class=\"line\">你还活在死寂的冬天</span><br></pre></td></tr></table></figure>\n<h3 id=\"远方的山\"><a href=\"#远方的山\" class=\"headerlink\" title=\"远方的山\"></a>远方的山</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">有些情</span><br><span class=\"line\">像远方的山</span><br><span class=\"line\">不知所起，亦不知所终</span><br><span class=\"line\">隔着呼啸的海浪</span><br><span class=\"line\">任心被激打</span><br><span class=\"line\">激打出沉默的浪花</span><br><span class=\"line\">何不做那海燕</span><br><span class=\"line\">到山那边歇歇脚</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"确认过眼神\"><a href=\"#确认过眼神\" class=\"headerlink\" title=\"确认过眼神\"></a>确认过眼神</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">它，睁开朦胧的双眼</span><br><span class=\"line\">看见天空</span><br><span class=\"line\">穿着蓝色的裙子</span><br><span class=\"line\">在微风中跳舞</span><br><span class=\"line\">红了脸</span><br><span class=\"line\">害羞地躲到云朵中</span><br><span class=\"line\"></span><br><span class=\"line\">它，热烈地燃烧</span><br><span class=\"line\">想带给天空温暖</span><br><span class=\"line\">却抵挡不了黑夜的到来</span><br><span class=\"line\">黑夜一无所有</span><br><span class=\"line\">却能给天空安慰</span><br><span class=\"line\"></span><br><span class=\"line\">它，裹在云朵中哭泣</span><br><span class=\"line\">眼泪在泥土上溅起水花</span><br><span class=\"line\">弄脏了天空的裙子</span><br><span class=\"line\">又停止哭泣</span><br><span class=\"line\">给天空画上了美丽的彩虹</span><br></pre></td></tr></table></figure>\n<h3 id=\"1900\"><a href=\"#1900\" class=\"headerlink\" title=\"1900\"></a>1900</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">冬天来了</span><br><span class=\"line\">你迫不及待地等待夏天</span><br><span class=\"line\">夏天来了</span><br><span class=\"line\">你还活在死寂的冬天</span><br></pre></td></tr></table></figure>\n<h3 id=\"远方的山\"><a href=\"#远方的山\" class=\"headerlink\" title=\"远方的山\"></a>远方的山</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">有些情</span><br><span class=\"line\">像远方的山</span><br><span class=\"line\">不知所起，亦不知所终</span><br><span class=\"line\">隔着呼啸的海浪</span><br><span class=\"line\">任心被激打</span><br><span class=\"line\">激打出沉默的浪花</span><br><span class=\"line\">何不做那海燕</span><br><span class=\"line\">到山那边歇歇脚</span><br></pre></td></tr></table></figure>\n"},{"title":"神经风格迁移","date":"2018-09-04T06:25:53.000Z","mathjax":true,"_content":"**神经风格迁移（Neural style transfer）** 将参考风格图像的风格“迁移”到另外一张内容图像中，生成具有其特色的图像。\n\n![Neural-style-transfer](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Neural-style-transfer.png)\n\n### 深度卷积网络在学什么？\n\n想要理解如何实现神经风格转换，首先要理解在输入图像数据后，一个深度卷积网络从中都学到了些什么。我们借助可视化来做到这一点。\n\n![Visualizing-deep-layers](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Visualizing-deep-layers.png)\n\n我们通过遍历所有的训练样本，找出使该层激活函数输出最大的 9 块图像区域。可以看出，浅层的隐藏层通常检测出的是原始图像的边缘、颜色、阴影等简单信息。随着层数的增加，隐藏单元能捕捉的区域更大，学习到的特征也由从边缘到纹理再到具体物体，变得更加复杂。\n\n相关论文：[Zeiler and Fergus., 2013, Visualizing and understanding convolutional networks](https://arxiv.org/pdf/1311.2901.pdf)\n\n### 代价函数\n\n神经风格迁移生成图片 G 的代价函数如下：\n\n$$J(G) = \\alpha \\cdot J_{content}(C, G) + \\beta \\cdot J_{style}(S, G)$$\n\n其中，$\\alpha$、$\\beta$ 是用于控制相似度比重的超参数。\n\n神经风格迁移的算法步骤如下：\n\n1. 随机生成图片 G 的所有像素点；\n2. 使用梯度下降算法使代价函数最小化，以不断修正 G 的所有像素点。\n\n相关论文：[Gatys al., 2015. A neural algorithm of artistic style](https://arxiv.org/pdf/1508.06576v2.pdf)\n\n#### 内容代价函数\n\n上述代价函数包含一个内容代价部分和风格代价部分。我们先来讨论内容代价函数 $J_{content}(C, G)$，它表示内容图片 C 和生成图片 G 之间的相似度。\n\n$J_{content}(C, G)$ 的计算过程如下：\n\n* 使用一个预训练好的 CNN（例如 VGG）；\n* 选择一个隐藏层 $l$ 来计算内容代价。$l$ 太小则内容图片和生成图片像素级别相似，$l$ 太大则可能只有具体物体级别的相似。因此，$l$ 一般选一个中间层；\n* 设 $a^{(C)[l]}$、$a^{(G)[l]}$ 为 C 和 G 在 $l$ 层的激活，则有：\n\n$$J_{content}(C, G) = \\frac{1}{2}||(a^{(C)[l]} - a^{(G)[l]})||^2$$\n\n$a^{(C)[l]}$ 和 $a^{(G)[l]}$ 越相似，则 $J_{content}(C, G)$ 越小。\n\n#### 风格代价函数\n\n![Intuition-about-style-of-an-image](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Intuition-about-style-of-an-image.png)\n\n每个通道提取图片的特征不同，比如标为红色的通道提取的是图片的垂直纹理特征，标为黄色的通道提取的是图片的橙色背景特征。那么计算这两个通道的相关性，相关性的大小，即表示原始图片既包含了垂直纹理也包含了该橙色背景的可能性大小。通过 CNN，**“风格”被定义为同一个隐藏层不同通道之间激活值的相关系数，因其反映了原始图片特征间的相互关系。**\n\n对于风格图像 S，选定网络中的第 $l$ 层，则相关系数以一个 gram 矩阵的形式表示：\n\n$$G^{(S)[l]}_{kk'} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}\\_W}\\_{j=1} a^{(S)[l]}\\_{ijk} a^{(S)[l]}_{ijk'}$$\n\n其中，$i$ 和 $j$ 为第 $l$ 层的高度和宽度；$k$ 和 $k'$ 为选定的通道，其范围为 $1$ 到 $n_C^{[l]}$；$a^{(S)[l]}_{ijk}$ 为激活。\n\n同理，对于生成图像 G，有：\n\n$$G^{(G)[l]}_{kk'} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}\\_W}\\_{j=1} a^{(G)[l]}\\_{ijk} a^{(G)[l]}_{ijk'}$$\n\n因此，第 $l$ 层的风格代价函数为：\n\n$$J^{[l]}_{style}(S, G) = \\frac{1}{(2n^{[l]}_Hn^{[l]}\\_Wn^{[l]}_C)^2} \\sum_k \\sum_{k'}(G^{(S)[l]}\\_{kk'} - G^{(G)[l]}_{kk'})^2$$\n\n如果对各层都使用风格代价函数，效果会更好。因此有：\n\n$$J_{style}(S, G) = \\sum_l \\lambda^{[l]} J^{[l]}_{style}(S, G)$$\n\n其中，$lambda$ 是用于设置不同层所占权重的超参数。\n","source":"_posts/神经风格迁移.md","raw":"---\ntitle: 神经风格迁移\ndate: 2018-09-04 14:25:53\ntags: 计算机视觉\ncategories: 深度学习\nmathjax: true\n---\n**神经风格迁移（Neural style transfer）** 将参考风格图像的风格“迁移”到另外一张内容图像中，生成具有其特色的图像。\n\n![Neural-style-transfer](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Neural-style-transfer.png)\n\n### 深度卷积网络在学什么？\n\n想要理解如何实现神经风格转换，首先要理解在输入图像数据后，一个深度卷积网络从中都学到了些什么。我们借助可视化来做到这一点。\n\n![Visualizing-deep-layers](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Visualizing-deep-layers.png)\n\n我们通过遍历所有的训练样本，找出使该层激活函数输出最大的 9 块图像区域。可以看出，浅层的隐藏层通常检测出的是原始图像的边缘、颜色、阴影等简单信息。随着层数的增加，隐藏单元能捕捉的区域更大，学习到的特征也由从边缘到纹理再到具体物体，变得更加复杂。\n\n相关论文：[Zeiler and Fergus., 2013, Visualizing and understanding convolutional networks](https://arxiv.org/pdf/1311.2901.pdf)\n\n### 代价函数\n\n神经风格迁移生成图片 G 的代价函数如下：\n\n$$J(G) = \\alpha \\cdot J_{content}(C, G) + \\beta \\cdot J_{style}(S, G)$$\n\n其中，$\\alpha$、$\\beta$ 是用于控制相似度比重的超参数。\n\n神经风格迁移的算法步骤如下：\n\n1. 随机生成图片 G 的所有像素点；\n2. 使用梯度下降算法使代价函数最小化，以不断修正 G 的所有像素点。\n\n相关论文：[Gatys al., 2015. A neural algorithm of artistic style](https://arxiv.org/pdf/1508.06576v2.pdf)\n\n#### 内容代价函数\n\n上述代价函数包含一个内容代价部分和风格代价部分。我们先来讨论内容代价函数 $J_{content}(C, G)$，它表示内容图片 C 和生成图片 G 之间的相似度。\n\n$J_{content}(C, G)$ 的计算过程如下：\n\n* 使用一个预训练好的 CNN（例如 VGG）；\n* 选择一个隐藏层 $l$ 来计算内容代价。$l$ 太小则内容图片和生成图片像素级别相似，$l$ 太大则可能只有具体物体级别的相似。因此，$l$ 一般选一个中间层；\n* 设 $a^{(C)[l]}$、$a^{(G)[l]}$ 为 C 和 G 在 $l$ 层的激活，则有：\n\n$$J_{content}(C, G) = \\frac{1}{2}||(a^{(C)[l]} - a^{(G)[l]})||^2$$\n\n$a^{(C)[l]}$ 和 $a^{(G)[l]}$ 越相似，则 $J_{content}(C, G)$ 越小。\n\n#### 风格代价函数\n\n![Intuition-about-style-of-an-image](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Intuition-about-style-of-an-image.png)\n\n每个通道提取图片的特征不同，比如标为红色的通道提取的是图片的垂直纹理特征，标为黄色的通道提取的是图片的橙色背景特征。那么计算这两个通道的相关性，相关性的大小，即表示原始图片既包含了垂直纹理也包含了该橙色背景的可能性大小。通过 CNN，**“风格”被定义为同一个隐藏层不同通道之间激活值的相关系数，因其反映了原始图片特征间的相互关系。**\n\n对于风格图像 S，选定网络中的第 $l$ 层，则相关系数以一个 gram 矩阵的形式表示：\n\n$$G^{(S)[l]}_{kk'} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}\\_W}\\_{j=1} a^{(S)[l]}\\_{ijk} a^{(S)[l]}_{ijk'}$$\n\n其中，$i$ 和 $j$ 为第 $l$ 层的高度和宽度；$k$ 和 $k'$ 为选定的通道，其范围为 $1$ 到 $n_C^{[l]}$；$a^{(S)[l]}_{ijk}$ 为激活。\n\n同理，对于生成图像 G，有：\n\n$$G^{(G)[l]}_{kk'} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}\\_W}\\_{j=1} a^{(G)[l]}\\_{ijk} a^{(G)[l]}_{ijk'}$$\n\n因此，第 $l$ 层的风格代价函数为：\n\n$$J^{[l]}_{style}(S, G) = \\frac{1}{(2n^{[l]}_Hn^{[l]}\\_Wn^{[l]}_C)^2} \\sum_k \\sum_{k'}(G^{(S)[l]}\\_{kk'} - G^{(G)[l]}_{kk'})^2$$\n\n如果对各层都使用风格代价函数，效果会更好。因此有：\n\n$$J_{style}(S, G) = \\sum_l \\lambda^{[l]} J^{[l]}_{style}(S, G)$$\n\n其中，$lambda$ 是用于设置不同层所占权重的超参数。\n","slug":"神经风格迁移","published":1,"updated":"2018-09-05T11:51:36.557Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds6s0049pcvor4x38y4d","content":"<p><strong>神经风格迁移（Neural style transfer）</strong> 将参考风格图像的风格“迁移”到另外一张内容图像中，生成具有其特色的图像。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Neural-style-transfer.png\" alt=\"Neural-style-transfer\"></p>\n<h3 id=\"深度卷积网络在学什么？\"><a href=\"#深度卷积网络在学什么？\" class=\"headerlink\" title=\"深度卷积网络在学什么？\"></a>深度卷积网络在学什么？</h3><p>想要理解如何实现神经风格转换，首先要理解在输入图像数据后，一个深度卷积网络从中都学到了些什么。我们借助可视化来做到这一点。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Visualizing-deep-layers.png\" alt=\"Visualizing-deep-layers\"></p>\n<p>我们通过遍历所有的训练样本，找出使该层激活函数输出最大的 9 块图像区域。可以看出，浅层的隐藏层通常检测出的是原始图像的边缘、颜色、阴影等简单信息。随着层数的增加，隐藏单元能捕捉的区域更大，学习到的特征也由从边缘到纹理再到具体物体，变得更加复杂。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1311.2901.pdf\" target=\"_blank\" rel=\"noopener\">Zeiler and Fergus., 2013, Visualizing and understanding convolutional networks</a></p>\n<h3 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h3><p>神经风格迁移生成图片 G 的代价函数如下：</p>\n<p>$$J(G) = \\alpha \\cdot J_{content}(C, G) + \\beta \\cdot J_{style}(S, G)$$</p>\n<p>其中，$\\alpha$、$\\beta$ 是用于控制相似度比重的超参数。</p>\n<p>神经风格迁移的算法步骤如下：</p>\n<ol>\n<li>随机生成图片 G 的所有像素点；</li>\n<li>使用梯度下降算法使代价函数最小化，以不断修正 G 的所有像素点。</li>\n</ol>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1508.06576v2.pdf\" target=\"_blank\" rel=\"noopener\">Gatys al., 2015. A neural algorithm of artistic style</a></p>\n<h4 id=\"内容代价函数\"><a href=\"#内容代价函数\" class=\"headerlink\" title=\"内容代价函数\"></a>内容代价函数</h4><p>上述代价函数包含一个内容代价部分和风格代价部分。我们先来讨论内容代价函数 $J_{content}(C, G)$，它表示内容图片 C 和生成图片 G 之间的相似度。</p>\n<p>$J_{content}(C, G)$ 的计算过程如下：</p>\n<ul>\n<li>使用一个预训练好的 CNN（例如 VGG）；</li>\n<li>选择一个隐藏层 $l$ 来计算内容代价。$l$ 太小则内容图片和生成图片像素级别相似，$l$ 太大则可能只有具体物体级别的相似。因此，$l$ 一般选一个中间层；</li>\n<li>设 $a^{(C)[l]}$、$a^{(G)[l]}$ 为 C 和 G 在 $l$ 层的激活，则有：</li>\n</ul>\n<p>$$J_{content}(C, G) = \\frac{1}{2}||(a^{(C)[l]} - a^{(G)[l]})||^2$$</p>\n<p>$a^{(C)[l]}$ 和 $a^{(G)[l]}$ 越相似，则 $J_{content}(C, G)$ 越小。</p>\n<h4 id=\"风格代价函数\"><a href=\"#风格代价函数\" class=\"headerlink\" title=\"风格代价函数\"></a>风格代价函数</h4><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Intuition-about-style-of-an-image.png\" alt=\"Intuition-about-style-of-an-image\"></p>\n<p>每个通道提取图片的特征不同，比如标为红色的通道提取的是图片的垂直纹理特征，标为黄色的通道提取的是图片的橙色背景特征。那么计算这两个通道的相关性，相关性的大小，即表示原始图片既包含了垂直纹理也包含了该橙色背景的可能性大小。通过 CNN，<strong>“风格”被定义为同一个隐藏层不同通道之间激活值的相关系数，因其反映了原始图片特征间的相互关系。</strong></p>\n<p>对于风格图像 S，选定网络中的第 $l$ 层，则相关系数以一个 gram 矩阵的形式表示：</p>\n<p>$$G^{(S)[l]}_{kk’} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}_W}_{j=1} a^{(S)[l]}_{ijk} a^{(S)[l]}_{ijk’}$$</p>\n<p>其中，$i$ 和 $j$ 为第 $l$ 层的高度和宽度；$k$ 和 $k’$ 为选定的通道，其范围为 $1$ 到 $n_C^{[l]}$；$a^{(S)[l]}_{ijk}$ 为激活。</p>\n<p>同理，对于生成图像 G，有：</p>\n<p>$$G^{(G)[l]}_{kk’} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}_W}_{j=1} a^{(G)[l]}_{ijk} a^{(G)[l]}_{ijk’}$$</p>\n<p>因此，第 $l$ 层的风格代价函数为：</p>\n<p>$$J^{[l]}_{style}(S, G) = \\frac{1}{(2n^{[l]}_Hn^{[l]}_Wn^{[l]}_C)^2} \\sum_k \\sum_{k’}(G^{(S)[l]}_{kk’} - G^{(G)[l]}_{kk’})^2$$</p>\n<p>如果对各层都使用风格代价函数，效果会更好。因此有：</p>\n<p>$$J_{style}(S, G) = \\sum_l \\lambda^{[l]} J^{[l]}_{style}(S, G)$$</p>\n<p>其中，$lambda$ 是用于设置不同层所占权重的超参数。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>神经风格迁移（Neural style transfer）</strong> 将参考风格图像的风格“迁移”到另外一张内容图像中，生成具有其特色的图像。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Neural-style-transfer.png\" alt=\"Neural-style-transfer\"></p>\n<h3 id=\"深度卷积网络在学什么？\"><a href=\"#深度卷积网络在学什么？\" class=\"headerlink\" title=\"深度卷积网络在学什么？\"></a>深度卷积网络在学什么？</h3><p>想要理解如何实现神经风格转换，首先要理解在输入图像数据后，一个深度卷积网络从中都学到了些什么。我们借助可视化来做到这一点。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Visualizing-deep-layers.png\" alt=\"Visualizing-deep-layers\"></p>\n<p>我们通过遍历所有的训练样本，找出使该层激活函数输出最大的 9 块图像区域。可以看出，浅层的隐藏层通常检测出的是原始图像的边缘、颜色、阴影等简单信息。随着层数的增加，隐藏单元能捕捉的区域更大，学习到的特征也由从边缘到纹理再到具体物体，变得更加复杂。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1311.2901.pdf\" target=\"_blank\" rel=\"noopener\">Zeiler and Fergus., 2013, Visualizing and understanding convolutional networks</a></p>\n<h3 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h3><p>神经风格迁移生成图片 G 的代价函数如下：</p>\n<p>$$J(G) = \\alpha \\cdot J_{content}(C, G) + \\beta \\cdot J_{style}(S, G)$$</p>\n<p>其中，$\\alpha$、$\\beta$ 是用于控制相似度比重的超参数。</p>\n<p>神经风格迁移的算法步骤如下：</p>\n<ol>\n<li>随机生成图片 G 的所有像素点；</li>\n<li>使用梯度下降算法使代价函数最小化，以不断修正 G 的所有像素点。</li>\n</ol>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1508.06576v2.pdf\" target=\"_blank\" rel=\"noopener\">Gatys al., 2015. A neural algorithm of artistic style</a></p>\n<h4 id=\"内容代价函数\"><a href=\"#内容代价函数\" class=\"headerlink\" title=\"内容代价函数\"></a>内容代价函数</h4><p>上述代价函数包含一个内容代价部分和风格代价部分。我们先来讨论内容代价函数 $J_{content}(C, G)$，它表示内容图片 C 和生成图片 G 之间的相似度。</p>\n<p>$J_{content}(C, G)$ 的计算过程如下：</p>\n<ul>\n<li>使用一个预训练好的 CNN（例如 VGG）；</li>\n<li>选择一个隐藏层 $l$ 来计算内容代价。$l$ 太小则内容图片和生成图片像素级别相似，$l$ 太大则可能只有具体物体级别的相似。因此，$l$ 一般选一个中间层；</li>\n<li>设 $a^{(C)[l]}$、$a^{(G)[l]}$ 为 C 和 G 在 $l$ 层的激活，则有：</li>\n</ul>\n<p>$$J_{content}(C, G) = \\frac{1}{2}||(a^{(C)[l]} - a^{(G)[l]})||^2$$</p>\n<p>$a^{(C)[l]}$ 和 $a^{(G)[l]}$ 越相似，则 $J_{content}(C, G)$ 越小。</p>\n<h4 id=\"风格代价函数\"><a href=\"#风格代价函数\" class=\"headerlink\" title=\"风格代价函数\"></a>风格代价函数</h4><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Intuition-about-style-of-an-image.png\" alt=\"Intuition-about-style-of-an-image\"></p>\n<p>每个通道提取图片的特征不同，比如标为红色的通道提取的是图片的垂直纹理特征，标为黄色的通道提取的是图片的橙色背景特征。那么计算这两个通道的相关性，相关性的大小，即表示原始图片既包含了垂直纹理也包含了该橙色背景的可能性大小。通过 CNN，<strong>“风格”被定义为同一个隐藏层不同通道之间激活值的相关系数，因其反映了原始图片特征间的相互关系。</strong></p>\n<p>对于风格图像 S，选定网络中的第 $l$ 层，则相关系数以一个 gram 矩阵的形式表示：</p>\n<p>$$G^{(S)[l]}_{kk’} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}_W}_{j=1} a^{(S)[l]}_{ijk} a^{(S)[l]}_{ijk’}$$</p>\n<p>其中，$i$ 和 $j$ 为第 $l$ 层的高度和宽度；$k$ 和 $k’$ 为选定的通道，其范围为 $1$ 到 $n_C^{[l]}$；$a^{(S)[l]}_{ijk}$ 为激活。</p>\n<p>同理，对于生成图像 G，有：</p>\n<p>$$G^{(G)[l]}_{kk’} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}_W}_{j=1} a^{(G)[l]}_{ijk} a^{(G)[l]}_{ijk’}$$</p>\n<p>因此，第 $l$ 层的风格代价函数为：</p>\n<p>$$J^{[l]}_{style}(S, G) = \\frac{1}{(2n^{[l]}_Hn^{[l]}_Wn^{[l]}_C)^2} \\sum_k \\sum_{k’}(G^{(S)[l]}_{kk’} - G^{(G)[l]}_{kk’})^2$$</p>\n<p>如果对各层都使用风格代价函数，效果会更好。因此有：</p>\n<p>$$J_{style}(S, G) = \\sum_l \\lambda^{[l]} J^{[l]}_{style}(S, G)$$</p>\n<p>其中，$lambda$ 是用于设置不同层所占权重的超参数。</p>\n"},{"title":"神经网络中的通用函数代码","date":"2018-07-21T08:58:55.000Z","_content":"\n## 激活函数\n\n### Sigmoid\n\n```python\ndef sigmoid(Z):\n    \"\"\"\n    Implements the sigmoid activation in numpy\n\n    Arguments:\n    Z -- numpy array of any shape\n\n    Returns:\n    A -- output of sigmoid(z), same shape as Z\n    cache -- returns Z as well, useful during backpropagation\n    \"\"\"\n    A = 1 / (1 + np.exp(-Z))\n    cache = Z\n    return A, cache\n\ndef sigmoid_backward(dA, cache):\n    \"\"\"\n    Implement the backward propagation for a single SIGMOID unit.\n\n    Arguments:\n    dA -- post-activation gradient, of any shape\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    s = 1 / (1 + np.exp(-Z))\n    dZ = dA * s * (1 - s)\n    assert (dZ.shape == Z.shape)\n    return dZ\n```\n\n### Relu\n\n```python\ndef relu(Z):\n    \"\"\"\n    Implement the RELU function.\n\n    Arguments:\n    Z -- Output of the linear layer, of any shape\n\n    Returns:\n    A -- Post-activation parameter, of the same shape as Z\n    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    A = np.maximum(0, Z)\n    assert(A.shape == Z.shape)\n    cache = Z\n    return A, cache\n\ndef relu_backward(dA, cache):\n    \"\"\"\n    Implement the backward propagation for a single RELU unit.\n\n    Arguments:\n    dA -- post-activation gradient, of any shape\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    dZ = np.array(dA, copy=True)  # just converting dz to a correct object.\n    # When z <= 0, you should set dz to 0 as well.\n    dZ[Z <= 0] = 0\n    assert (dZ.shape == Z.shape)\n    return dZ\n```\n\n## 代价函数\n\n### 交叉熵\n\n```python\ndef compute_cost(AL, Y):\n    \"\"\"\n    Implement the cost function\n\n    Arguments:\n    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n\n    Returns:\n    cost -- cross-entropy cost\n    \"\"\"\n    m = Y.shape[1]\n    # Compute loss from aL and y.\n    cost = -1 / m * np.sum(np.dot(Y, np.log(AL).T) + np.dot(1 - Y, np.log(1 - AL).T))\n    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n    assert(cost.shape == ())\n    return cost\n```\n\n### L1 and L2 Loss\n\n```python\ndef L1(yhat, y):\n    \"\"\"\n    Arguments:\n    yhat -- vector of size m (predicted labels)\n    y -- vector of size m (true labels)\n\n    Returns:\n    loss -- the value of the L1 loss function defined above\n    \"\"\"\n    loss = np.sum(abs(yhat - y))\n    return loss\n\ndef L2(yhat, y):\n    \"\"\"\n    Arguments:\n    yhat -- vector of size m (predicted labels)\n    y -- vector of size m (true labels)\n\n    Returns:\n    loss -- the value of the L2 loss function defined above\n    \"\"\"\n    loss = np.sum((y - yhat) ** 2)\n    return loss\n```\n\n## 线性函数\n\n```python\ndef linear_forward(A, W, b):\n    \"\"\"\n    Implement the linear part of a layer's forward propagation.\n\n    Arguments:\n    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n\n    Returns:\n    Z -- the input of the activation function, also called pre-activation parameter\n    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    Z = np.dot(W, A) + b\n    assert(Z.shape == (W.shape[0], A.shape[1]))\n    cache = (A, W, b)\n    return Z, cache\n\ndef linear_backward(dZ, cache):\n    \"\"\"\n    Implement the linear portion of backward propagation for a single layer (layer l)\n\n    Arguments:\n    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    A_prev, W, b = cache\n    m = A_prev.shape[1]\n    dW = 1 / m * np.dot(dZ, A_prev.T)\n    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n    dA_prev = np.dot(W.T, dZ)\n    assert (dA_prev.shape == A_prev.shape)\n    assert (dW.shape == W.shape)\n    assert (db.shape == b.shape)\n    return dA_prev, dW, db\n```\n\n## 线性到激活层\n\n```python\ndef linear_activation_forward(A_prev, W, b, activation):\n    \"\"\"\n    Implement the forward propagation for the LINEAR->ACTIVATION layer\n\n    Arguments:\n    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n\n    Returns:\n    A -- the output of the activation function, also called the post-activation value\n    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n             stored for computing the backward pass efficiently\n    \"\"\"\n    if activation == \"sigmoid\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = sigmoid(Z)\n    elif activation == \"relu\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = relu(Z)\n    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n    cache = (linear_cache, activation_cache)\n    return A, cache\n\ndef linear_activation_backward(dA, cache, activation):\n    \"\"\"\n    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n\n    Arguments:\n    dA -- post-activation gradient for current layer l\n    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    linear_cache, activation_cache = cache\n    if activation == \"relu\":\n        dZ = relu_backward(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    elif activation == \"sigmoid\":\n        dZ = sigmoid_backward(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    return dA_prev, dW, db\n```\n\n## L层前馈网络\n\n```python\ndef L_model_forward(X, parameters):\n    \"\"\"\n    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n\n    Arguments:\n    X -- data, numpy array of shape (input size, number of examples)\n    parameters -- output of initialize_parameters_deep()\n\n    Returns:\n    AL -- last post-activation value\n    caches -- list of caches containing:\n                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n    \"\"\"\n    caches = []\n    A = X\n    L = len(parameters) // 2                  # number of layers in the neural network\n    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n    for l in range(1, L):\n        A_prev = A\n        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n        caches.append(cache)\n    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")    # 注意这里是 A\n    caches.append(cache)\n    assert(AL.shape == (1, X.shape[1]))\n    return AL, caches\n\ndef L_model_backward(AL, Y, caches):\n    \"\"\"\n    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n\n    Arguments:\n    AL -- probability vector, output of the forward propagation (L_model_forward())\n    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n    caches -- list of caches containing:\n                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n\n    Returns:\n    grads -- A dictionary with the gradients\n             grads[\"dA\" + str(l)] = ...\n             grads[\"dW\" + str(l)] = ...\n             grads[\"db\" + str(l)] = ...\n    \"\"\"\n    grads = {}\n    L = len(caches)  # the number of layers\n    # m = AL.shape[1]\n    Y = Y.reshape(AL.shape)  # after this line, Y is the same shape as AL\n    # Initializing the backpropagation\n    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n    # Lth layer (SIGMOID -> LINEAR) gradients.\n    current_cache = caches[L - 1]\n    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, 'sigmoid')\n    for l in reversed(range(L - 1)):\n        # lth layer: (RELU -> LINEAR) gradients.\n        current_cache = caches[l]\n        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], caches[l], 'relu')\n        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n        grads[\"dW\" + str(l + 1)] = dW_temp\n        grads[\"db\" + str(l + 1)] = db_temp\n    return grads\n```\n\n## 参数初始化\n\n```python\ndef initialize_parameters_deep(layer_dims):\n    \"\"\"\n    Arguments:\n    layer_dims -- python array (list) containing the dimensions of each layer in our network\n\n    Returns:\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n                    bl -- bias vector of shape (layer_dims[l], 1)\n    \"\"\"\n    np.random.seed(3)\n    parameters = {}\n    L = len(layer_dims)            # number of layers in the network\n    for l in range(1, L):\n        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * np.sqrt(2 / layer_dims[l - 1])  # He initialization\n        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n    return parameters\n```\n\n## 参数更新（梯度下降）\n\n```python\ndef update_parameters(parameters, grads, learning_rate):\n    \"\"\"\n    Update parameters using gradient descent\n\n    Arguments:\n    parameters -- python dictionary containing your parameters\n    grads -- python dictionary containing your gradients, output of L_model_backward\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters\n                  parameters[\"W\" + str(l)] = ...\n                  parameters[\"b\" + str(l)] = ...\n    \"\"\"\n    L = len(parameters) // 2  # number of layers in the neural network\n    # Update rule for each parameter. Use a for loop.\n    for l in range(L):\n        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n    return parameters\n```\n\n## 训练模型\n\n```python\ndef L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False):  # lr was 0.009\n    \"\"\"\n    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n\n    Arguments:\n    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    costs = []                         # keep track of cost\n    # Parameters initialization.\n    parameters = initialize_parameters_deep(layers_dims)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n        AL, caches = L_model_forward(X, parameters)\n        # Compute cost.\n        cost = compute_cost(AL, Y)\n        # Backward propagation.\n        grads = L_model_backward(AL, Y, caches)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads, learning_rate=0.0075)\n        # Print the cost every 100 training example\n        if print_cost and i % 100 == 0:\n            print(\"Cost after iteration %i: %f\" % (i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)\n    # plot the cost\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Learning rate =\" + str(learning_rate))\n    plt.show()\n    return parameters\n```\n\n## 预测\n\n```python\ndef predict(X, y, parameters):\n    \"\"\"\n    This function is used to predict the results of a  L-layer neural network.\n\n    Arguments:\n    X -- data set of examples you would like to label\n    parameters -- parameters of the trained model\n\n    Returns:\n    p -- predictions for the given dataset X\n    \"\"\"\n    m = X.shape[1]\n    p = np.zeros((1, m))\n    # Forward propagation\n    probas, caches = L_model_forward(X, parameters)\n    # convert probas to 0/1 predictions\n    for i in range(0, probas.shape[1]):\n        if probas[0, i] > 0.5:\n            p[0, i] = 1\n        else:\n            p[0, i] = 0\n    print(\"Accuracy: \" + str(np.sum((p == y) / m)))\n    return p\n```\n","source":"_posts/神经网络中的通用函数代码.md","raw":"---\ntitle: 神经网络中的通用函数代码\ndate: 2018-07-21 16:58:55\ntags: 神经网络\ncategories: 深度学习\n---\n\n## 激活函数\n\n### Sigmoid\n\n```python\ndef sigmoid(Z):\n    \"\"\"\n    Implements the sigmoid activation in numpy\n\n    Arguments:\n    Z -- numpy array of any shape\n\n    Returns:\n    A -- output of sigmoid(z), same shape as Z\n    cache -- returns Z as well, useful during backpropagation\n    \"\"\"\n    A = 1 / (1 + np.exp(-Z))\n    cache = Z\n    return A, cache\n\ndef sigmoid_backward(dA, cache):\n    \"\"\"\n    Implement the backward propagation for a single SIGMOID unit.\n\n    Arguments:\n    dA -- post-activation gradient, of any shape\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    s = 1 / (1 + np.exp(-Z))\n    dZ = dA * s * (1 - s)\n    assert (dZ.shape == Z.shape)\n    return dZ\n```\n\n### Relu\n\n```python\ndef relu(Z):\n    \"\"\"\n    Implement the RELU function.\n\n    Arguments:\n    Z -- Output of the linear layer, of any shape\n\n    Returns:\n    A -- Post-activation parameter, of the same shape as Z\n    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    A = np.maximum(0, Z)\n    assert(A.shape == Z.shape)\n    cache = Z\n    return A, cache\n\ndef relu_backward(dA, cache):\n    \"\"\"\n    Implement the backward propagation for a single RELU unit.\n\n    Arguments:\n    dA -- post-activation gradient, of any shape\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    dZ = np.array(dA, copy=True)  # just converting dz to a correct object.\n    # When z <= 0, you should set dz to 0 as well.\n    dZ[Z <= 0] = 0\n    assert (dZ.shape == Z.shape)\n    return dZ\n```\n\n## 代价函数\n\n### 交叉熵\n\n```python\ndef compute_cost(AL, Y):\n    \"\"\"\n    Implement the cost function\n\n    Arguments:\n    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n\n    Returns:\n    cost -- cross-entropy cost\n    \"\"\"\n    m = Y.shape[1]\n    # Compute loss from aL and y.\n    cost = -1 / m * np.sum(np.dot(Y, np.log(AL).T) + np.dot(1 - Y, np.log(1 - AL).T))\n    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n    assert(cost.shape == ())\n    return cost\n```\n\n### L1 and L2 Loss\n\n```python\ndef L1(yhat, y):\n    \"\"\"\n    Arguments:\n    yhat -- vector of size m (predicted labels)\n    y -- vector of size m (true labels)\n\n    Returns:\n    loss -- the value of the L1 loss function defined above\n    \"\"\"\n    loss = np.sum(abs(yhat - y))\n    return loss\n\ndef L2(yhat, y):\n    \"\"\"\n    Arguments:\n    yhat -- vector of size m (predicted labels)\n    y -- vector of size m (true labels)\n\n    Returns:\n    loss -- the value of the L2 loss function defined above\n    \"\"\"\n    loss = np.sum((y - yhat) ** 2)\n    return loss\n```\n\n## 线性函数\n\n```python\ndef linear_forward(A, W, b):\n    \"\"\"\n    Implement the linear part of a layer's forward propagation.\n\n    Arguments:\n    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n\n    Returns:\n    Z -- the input of the activation function, also called pre-activation parameter\n    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    Z = np.dot(W, A) + b\n    assert(Z.shape == (W.shape[0], A.shape[1]))\n    cache = (A, W, b)\n    return Z, cache\n\ndef linear_backward(dZ, cache):\n    \"\"\"\n    Implement the linear portion of backward propagation for a single layer (layer l)\n\n    Arguments:\n    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    A_prev, W, b = cache\n    m = A_prev.shape[1]\n    dW = 1 / m * np.dot(dZ, A_prev.T)\n    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n    dA_prev = np.dot(W.T, dZ)\n    assert (dA_prev.shape == A_prev.shape)\n    assert (dW.shape == W.shape)\n    assert (db.shape == b.shape)\n    return dA_prev, dW, db\n```\n\n## 线性到激活层\n\n```python\ndef linear_activation_forward(A_prev, W, b, activation):\n    \"\"\"\n    Implement the forward propagation for the LINEAR->ACTIVATION layer\n\n    Arguments:\n    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n\n    Returns:\n    A -- the output of the activation function, also called the post-activation value\n    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n             stored for computing the backward pass efficiently\n    \"\"\"\n    if activation == \"sigmoid\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = sigmoid(Z)\n    elif activation == \"relu\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = relu(Z)\n    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n    cache = (linear_cache, activation_cache)\n    return A, cache\n\ndef linear_activation_backward(dA, cache, activation):\n    \"\"\"\n    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n\n    Arguments:\n    dA -- post-activation gradient for current layer l\n    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    linear_cache, activation_cache = cache\n    if activation == \"relu\":\n        dZ = relu_backward(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    elif activation == \"sigmoid\":\n        dZ = sigmoid_backward(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    return dA_prev, dW, db\n```\n\n## L层前馈网络\n\n```python\ndef L_model_forward(X, parameters):\n    \"\"\"\n    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n\n    Arguments:\n    X -- data, numpy array of shape (input size, number of examples)\n    parameters -- output of initialize_parameters_deep()\n\n    Returns:\n    AL -- last post-activation value\n    caches -- list of caches containing:\n                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n    \"\"\"\n    caches = []\n    A = X\n    L = len(parameters) // 2                  # number of layers in the neural network\n    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n    for l in range(1, L):\n        A_prev = A\n        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n        caches.append(cache)\n    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")    # 注意这里是 A\n    caches.append(cache)\n    assert(AL.shape == (1, X.shape[1]))\n    return AL, caches\n\ndef L_model_backward(AL, Y, caches):\n    \"\"\"\n    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n\n    Arguments:\n    AL -- probability vector, output of the forward propagation (L_model_forward())\n    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n    caches -- list of caches containing:\n                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n\n    Returns:\n    grads -- A dictionary with the gradients\n             grads[\"dA\" + str(l)] = ...\n             grads[\"dW\" + str(l)] = ...\n             grads[\"db\" + str(l)] = ...\n    \"\"\"\n    grads = {}\n    L = len(caches)  # the number of layers\n    # m = AL.shape[1]\n    Y = Y.reshape(AL.shape)  # after this line, Y is the same shape as AL\n    # Initializing the backpropagation\n    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n    # Lth layer (SIGMOID -> LINEAR) gradients.\n    current_cache = caches[L - 1]\n    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, 'sigmoid')\n    for l in reversed(range(L - 1)):\n        # lth layer: (RELU -> LINEAR) gradients.\n        current_cache = caches[l]\n        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], caches[l], 'relu')\n        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n        grads[\"dW\" + str(l + 1)] = dW_temp\n        grads[\"db\" + str(l + 1)] = db_temp\n    return grads\n```\n\n## 参数初始化\n\n```python\ndef initialize_parameters_deep(layer_dims):\n    \"\"\"\n    Arguments:\n    layer_dims -- python array (list) containing the dimensions of each layer in our network\n\n    Returns:\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n                    bl -- bias vector of shape (layer_dims[l], 1)\n    \"\"\"\n    np.random.seed(3)\n    parameters = {}\n    L = len(layer_dims)            # number of layers in the network\n    for l in range(1, L):\n        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * np.sqrt(2 / layer_dims[l - 1])  # He initialization\n        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n    return parameters\n```\n\n## 参数更新（梯度下降）\n\n```python\ndef update_parameters(parameters, grads, learning_rate):\n    \"\"\"\n    Update parameters using gradient descent\n\n    Arguments:\n    parameters -- python dictionary containing your parameters\n    grads -- python dictionary containing your gradients, output of L_model_backward\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters\n                  parameters[\"W\" + str(l)] = ...\n                  parameters[\"b\" + str(l)] = ...\n    \"\"\"\n    L = len(parameters) // 2  # number of layers in the neural network\n    # Update rule for each parameter. Use a for loop.\n    for l in range(L):\n        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n    return parameters\n```\n\n## 训练模型\n\n```python\ndef L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False):  # lr was 0.009\n    \"\"\"\n    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n\n    Arguments:\n    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    costs = []                         # keep track of cost\n    # Parameters initialization.\n    parameters = initialize_parameters_deep(layers_dims)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n        AL, caches = L_model_forward(X, parameters)\n        # Compute cost.\n        cost = compute_cost(AL, Y)\n        # Backward propagation.\n        grads = L_model_backward(AL, Y, caches)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads, learning_rate=0.0075)\n        # Print the cost every 100 training example\n        if print_cost and i % 100 == 0:\n            print(\"Cost after iteration %i: %f\" % (i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)\n    # plot the cost\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Learning rate =\" + str(learning_rate))\n    plt.show()\n    return parameters\n```\n\n## 预测\n\n```python\ndef predict(X, y, parameters):\n    \"\"\"\n    This function is used to predict the results of a  L-layer neural network.\n\n    Arguments:\n    X -- data set of examples you would like to label\n    parameters -- parameters of the trained model\n\n    Returns:\n    p -- predictions for the given dataset X\n    \"\"\"\n    m = X.shape[1]\n    p = np.zeros((1, m))\n    # Forward propagation\n    probas, caches = L_model_forward(X, parameters)\n    # convert probas to 0/1 predictions\n    for i in range(0, probas.shape[1]):\n        if probas[0, i] > 0.5:\n            p[0, i] = 1\n        else:\n            p[0, i] = 0\n    print(\"Accuracy: \" + str(np.sum((p == y) / m)))\n    return p\n```\n","slug":"神经网络中的通用函数代码","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds6s004cpcvofzjw1hgy","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"激活函数\"><a href=\"#激活函数\" class=\"headerlink\" title=\"激活函数\"></a>激活函数</h2><h3 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sigmoid</span><span class=\"params\">(Z)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implements the sigmoid activation in numpy</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    Z -- numpy array of any shape</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    A -- output of sigmoid(z), same shape as Z</span></span><br><span class=\"line\"><span class=\"string\">    cache -- returns Z as well, useful during backpropagation</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    A = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + np.exp(-Z))</span><br><span class=\"line\">    cache = Z</span><br><span class=\"line\">    <span class=\"keyword\">return</span> A, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sigmoid_backward</span><span class=\"params\">(dA, cache)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the backward propagation for a single SIGMOID unit.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    dA -- post-activation gradient, of any shape</span></span><br><span class=\"line\"><span class=\"string\">    cache -- 'Z' where we store for computing backward propagation efficiently</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    dZ -- Gradient of the cost with respect to Z</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    Z = cache</span><br><span class=\"line\">    s = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + np.exp(-Z))</span><br><span class=\"line\">    dZ = dA * s * (<span class=\"number\">1</span> - s)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dZ.shape == Z.shape)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dZ</span><br></pre></td></tr></table></figure>\n<h3 id=\"Relu\"><a href=\"#Relu\" class=\"headerlink\" title=\"Relu\"></a>Relu</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">relu</span><span class=\"params\">(Z)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the RELU function.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    Z -- Output of the linear layer, of any shape</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    A -- Post-activation parameter, of the same shape as Z</span></span><br><span class=\"line\"><span class=\"string\">    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    A = np.maximum(<span class=\"number\">0</span>, Z)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span>(A.shape == Z.shape)</span><br><span class=\"line\">    cache = Z</span><br><span class=\"line\">    <span class=\"keyword\">return</span> A, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">relu_backward</span><span class=\"params\">(dA, cache)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the backward propagation for a single RELU unit.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    dA -- post-activation gradient, of any shape</span></span><br><span class=\"line\"><span class=\"string\">    cache -- 'Z' where we store for computing backward propagation efficiently</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    dZ -- Gradient of the cost with respect to Z</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    Z = cache</span><br><span class=\"line\">    dZ = np.array(dA, copy=<span class=\"keyword\">True</span>)  <span class=\"comment\"># just converting dz to a correct object.</span></span><br><span class=\"line\">    <span class=\"comment\"># When z &lt;= 0, you should set dz to 0 as well.</span></span><br><span class=\"line\">    dZ[Z &lt;= <span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dZ.shape == Z.shape)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dZ</span><br></pre></td></tr></table></figure>\n<h2 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h2><h3 id=\"交叉熵\"><a href=\"#交叉熵\" class=\"headerlink\" title=\"交叉熵\"></a>交叉熵</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">compute_cost</span><span class=\"params\">(AL, Y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the cost function</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    cost -- cross-entropy cost</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    m = Y.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"comment\"># Compute loss from aL and y.</span></span><br><span class=\"line\">    cost = <span class=\"number\">-1</span> / m * np.sum(np.dot(Y, np.log(AL).T) + np.dot(<span class=\"number\">1</span> - Y, np.log(<span class=\"number\">1</span> - AL).T))</span><br><span class=\"line\">    cost = np.squeeze(cost)      <span class=\"comment\"># To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span>(cost.shape == ())</span><br><span class=\"line\">    <span class=\"keyword\">return</span> cost</span><br></pre></td></tr></table></figure>\n<h3 id=\"L1-and-L2-Loss\"><a href=\"#L1-and-L2-Loss\" class=\"headerlink\" title=\"L1 and L2 Loss\"></a>L1 and L2 Loss</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L1</span><span class=\"params\">(yhat, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    yhat -- vector of size m (predicted labels)</span></span><br><span class=\"line\"><span class=\"string\">    y -- vector of size m (true labels)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    loss -- the value of the L1 loss function defined above</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    loss = np.sum(abs(yhat - y))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L2</span><span class=\"params\">(yhat, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    yhat -- vector of size m (predicted labels)</span></span><br><span class=\"line\"><span class=\"string\">    y -- vector of size m (true labels)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    loss -- the value of the L2 loss function defined above</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    loss = np.sum((y - yhat) ** <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss</span><br></pre></td></tr></table></figure>\n<h2 id=\"线性函数\"><a href=\"#线性函数\" class=\"headerlink\" title=\"线性函数\"></a>线性函数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear_forward</span><span class=\"params\">(A, W, b)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the linear part of a layer's forward propagation.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    A -- activations from previous layer (or input data): (size of previous layer, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)</span></span><br><span class=\"line\"><span class=\"string\">    b -- bias vector, numpy array of shape (size of the current layer, 1)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    Z -- the input of the activation function, also called pre-activation parameter</span></span><br><span class=\"line\"><span class=\"string\">    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    Z = np.dot(W, A) + b</span><br><span class=\"line\">    <span class=\"keyword\">assert</span>(Z.shape == (W.shape[<span class=\"number\">0</span>], A.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    cache = (A, W, b)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Z, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear_backward</span><span class=\"params\">(dZ, cache)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the linear portion of backward propagation for a single layer (layer l)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    dZ -- Gradient of the cost with respect to the linear output (of current layer l)</span></span><br><span class=\"line\"><span class=\"string\">    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev</span></span><br><span class=\"line\"><span class=\"string\">    dW -- Gradient of the cost with respect to W (current layer l), same shape as W</span></span><br><span class=\"line\"><span class=\"string\">    db -- Gradient of the cost with respect to b (current layer l), same shape as b</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    A_prev, W, b = cache</span><br><span class=\"line\">    m = A_prev.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    dW = <span class=\"number\">1</span> / m * np.dot(dZ, A_prev.T)</span><br><span class=\"line\">    db = <span class=\"number\">1</span> / m * np.sum(dZ, axis=<span class=\"number\">1</span>, keepdims=<span class=\"keyword\">True</span>)</span><br><span class=\"line\">    dA_prev = np.dot(W.T, dZ)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dA_prev.shape == A_prev.shape)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dW.shape == W.shape)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (db.shape == b.shape)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dA_prev, dW, db</span><br></pre></td></tr></table></figure>\n<h2 id=\"线性到激活层\"><a href=\"#线性到激活层\" class=\"headerlink\" title=\"线性到激活层\"></a>线性到激活层</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear_activation_forward</span><span class=\"params\">(A_prev, W, b, activation)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)</span></span><br><span class=\"line\"><span class=\"string\">    b -- bias vector, numpy array of shape (size of the current layer, 1)</span></span><br><span class=\"line\"><span class=\"string\">    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    A -- the output of the activation function, also called the post-activation value</span></span><br><span class=\"line\"><span class=\"string\">    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";</span></span><br><span class=\"line\"><span class=\"string\">             stored for computing the backward pass efficiently</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> activation == <span class=\"string\">\"sigmoid\"</span>:</span><br><span class=\"line\">        Z, linear_cache = linear_forward(A_prev, W, b)</span><br><span class=\"line\">        A, activation_cache = sigmoid(Z)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> activation == <span class=\"string\">\"relu\"</span>:</span><br><span class=\"line\">        Z, linear_cache = linear_forward(A_prev, W, b)</span><br><span class=\"line\">        A, activation_cache = relu(Z)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (A.shape == (W.shape[<span class=\"number\">0</span>], A_prev.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    cache = (linear_cache, activation_cache)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> A, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear_activation_backward</span><span class=\"params\">(dA, cache, activation)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    dA -- post-activation gradient for current layer l</span></span><br><span class=\"line\"><span class=\"string\">    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently</span></span><br><span class=\"line\"><span class=\"string\">    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev</span></span><br><span class=\"line\"><span class=\"string\">    dW -- Gradient of the cost with respect to W (current layer l), same shape as W</span></span><br><span class=\"line\"><span class=\"string\">    db -- Gradient of the cost with respect to b (current layer l), same shape as b</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    linear_cache, activation_cache = cache</span><br><span class=\"line\">    <span class=\"keyword\">if</span> activation == <span class=\"string\">\"relu\"</span>:</span><br><span class=\"line\">        dZ = relu_backward(dA, activation_cache)</span><br><span class=\"line\">        dA_prev, dW, db = linear_backward(dZ, linear_cache)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> activation == <span class=\"string\">\"sigmoid\"</span>:</span><br><span class=\"line\">        dZ = sigmoid_backward(dA, activation_cache)</span><br><span class=\"line\">        dA_prev, dW, db = linear_backward(dZ, linear_cache)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dA_prev, dW, db</span><br></pre></td></tr></table></figure>\n<h2 id=\"L层前馈网络\"><a href=\"#L层前馈网络\" class=\"headerlink\" title=\"L层前馈网络\"></a>L层前馈网络</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L_model_forward</span><span class=\"params\">(X, parameters)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement forward propagation for the [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID computation</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- data, numpy array of shape (input size, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- output of initialize_parameters_deep()</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    AL -- last post-activation value</span></span><br><span class=\"line\"><span class=\"string\">    caches -- list of caches containing:</span></span><br><span class=\"line\"><span class=\"string\">                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)</span></span><br><span class=\"line\"><span class=\"string\">                the cache of linear_sigmoid_forward() (there is one, indexed L-1)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    caches = []</span><br><span class=\"line\">    A = X</span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span>                  <span class=\"comment\"># number of layers in the neural network</span></span><br><span class=\"line\">    <span class=\"comment\"># Implement [LINEAR -&gt; RELU]*(L-1). Add \"cache\" to the \"caches\" list.</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, L):</span><br><span class=\"line\">        A_prev = A</span><br><span class=\"line\">        A, cache = linear_activation_forward(A_prev, parameters[<span class=\"string\">'W'</span> + str(l)], parameters[<span class=\"string\">'b'</span> + str(l)], <span class=\"string\">\"relu\"</span>)</span><br><span class=\"line\">        caches.append(cache)</span><br><span class=\"line\">    <span class=\"comment\"># Implement LINEAR -&gt; SIGMOID. Add \"cache\" to the \"caches\" list.</span></span><br><span class=\"line\">    AL, cache = linear_activation_forward(A, parameters[<span class=\"string\">'W'</span> + str(L)], parameters[<span class=\"string\">'b'</span> + str(L)], <span class=\"string\">\"sigmoid\"</span>)    <span class=\"comment\"># 注意这里是 A</span></span><br><span class=\"line\">    caches.append(cache)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span>(AL.shape == (<span class=\"number\">1</span>, X.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> AL, caches</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L_model_backward</span><span class=\"params\">(AL, Y, caches)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the backward propagation for the [LINEAR-&gt;RELU] * (L-1) -&gt; LINEAR -&gt; SIGMOID group</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    AL -- probability vector, output of the forward propagation (L_model_forward())</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)</span></span><br><span class=\"line\"><span class=\"string\">    caches -- list of caches containing:</span></span><br><span class=\"line\"><span class=\"string\">                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)</span></span><br><span class=\"line\"><span class=\"string\">                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    grads -- A dictionary with the gradients</span></span><br><span class=\"line\"><span class=\"string\">             grads[\"dA\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">             grads[\"dW\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">             grads[\"db\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    grads = &#123;&#125;</span><br><span class=\"line\">    L = len(caches)  <span class=\"comment\"># the number of layers</span></span><br><span class=\"line\">    <span class=\"comment\"># m = AL.shape[1]</span></span><br><span class=\"line\">    Y = Y.reshape(AL.shape)  <span class=\"comment\"># after this line, Y is the same shape as AL</span></span><br><span class=\"line\">    <span class=\"comment\"># Initializing the backpropagation</span></span><br><span class=\"line\">    dAL = - (np.divide(Y, AL) - np.divide(<span class=\"number\">1</span> - Y, <span class=\"number\">1</span> - AL))</span><br><span class=\"line\">    <span class=\"comment\"># Lth layer (SIGMOID -&gt; LINEAR) gradients.</span></span><br><span class=\"line\">    current_cache = caches[L - <span class=\"number\">1</span>]</span><br><span class=\"line\">    grads[<span class=\"string\">\"dA\"</span> + str(L)], grads[<span class=\"string\">\"dW\"</span> + str(L)], grads[<span class=\"string\">\"db\"</span> + str(L)] = linear_activation_backward(dAL, current_cache, <span class=\"string\">'sigmoid'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> reversed(range(L - <span class=\"number\">1</span>)):</span><br><span class=\"line\">        <span class=\"comment\"># lth layer: (RELU -&gt; LINEAR) gradients.</span></span><br><span class=\"line\">        current_cache = caches[l]</span><br><span class=\"line\">        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[<span class=\"string\">\"dA\"</span> + str(l + <span class=\"number\">2</span>)], caches[l], <span class=\"string\">'relu'</span>)</span><br><span class=\"line\">        grads[<span class=\"string\">\"dA\"</span> + str(l + <span class=\"number\">1</span>)] = dA_prev_temp</span><br><span class=\"line\">        grads[<span class=\"string\">\"dW\"</span> + str(l + <span class=\"number\">1</span>)] = dW_temp</span><br><span class=\"line\">        grads[<span class=\"string\">\"db\"</span> + str(l + <span class=\"number\">1</span>)] = db_temp</span><br><span class=\"line\">    <span class=\"keyword\">return</span> grads</span><br></pre></td></tr></table></figure>\n<h2 id=\"参数初始化\"><a href=\"#参数初始化\" class=\"headerlink\" title=\"参数初始化\"></a>参数初始化</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">initialize_parameters_deep</span><span class=\"params\">(layer_dims)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    layer_dims -- python array (list) containing the dimensions of each layer in our network</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":</span></span><br><span class=\"line\"><span class=\"string\">                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])</span></span><br><span class=\"line\"><span class=\"string\">                    bl -- bias vector of shape (layer_dims[l], 1)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    np.random.seed(<span class=\"number\">3</span>)</span><br><span class=\"line\">    parameters = &#123;&#125;</span><br><span class=\"line\">    L = len(layer_dims)            <span class=\"comment\"># number of layers in the network</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, L):</span><br><span class=\"line\">        parameters[<span class=\"string\">'W'</span> + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - <span class=\"number\">1</span>]) * np.sqrt(<span class=\"number\">2</span> / layer_dims[l - <span class=\"number\">1</span>])  <span class=\"comment\"># He initialization</span></span><br><span class=\"line\">        parameters[<span class=\"string\">'b'</span> + str(l)] = np.zeros((layer_dims[l], <span class=\"number\">1</span>))</span><br><span class=\"line\">        <span class=\"keyword\">assert</span>(parameters[<span class=\"string\">'W'</span> + str(l)].shape == (layer_dims[l], layer_dims[l - <span class=\"number\">1</span>]))</span><br><span class=\"line\">        <span class=\"keyword\">assert</span>(parameters[<span class=\"string\">'b'</span> + str(l)].shape == (layer_dims[l], <span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br></pre></td></tr></table></figure>\n<h2 id=\"参数更新（梯度下降）\"><a href=\"#参数更新（梯度下降）\" class=\"headerlink\" title=\"参数更新（梯度下降）\"></a>参数更新（梯度下降）</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">update_parameters</span><span class=\"params\">(parameters, grads, learning_rate)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Update parameters using gradient descent</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters</span></span><br><span class=\"line\"><span class=\"string\">    grads -- python dictionary containing your gradients, output of L_model_backward</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your updated parameters</span></span><br><span class=\"line\"><span class=\"string\">                  parameters[\"W\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">                  parameters[\"b\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span>  <span class=\"comment\"># number of layers in the neural network</span></span><br><span class=\"line\">    <span class=\"comment\"># Update rule for each parameter. Use a for loop.</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):</span><br><span class=\"line\">        parameters[<span class=\"string\">\"W\"</span> + str(l + <span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"W\"</span> + str(l + <span class=\"number\">1</span>)] - learning_rate * grads[<span class=\"string\">\"dW\"</span> + str(l + <span class=\"number\">1</span>)]</span><br><span class=\"line\">        parameters[<span class=\"string\">\"b\"</span> + str(l + <span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"b\"</span> + str(l + <span class=\"number\">1</span>)] - learning_rate * grads[<span class=\"string\">\"db\"</span> + str(l + <span class=\"number\">1</span>)]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br></pre></td></tr></table></figure>\n<h2 id=\"训练模型\"><a href=\"#训练模型\" class=\"headerlink\" title=\"训练模型\"></a>训练模型</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L_layer_model</span><span class=\"params\">(X, Y, layers_dims, learning_rate=<span class=\"number\">0.0075</span>, num_iterations=<span class=\"number\">3000</span>, print_cost=False)</span>:</span>  <span class=\"comment\"># lr was 0.009</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implements a L-layer neural network: [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- learning rate of the gradient descent update rule</span></span><br><span class=\"line\"><span class=\"string\">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class=\"line\"><span class=\"string\">    print_cost -- if True, it prints the cost every 100 steps</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    costs = []                         <span class=\"comment\"># keep track of cost</span></span><br><span class=\"line\">    <span class=\"comment\"># Parameters initialization.</span></span><br><span class=\"line\">    parameters = initialize_parameters_deep(layers_dims)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Loop (gradient descent)</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_iterations):</span><br><span class=\"line\">        <span class=\"comment\"># Forward propagation: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class=\"line\">        AL, caches = L_model_forward(X, parameters)</span><br><span class=\"line\">        <span class=\"comment\"># Compute cost.</span></span><br><span class=\"line\">        cost = compute_cost(AL, Y)</span><br><span class=\"line\">        <span class=\"comment\"># Backward propagation.</span></span><br><span class=\"line\">        grads = L_model_backward(AL, Y, caches)</span><br><span class=\"line\">        <span class=\"comment\"># Update parameters.</span></span><br><span class=\"line\">        parameters = update_parameters(parameters, grads, learning_rate=<span class=\"number\">0.0075</span>)</span><br><span class=\"line\">        <span class=\"comment\"># Print the cost every 100 training example</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            print(<span class=\"string\">\"Cost after iteration %i: %f\"</span> % (i, cost))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            costs.append(cost)</span><br><span class=\"line\">    <span class=\"comment\"># plot the cost</span></span><br><span class=\"line\">    plt.plot(np.squeeze(costs))</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">'cost'</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">'iterations (per tens)'</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">\"Learning rate =\"</span> + str(learning_rate))</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br></pre></td></tr></table></figure>\n<h2 id=\"预测\"><a href=\"#预测\" class=\"headerlink\" title=\"预测\"></a>预测</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">predict</span><span class=\"params\">(X, y, parameters)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    This function is used to predict the results of a  L-layer neural network.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- data set of examples you would like to label</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- parameters of the trained model</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    p -- predictions for the given dataset X</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    m = X.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    p = np.zeros((<span class=\"number\">1</span>, m))</span><br><span class=\"line\">    <span class=\"comment\"># Forward propagation</span></span><br><span class=\"line\">    probas, caches = L_model_forward(X, parameters)</span><br><span class=\"line\">    <span class=\"comment\"># convert probas to 0/1 predictions</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, probas.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> probas[<span class=\"number\">0</span>, i] &gt; <span class=\"number\">0.5</span>:</span><br><span class=\"line\">            p[<span class=\"number\">0</span>, i] = <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            p[<span class=\"number\">0</span>, i] = <span class=\"number\">0</span></span><br><span class=\"line\">    print(<span class=\"string\">\"Accuracy: \"</span> + str(np.sum((p == y) / m)))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"激活函数\"><a href=\"#激活函数\" class=\"headerlink\" title=\"激活函数\"></a>激活函数</h2><h3 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sigmoid</span><span class=\"params\">(Z)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implements the sigmoid activation in numpy</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    Z -- numpy array of any shape</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    A -- output of sigmoid(z), same shape as Z</span></span><br><span class=\"line\"><span class=\"string\">    cache -- returns Z as well, useful during backpropagation</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    A = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + np.exp(-Z))</span><br><span class=\"line\">    cache = Z</span><br><span class=\"line\">    <span class=\"keyword\">return</span> A, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sigmoid_backward</span><span class=\"params\">(dA, cache)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the backward propagation for a single SIGMOID unit.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    dA -- post-activation gradient, of any shape</span></span><br><span class=\"line\"><span class=\"string\">    cache -- 'Z' where we store for computing backward propagation efficiently</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    dZ -- Gradient of the cost with respect to Z</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    Z = cache</span><br><span class=\"line\">    s = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + np.exp(-Z))</span><br><span class=\"line\">    dZ = dA * s * (<span class=\"number\">1</span> - s)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dZ.shape == Z.shape)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dZ</span><br></pre></td></tr></table></figure>\n<h3 id=\"Relu\"><a href=\"#Relu\" class=\"headerlink\" title=\"Relu\"></a>Relu</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">relu</span><span class=\"params\">(Z)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the RELU function.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    Z -- Output of the linear layer, of any shape</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    A -- Post-activation parameter, of the same shape as Z</span></span><br><span class=\"line\"><span class=\"string\">    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    A = np.maximum(<span class=\"number\">0</span>, Z)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span>(A.shape == Z.shape)</span><br><span class=\"line\">    cache = Z</span><br><span class=\"line\">    <span class=\"keyword\">return</span> A, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">relu_backward</span><span class=\"params\">(dA, cache)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the backward propagation for a single RELU unit.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    dA -- post-activation gradient, of any shape</span></span><br><span class=\"line\"><span class=\"string\">    cache -- 'Z' where we store for computing backward propagation efficiently</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    dZ -- Gradient of the cost with respect to Z</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    Z = cache</span><br><span class=\"line\">    dZ = np.array(dA, copy=<span class=\"keyword\">True</span>)  <span class=\"comment\"># just converting dz to a correct object.</span></span><br><span class=\"line\">    <span class=\"comment\"># When z &lt;= 0, you should set dz to 0 as well.</span></span><br><span class=\"line\">    dZ[Z &lt;= <span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dZ.shape == Z.shape)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dZ</span><br></pre></td></tr></table></figure>\n<h2 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h2><h3 id=\"交叉熵\"><a href=\"#交叉熵\" class=\"headerlink\" title=\"交叉熵\"></a>交叉熵</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">compute_cost</span><span class=\"params\">(AL, Y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the cost function</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    cost -- cross-entropy cost</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    m = Y.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"comment\"># Compute loss from aL and y.</span></span><br><span class=\"line\">    cost = <span class=\"number\">-1</span> / m * np.sum(np.dot(Y, np.log(AL).T) + np.dot(<span class=\"number\">1</span> - Y, np.log(<span class=\"number\">1</span> - AL).T))</span><br><span class=\"line\">    cost = np.squeeze(cost)      <span class=\"comment\"># To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span>(cost.shape == ())</span><br><span class=\"line\">    <span class=\"keyword\">return</span> cost</span><br></pre></td></tr></table></figure>\n<h3 id=\"L1-and-L2-Loss\"><a href=\"#L1-and-L2-Loss\" class=\"headerlink\" title=\"L1 and L2 Loss\"></a>L1 and L2 Loss</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L1</span><span class=\"params\">(yhat, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    yhat -- vector of size m (predicted labels)</span></span><br><span class=\"line\"><span class=\"string\">    y -- vector of size m (true labels)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    loss -- the value of the L1 loss function defined above</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    loss = np.sum(abs(yhat - y))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L2</span><span class=\"params\">(yhat, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    yhat -- vector of size m (predicted labels)</span></span><br><span class=\"line\"><span class=\"string\">    y -- vector of size m (true labels)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    loss -- the value of the L2 loss function defined above</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    loss = np.sum((y - yhat) ** <span class=\"number\">2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss</span><br></pre></td></tr></table></figure>\n<h2 id=\"线性函数\"><a href=\"#线性函数\" class=\"headerlink\" title=\"线性函数\"></a>线性函数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear_forward</span><span class=\"params\">(A, W, b)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the linear part of a layer's forward propagation.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    A -- activations from previous layer (or input data): (size of previous layer, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)</span></span><br><span class=\"line\"><span class=\"string\">    b -- bias vector, numpy array of shape (size of the current layer, 1)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    Z -- the input of the activation function, also called pre-activation parameter</span></span><br><span class=\"line\"><span class=\"string\">    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    Z = np.dot(W, A) + b</span><br><span class=\"line\">    <span class=\"keyword\">assert</span>(Z.shape == (W.shape[<span class=\"number\">0</span>], A.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    cache = (A, W, b)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Z, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear_backward</span><span class=\"params\">(dZ, cache)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the linear portion of backward propagation for a single layer (layer l)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    dZ -- Gradient of the cost with respect to the linear output (of current layer l)</span></span><br><span class=\"line\"><span class=\"string\">    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev</span></span><br><span class=\"line\"><span class=\"string\">    dW -- Gradient of the cost with respect to W (current layer l), same shape as W</span></span><br><span class=\"line\"><span class=\"string\">    db -- Gradient of the cost with respect to b (current layer l), same shape as b</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    A_prev, W, b = cache</span><br><span class=\"line\">    m = A_prev.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    dW = <span class=\"number\">1</span> / m * np.dot(dZ, A_prev.T)</span><br><span class=\"line\">    db = <span class=\"number\">1</span> / m * np.sum(dZ, axis=<span class=\"number\">1</span>, keepdims=<span class=\"keyword\">True</span>)</span><br><span class=\"line\">    dA_prev = np.dot(W.T, dZ)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dA_prev.shape == A_prev.shape)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dW.shape == W.shape)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (db.shape == b.shape)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dA_prev, dW, db</span><br></pre></td></tr></table></figure>\n<h2 id=\"线性到激活层\"><a href=\"#线性到激活层\" class=\"headerlink\" title=\"线性到激活层\"></a>线性到激活层</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear_activation_forward</span><span class=\"params\">(A_prev, W, b, activation)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)</span></span><br><span class=\"line\"><span class=\"string\">    b -- bias vector, numpy array of shape (size of the current layer, 1)</span></span><br><span class=\"line\"><span class=\"string\">    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    A -- the output of the activation function, also called the post-activation value</span></span><br><span class=\"line\"><span class=\"string\">    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";</span></span><br><span class=\"line\"><span class=\"string\">             stored for computing the backward pass efficiently</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> activation == <span class=\"string\">\"sigmoid\"</span>:</span><br><span class=\"line\">        Z, linear_cache = linear_forward(A_prev, W, b)</span><br><span class=\"line\">        A, activation_cache = sigmoid(Z)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> activation == <span class=\"string\">\"relu\"</span>:</span><br><span class=\"line\">        Z, linear_cache = linear_forward(A_prev, W, b)</span><br><span class=\"line\">        A, activation_cache = relu(Z)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (A.shape == (W.shape[<span class=\"number\">0</span>], A_prev.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    cache = (linear_cache, activation_cache)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> A, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear_activation_backward</span><span class=\"params\">(dA, cache, activation)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    dA -- post-activation gradient for current layer l</span></span><br><span class=\"line\"><span class=\"string\">    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently</span></span><br><span class=\"line\"><span class=\"string\">    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev</span></span><br><span class=\"line\"><span class=\"string\">    dW -- Gradient of the cost with respect to W (current layer l), same shape as W</span></span><br><span class=\"line\"><span class=\"string\">    db -- Gradient of the cost with respect to b (current layer l), same shape as b</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    linear_cache, activation_cache = cache</span><br><span class=\"line\">    <span class=\"keyword\">if</span> activation == <span class=\"string\">\"relu\"</span>:</span><br><span class=\"line\">        dZ = relu_backward(dA, activation_cache)</span><br><span class=\"line\">        dA_prev, dW, db = linear_backward(dZ, linear_cache)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> activation == <span class=\"string\">\"sigmoid\"</span>:</span><br><span class=\"line\">        dZ = sigmoid_backward(dA, activation_cache)</span><br><span class=\"line\">        dA_prev, dW, db = linear_backward(dZ, linear_cache)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dA_prev, dW, db</span><br></pre></td></tr></table></figure>\n<h2 id=\"L层前馈网络\"><a href=\"#L层前馈网络\" class=\"headerlink\" title=\"L层前馈网络\"></a>L层前馈网络</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L_model_forward</span><span class=\"params\">(X, parameters)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement forward propagation for the [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID computation</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- data, numpy array of shape (input size, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- output of initialize_parameters_deep()</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    AL -- last post-activation value</span></span><br><span class=\"line\"><span class=\"string\">    caches -- list of caches containing:</span></span><br><span class=\"line\"><span class=\"string\">                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)</span></span><br><span class=\"line\"><span class=\"string\">                the cache of linear_sigmoid_forward() (there is one, indexed L-1)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    caches = []</span><br><span class=\"line\">    A = X</span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span>                  <span class=\"comment\"># number of layers in the neural network</span></span><br><span class=\"line\">    <span class=\"comment\"># Implement [LINEAR -&gt; RELU]*(L-1). Add \"cache\" to the \"caches\" list.</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, L):</span><br><span class=\"line\">        A_prev = A</span><br><span class=\"line\">        A, cache = linear_activation_forward(A_prev, parameters[<span class=\"string\">'W'</span> + str(l)], parameters[<span class=\"string\">'b'</span> + str(l)], <span class=\"string\">\"relu\"</span>)</span><br><span class=\"line\">        caches.append(cache)</span><br><span class=\"line\">    <span class=\"comment\"># Implement LINEAR -&gt; SIGMOID. Add \"cache\" to the \"caches\" list.</span></span><br><span class=\"line\">    AL, cache = linear_activation_forward(A, parameters[<span class=\"string\">'W'</span> + str(L)], parameters[<span class=\"string\">'b'</span> + str(L)], <span class=\"string\">\"sigmoid\"</span>)    <span class=\"comment\"># 注意这里是 A</span></span><br><span class=\"line\">    caches.append(cache)</span><br><span class=\"line\">    <span class=\"keyword\">assert</span>(AL.shape == (<span class=\"number\">1</span>, X.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> AL, caches</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L_model_backward</span><span class=\"params\">(AL, Y, caches)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implement the backward propagation for the [LINEAR-&gt;RELU] * (L-1) -&gt; LINEAR -&gt; SIGMOID group</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    AL -- probability vector, output of the forward propagation (L_model_forward())</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)</span></span><br><span class=\"line\"><span class=\"string\">    caches -- list of caches containing:</span></span><br><span class=\"line\"><span class=\"string\">                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)</span></span><br><span class=\"line\"><span class=\"string\">                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    grads -- A dictionary with the gradients</span></span><br><span class=\"line\"><span class=\"string\">             grads[\"dA\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">             grads[\"dW\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">             grads[\"db\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    grads = &#123;&#125;</span><br><span class=\"line\">    L = len(caches)  <span class=\"comment\"># the number of layers</span></span><br><span class=\"line\">    <span class=\"comment\"># m = AL.shape[1]</span></span><br><span class=\"line\">    Y = Y.reshape(AL.shape)  <span class=\"comment\"># after this line, Y is the same shape as AL</span></span><br><span class=\"line\">    <span class=\"comment\"># Initializing the backpropagation</span></span><br><span class=\"line\">    dAL = - (np.divide(Y, AL) - np.divide(<span class=\"number\">1</span> - Y, <span class=\"number\">1</span> - AL))</span><br><span class=\"line\">    <span class=\"comment\"># Lth layer (SIGMOID -&gt; LINEAR) gradients.</span></span><br><span class=\"line\">    current_cache = caches[L - <span class=\"number\">1</span>]</span><br><span class=\"line\">    grads[<span class=\"string\">\"dA\"</span> + str(L)], grads[<span class=\"string\">\"dW\"</span> + str(L)], grads[<span class=\"string\">\"db\"</span> + str(L)] = linear_activation_backward(dAL, current_cache, <span class=\"string\">'sigmoid'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> reversed(range(L - <span class=\"number\">1</span>)):</span><br><span class=\"line\">        <span class=\"comment\"># lth layer: (RELU -&gt; LINEAR) gradients.</span></span><br><span class=\"line\">        current_cache = caches[l]</span><br><span class=\"line\">        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[<span class=\"string\">\"dA\"</span> + str(l + <span class=\"number\">2</span>)], caches[l], <span class=\"string\">'relu'</span>)</span><br><span class=\"line\">        grads[<span class=\"string\">\"dA\"</span> + str(l + <span class=\"number\">1</span>)] = dA_prev_temp</span><br><span class=\"line\">        grads[<span class=\"string\">\"dW\"</span> + str(l + <span class=\"number\">1</span>)] = dW_temp</span><br><span class=\"line\">        grads[<span class=\"string\">\"db\"</span> + str(l + <span class=\"number\">1</span>)] = db_temp</span><br><span class=\"line\">    <span class=\"keyword\">return</span> grads</span><br></pre></td></tr></table></figure>\n<h2 id=\"参数初始化\"><a href=\"#参数初始化\" class=\"headerlink\" title=\"参数初始化\"></a>参数初始化</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">initialize_parameters_deep</span><span class=\"params\">(layer_dims)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    layer_dims -- python array (list) containing the dimensions of each layer in our network</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":</span></span><br><span class=\"line\"><span class=\"string\">                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])</span></span><br><span class=\"line\"><span class=\"string\">                    bl -- bias vector of shape (layer_dims[l], 1)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    np.random.seed(<span class=\"number\">3</span>)</span><br><span class=\"line\">    parameters = &#123;&#125;</span><br><span class=\"line\">    L = len(layer_dims)            <span class=\"comment\"># number of layers in the network</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, L):</span><br><span class=\"line\">        parameters[<span class=\"string\">'W'</span> + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - <span class=\"number\">1</span>]) * np.sqrt(<span class=\"number\">2</span> / layer_dims[l - <span class=\"number\">1</span>])  <span class=\"comment\"># He initialization</span></span><br><span class=\"line\">        parameters[<span class=\"string\">'b'</span> + str(l)] = np.zeros((layer_dims[l], <span class=\"number\">1</span>))</span><br><span class=\"line\">        <span class=\"keyword\">assert</span>(parameters[<span class=\"string\">'W'</span> + str(l)].shape == (layer_dims[l], layer_dims[l - <span class=\"number\">1</span>]))</span><br><span class=\"line\">        <span class=\"keyword\">assert</span>(parameters[<span class=\"string\">'b'</span> + str(l)].shape == (layer_dims[l], <span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br></pre></td></tr></table></figure>\n<h2 id=\"参数更新（梯度下降）\"><a href=\"#参数更新（梯度下降）\" class=\"headerlink\" title=\"参数更新（梯度下降）\"></a>参数更新（梯度下降）</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">update_parameters</span><span class=\"params\">(parameters, grads, learning_rate)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Update parameters using gradient descent</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your parameters</span></span><br><span class=\"line\"><span class=\"string\">    grads -- python dictionary containing your gradients, output of L_model_backward</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- python dictionary containing your updated parameters</span></span><br><span class=\"line\"><span class=\"string\">                  parameters[\"W\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">                  parameters[\"b\" + str(l)] = ...</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    L = len(parameters) // <span class=\"number\">2</span>  <span class=\"comment\"># number of layers in the neural network</span></span><br><span class=\"line\">    <span class=\"comment\"># Update rule for each parameter. Use a for loop.</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(L):</span><br><span class=\"line\">        parameters[<span class=\"string\">\"W\"</span> + str(l + <span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"W\"</span> + str(l + <span class=\"number\">1</span>)] - learning_rate * grads[<span class=\"string\">\"dW\"</span> + str(l + <span class=\"number\">1</span>)]</span><br><span class=\"line\">        parameters[<span class=\"string\">\"b\"</span> + str(l + <span class=\"number\">1</span>)] = parameters[<span class=\"string\">\"b\"</span> + str(l + <span class=\"number\">1</span>)] - learning_rate * grads[<span class=\"string\">\"db\"</span> + str(l + <span class=\"number\">1</span>)]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br></pre></td></tr></table></figure>\n<h2 id=\"训练模型\"><a href=\"#训练模型\" class=\"headerlink\" title=\"训练模型\"></a>训练模型</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">L_layer_model</span><span class=\"params\">(X, Y, layers_dims, learning_rate=<span class=\"number\">0.0075</span>, num_iterations=<span class=\"number\">3000</span>, print_cost=False)</span>:</span>  <span class=\"comment\"># lr was 0.009</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Implements a L-layer neural network: [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)</span></span><br><span class=\"line\"><span class=\"string\">    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)</span></span><br><span class=\"line\"><span class=\"string\">    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).</span></span><br><span class=\"line\"><span class=\"string\">    learning_rate -- learning rate of the gradient descent update rule</span></span><br><span class=\"line\"><span class=\"string\">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class=\"line\"><span class=\"string\">    print_cost -- if True, it prints the cost every 100 steps</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    costs = []                         <span class=\"comment\"># keep track of cost</span></span><br><span class=\"line\">    <span class=\"comment\"># Parameters initialization.</span></span><br><span class=\"line\">    parameters = initialize_parameters_deep(layers_dims)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Loop (gradient descent)</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, num_iterations):</span><br><span class=\"line\">        <span class=\"comment\"># Forward propagation: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class=\"line\">        AL, caches = L_model_forward(X, parameters)</span><br><span class=\"line\">        <span class=\"comment\"># Compute cost.</span></span><br><span class=\"line\">        cost = compute_cost(AL, Y)</span><br><span class=\"line\">        <span class=\"comment\"># Backward propagation.</span></span><br><span class=\"line\">        grads = L_model_backward(AL, Y, caches)</span><br><span class=\"line\">        <span class=\"comment\"># Update parameters.</span></span><br><span class=\"line\">        parameters = update_parameters(parameters, grads, learning_rate=<span class=\"number\">0.0075</span>)</span><br><span class=\"line\">        <span class=\"comment\"># Print the cost every 100 training example</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            print(<span class=\"string\">\"Cost after iteration %i: %f\"</span> % (i, cost))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> print_cost <span class=\"keyword\">and</span> i % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            costs.append(cost)</span><br><span class=\"line\">    <span class=\"comment\"># plot the cost</span></span><br><span class=\"line\">    plt.plot(np.squeeze(costs))</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">'cost'</span>)</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">'iterations (per tens)'</span>)</span><br><span class=\"line\">    plt.title(<span class=\"string\">\"Learning rate =\"</span> + str(learning_rate))</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parameters</span><br></pre></td></tr></table></figure>\n<h2 id=\"预测\"><a href=\"#预测\" class=\"headerlink\" title=\"预测\"></a>预测</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">predict</span><span class=\"params\">(X, y, parameters)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    This function is used to predict the results of a  L-layer neural network.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">    X -- data set of examples you would like to label</span></span><br><span class=\"line\"><span class=\"string\">    parameters -- parameters of the trained model</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    p -- predictions for the given dataset X</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    m = X.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    p = np.zeros((<span class=\"number\">1</span>, m))</span><br><span class=\"line\">    <span class=\"comment\"># Forward propagation</span></span><br><span class=\"line\">    probas, caches = L_model_forward(X, parameters)</span><br><span class=\"line\">    <span class=\"comment\"># convert probas to 0/1 predictions</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, probas.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> probas[<span class=\"number\">0</span>, i] &gt; <span class=\"number\">0.5</span>:</span><br><span class=\"line\">            p[<span class=\"number\">0</span>, i] = <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            p[<span class=\"number\">0</span>, i] = <span class=\"number\">0</span></span><br><span class=\"line\">    print(<span class=\"string\">\"Accuracy: \"</span> + str(np.sum((p == y) / m)))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p</span><br></pre></td></tr></table></figure>\n"},{"title":"深度学习中的优化算法","date":"2018-08-04T05:26:01.000Z","mathjax":true,"_content":"深度学习难以在大数据领域发挥最大效果的一个原因是，在巨大的数据集基础上进行训练速度很慢。而优化算法能够帮助快速训练模型，大大提高效率。\n\n## batch 梯度下降法\n\n**batch 梯度下降法**（批梯度下降法，我们之前一直使用的梯度下降法）是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。\n\n对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，处理速度就会比较慢。\n\n但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为 **mini-batch**。\n\n## Mini-Batch 梯度下降法\n\n**Mini-Batch 梯度下降法**（小批量梯度下降法）每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。\n\n使用 batch 梯度下降法，对整个训练集的一次遍历只能做一个梯度下降；而使用 Mini-Batch 梯度下降法，对整个训练集的一次遍历（称为一个 epoch）能做 mini-batch 个数个梯度下降。之后，可以一直遍历训练集，直到最后收敛到一个合适的精度。\n\nbatch 梯度下降法和 Mini-batch 梯度下降法代价函数的变化趋势如下：\n\n![training-with-mini-batch-gradient-descent](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/training-with-mini-batch-gradient-descent.png)\n\n### batch 的不同大小（size）带来的影响\n\n* mini-batch 的大小为 1，即是**随机梯度下降法（stochastic gradient descent）**，每个样本都是独立的 mini-batch；\n* mini-batch 的大小为 m（数据集大小），即是 batch 梯度下降法；\n\n![choosing-mini-batch-size](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/choosing-mini-batch-size.png)\n\n* batch 梯度下降法：\n    * 对所有 m 个训练样本执行一次梯度下降，**每一次迭代时间较长，训练过程慢**； \n    * 相对噪声低一些，幅度也大一些；\n    * 成本函数总是向减小的方向下降。\n\n* 随机梯度下降法：\n    * 对每一个训练样本执行一次梯度下降，训练速度快，但**丢失了向量化带来的计算加速**；\n    * 有很多噪声，减小学习率可以适当；\n    * 成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。\n\n因此，选择一个`1 < size < m`的合适的大小进行 Mini-batch 梯度下降，可以实现快速学习，也应用了向量化带来的好处，且成本函数的下降处于前两者之间。\n\n### mini-batch 大小的选择\n\n* 如果训练样本的大小比较小，如 $m \\lt 2000$ 时，选择 batch 梯度下降法；\n* 如果训练样本的大小比较大，选择 Mini-Batch 梯度下降法。为了和计算机的信息存储方式相适应，代码在 mini-batch 大小为 2 的幂次时运行要快一些。典型的大小为 $2^6$、$2^7$、...、$2^9$；\n* mini-batch 的大小要符合 CPU/GPU 内存。\n\nmini-batch 的大小也是一个重要的超变量，需要根据经验快速尝试，找到能够最有效地减少成本函数的值。\n\n### 获得 mini-batch 的步骤\n\n1. 将数据集打乱；\n2. 按照既定的大小分割数据集；\n\n其中打乱数据集的代码：\n\n```py\nm = X.shape[1] \npermutation = list(np.random.permutation(m))\nshuffled_X = X[:, permutation]\nshuffled_Y = Y[:, permutation].reshape((1,m))\n```\n\n`np.random.permutation`与`np.random.shuffle`有两处不同：\n\n1. 如果传给`permutation`一个矩阵，它会返回一个洗牌后的矩阵副本；而`shuffle`只是对一个矩阵进行洗牌，没有返回值。\n2. 如果传入一个整数，它会返回一个洗牌后的`arange`。\n\n### 符号表示\n\n* 使用上角小括号 i 表示训练集里的值，$x^{(i)}$ 是第 i 个训练样本；\n* 使用上角中括号 l 表示神经网络的层数，$z^{[l]}$ 表示神经网络中第 l 层的 z 值；\n* 现在引入大括号 t 来代表不同的 mini-batch，因此有 $X^{t}$、$Y^{t}$。\n\n## 指数平均加权\n\n**指数加权平均（Exponentially Weight Average）**是一种常用的序列数据处理方式，计算公式为：\n\n$$\nS\\_t = \n\\begin{cases} \nY\\_1, &t = 1 \\\\\\\\ \n\\beta S\\_{t-1} + (1-\\beta)Y_t, &t > 1 \n\\end{cases}\n$$\n\n其中 $Y\\_t$ 为 t 下的实际值，$S\\_t$ 为 t 下加权平均后的值，β 为权重值。\n\n指数加权平均数在统计学中被称为“指数加权移动平均值”。\n\n![Exponentially-weight-average](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Exponentially-weight-average.png)\n\n给定一个时间序列，例如伦敦一年每天的气温值，图中蓝色的点代表真实数据。对于一个即时的气温值，取权重值 β 为 0.9，根据求得的值可以得到图中的红色曲线，它反映了气温变化的大致趋势。\n\n当取权重值 β=0.98 时，可以得到图中更为平滑的绿色曲线。而当取权重值 β=0.5 时，得到图中噪点更多的黄色曲线。**β 越大相当于求取平均利用的天数越多**，曲线自然就会越平滑而且越滞后。\n\n### 理解指数平均加权\n\n当 β 为 0.9 时，\n\n$$v\\_{100} = 0.9v\\_{99} + 0.1 \\theta\\_{100}$$\n\n$$v\\_{99} = 0.9v\\_{98} + 0.1 \\theta\\_{99}$$\n\n$$v\\_{98} = 0.9v\\_{97} + 0.1 \\theta\\_{98}$$\n$$...$$\n\n展开：\n\n$$v\\_{100} = 0.1 \\theta\\_{100} + 0.1 \\* 0.9 \\theta\\_{99} + 0.1 \\* {(0.9)}^2 \\theta\\_{98} + ...$$\n\n其中 θi 指第 i 天的实际数据。所有 θ 前面的系数（不包括 0.1）相加起来为 1 或者接近于 1，这些系数被称作**偏差修正（Bias Correction）**。\n\n根据函数极限的一条定理：\n\n$$\\lim\\_{\\beta\\to 0}(1 - \\beta)^\\frac{1}{\\beta} = \\frac{1}{e} \\approx 0.368$$\n\n当 β 为 0.9 时，可以当作把过去 10 天的气温指数加权平均作为当日的气温，因为 10 天后权重已经下降到了当天的 1/3 左右。同理，当 β 为 0.98 时，可以把过去 50 天的气温指数加权平均作为当日的气温。\n\n因此，在计算当前时刻的平均值时，只需要前一天的平均值和当前时刻的值。\n\n$$v\\_t = \\beta v\\_{t-1} + (1 - \\beta)\\theta_t$$\n\n考虑到代码，只需要不断更新 v 即可：\n\n$$v := \\beta v + (1 - \\beta)\\theta_t$$\n<!--此处应有公式的实现代码-->\n\n指数平均加权并**不是最精准**的计算平均数的方法，你可以直接计算过去 10 天或 50 天的平均值来得到更好的估计，但缺点是保存数据需要占用更多内存，执行更加复杂，计算成本更加高昂。\n\n指数加权平均数公式的好处之一在于它只需要一行代码，且占用极少内存，因此**效率极高，且节省成本**。\n\n### 指数平均加权的偏差修正\n\n我们通常有\n\n$$v\\_0 = 0$$\n$$v\\_1 = 0.98v\\_0 + 0.02\\theta\\_1$$\n\n因此，$v\\_1$ 仅为第一个数据的 0.02（或者说 1-β），显然不准确。往后递推同理。\n\n因此，我们修改公式为\n\n$$v\\_t = \\frac{\\beta v\\_{t-1} + (1 - \\beta)\\theta_t}{1-\\beta^t}$$\n\n随着 t 的增大，β 的 t 次方趋近于 0。因此当 t 很大的时候，偏差修正几乎没有作用，但是在前期学习可以帮助更好的预测数据。在实际过程中，一般会忽略前期偏差的影响。\n\n## 动量梯度下降法\n\n**动量梯度下降（Gradient Descent with Momentum）**是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：\n\nfor l = 1, .. , L：\n\n$$v\\_{dW^{[l]}} = \\beta v\\_{dW^{[l]}} + (1 - \\beta) dW^{[l]}$$\n$$v\\_{db^{[l]}} = \\beta v\\_{db^{[l]}} + (1 - \\beta) db^{[l]}$$\n$$W^{[l]} := W^{[l]} - \\alpha v\\_{dW^{[l]}}$$\n$$b^{[l]} := b^{[l]} - \\alpha v\\_{db^{[l]}}$$\n\n其中，将动量衰减参数 β 设置为 0.9 是超参数的一个常见且效果不错的选择。当 β 被设置为 0 时，显然就成了 batch 梯度下降法。\n\n![Gradient-Descent-with-Momentum](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Gradient-Descent-with-Momentum.png)\n\n进行一般的梯度下降将会得到图中的蓝色曲线，由于存在上下波动，减缓了梯度下降的速度，因此只能使用一个较小的学习率进行迭代。如果用较大的学习率，结果可能会像紫色曲线一样偏离函数的范围。\n\n而使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色的曲线。\n\n当前后梯度方向一致时，动量梯度下降能够加速学习；而前后梯度方向不一致时，动量梯度下降能够抑制震荡。\n\n另外，在 10 次迭代之后，移动平均已经不再是一个具有偏差的预测。因此实际在使用梯度下降法或者动量梯度下降法时，不会同时进行偏差修正。\n\n### 动量梯度下降法的形象解释\n\n将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v\\_{dw}$、$v\\_{db}$ 相当于速度。\n\n小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。\n\n## RMSProp 算法\n\n**RMSProp（Root Mean Square Prop，均方根支）**算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为（省略了 l）：\n\n$$s\\_{dw} = \\beta s\\_{dw} + (1 - \\beta)(dw)^2$$\n$$s\\_{db} = \\beta s\\_{db} + (1 - \\beta)(db)^2$$\n$$w := w - \\alpha \\frac{dw}{\\sqrt{s\\_{dw} + \\epsilon}}$$\n$$b := b - \\alpha \\frac{db}{\\sqrt{s\\_{db} + \\epsilon}}$$\n\n其中，ϵ 是一个实际操作时加上的较小数（例如10^-8），为了防止分母太小而导致的数值不稳定。\n\n当 dw 或 db 较大时，$(dw)^2$、$(db)^2$会较大，进而 $s\\_{dw}$、$s\\_{db}$也会较大，最终使得\n\n$$\\frac{dw}{\\sqrt{s\\_{dw} + \\epsilon}}$$\n\n和\n\n$$\\frac{db}{\\sqrt{s\\_{db} + \\epsilon}}$$\n\n较小，从而减小某些维度梯度更新波动较大的情况，使下降速度变得更快。\n\n![RMSProp](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/RMSProp.png)\n\nRMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。并且，它和 Adam 优化算法已被证明适用于不同的深度学习网络结构。\n\n注意，β 也是一个超参数。\n\n## Adam 优化算法\n\n**Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）**基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。具体过程如下（省略了 l）：\n\n首先进行初始化：\n\n$$v\\_{dW} = 0, s\\_{dW} = 0, v\\_{db} = 0, s\\_{db} = 0$$\n\n用每一个 mini-batch 计算 dW、db，第 t 次迭代时：\n\n$$v\\_{dW} = \\beta\\_1 v\\_{dW} + (1 - \\beta\\_1) dW$$\n$$v\\_{db} = \\beta\\_1 v\\_{db} + (1 - \\beta\\_1) db$$\n$$s\\_{dW} = \\beta\\_2 s\\_{dW} + (1 - \\beta\\_2) (dW)^2$$\n$$s\\_{db} = \\beta\\_2 s\\_{db} + (1 - \\beta\\_2) (db)^2$$\n\n一般使用 Adam 算法时需要计算偏差修正：\n\n$$v^{corrected}\\_{dW} = \\frac{v\\_{dW}}{1-{\\beta\\_1}^t}$$\n$$v^{corrected}\\_{db} = \\frac{v\\_{db}}{1-{\\beta\\_1}^t}$$\n$$s^{corrected}\\_{dW} = \\frac{s\\_{dW}}{1-{\\beta\\_2}^t}$$\n$$s^{corrected}\\_{db} = \\frac{s\\_{db}}{1-{\\beta\\_2}^t}$$\n\n所以，更新 W、b 时有：\n\n$$W := W - \\alpha \\frac{v^{corrected}\\_{dW}}{\\sqrt{s^{corrected}\\_{dW} + \\epsilon}}$$\n\n$$b := b - \\alpha \\frac{v^{corrected}\\_{db}}{\\sqrt{s^{corrected}\\_{db}} + \\epsilon}$$\n\n（可以看到 Andrew 在这里 ϵ 没有写到平方根里去，和他在 RMSProp 中写的不太一样。考虑到 ϵ 所起的作用，我感觉影响不大）\n\n### 超参数的选择\n\nAdam 优化算法有很多的超参数，其中\n\n* 学习率 α：需要尝试一系列的值，来寻找比较合适的；\n* β1：常用的缺省值为 0.9；\n* β2：Adam 算法的作者建议为 0.999；\n* ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；\n\nβ1、β2、ϵ 通常不需要调试。\n\n## 学习率衰减\n\n如果设置一个固定的学习率 α，在最小值点附近，由于不同的 batch 中存在一定的噪声，因此不会精确收敛，而是始终在最小值周围一个较大的范围内波动。\n\n而如果随着时间慢慢减少学习率 α 的大小，在初期 α 较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小 α 的值，即减小步长，有助于算法的收敛，更容易接近最优解。\n\n最常用的学习率衰减方法：\n\n$$\\alpha = \\frac{1}{1 + decay\\\\\\_rate \\* epoch\\\\\\_num} \\* \\alpha\\_0$$\n\n其中，`decay_rate`为衰减率（超参数），`epoch_num`为将所有的训练样本完整过一遍的次数。\n\n* 指数衰减：\n\n$$\\alpha = 0.95^{epoch\\\\\\_num} \\* \\alpha\\_0$$\n\n* 其他：\n\n$$\\alpha = \\frac{k}{\\sqrt{epoch\\\\\\_num}} \\* \\alpha\\_0$$\n\n* 离散下降\n\n对于较小的模型，也有人会在训练时根据进度手动调小学习率。\n\n## 局部最优问题\n\n![saddle](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/saddle.png)\n\n**鞍点（saddle）**是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。\n\n结论：\n\n* 在训练较大的神经网络、存在大量参数，并且成本函数被定义在较高的维度空间时，困在极差的局部最优中是不大可能的；\n* 鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。\n","source":"_posts/深度学习中的优化算法.md","raw":"---\ntitle: 深度学习中的优化算法\ndate: 2018-08-04 13:26:01\ntags: 优化算法\ncategories: 深度学习\nmathjax: true\n---\n深度学习难以在大数据领域发挥最大效果的一个原因是，在巨大的数据集基础上进行训练速度很慢。而优化算法能够帮助快速训练模型，大大提高效率。\n\n## batch 梯度下降法\n\n**batch 梯度下降法**（批梯度下降法，我们之前一直使用的梯度下降法）是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。\n\n对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，处理速度就会比较慢。\n\n但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为 **mini-batch**。\n\n## Mini-Batch 梯度下降法\n\n**Mini-Batch 梯度下降法**（小批量梯度下降法）每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。\n\n使用 batch 梯度下降法，对整个训练集的一次遍历只能做一个梯度下降；而使用 Mini-Batch 梯度下降法，对整个训练集的一次遍历（称为一个 epoch）能做 mini-batch 个数个梯度下降。之后，可以一直遍历训练集，直到最后收敛到一个合适的精度。\n\nbatch 梯度下降法和 Mini-batch 梯度下降法代价函数的变化趋势如下：\n\n![training-with-mini-batch-gradient-descent](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/training-with-mini-batch-gradient-descent.png)\n\n### batch 的不同大小（size）带来的影响\n\n* mini-batch 的大小为 1，即是**随机梯度下降法（stochastic gradient descent）**，每个样本都是独立的 mini-batch；\n* mini-batch 的大小为 m（数据集大小），即是 batch 梯度下降法；\n\n![choosing-mini-batch-size](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/choosing-mini-batch-size.png)\n\n* batch 梯度下降法：\n    * 对所有 m 个训练样本执行一次梯度下降，**每一次迭代时间较长，训练过程慢**； \n    * 相对噪声低一些，幅度也大一些；\n    * 成本函数总是向减小的方向下降。\n\n* 随机梯度下降法：\n    * 对每一个训练样本执行一次梯度下降，训练速度快，但**丢失了向量化带来的计算加速**；\n    * 有很多噪声，减小学习率可以适当；\n    * 成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。\n\n因此，选择一个`1 < size < m`的合适的大小进行 Mini-batch 梯度下降，可以实现快速学习，也应用了向量化带来的好处，且成本函数的下降处于前两者之间。\n\n### mini-batch 大小的选择\n\n* 如果训练样本的大小比较小，如 $m \\lt 2000$ 时，选择 batch 梯度下降法；\n* 如果训练样本的大小比较大，选择 Mini-Batch 梯度下降法。为了和计算机的信息存储方式相适应，代码在 mini-batch 大小为 2 的幂次时运行要快一些。典型的大小为 $2^6$、$2^7$、...、$2^9$；\n* mini-batch 的大小要符合 CPU/GPU 内存。\n\nmini-batch 的大小也是一个重要的超变量，需要根据经验快速尝试，找到能够最有效地减少成本函数的值。\n\n### 获得 mini-batch 的步骤\n\n1. 将数据集打乱；\n2. 按照既定的大小分割数据集；\n\n其中打乱数据集的代码：\n\n```py\nm = X.shape[1] \npermutation = list(np.random.permutation(m))\nshuffled_X = X[:, permutation]\nshuffled_Y = Y[:, permutation].reshape((1,m))\n```\n\n`np.random.permutation`与`np.random.shuffle`有两处不同：\n\n1. 如果传给`permutation`一个矩阵，它会返回一个洗牌后的矩阵副本；而`shuffle`只是对一个矩阵进行洗牌，没有返回值。\n2. 如果传入一个整数，它会返回一个洗牌后的`arange`。\n\n### 符号表示\n\n* 使用上角小括号 i 表示训练集里的值，$x^{(i)}$ 是第 i 个训练样本；\n* 使用上角中括号 l 表示神经网络的层数，$z^{[l]}$ 表示神经网络中第 l 层的 z 值；\n* 现在引入大括号 t 来代表不同的 mini-batch，因此有 $X^{t}$、$Y^{t}$。\n\n## 指数平均加权\n\n**指数加权平均（Exponentially Weight Average）**是一种常用的序列数据处理方式，计算公式为：\n\n$$\nS\\_t = \n\\begin{cases} \nY\\_1, &t = 1 \\\\\\\\ \n\\beta S\\_{t-1} + (1-\\beta)Y_t, &t > 1 \n\\end{cases}\n$$\n\n其中 $Y\\_t$ 为 t 下的实际值，$S\\_t$ 为 t 下加权平均后的值，β 为权重值。\n\n指数加权平均数在统计学中被称为“指数加权移动平均值”。\n\n![Exponentially-weight-average](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Exponentially-weight-average.png)\n\n给定一个时间序列，例如伦敦一年每天的气温值，图中蓝色的点代表真实数据。对于一个即时的气温值，取权重值 β 为 0.9，根据求得的值可以得到图中的红色曲线，它反映了气温变化的大致趋势。\n\n当取权重值 β=0.98 时，可以得到图中更为平滑的绿色曲线。而当取权重值 β=0.5 时，得到图中噪点更多的黄色曲线。**β 越大相当于求取平均利用的天数越多**，曲线自然就会越平滑而且越滞后。\n\n### 理解指数平均加权\n\n当 β 为 0.9 时，\n\n$$v\\_{100} = 0.9v\\_{99} + 0.1 \\theta\\_{100}$$\n\n$$v\\_{99} = 0.9v\\_{98} + 0.1 \\theta\\_{99}$$\n\n$$v\\_{98} = 0.9v\\_{97} + 0.1 \\theta\\_{98}$$\n$$...$$\n\n展开：\n\n$$v\\_{100} = 0.1 \\theta\\_{100} + 0.1 \\* 0.9 \\theta\\_{99} + 0.1 \\* {(0.9)}^2 \\theta\\_{98} + ...$$\n\n其中 θi 指第 i 天的实际数据。所有 θ 前面的系数（不包括 0.1）相加起来为 1 或者接近于 1，这些系数被称作**偏差修正（Bias Correction）**。\n\n根据函数极限的一条定理：\n\n$$\\lim\\_{\\beta\\to 0}(1 - \\beta)^\\frac{1}{\\beta} = \\frac{1}{e} \\approx 0.368$$\n\n当 β 为 0.9 时，可以当作把过去 10 天的气温指数加权平均作为当日的气温，因为 10 天后权重已经下降到了当天的 1/3 左右。同理，当 β 为 0.98 时，可以把过去 50 天的气温指数加权平均作为当日的气温。\n\n因此，在计算当前时刻的平均值时，只需要前一天的平均值和当前时刻的值。\n\n$$v\\_t = \\beta v\\_{t-1} + (1 - \\beta)\\theta_t$$\n\n考虑到代码，只需要不断更新 v 即可：\n\n$$v := \\beta v + (1 - \\beta)\\theta_t$$\n<!--此处应有公式的实现代码-->\n\n指数平均加权并**不是最精准**的计算平均数的方法，你可以直接计算过去 10 天或 50 天的平均值来得到更好的估计，但缺点是保存数据需要占用更多内存，执行更加复杂，计算成本更加高昂。\n\n指数加权平均数公式的好处之一在于它只需要一行代码，且占用极少内存，因此**效率极高，且节省成本**。\n\n### 指数平均加权的偏差修正\n\n我们通常有\n\n$$v\\_0 = 0$$\n$$v\\_1 = 0.98v\\_0 + 0.02\\theta\\_1$$\n\n因此，$v\\_1$ 仅为第一个数据的 0.02（或者说 1-β），显然不准确。往后递推同理。\n\n因此，我们修改公式为\n\n$$v\\_t = \\frac{\\beta v\\_{t-1} + (1 - \\beta)\\theta_t}{1-\\beta^t}$$\n\n随着 t 的增大，β 的 t 次方趋近于 0。因此当 t 很大的时候，偏差修正几乎没有作用，但是在前期学习可以帮助更好的预测数据。在实际过程中，一般会忽略前期偏差的影响。\n\n## 动量梯度下降法\n\n**动量梯度下降（Gradient Descent with Momentum）**是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：\n\nfor l = 1, .. , L：\n\n$$v\\_{dW^{[l]}} = \\beta v\\_{dW^{[l]}} + (1 - \\beta) dW^{[l]}$$\n$$v\\_{db^{[l]}} = \\beta v\\_{db^{[l]}} + (1 - \\beta) db^{[l]}$$\n$$W^{[l]} := W^{[l]} - \\alpha v\\_{dW^{[l]}}$$\n$$b^{[l]} := b^{[l]} - \\alpha v\\_{db^{[l]}}$$\n\n其中，将动量衰减参数 β 设置为 0.9 是超参数的一个常见且效果不错的选择。当 β 被设置为 0 时，显然就成了 batch 梯度下降法。\n\n![Gradient-Descent-with-Momentum](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Gradient-Descent-with-Momentum.png)\n\n进行一般的梯度下降将会得到图中的蓝色曲线，由于存在上下波动，减缓了梯度下降的速度，因此只能使用一个较小的学习率进行迭代。如果用较大的学习率，结果可能会像紫色曲线一样偏离函数的范围。\n\n而使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色的曲线。\n\n当前后梯度方向一致时，动量梯度下降能够加速学习；而前后梯度方向不一致时，动量梯度下降能够抑制震荡。\n\n另外，在 10 次迭代之后，移动平均已经不再是一个具有偏差的预测。因此实际在使用梯度下降法或者动量梯度下降法时，不会同时进行偏差修正。\n\n### 动量梯度下降法的形象解释\n\n将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v\\_{dw}$、$v\\_{db}$ 相当于速度。\n\n小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。\n\n## RMSProp 算法\n\n**RMSProp（Root Mean Square Prop，均方根支）**算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为（省略了 l）：\n\n$$s\\_{dw} = \\beta s\\_{dw} + (1 - \\beta)(dw)^2$$\n$$s\\_{db} = \\beta s\\_{db} + (1 - \\beta)(db)^2$$\n$$w := w - \\alpha \\frac{dw}{\\sqrt{s\\_{dw} + \\epsilon}}$$\n$$b := b - \\alpha \\frac{db}{\\sqrt{s\\_{db} + \\epsilon}}$$\n\n其中，ϵ 是一个实际操作时加上的较小数（例如10^-8），为了防止分母太小而导致的数值不稳定。\n\n当 dw 或 db 较大时，$(dw)^2$、$(db)^2$会较大，进而 $s\\_{dw}$、$s\\_{db}$也会较大，最终使得\n\n$$\\frac{dw}{\\sqrt{s\\_{dw} + \\epsilon}}$$\n\n和\n\n$$\\frac{db}{\\sqrt{s\\_{db} + \\epsilon}}$$\n\n较小，从而减小某些维度梯度更新波动较大的情况，使下降速度变得更快。\n\n![RMSProp](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/RMSProp.png)\n\nRMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。并且，它和 Adam 优化算法已被证明适用于不同的深度学习网络结构。\n\n注意，β 也是一个超参数。\n\n## Adam 优化算法\n\n**Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）**基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。具体过程如下（省略了 l）：\n\n首先进行初始化：\n\n$$v\\_{dW} = 0, s\\_{dW} = 0, v\\_{db} = 0, s\\_{db} = 0$$\n\n用每一个 mini-batch 计算 dW、db，第 t 次迭代时：\n\n$$v\\_{dW} = \\beta\\_1 v\\_{dW} + (1 - \\beta\\_1) dW$$\n$$v\\_{db} = \\beta\\_1 v\\_{db} + (1 - \\beta\\_1) db$$\n$$s\\_{dW} = \\beta\\_2 s\\_{dW} + (1 - \\beta\\_2) (dW)^2$$\n$$s\\_{db} = \\beta\\_2 s\\_{db} + (1 - \\beta\\_2) (db)^2$$\n\n一般使用 Adam 算法时需要计算偏差修正：\n\n$$v^{corrected}\\_{dW} = \\frac{v\\_{dW}}{1-{\\beta\\_1}^t}$$\n$$v^{corrected}\\_{db} = \\frac{v\\_{db}}{1-{\\beta\\_1}^t}$$\n$$s^{corrected}\\_{dW} = \\frac{s\\_{dW}}{1-{\\beta\\_2}^t}$$\n$$s^{corrected}\\_{db} = \\frac{s\\_{db}}{1-{\\beta\\_2}^t}$$\n\n所以，更新 W、b 时有：\n\n$$W := W - \\alpha \\frac{v^{corrected}\\_{dW}}{\\sqrt{s^{corrected}\\_{dW} + \\epsilon}}$$\n\n$$b := b - \\alpha \\frac{v^{corrected}\\_{db}}{\\sqrt{s^{corrected}\\_{db}} + \\epsilon}$$\n\n（可以看到 Andrew 在这里 ϵ 没有写到平方根里去，和他在 RMSProp 中写的不太一样。考虑到 ϵ 所起的作用，我感觉影响不大）\n\n### 超参数的选择\n\nAdam 优化算法有很多的超参数，其中\n\n* 学习率 α：需要尝试一系列的值，来寻找比较合适的；\n* β1：常用的缺省值为 0.9；\n* β2：Adam 算法的作者建议为 0.999；\n* ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；\n\nβ1、β2、ϵ 通常不需要调试。\n\n## 学习率衰减\n\n如果设置一个固定的学习率 α，在最小值点附近，由于不同的 batch 中存在一定的噪声，因此不会精确收敛，而是始终在最小值周围一个较大的范围内波动。\n\n而如果随着时间慢慢减少学习率 α 的大小，在初期 α 较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小 α 的值，即减小步长，有助于算法的收敛，更容易接近最优解。\n\n最常用的学习率衰减方法：\n\n$$\\alpha = \\frac{1}{1 + decay\\\\\\_rate \\* epoch\\\\\\_num} \\* \\alpha\\_0$$\n\n其中，`decay_rate`为衰减率（超参数），`epoch_num`为将所有的训练样本完整过一遍的次数。\n\n* 指数衰减：\n\n$$\\alpha = 0.95^{epoch\\\\\\_num} \\* \\alpha\\_0$$\n\n* 其他：\n\n$$\\alpha = \\frac{k}{\\sqrt{epoch\\\\\\_num}} \\* \\alpha\\_0$$\n\n* 离散下降\n\n对于较小的模型，也有人会在训练时根据进度手动调小学习率。\n\n## 局部最优问题\n\n![saddle](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/saddle.png)\n\n**鞍点（saddle）**是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。\n\n结论：\n\n* 在训练较大的神经网络、存在大量参数，并且成本函数被定义在较高的维度空间时，困在极差的局部最优中是不大可能的；\n* 鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。\n","slug":"深度学习中的优化算法","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds6s004fpcvo7z2sh4st","comments":1,"layout":"post","photos":[],"link":"","content":"<p>深度学习难以在大数据领域发挥最大效果的一个原因是，在巨大的数据集基础上进行训练速度很慢。而优化算法能够帮助快速训练模型，大大提高效率。</p>\n<h2 id=\"batch-梯度下降法\"><a href=\"#batch-梯度下降法\" class=\"headerlink\" title=\"batch 梯度下降法\"></a>batch 梯度下降法</h2><p><strong>batch 梯度下降法</strong>（批梯度下降法，我们之前一直使用的梯度下降法）是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。</p>\n<p>对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，处理速度就会比较慢。</p>\n<p>但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为 <strong>mini-batch</strong>。</p>\n<h2 id=\"Mini-Batch-梯度下降法\"><a href=\"#Mini-Batch-梯度下降法\" class=\"headerlink\" title=\"Mini-Batch 梯度下降法\"></a>Mini-Batch 梯度下降法</h2><p><strong>Mini-Batch 梯度下降法</strong>（小批量梯度下降法）每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。</p>\n<p>使用 batch 梯度下降法，对整个训练集的一次遍历只能做一个梯度下降；而使用 Mini-Batch 梯度下降法，对整个训练集的一次遍历（称为一个 epoch）能做 mini-batch 个数个梯度下降。之后，可以一直遍历训练集，直到最后收敛到一个合适的精度。</p>\n<p>batch 梯度下降法和 Mini-batch 梯度下降法代价函数的变化趋势如下：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/training-with-mini-batch-gradient-descent.png\" alt=\"training-with-mini-batch-gradient-descent\"></p>\n<h3 id=\"batch-的不同大小（size）带来的影响\"><a href=\"#batch-的不同大小（size）带来的影响\" class=\"headerlink\" title=\"batch 的不同大小（size）带来的影响\"></a>batch 的不同大小（size）带来的影响</h3><ul>\n<li>mini-batch 的大小为 1，即是<strong>随机梯度下降法（stochastic gradient descent）</strong>，每个样本都是独立的 mini-batch；</li>\n<li>mini-batch 的大小为 m（数据集大小），即是 batch 梯度下降法；</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/choosing-mini-batch-size.png\" alt=\"choosing-mini-batch-size\"></p>\n<ul>\n<li><p>batch 梯度下降法：</p>\n<ul>\n<li>对所有 m 个训练样本执行一次梯度下降，<strong>每一次迭代时间较长，训练过程慢</strong>； </li>\n<li>相对噪声低一些，幅度也大一些；</li>\n<li>成本函数总是向减小的方向下降。</li>\n</ul>\n</li>\n<li><p>随机梯度下降法：</p>\n<ul>\n<li>对每一个训练样本执行一次梯度下降，训练速度快，但<strong>丢失了向量化带来的计算加速</strong>；</li>\n<li>有很多噪声，减小学习率可以适当；</li>\n<li>成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。</li>\n</ul>\n</li>\n</ul>\n<p>因此，选择一个<code>1 &lt; size &lt; m</code>的合适的大小进行 Mini-batch 梯度下降，可以实现快速学习，也应用了向量化带来的好处，且成本函数的下降处于前两者之间。</p>\n<h3 id=\"mini-batch-大小的选择\"><a href=\"#mini-batch-大小的选择\" class=\"headerlink\" title=\"mini-batch 大小的选择\"></a>mini-batch 大小的选择</h3><ul>\n<li>如果训练样本的大小比较小，如 $m \\lt 2000$ 时，选择 batch 梯度下降法；</li>\n<li>如果训练样本的大小比较大，选择 Mini-Batch 梯度下降法。为了和计算机的信息存储方式相适应，代码在 mini-batch 大小为 2 的幂次时运行要快一些。典型的大小为 $2^6$、$2^7$、…、$2^9$；</li>\n<li>mini-batch 的大小要符合 CPU/GPU 内存。</li>\n</ul>\n<p>mini-batch 的大小也是一个重要的超变量，需要根据经验快速尝试，找到能够最有效地减少成本函数的值。</p>\n<h3 id=\"获得-mini-batch-的步骤\"><a href=\"#获得-mini-batch-的步骤\" class=\"headerlink\" title=\"获得 mini-batch 的步骤\"></a>获得 mini-batch 的步骤</h3><ol>\n<li>将数据集打乱；</li>\n<li>按照既定的大小分割数据集；</li>\n</ol>\n<p>其中打乱数据集的代码：</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">m = X.shape[<span class=\"number\">1</span>] </span><br><span class=\"line\">permutation = list(np.random.permutation(m))</span><br><span class=\"line\">shuffled_X = X[:, permutation]</span><br><span class=\"line\">shuffled_Y = Y[:, permutation].reshape((<span class=\"number\">1</span>,m))</span><br></pre></td></tr></table></figure>\n<p><code>np.random.permutation</code>与<code>np.random.shuffle</code>有两处不同：</p>\n<ol>\n<li>如果传给<code>permutation</code>一个矩阵，它会返回一个洗牌后的矩阵副本；而<code>shuffle</code>只是对一个矩阵进行洗牌，没有返回值。</li>\n<li>如果传入一个整数，它会返回一个洗牌后的<code>arange</code>。</li>\n</ol>\n<h3 id=\"符号表示\"><a href=\"#符号表示\" class=\"headerlink\" title=\"符号表示\"></a>符号表示</h3><ul>\n<li>使用上角小括号 i 表示训练集里的值，$x^{(i)}$ 是第 i 个训练样本；</li>\n<li>使用上角中括号 l 表示神经网络的层数，$z^{[l]}$ 表示神经网络中第 l 层的 z 值；</li>\n<li>现在引入大括号 t 来代表不同的 mini-batch，因此有 $X^{t}$、$Y^{t}$。</li>\n</ul>\n<h2 id=\"指数平均加权\"><a href=\"#指数平均加权\" class=\"headerlink\" title=\"指数平均加权\"></a>指数平均加权</h2><p><strong>指数加权平均（Exponentially Weight Average）</strong>是一种常用的序列数据处理方式，计算公式为：</p>\n<p>$$<br>S_t =<br>\\begin{cases}<br>Y_1, &amp;t = 1 \\\\<br>\\beta S_{t-1} + (1-\\beta)Y_t, &amp;t &gt; 1<br>\\end{cases}<br>$$</p>\n<p>其中 $Y_t$ 为 t 下的实际值，$S_t$ 为 t 下加权平均后的值，β 为权重值。</p>\n<p>指数加权平均数在统计学中被称为“指数加权移动平均值”。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Exponentially-weight-average.png\" alt=\"Exponentially-weight-average\"></p>\n<p>给定一个时间序列，例如伦敦一年每天的气温值，图中蓝色的点代表真实数据。对于一个即时的气温值，取权重值 β 为 0.9，根据求得的值可以得到图中的红色曲线，它反映了气温变化的大致趋势。</p>\n<p>当取权重值 β=0.98 时，可以得到图中更为平滑的绿色曲线。而当取权重值 β=0.5 时，得到图中噪点更多的黄色曲线。<strong>β 越大相当于求取平均利用的天数越多</strong>，曲线自然就会越平滑而且越滞后。</p>\n<h3 id=\"理解指数平均加权\"><a href=\"#理解指数平均加权\" class=\"headerlink\" title=\"理解指数平均加权\"></a>理解指数平均加权</h3><p>当 β 为 0.9 时，</p>\n<p>$$v_{100} = 0.9v_{99} + 0.1 \\theta_{100}$$</p>\n<p>$$v_{99} = 0.9v_{98} + 0.1 \\theta_{99}$$</p>\n<p>$$v_{98} = 0.9v_{97} + 0.1 \\theta_{98}$$<br>$$…$$</p>\n<p>展开：</p>\n<p>$$v_{100} = 0.1 \\theta_{100} + 0.1 * 0.9 \\theta_{99} + 0.1 * {(0.9)}^2 \\theta_{98} + …$$</p>\n<p>其中 θi 指第 i 天的实际数据。所有 θ 前面的系数（不包括 0.1）相加起来为 1 或者接近于 1，这些系数被称作<strong>偏差修正（Bias Correction）</strong>。</p>\n<p>根据函数极限的一条定理：</p>\n<p>$$\\lim_{\\beta\\to 0}(1 - \\beta)^\\frac{1}{\\beta} = \\frac{1}{e} \\approx 0.368$$</p>\n<p>当 β 为 0.9 时，可以当作把过去 10 天的气温指数加权平均作为当日的气温，因为 10 天后权重已经下降到了当天的 1/3 左右。同理，当 β 为 0.98 时，可以把过去 50 天的气温指数加权平均作为当日的气温。</p>\n<p>因此，在计算当前时刻的平均值时，只需要前一天的平均值和当前时刻的值。</p>\n<p>$$v_t = \\beta v_{t-1} + (1 - \\beta)\\theta_t$$</p>\n<p>考虑到代码，只需要不断更新 v 即可：</p>\n<p>$$v := \\beta v + (1 - \\beta)\\theta_t$$<br><!--此处应有公式的实现代码--></p>\n<p>指数平均加权并<strong>不是最精准</strong>的计算平均数的方法，你可以直接计算过去 10 天或 50 天的平均值来得到更好的估计，但缺点是保存数据需要占用更多内存，执行更加复杂，计算成本更加高昂。</p>\n<p>指数加权平均数公式的好处之一在于它只需要一行代码，且占用极少内存，因此<strong>效率极高，且节省成本</strong>。</p>\n<h3 id=\"指数平均加权的偏差修正\"><a href=\"#指数平均加权的偏差修正\" class=\"headerlink\" title=\"指数平均加权的偏差修正\"></a>指数平均加权的偏差修正</h3><p>我们通常有</p>\n<p>$$v_0 = 0$$<br>$$v_1 = 0.98v_0 + 0.02\\theta_1$$</p>\n<p>因此，$v_1$ 仅为第一个数据的 0.02（或者说 1-β），显然不准确。往后递推同理。</p>\n<p>因此，我们修改公式为</p>\n<p>$$v_t = \\frac{\\beta v_{t-1} + (1 - \\beta)\\theta_t}{1-\\beta^t}$$</p>\n<p>随着 t 的增大，β 的 t 次方趋近于 0。因此当 t 很大的时候，偏差修正几乎没有作用，但是在前期学习可以帮助更好的预测数据。在实际过程中，一般会忽略前期偏差的影响。</p>\n<h2 id=\"动量梯度下降法\"><a href=\"#动量梯度下降法\" class=\"headerlink\" title=\"动量梯度下降法\"></a>动量梯度下降法</h2><p><strong>动量梯度下降（Gradient Descent with Momentum）</strong>是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：</p>\n<p>for l = 1, .. , L：</p>\n<p>$$v_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]}$$<br>$$v_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]}$$<br>$$W^{[l]} := W^{[l]} - \\alpha v_{dW^{[l]}}$$<br>$$b^{[l]} := b^{[l]} - \\alpha v_{db^{[l]}}$$</p>\n<p>其中，将动量衰减参数 β 设置为 0.9 是超参数的一个常见且效果不错的选择。当 β 被设置为 0 时，显然就成了 batch 梯度下降法。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Gradient-Descent-with-Momentum.png\" alt=\"Gradient-Descent-with-Momentum\"></p>\n<p>进行一般的梯度下降将会得到图中的蓝色曲线，由于存在上下波动，减缓了梯度下降的速度，因此只能使用一个较小的学习率进行迭代。如果用较大的学习率，结果可能会像紫色曲线一样偏离函数的范围。</p>\n<p>而使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色的曲线。</p>\n<p>当前后梯度方向一致时，动量梯度下降能够加速学习；而前后梯度方向不一致时，动量梯度下降能够抑制震荡。</p>\n<p>另外，在 10 次迭代之后，移动平均已经不再是一个具有偏差的预测。因此实际在使用梯度下降法或者动量梯度下降法时，不会同时进行偏差修正。</p>\n<h3 id=\"动量梯度下降法的形象解释\"><a href=\"#动量梯度下降法的形象解释\" class=\"headerlink\" title=\"动量梯度下降法的形象解释\"></a>动量梯度下降法的形象解释</h3><p>将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v_{dw}$、$v_{db}$ 相当于速度。</p>\n<p>小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。</p>\n<h2 id=\"RMSProp-算法\"><a href=\"#RMSProp-算法\" class=\"headerlink\" title=\"RMSProp 算法\"></a>RMSProp 算法</h2><p><strong>RMSProp（Root Mean Square Prop，均方根支）</strong>算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为（省略了 l）：</p>\n<p>$$s_{dw} = \\beta s_{dw} + (1 - \\beta)(dw)^2$$<br>$$s_{db} = \\beta s_{db} + (1 - \\beta)(db)^2$$<br>$$w := w - \\alpha \\frac{dw}{\\sqrt{s_{dw} + \\epsilon}}$$<br>$$b := b - \\alpha \\frac{db}{\\sqrt{s_{db} + \\epsilon}}$$</p>\n<p>其中，ϵ 是一个实际操作时加上的较小数（例如10^-8），为了防止分母太小而导致的数值不稳定。</p>\n<p>当 dw 或 db 较大时，$(dw)^2$、$(db)^2$会较大，进而 $s_{dw}$、$s_{db}$也会较大，最终使得</p>\n<p>$$\\frac{dw}{\\sqrt{s_{dw} + \\epsilon}}$$</p>\n<p>和</p>\n<p>$$\\frac{db}{\\sqrt{s_{db} + \\epsilon}}$$</p>\n<p>较小，从而减小某些维度梯度更新波动较大的情况，使下降速度变得更快。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/RMSProp.png\" alt=\"RMSProp\"></p>\n<p>RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。并且，它和 Adam 优化算法已被证明适用于不同的深度学习网络结构。</p>\n<p>注意，β 也是一个超参数。</p>\n<h2 id=\"Adam-优化算法\"><a href=\"#Adam-优化算法\" class=\"headerlink\" title=\"Adam 优化算法\"></a>Adam 优化算法</h2><p><strong>Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）</strong>基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。具体过程如下（省略了 l）：</p>\n<p>首先进行初始化：</p>\n<p>$$v_{dW} = 0, s_{dW} = 0, v_{db} = 0, s_{db} = 0$$</p>\n<p>用每一个 mini-batch 计算 dW、db，第 t 次迭代时：</p>\n<p>$$v_{dW} = \\beta_1 v_{dW} + (1 - \\beta_1) dW$$<br>$$v_{db} = \\beta_1 v_{db} + (1 - \\beta_1) db$$<br>$$s_{dW} = \\beta_2 s_{dW} + (1 - \\beta_2) (dW)^2$$<br>$$s_{db} = \\beta_2 s_{db} + (1 - \\beta_2) (db)^2$$</p>\n<p>一般使用 Adam 算法时需要计算偏差修正：</p>\n<p>$$v^{corrected}_{dW} = \\frac{v_{dW}}{1-{\\beta_1}^t}$$<br>$$v^{corrected}_{db} = \\frac{v_{db}}{1-{\\beta_1}^t}$$<br>$$s^{corrected}_{dW} = \\frac{s_{dW}}{1-{\\beta_2}^t}$$<br>$$s^{corrected}_{db} = \\frac{s_{db}}{1-{\\beta_2}^t}$$</p>\n<p>所以，更新 W、b 时有：</p>\n<p>$$W := W - \\alpha \\frac{v^{corrected}_{dW}}{\\sqrt{s^{corrected}_{dW} + \\epsilon}}$$</p>\n<p>$$b := b - \\alpha \\frac{v^{corrected}_{db}}{\\sqrt{s^{corrected}_{db}} + \\epsilon}$$</p>\n<p>（可以看到 Andrew 在这里 ϵ 没有写到平方根里去，和他在 RMSProp 中写的不太一样。考虑到 ϵ 所起的作用，我感觉影响不大）</p>\n<h3 id=\"超参数的选择\"><a href=\"#超参数的选择\" class=\"headerlink\" title=\"超参数的选择\"></a>超参数的选择</h3><p>Adam 优化算法有很多的超参数，其中</p>\n<ul>\n<li>学习率 α：需要尝试一系列的值，来寻找比较合适的；</li>\n<li>β1：常用的缺省值为 0.9；</li>\n<li>β2：Adam 算法的作者建议为 0.999；</li>\n<li>ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；</li>\n</ul>\n<p>β1、β2、ϵ 通常不需要调试。</p>\n<h2 id=\"学习率衰减\"><a href=\"#学习率衰减\" class=\"headerlink\" title=\"学习率衰减\"></a>学习率衰减</h2><p>如果设置一个固定的学习率 α，在最小值点附近，由于不同的 batch 中存在一定的噪声，因此不会精确收敛，而是始终在最小值周围一个较大的范围内波动。</p>\n<p>而如果随着时间慢慢减少学习率 α 的大小，在初期 α 较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小 α 的值，即减小步长，有助于算法的收敛，更容易接近最优解。</p>\n<p>最常用的学习率衰减方法：</p>\n<p>$$\\alpha = \\frac{1}{1 + decay\\_rate * epoch\\_num} * \\alpha_0$$</p>\n<p>其中，<code>decay_rate</code>为衰减率（超参数），<code>epoch_num</code>为将所有的训练样本完整过一遍的次数。</p>\n<ul>\n<li>指数衰减：</li>\n</ul>\n<p>$$\\alpha = 0.95^{epoch\\_num} * \\alpha_0$$</p>\n<ul>\n<li>其他：</li>\n</ul>\n<p>$$\\alpha = \\frac{k}{\\sqrt{epoch\\_num}} * \\alpha_0$$</p>\n<ul>\n<li>离散下降</li>\n</ul>\n<p>对于较小的模型，也有人会在训练时根据进度手动调小学习率。</p>\n<h2 id=\"局部最优问题\"><a href=\"#局部最优问题\" class=\"headerlink\" title=\"局部最优问题\"></a>局部最优问题</h2><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/saddle.png\" alt=\"saddle\"></p>\n<p><strong>鞍点（saddle）</strong>是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。</p>\n<p>结论：</p>\n<ul>\n<li>在训练较大的神经网络、存在大量参数，并且成本函数被定义在较高的维度空间时，困在极差的局部最优中是不大可能的；</li>\n<li>鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>深度学习难以在大数据领域发挥最大效果的一个原因是，在巨大的数据集基础上进行训练速度很慢。而优化算法能够帮助快速训练模型，大大提高效率。</p>\n<h2 id=\"batch-梯度下降法\"><a href=\"#batch-梯度下降法\" class=\"headerlink\" title=\"batch 梯度下降法\"></a>batch 梯度下降法</h2><p><strong>batch 梯度下降法</strong>（批梯度下降法，我们之前一直使用的梯度下降法）是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。</p>\n<p>对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，处理速度就会比较慢。</p>\n<p>但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为 <strong>mini-batch</strong>。</p>\n<h2 id=\"Mini-Batch-梯度下降法\"><a href=\"#Mini-Batch-梯度下降法\" class=\"headerlink\" title=\"Mini-Batch 梯度下降法\"></a>Mini-Batch 梯度下降法</h2><p><strong>Mini-Batch 梯度下降法</strong>（小批量梯度下降法）每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。</p>\n<p>使用 batch 梯度下降法，对整个训练集的一次遍历只能做一个梯度下降；而使用 Mini-Batch 梯度下降法，对整个训练集的一次遍历（称为一个 epoch）能做 mini-batch 个数个梯度下降。之后，可以一直遍历训练集，直到最后收敛到一个合适的精度。</p>\n<p>batch 梯度下降法和 Mini-batch 梯度下降法代价函数的变化趋势如下：</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/training-with-mini-batch-gradient-descent.png\" alt=\"training-with-mini-batch-gradient-descent\"></p>\n<h3 id=\"batch-的不同大小（size）带来的影响\"><a href=\"#batch-的不同大小（size）带来的影响\" class=\"headerlink\" title=\"batch 的不同大小（size）带来的影响\"></a>batch 的不同大小（size）带来的影响</h3><ul>\n<li>mini-batch 的大小为 1，即是<strong>随机梯度下降法（stochastic gradient descent）</strong>，每个样本都是独立的 mini-batch；</li>\n<li>mini-batch 的大小为 m（数据集大小），即是 batch 梯度下降法；</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/choosing-mini-batch-size.png\" alt=\"choosing-mini-batch-size\"></p>\n<ul>\n<li><p>batch 梯度下降法：</p>\n<ul>\n<li>对所有 m 个训练样本执行一次梯度下降，<strong>每一次迭代时间较长，训练过程慢</strong>； </li>\n<li>相对噪声低一些，幅度也大一些；</li>\n<li>成本函数总是向减小的方向下降。</li>\n</ul>\n</li>\n<li><p>随机梯度下降法：</p>\n<ul>\n<li>对每一个训练样本执行一次梯度下降，训练速度快，但<strong>丢失了向量化带来的计算加速</strong>；</li>\n<li>有很多噪声，减小学习率可以适当；</li>\n<li>成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。</li>\n</ul>\n</li>\n</ul>\n<p>因此，选择一个<code>1 &lt; size &lt; m</code>的合适的大小进行 Mini-batch 梯度下降，可以实现快速学习，也应用了向量化带来的好处，且成本函数的下降处于前两者之间。</p>\n<h3 id=\"mini-batch-大小的选择\"><a href=\"#mini-batch-大小的选择\" class=\"headerlink\" title=\"mini-batch 大小的选择\"></a>mini-batch 大小的选择</h3><ul>\n<li>如果训练样本的大小比较小，如 $m \\lt 2000$ 时，选择 batch 梯度下降法；</li>\n<li>如果训练样本的大小比较大，选择 Mini-Batch 梯度下降法。为了和计算机的信息存储方式相适应，代码在 mini-batch 大小为 2 的幂次时运行要快一些。典型的大小为 $2^6$、$2^7$、…、$2^9$；</li>\n<li>mini-batch 的大小要符合 CPU/GPU 内存。</li>\n</ul>\n<p>mini-batch 的大小也是一个重要的超变量，需要根据经验快速尝试，找到能够最有效地减少成本函数的值。</p>\n<h3 id=\"获得-mini-batch-的步骤\"><a href=\"#获得-mini-batch-的步骤\" class=\"headerlink\" title=\"获得 mini-batch 的步骤\"></a>获得 mini-batch 的步骤</h3><ol>\n<li>将数据集打乱；</li>\n<li>按照既定的大小分割数据集；</li>\n</ol>\n<p>其中打乱数据集的代码：</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">m = X.shape[<span class=\"number\">1</span>] </span><br><span class=\"line\">permutation = list(np.random.permutation(m))</span><br><span class=\"line\">shuffled_X = X[:, permutation]</span><br><span class=\"line\">shuffled_Y = Y[:, permutation].reshape((<span class=\"number\">1</span>,m))</span><br></pre></td></tr></table></figure>\n<p><code>np.random.permutation</code>与<code>np.random.shuffle</code>有两处不同：</p>\n<ol>\n<li>如果传给<code>permutation</code>一个矩阵，它会返回一个洗牌后的矩阵副本；而<code>shuffle</code>只是对一个矩阵进行洗牌，没有返回值。</li>\n<li>如果传入一个整数，它会返回一个洗牌后的<code>arange</code>。</li>\n</ol>\n<h3 id=\"符号表示\"><a href=\"#符号表示\" class=\"headerlink\" title=\"符号表示\"></a>符号表示</h3><ul>\n<li>使用上角小括号 i 表示训练集里的值，$x^{(i)}$ 是第 i 个训练样本；</li>\n<li>使用上角中括号 l 表示神经网络的层数，$z^{[l]}$ 表示神经网络中第 l 层的 z 值；</li>\n<li>现在引入大括号 t 来代表不同的 mini-batch，因此有 $X^{t}$、$Y^{t}$。</li>\n</ul>\n<h2 id=\"指数平均加权\"><a href=\"#指数平均加权\" class=\"headerlink\" title=\"指数平均加权\"></a>指数平均加权</h2><p><strong>指数加权平均（Exponentially Weight Average）</strong>是一种常用的序列数据处理方式，计算公式为：</p>\n<p>$$<br>S_t =<br>\\begin{cases}<br>Y_1, &amp;t = 1 \\\\<br>\\beta S_{t-1} + (1-\\beta)Y_t, &amp;t &gt; 1<br>\\end{cases}<br>$$</p>\n<p>其中 $Y_t$ 为 t 下的实际值，$S_t$ 为 t 下加权平均后的值，β 为权重值。</p>\n<p>指数加权平均数在统计学中被称为“指数加权移动平均值”。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Exponentially-weight-average.png\" alt=\"Exponentially-weight-average\"></p>\n<p>给定一个时间序列，例如伦敦一年每天的气温值，图中蓝色的点代表真实数据。对于一个即时的气温值，取权重值 β 为 0.9，根据求得的值可以得到图中的红色曲线，它反映了气温变化的大致趋势。</p>\n<p>当取权重值 β=0.98 时，可以得到图中更为平滑的绿色曲线。而当取权重值 β=0.5 时，得到图中噪点更多的黄色曲线。<strong>β 越大相当于求取平均利用的天数越多</strong>，曲线自然就会越平滑而且越滞后。</p>\n<h3 id=\"理解指数平均加权\"><a href=\"#理解指数平均加权\" class=\"headerlink\" title=\"理解指数平均加权\"></a>理解指数平均加权</h3><p>当 β 为 0.9 时，</p>\n<p>$$v_{100} = 0.9v_{99} + 0.1 \\theta_{100}$$</p>\n<p>$$v_{99} = 0.9v_{98} + 0.1 \\theta_{99}$$</p>\n<p>$$v_{98} = 0.9v_{97} + 0.1 \\theta_{98}$$<br>$$…$$</p>\n<p>展开：</p>\n<p>$$v_{100} = 0.1 \\theta_{100} + 0.1 * 0.9 \\theta_{99} + 0.1 * {(0.9)}^2 \\theta_{98} + …$$</p>\n<p>其中 θi 指第 i 天的实际数据。所有 θ 前面的系数（不包括 0.1）相加起来为 1 或者接近于 1，这些系数被称作<strong>偏差修正（Bias Correction）</strong>。</p>\n<p>根据函数极限的一条定理：</p>\n<p>$$\\lim_{\\beta\\to 0}(1 - \\beta)^\\frac{1}{\\beta} = \\frac{1}{e} \\approx 0.368$$</p>\n<p>当 β 为 0.9 时，可以当作把过去 10 天的气温指数加权平均作为当日的气温，因为 10 天后权重已经下降到了当天的 1/3 左右。同理，当 β 为 0.98 时，可以把过去 50 天的气温指数加权平均作为当日的气温。</p>\n<p>因此，在计算当前时刻的平均值时，只需要前一天的平均值和当前时刻的值。</p>\n<p>$$v_t = \\beta v_{t-1} + (1 - \\beta)\\theta_t$$</p>\n<p>考虑到代码，只需要不断更新 v 即可：</p>\n<p>$$v := \\beta v + (1 - \\beta)\\theta_t$$<br><!--此处应有公式的实现代码--></p>\n<p>指数平均加权并<strong>不是最精准</strong>的计算平均数的方法，你可以直接计算过去 10 天或 50 天的平均值来得到更好的估计，但缺点是保存数据需要占用更多内存，执行更加复杂，计算成本更加高昂。</p>\n<p>指数加权平均数公式的好处之一在于它只需要一行代码，且占用极少内存，因此<strong>效率极高，且节省成本</strong>。</p>\n<h3 id=\"指数平均加权的偏差修正\"><a href=\"#指数平均加权的偏差修正\" class=\"headerlink\" title=\"指数平均加权的偏差修正\"></a>指数平均加权的偏差修正</h3><p>我们通常有</p>\n<p>$$v_0 = 0$$<br>$$v_1 = 0.98v_0 + 0.02\\theta_1$$</p>\n<p>因此，$v_1$ 仅为第一个数据的 0.02（或者说 1-β），显然不准确。往后递推同理。</p>\n<p>因此，我们修改公式为</p>\n<p>$$v_t = \\frac{\\beta v_{t-1} + (1 - \\beta)\\theta_t}{1-\\beta^t}$$</p>\n<p>随着 t 的增大，β 的 t 次方趋近于 0。因此当 t 很大的时候，偏差修正几乎没有作用，但是在前期学习可以帮助更好的预测数据。在实际过程中，一般会忽略前期偏差的影响。</p>\n<h2 id=\"动量梯度下降法\"><a href=\"#动量梯度下降法\" class=\"headerlink\" title=\"动量梯度下降法\"></a>动量梯度下降法</h2><p><strong>动量梯度下降（Gradient Descent with Momentum）</strong>是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：</p>\n<p>for l = 1, .. , L：</p>\n<p>$$v_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]}$$<br>$$v_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]}$$<br>$$W^{[l]} := W^{[l]} - \\alpha v_{dW^{[l]}}$$<br>$$b^{[l]} := b^{[l]} - \\alpha v_{db^{[l]}}$$</p>\n<p>其中，将动量衰减参数 β 设置为 0.9 是超参数的一个常见且效果不错的选择。当 β 被设置为 0 时，显然就成了 batch 梯度下降法。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Gradient-Descent-with-Momentum.png\" alt=\"Gradient-Descent-with-Momentum\"></p>\n<p>进行一般的梯度下降将会得到图中的蓝色曲线，由于存在上下波动，减缓了梯度下降的速度，因此只能使用一个较小的学习率进行迭代。如果用较大的学习率，结果可能会像紫色曲线一样偏离函数的范围。</p>\n<p>而使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色的曲线。</p>\n<p>当前后梯度方向一致时，动量梯度下降能够加速学习；而前后梯度方向不一致时，动量梯度下降能够抑制震荡。</p>\n<p>另外，在 10 次迭代之后，移动平均已经不再是一个具有偏差的预测。因此实际在使用梯度下降法或者动量梯度下降法时，不会同时进行偏差修正。</p>\n<h3 id=\"动量梯度下降法的形象解释\"><a href=\"#动量梯度下降法的形象解释\" class=\"headerlink\" title=\"动量梯度下降法的形象解释\"></a>动量梯度下降法的形象解释</h3><p>将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v_{dw}$、$v_{db}$ 相当于速度。</p>\n<p>小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。</p>\n<h2 id=\"RMSProp-算法\"><a href=\"#RMSProp-算法\" class=\"headerlink\" title=\"RMSProp 算法\"></a>RMSProp 算法</h2><p><strong>RMSProp（Root Mean Square Prop，均方根支）</strong>算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为（省略了 l）：</p>\n<p>$$s_{dw} = \\beta s_{dw} + (1 - \\beta)(dw)^2$$<br>$$s_{db} = \\beta s_{db} + (1 - \\beta)(db)^2$$<br>$$w := w - \\alpha \\frac{dw}{\\sqrt{s_{dw} + \\epsilon}}$$<br>$$b := b - \\alpha \\frac{db}{\\sqrt{s_{db} + \\epsilon}}$$</p>\n<p>其中，ϵ 是一个实际操作时加上的较小数（例如10^-8），为了防止分母太小而导致的数值不稳定。</p>\n<p>当 dw 或 db 较大时，$(dw)^2$、$(db)^2$会较大，进而 $s_{dw}$、$s_{db}$也会较大，最终使得</p>\n<p>$$\\frac{dw}{\\sqrt{s_{dw} + \\epsilon}}$$</p>\n<p>和</p>\n<p>$$\\frac{db}{\\sqrt{s_{db} + \\epsilon}}$$</p>\n<p>较小，从而减小某些维度梯度更新波动较大的情况，使下降速度变得更快。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/RMSProp.png\" alt=\"RMSProp\"></p>\n<p>RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。并且，它和 Adam 优化算法已被证明适用于不同的深度学习网络结构。</p>\n<p>注意，β 也是一个超参数。</p>\n<h2 id=\"Adam-优化算法\"><a href=\"#Adam-优化算法\" class=\"headerlink\" title=\"Adam 优化算法\"></a>Adam 优化算法</h2><p><strong>Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）</strong>基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。具体过程如下（省略了 l）：</p>\n<p>首先进行初始化：</p>\n<p>$$v_{dW} = 0, s_{dW} = 0, v_{db} = 0, s_{db} = 0$$</p>\n<p>用每一个 mini-batch 计算 dW、db，第 t 次迭代时：</p>\n<p>$$v_{dW} = \\beta_1 v_{dW} + (1 - \\beta_1) dW$$<br>$$v_{db} = \\beta_1 v_{db} + (1 - \\beta_1) db$$<br>$$s_{dW} = \\beta_2 s_{dW} + (1 - \\beta_2) (dW)^2$$<br>$$s_{db} = \\beta_2 s_{db} + (1 - \\beta_2) (db)^2$$</p>\n<p>一般使用 Adam 算法时需要计算偏差修正：</p>\n<p>$$v^{corrected}_{dW} = \\frac{v_{dW}}{1-{\\beta_1}^t}$$<br>$$v^{corrected}_{db} = \\frac{v_{db}}{1-{\\beta_1}^t}$$<br>$$s^{corrected}_{dW} = \\frac{s_{dW}}{1-{\\beta_2}^t}$$<br>$$s^{corrected}_{db} = \\frac{s_{db}}{1-{\\beta_2}^t}$$</p>\n<p>所以，更新 W、b 时有：</p>\n<p>$$W := W - \\alpha \\frac{v^{corrected}_{dW}}{\\sqrt{s^{corrected}_{dW} + \\epsilon}}$$</p>\n<p>$$b := b - \\alpha \\frac{v^{corrected}_{db}}{\\sqrt{s^{corrected}_{db}} + \\epsilon}$$</p>\n<p>（可以看到 Andrew 在这里 ϵ 没有写到平方根里去，和他在 RMSProp 中写的不太一样。考虑到 ϵ 所起的作用，我感觉影响不大）</p>\n<h3 id=\"超参数的选择\"><a href=\"#超参数的选择\" class=\"headerlink\" title=\"超参数的选择\"></a>超参数的选择</h3><p>Adam 优化算法有很多的超参数，其中</p>\n<ul>\n<li>学习率 α：需要尝试一系列的值，来寻找比较合适的；</li>\n<li>β1：常用的缺省值为 0.9；</li>\n<li>β2：Adam 算法的作者建议为 0.999；</li>\n<li>ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；</li>\n</ul>\n<p>β1、β2、ϵ 通常不需要调试。</p>\n<h2 id=\"学习率衰减\"><a href=\"#学习率衰减\" class=\"headerlink\" title=\"学习率衰减\"></a>学习率衰减</h2><p>如果设置一个固定的学习率 α，在最小值点附近，由于不同的 batch 中存在一定的噪声，因此不会精确收敛，而是始终在最小值周围一个较大的范围内波动。</p>\n<p>而如果随着时间慢慢减少学习率 α 的大小，在初期 α 较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小 α 的值，即减小步长，有助于算法的收敛，更容易接近最优解。</p>\n<p>最常用的学习率衰减方法：</p>\n<p>$$\\alpha = \\frac{1}{1 + decay\\_rate * epoch\\_num} * \\alpha_0$$</p>\n<p>其中，<code>decay_rate</code>为衰减率（超参数），<code>epoch_num</code>为将所有的训练样本完整过一遍的次数。</p>\n<ul>\n<li>指数衰减：</li>\n</ul>\n<p>$$\\alpha = 0.95^{epoch\\_num} * \\alpha_0$$</p>\n<ul>\n<li>其他：</li>\n</ul>\n<p>$$\\alpha = \\frac{k}{\\sqrt{epoch\\_num}} * \\alpha_0$$</p>\n<ul>\n<li>离散下降</li>\n</ul>\n<p>对于较小的模型，也有人会在训练时根据进度手动调小学习率。</p>\n<h2 id=\"局部最优问题\"><a href=\"#局部最优问题\" class=\"headerlink\" title=\"局部最优问题\"></a>局部最优问题</h2><p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/saddle.png\" alt=\"saddle\"></p>\n<p><strong>鞍点（saddle）</strong>是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。</p>\n<p>结论：</p>\n<ul>\n<li>在训练较大的神经网络、存在大量参数，并且成本函数被定义在较高的维度空间时，困在极差的局部最优中是不大可能的；</li>\n<li>鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。</li>\n</ul>\n"},{"title":"贞洁禁忌","date":"2018-07-21T07:31:50.000Z","_content":"## 现象\n\n**处女不能将贞洁保留给新郎或未来的伴侣，习俗上要求新郎避开使处女失贞这一行为。**史实记载在澳大利亚的Dieri部落,女孩到青春期破处是普遍的习俗。\n\n## 解释\n\n### 对血的恐惧\n\n贞洁禁忌与普遍存在的月经禁忌有关。面对每月流血这一令人迷惑的现象，原始人无法把它与施虐观点相连，而被解释为某种鬼怪咬了女孩。\n\n### 对新事物的恐惧\n\n正如精神分析理论所研究的焦虑神经症一样，原始人也长期受到潜在忧虑的影响。在不同寻常的场合，这种忧虑尤其强烈，包括遇到新事物或预料之外的情况、无法理解或神秘之事。这也是各种仪式的根源，后来被宗教广泛采用。威胁焦虑者的危险只会在他自己期待中生动上演，而非在真实的危险情境中。因此，婚姻中首行性事之前做些预防措施十分重要。\n\n### 贞洁禁忌是整个性生活的一部分\n\n不仅与女人的第一次性交是禁忌，而且性交总体上就是个禁忌。在多数情况下，原始人的性生活被各种禁止强有力地约束着，并不像在文明社会中已达到的较高水平。当原始人从事重要活动，如出发探索周围环境，狩猎或参加战役时，就必须远离自己的妻子，尤其不能与她性交。\n\n只要原始人设立禁忌，就意味着惧怕事物，不容争议的是，所有回避女人的规定都表达了对女人整体的恐惧。或许这种恐惧建立在男女不同的事实上，即女人永远都无法令人理解、神秘且陌生，因此明显地与男人敌对。男人害怕受女性气质的感染，害怕变得像女人一样脆弱无能。性交的效果--卸载紧张、引发身体疲软--或许是男人惧怕女人的原型。\n\n## 结论\n\n在文明社会中，“失贞”不仅会长久地把女性束缚在男性身上，还会从女性身上释放出对男性的敌意反应。女性对男性的敌意反应可以采取病态形式，并常常表现为婚后对性生活的抑制，同时，我们也可以把第二段婚姻比第一段婚姻更美满的原因归结于此。\n\n十分有趣的是，精神分析家还会遇到这样的女人：她们心中同时存在着归属于敌意两种冲动，而且着两种冲动彼此间的联系十分紧密。她们可能看起来完全离开了丈夫，但心里还会受到丈夫的影响。当她试图爱上别的男人时，前任的形象就会冒出来干扰，对她的新爱情产生抑制效果。分析表明，这类女人确实还与前任有联结，尽管这不是一种情感联结。她们之所以离不开前任，是因为自己还没有完成复仇计划。\n","source":"_posts/贞洁禁忌.md","raw":"---\ntitle: 贞洁禁忌\ndate: 2018-07-21 15:31:50\ntags: 爱情心理学\ncategories: 心理学\n---\n## 现象\n\n**处女不能将贞洁保留给新郎或未来的伴侣，习俗上要求新郎避开使处女失贞这一行为。**史实记载在澳大利亚的Dieri部落,女孩到青春期破处是普遍的习俗。\n\n## 解释\n\n### 对血的恐惧\n\n贞洁禁忌与普遍存在的月经禁忌有关。面对每月流血这一令人迷惑的现象，原始人无法把它与施虐观点相连，而被解释为某种鬼怪咬了女孩。\n\n### 对新事物的恐惧\n\n正如精神分析理论所研究的焦虑神经症一样，原始人也长期受到潜在忧虑的影响。在不同寻常的场合，这种忧虑尤其强烈，包括遇到新事物或预料之外的情况、无法理解或神秘之事。这也是各种仪式的根源，后来被宗教广泛采用。威胁焦虑者的危险只会在他自己期待中生动上演，而非在真实的危险情境中。因此，婚姻中首行性事之前做些预防措施十分重要。\n\n### 贞洁禁忌是整个性生活的一部分\n\n不仅与女人的第一次性交是禁忌，而且性交总体上就是个禁忌。在多数情况下，原始人的性生活被各种禁止强有力地约束着，并不像在文明社会中已达到的较高水平。当原始人从事重要活动，如出发探索周围环境，狩猎或参加战役时，就必须远离自己的妻子，尤其不能与她性交。\n\n只要原始人设立禁忌，就意味着惧怕事物，不容争议的是，所有回避女人的规定都表达了对女人整体的恐惧。或许这种恐惧建立在男女不同的事实上，即女人永远都无法令人理解、神秘且陌生，因此明显地与男人敌对。男人害怕受女性气质的感染，害怕变得像女人一样脆弱无能。性交的效果--卸载紧张、引发身体疲软--或许是男人惧怕女人的原型。\n\n## 结论\n\n在文明社会中，“失贞”不仅会长久地把女性束缚在男性身上，还会从女性身上释放出对男性的敌意反应。女性对男性的敌意反应可以采取病态形式，并常常表现为婚后对性生活的抑制，同时，我们也可以把第二段婚姻比第一段婚姻更美满的原因归结于此。\n\n十分有趣的是，精神分析家还会遇到这样的女人：她们心中同时存在着归属于敌意两种冲动，而且着两种冲动彼此间的联系十分紧密。她们可能看起来完全离开了丈夫，但心里还会受到丈夫的影响。当她试图爱上别的男人时，前任的形象就会冒出来干扰，对她的新爱情产生抑制效果。分析表明，这类女人确实还与前任有联结，尽管这不是一种情感联结。她们之所以离不开前任，是因为自己还没有完成复仇计划。\n","slug":"贞洁禁忌","published":1,"updated":"2018-09-28T06:50:38.147Z","_id":"cjmk9ds6s004jpcvoq9b4rtgm","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"现象\"><a href=\"#现象\" class=\"headerlink\" title=\"现象\"></a>现象</h2><p><strong>处女不能将贞洁保留给新郎或未来的伴侣，习俗上要求新郎避开使处女失贞这一行为。</strong>史实记载在澳大利亚的Dieri部落,女孩到青春期破处是普遍的习俗。</p>\n<h2 id=\"解释\"><a href=\"#解释\" class=\"headerlink\" title=\"解释\"></a>解释</h2><h3 id=\"对血的恐惧\"><a href=\"#对血的恐惧\" class=\"headerlink\" title=\"对血的恐惧\"></a>对血的恐惧</h3><p>贞洁禁忌与普遍存在的月经禁忌有关。面对每月流血这一令人迷惑的现象，原始人无法把它与施虐观点相连，而被解释为某种鬼怪咬了女孩。</p>\n<h3 id=\"对新事物的恐惧\"><a href=\"#对新事物的恐惧\" class=\"headerlink\" title=\"对新事物的恐惧\"></a>对新事物的恐惧</h3><p>正如精神分析理论所研究的焦虑神经症一样，原始人也长期受到潜在忧虑的影响。在不同寻常的场合，这种忧虑尤其强烈，包括遇到新事物或预料之外的情况、无法理解或神秘之事。这也是各种仪式的根源，后来被宗教广泛采用。威胁焦虑者的危险只会在他自己期待中生动上演，而非在真实的危险情境中。因此，婚姻中首行性事之前做些预防措施十分重要。</p>\n<h3 id=\"贞洁禁忌是整个性生活的一部分\"><a href=\"#贞洁禁忌是整个性生活的一部分\" class=\"headerlink\" title=\"贞洁禁忌是整个性生活的一部分\"></a>贞洁禁忌是整个性生活的一部分</h3><p>不仅与女人的第一次性交是禁忌，而且性交总体上就是个禁忌。在多数情况下，原始人的性生活被各种禁止强有力地约束着，并不像在文明社会中已达到的较高水平。当原始人从事重要活动，如出发探索周围环境，狩猎或参加战役时，就必须远离自己的妻子，尤其不能与她性交。</p>\n<p>只要原始人设立禁忌，就意味着惧怕事物，不容争议的是，所有回避女人的规定都表达了对女人整体的恐惧。或许这种恐惧建立在男女不同的事实上，即女人永远都无法令人理解、神秘且陌生，因此明显地与男人敌对。男人害怕受女性气质的感染，害怕变得像女人一样脆弱无能。性交的效果–卸载紧张、引发身体疲软–或许是男人惧怕女人的原型。</p>\n<h2 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h2><p>在文明社会中，“失贞”不仅会长久地把女性束缚在男性身上，还会从女性身上释放出对男性的敌意反应。女性对男性的敌意反应可以采取病态形式，并常常表现为婚后对性生活的抑制，同时，我们也可以把第二段婚姻比第一段婚姻更美满的原因归结于此。</p>\n<p>十分有趣的是，精神分析家还会遇到这样的女人：她们心中同时存在着归属于敌意两种冲动，而且着两种冲动彼此间的联系十分紧密。她们可能看起来完全离开了丈夫，但心里还会受到丈夫的影响。当她试图爱上别的男人时，前任的形象就会冒出来干扰，对她的新爱情产生抑制效果。分析表明，这类女人确实还与前任有联结，尽管这不是一种情感联结。她们之所以离不开前任，是因为自己还没有完成复仇计划。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"现象\"><a href=\"#现象\" class=\"headerlink\" title=\"现象\"></a>现象</h2><p><strong>处女不能将贞洁保留给新郎或未来的伴侣，习俗上要求新郎避开使处女失贞这一行为。</strong>史实记载在澳大利亚的Dieri部落,女孩到青春期破处是普遍的习俗。</p>\n<h2 id=\"解释\"><a href=\"#解释\" class=\"headerlink\" title=\"解释\"></a>解释</h2><h3 id=\"对血的恐惧\"><a href=\"#对血的恐惧\" class=\"headerlink\" title=\"对血的恐惧\"></a>对血的恐惧</h3><p>贞洁禁忌与普遍存在的月经禁忌有关。面对每月流血这一令人迷惑的现象，原始人无法把它与施虐观点相连，而被解释为某种鬼怪咬了女孩。</p>\n<h3 id=\"对新事物的恐惧\"><a href=\"#对新事物的恐惧\" class=\"headerlink\" title=\"对新事物的恐惧\"></a>对新事物的恐惧</h3><p>正如精神分析理论所研究的焦虑神经症一样，原始人也长期受到潜在忧虑的影响。在不同寻常的场合，这种忧虑尤其强烈，包括遇到新事物或预料之外的情况、无法理解或神秘之事。这也是各种仪式的根源，后来被宗教广泛采用。威胁焦虑者的危险只会在他自己期待中生动上演，而非在真实的危险情境中。因此，婚姻中首行性事之前做些预防措施十分重要。</p>\n<h3 id=\"贞洁禁忌是整个性生活的一部分\"><a href=\"#贞洁禁忌是整个性生活的一部分\" class=\"headerlink\" title=\"贞洁禁忌是整个性生活的一部分\"></a>贞洁禁忌是整个性生活的一部分</h3><p>不仅与女人的第一次性交是禁忌，而且性交总体上就是个禁忌。在多数情况下，原始人的性生活被各种禁止强有力地约束着，并不像在文明社会中已达到的较高水平。当原始人从事重要活动，如出发探索周围环境，狩猎或参加战役时，就必须远离自己的妻子，尤其不能与她性交。</p>\n<p>只要原始人设立禁忌，就意味着惧怕事物，不容争议的是，所有回避女人的规定都表达了对女人整体的恐惧。或许这种恐惧建立在男女不同的事实上，即女人永远都无法令人理解、神秘且陌生，因此明显地与男人敌对。男人害怕受女性气质的感染，害怕变得像女人一样脆弱无能。性交的效果–卸载紧张、引发身体疲软–或许是男人惧怕女人的原型。</p>\n<h2 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h2><p>在文明社会中，“失贞”不仅会长久地把女性束缚在男性身上，还会从女性身上释放出对男性的敌意反应。女性对男性的敌意反应可以采取病态形式，并常常表现为婚后对性生活的抑制，同时，我们也可以把第二段婚姻比第一段婚姻更美满的原因归结于此。</p>\n<p>十分有趣的是，精神分析家还会遇到这样的女人：她们心中同时存在着归属于敌意两种冲动，而且着两种冲动彼此间的联系十分紧密。她们可能看起来完全离开了丈夫，但心里还会受到丈夫的影响。当她试图爱上别的男人时，前任的形象就会冒出来干扰，对她的新爱情产生抑制效果。分析表明，这类女人确实还与前任有联结，尽管这不是一种情感联结。她们之所以离不开前任，是因为自己还没有完成复仇计划。</p>\n"},{"title":"目标检测","date":"2018-09-02T12:06:02.000Z","mathjax":true,"_content":"\n目标检测是计算机视觉领域中一个新兴的应用方向，其任务是对输入图像进行分类的同时，检测图像中是否包含某些目标，并对他们准确定位并标识。\n\n## 目标定位\n\n定位分类问题不仅要求判断出图片中物体的种类，还要在图片中标记出它的具体位置，用 **边框（Bounding Box，或者称包围盒）** 把物体圈起来。一般来说，定位分类问题通常只有一个较大的对象位于图片中间位置；而在目标检测问题中，图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象。\n\n为了定位图片中汽车的位置，可以让神经网络多输出 4 个数字，标记为 $b_x$、$b_y$、$b_h$、$b_w$。将图片左上角标记为 (0, 0)，右下角标记为 (1, 1)，则有：\n\n* 红色方框的中心点：($b_x$，$b_y$)\n* 边界框的高度：$b_h$\n* 边界框的宽度：$b_w$\n\n因此，训练集不仅包含对象分类标签，还包含表示边界框的四个数字。定义目标标签 Y 如下：\n\n$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n则有：\n\n$$P_c=1, Y = \\left[\\begin{matrix}1, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n其中，$c_n$表示存在第 $n$ 个种类的概率；如果 $P_c=0$，表示没有检测到目标，则输出标签后面的 7 个参数都是无效的，可以忽略（用 ? 来表示）。\n\n$$P_c=0, Y = \\left[\\begin{matrix}0, ?, ?, ?, ?, ?, ?, ?\\end{matrix}\\right]^T$$\n\n损失函数可以表示为 $L(\\hat y, y)$，如果使用平方误差形式，对于不同的 $P_c$有不同的损失函数（注意下标 $i$指标签的第 $i$个值）：\n\n1. $P_c=1$，即$y_1=1$：\n\n    $L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2$\n\n2. $P_c=0$，即$y_1=0$：\n\n    $L(\\hat y,y)=(\\hat y_1-y_1)^2$\n\n除了使用平方误差，也可以使用逻辑回归损失函数，类标签 $c_1,c_2,c_3$ 也可以通过 softmax 输出。相比较而言，平方误差已经能够取得比较好的效果。\n\n## 特征点检测\n\n神经网络可以像标识目标的中心点位置那样，通过输出图片上的特征点，来实现对目标特征的识别。在标签中，这些特征点以多个二维坐标的形式表示。\n\n通过检测人脸特征点可以进行情绪分类与判断，或者应用于 AR 领域等等。也可以透过检测姿态特征点来进行人体姿态检测。\n\n## 目标检测\n\n想要实现目标检测，可以采用 **基于滑动窗口的目标检测（Sliding Windows Detection）** 算法。该算法的步骤如下：\n\n1. 训练集上搜集相应的各种目标图片和非目标图片，样本图片要求尺寸较小，相应目标居于图片中心位置并基本占据整张图片。\n2. 使用训练集构建 CNN 模型，使得模型有较高的识别率。\n3. 选择大小适宜的窗口与合适的固定步幅，对测试图片进行从左到右、从上倒下的滑动遍历。每个窗口区域使用已经训练好的 CNN 模型进行识别判断。\n4. 可以选择更大的窗口，然后重复第三步的操作。\n\n![Sliding-windows-detection](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Sliding-windows-detection.png)\n\n滑动窗口目标检测的 **优点** 是原理简单，且不需要人为选定目标区域；**缺点** 是需要人为直观设定滑动窗口的大小和步幅。滑动窗口过小或过大，步幅过大均会降低目标检测的正确率。另外，每次滑动都要进行一次 CNN 网络计算，如果滑动窗口和步幅较小，计算成本往往很大。\n\n所以，滑动窗口目标检测算法虽然简单，但是性能不佳，效率较低。\n\n## 基于卷积的滑动窗口实现\n\n相比从较大图片多次截取，在卷积层上应用滑动窗口目标检测算法可以提高运行速度。所要做的仅是将全连接层换成卷积层，即使用与上一层尺寸一致的滤波器进行卷积运算。\n\n![Convolution-implementation-of-sliding-windows](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Convolution-implementation-of-sliding-windows.png)\n\n如图，对于 16x16x3 的图片，步长为 2，CNN 网络得到的输出层为 2x2x4。其中，2x2 表示共有 4 个窗口结果。对于更复杂的 28x28x3 的图片，得到的输出层为 8x8x4，共 64 个窗口结果。最大池化层的宽高和步长相等。\n\n运行速度提高的原理：在滑动窗口的过程中，需要重复进行 CNN 正向计算。因此，不需要将输入图片分割成多个子集，分别执行向前传播，而是将它们作为一张图片输入给卷积网络进行一次 CNN 正向计算。这样，公共区域的计算可以共享，以降低运算成本。\n\n相关论文：[Sermanet et al., 2014. OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks](https://arxiv.org/pdf/1312.6229.pdf)\n\n## 边框预测\n\n在上述算法中，边框的位置可能无法完美覆盖目标，或者大小不合适，或者最准确的边框并非正方形，而是长方形。\n\n**YOLO（You Only Look Once）算法** 可以用于得到更精确的边框。YOLO 算法将原始图片划分为 n×n 网格，并将目标定位一节中提到的图像分类和目标定位算法，逐一应用在每个网格中，每个网格都有标签如：\n\n$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n若某个目标的中点落在某个网格，则该网格负责检测该对象。\n\n![Bounding-Box-Predictions](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Bounding-Box-Predictions.png)\n\n如上面的示例中，如果将输入的图片划分为 3×3 的网格、需要检测的目标有 3 类，则每一网格部分图片的标签会是一个 8 维的列矩阵，最终输出的就是大小为 3×3×8 的结果。要得到这个结果，就要训练一个输入大小为 100×100×3，输出大小为 3×3×8 的 CNN。在实践中，可能使用更为精细的 19×19 网格，则两个目标的中点在同一个网格的概率更小。\n\nYOLO 算法的优点：\n\n1. 和图像分类和目标定位算法类似，显式输出边框坐标和大小，不会受到滑窗分类器的步长大小限制。\n2. 仍然只进行一次 CNN 正向计算，效率很高，甚至可以达到实时识别。\n\n如何编码边框 $b_x$、$b_y$、$b_h$、$b_w$？YOLO 算法设 $b_x$、$b_y$、$b_h$、$b_w$ 的值是相对于网格长的比例。则 $b_x$、$b_y$ 在 0 到 1 之间，而 $b_h$、$b_w$ 可以大于 1。当然，也有其他参数化的形式，且效果可能更好。这里只是给出一个通用的表示方法。\n\n相关论文：[Redmon et al., 2015. You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf)。\n\n## 交互比\n\n**交互比（IoU, Intersection Over Union）** 函数用于评价对象检测算法，它计算预测边框和实际边框交集（I）与并集（U）之比：\n\n$$IoU = \\frac{I}{U}$$\n\nIoU 的值在 0～1 之间，且越接近 1 表示目标的定位越准确。IoU 大于等于 0.5 时，一般可以认为预测边框是正确的，当然也可以更加严格地要求一个更高的阈值。\n\n## 非极大值抑制\n\nYOLO 算法中，可能有很多网格检测到同一目标。**非极大值抑制（Non-max Suppression）** 会通过清理检测结果，找到每个目标中点所位于的网格，确保算法对每个目标只检测一次。\n\n进行非极大值抑制的步骤如下：\n\n1. 将包含目标中心坐标的可信度 $P_c$ 小于阈值（例如 0.6）的网格丢弃；\n2. 选取拥有最大 $P_c$ 的网格；\n3. 分别计算该网格和其他所有网格的 IoU，将 IoU 超过预设阈值的网格丢弃；\n4. 重复第 2~3 步，直到不存在未处理的网格。\n\n上述步骤适用于单类别目标检测。进行多个类别目标检测时，对于每个类别，应该单独做一次非极大值抑制。\n\n## Anchor Boxes\n\n到目前为止，我们讨论的情况都是一个网格只检测一个对象。如果要将算法运用在多目标检测上，需要用到 Anchor Boxes。一个网格的标签中将包含多个 Anchor Box，相当于存在多个用以标识不同目标的边框。\n\n![Overlapping-objects](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Overlapping-objects.png)\n\n在上图示例中，我们希望同时检测人和汽车。因此，每个网格的的标签中含有两个 Anchor Box。输出的标签结果大小从 3×3×8 变为 3×3×16。若两个 $P_c$ 都大于预设阈值，则说明检测到了两个目标。\n\n在单目标检测中，图像中的目标被分配给了包含该目标中点的那个网格；引入 Anchor Box 进行多目标检测时，图像中的目标则被分配到了包含该目标中点的那个网格以及具有最高 IoU 值的该网格的 Anchor Box。\n\nAnchor Boxes 也有局限性，对于同一网格有三个及以上目标，或者两个目标的 Anchor Box 高度重合的情况处理不好。\n\nAnchor Box 的形状一般通过人工选取。高级一点的方法是用 k-means 将两类对象形状聚类，选择最具代表性的 Anchor Box。\n\n## R-CNN\n\n前面介绍的滑动窗口目标检测算法对一些明显没有目标的区域也进行了扫描，这降低了算法的运行效率。为了解决这个问题，**R-CNN（Region CNN，带区域的 CNN）** 被提出。通过对输入图片运行 **图像分割算法**，在不同的色块上找出 **候选区域（Region Proposal）**，就只需要在这些区域上运行分类器。\n\n![R-CNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/R-CNN.png)\n\nR-CNN 的缺点是运行速度很慢，所以有一系列后续研究工作改进。例如 Fast R-CNN（与基于卷积的滑动窗口实现相似，但得到候选区域的聚类步骤依然很慢）、Faster R-CNN（使用卷积对图片进行分割）。不过大多数时候还是比 YOLO 算法慢。\n\n相关论文：\n\n* R-CNN：[Girshik et al., 2013. Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf)\n* Fast R-CNN：[Girshik, 2015. Fast R-CNN](https://arxiv.org/pdf/1504.08083.pdf)\n* Faster R-CNN：[Ren et al., 2016. Faster R-CNN: Towards real-time object detection with region proposal networks](https://arxiv.org/pdf/1506.01497v3.pdf)\n","source":"_posts/目标检测.md","raw":"---\ntitle: 目标检测\ndate: 2018-09-02 20:06:02\ntags: 计算机视觉\ncategories: 深度学习\nmathjax: true\n---\n\n目标检测是计算机视觉领域中一个新兴的应用方向，其任务是对输入图像进行分类的同时，检测图像中是否包含某些目标，并对他们准确定位并标识。\n\n## 目标定位\n\n定位分类问题不仅要求判断出图片中物体的种类，还要在图片中标记出它的具体位置，用 **边框（Bounding Box，或者称包围盒）** 把物体圈起来。一般来说，定位分类问题通常只有一个较大的对象位于图片中间位置；而在目标检测问题中，图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象。\n\n为了定位图片中汽车的位置，可以让神经网络多输出 4 个数字，标记为 $b_x$、$b_y$、$b_h$、$b_w$。将图片左上角标记为 (0, 0)，右下角标记为 (1, 1)，则有：\n\n* 红色方框的中心点：($b_x$，$b_y$)\n* 边界框的高度：$b_h$\n* 边界框的宽度：$b_w$\n\n因此，训练集不仅包含对象分类标签，还包含表示边界框的四个数字。定义目标标签 Y 如下：\n\n$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n则有：\n\n$$P_c=1, Y = \\left[\\begin{matrix}1, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n其中，$c_n$表示存在第 $n$ 个种类的概率；如果 $P_c=0$，表示没有检测到目标，则输出标签后面的 7 个参数都是无效的，可以忽略（用 ? 来表示）。\n\n$$P_c=0, Y = \\left[\\begin{matrix}0, ?, ?, ?, ?, ?, ?, ?\\end{matrix}\\right]^T$$\n\n损失函数可以表示为 $L(\\hat y, y)$，如果使用平方误差形式，对于不同的 $P_c$有不同的损失函数（注意下标 $i$指标签的第 $i$个值）：\n\n1. $P_c=1$，即$y_1=1$：\n\n    $L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2$\n\n2. $P_c=0$，即$y_1=0$：\n\n    $L(\\hat y,y)=(\\hat y_1-y_1)^2$\n\n除了使用平方误差，也可以使用逻辑回归损失函数，类标签 $c_1,c_2,c_3$ 也可以通过 softmax 输出。相比较而言，平方误差已经能够取得比较好的效果。\n\n## 特征点检测\n\n神经网络可以像标识目标的中心点位置那样，通过输出图片上的特征点，来实现对目标特征的识别。在标签中，这些特征点以多个二维坐标的形式表示。\n\n通过检测人脸特征点可以进行情绪分类与判断，或者应用于 AR 领域等等。也可以透过检测姿态特征点来进行人体姿态检测。\n\n## 目标检测\n\n想要实现目标检测，可以采用 **基于滑动窗口的目标检测（Sliding Windows Detection）** 算法。该算法的步骤如下：\n\n1. 训练集上搜集相应的各种目标图片和非目标图片，样本图片要求尺寸较小，相应目标居于图片中心位置并基本占据整张图片。\n2. 使用训练集构建 CNN 模型，使得模型有较高的识别率。\n3. 选择大小适宜的窗口与合适的固定步幅，对测试图片进行从左到右、从上倒下的滑动遍历。每个窗口区域使用已经训练好的 CNN 模型进行识别判断。\n4. 可以选择更大的窗口，然后重复第三步的操作。\n\n![Sliding-windows-detection](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Sliding-windows-detection.png)\n\n滑动窗口目标检测的 **优点** 是原理简单，且不需要人为选定目标区域；**缺点** 是需要人为直观设定滑动窗口的大小和步幅。滑动窗口过小或过大，步幅过大均会降低目标检测的正确率。另外，每次滑动都要进行一次 CNN 网络计算，如果滑动窗口和步幅较小，计算成本往往很大。\n\n所以，滑动窗口目标检测算法虽然简单，但是性能不佳，效率较低。\n\n## 基于卷积的滑动窗口实现\n\n相比从较大图片多次截取，在卷积层上应用滑动窗口目标检测算法可以提高运行速度。所要做的仅是将全连接层换成卷积层，即使用与上一层尺寸一致的滤波器进行卷积运算。\n\n![Convolution-implementation-of-sliding-windows](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Convolution-implementation-of-sliding-windows.png)\n\n如图，对于 16x16x3 的图片，步长为 2，CNN 网络得到的输出层为 2x2x4。其中，2x2 表示共有 4 个窗口结果。对于更复杂的 28x28x3 的图片，得到的输出层为 8x8x4，共 64 个窗口结果。最大池化层的宽高和步长相等。\n\n运行速度提高的原理：在滑动窗口的过程中，需要重复进行 CNN 正向计算。因此，不需要将输入图片分割成多个子集，分别执行向前传播，而是将它们作为一张图片输入给卷积网络进行一次 CNN 正向计算。这样，公共区域的计算可以共享，以降低运算成本。\n\n相关论文：[Sermanet et al., 2014. OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks](https://arxiv.org/pdf/1312.6229.pdf)\n\n## 边框预测\n\n在上述算法中，边框的位置可能无法完美覆盖目标，或者大小不合适，或者最准确的边框并非正方形，而是长方形。\n\n**YOLO（You Only Look Once）算法** 可以用于得到更精确的边框。YOLO 算法将原始图片划分为 n×n 网格，并将目标定位一节中提到的图像分类和目标定位算法，逐一应用在每个网格中，每个网格都有标签如：\n\n$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n若某个目标的中点落在某个网格，则该网格负责检测该对象。\n\n![Bounding-Box-Predictions](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Bounding-Box-Predictions.png)\n\n如上面的示例中，如果将输入的图片划分为 3×3 的网格、需要检测的目标有 3 类，则每一网格部分图片的标签会是一个 8 维的列矩阵，最终输出的就是大小为 3×3×8 的结果。要得到这个结果，就要训练一个输入大小为 100×100×3，输出大小为 3×3×8 的 CNN。在实践中，可能使用更为精细的 19×19 网格，则两个目标的中点在同一个网格的概率更小。\n\nYOLO 算法的优点：\n\n1. 和图像分类和目标定位算法类似，显式输出边框坐标和大小，不会受到滑窗分类器的步长大小限制。\n2. 仍然只进行一次 CNN 正向计算，效率很高，甚至可以达到实时识别。\n\n如何编码边框 $b_x$、$b_y$、$b_h$、$b_w$？YOLO 算法设 $b_x$、$b_y$、$b_h$、$b_w$ 的值是相对于网格长的比例。则 $b_x$、$b_y$ 在 0 到 1 之间，而 $b_h$、$b_w$ 可以大于 1。当然，也有其他参数化的形式，且效果可能更好。这里只是给出一个通用的表示方法。\n\n相关论文：[Redmon et al., 2015. You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf)。\n\n## 交互比\n\n**交互比（IoU, Intersection Over Union）** 函数用于评价对象检测算法，它计算预测边框和实际边框交集（I）与并集（U）之比：\n\n$$IoU = \\frac{I}{U}$$\n\nIoU 的值在 0～1 之间，且越接近 1 表示目标的定位越准确。IoU 大于等于 0.5 时，一般可以认为预测边框是正确的，当然也可以更加严格地要求一个更高的阈值。\n\n## 非极大值抑制\n\nYOLO 算法中，可能有很多网格检测到同一目标。**非极大值抑制（Non-max Suppression）** 会通过清理检测结果，找到每个目标中点所位于的网格，确保算法对每个目标只检测一次。\n\n进行非极大值抑制的步骤如下：\n\n1. 将包含目标中心坐标的可信度 $P_c$ 小于阈值（例如 0.6）的网格丢弃；\n2. 选取拥有最大 $P_c$ 的网格；\n3. 分别计算该网格和其他所有网格的 IoU，将 IoU 超过预设阈值的网格丢弃；\n4. 重复第 2~3 步，直到不存在未处理的网格。\n\n上述步骤适用于单类别目标检测。进行多个类别目标检测时，对于每个类别，应该单独做一次非极大值抑制。\n\n## Anchor Boxes\n\n到目前为止，我们讨论的情况都是一个网格只检测一个对象。如果要将算法运用在多目标检测上，需要用到 Anchor Boxes。一个网格的标签中将包含多个 Anchor Box，相当于存在多个用以标识不同目标的边框。\n\n![Overlapping-objects](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Overlapping-objects.png)\n\n在上图示例中，我们希望同时检测人和汽车。因此，每个网格的的标签中含有两个 Anchor Box。输出的标签结果大小从 3×3×8 变为 3×3×16。若两个 $P_c$ 都大于预设阈值，则说明检测到了两个目标。\n\n在单目标检测中，图像中的目标被分配给了包含该目标中点的那个网格；引入 Anchor Box 进行多目标检测时，图像中的目标则被分配到了包含该目标中点的那个网格以及具有最高 IoU 值的该网格的 Anchor Box。\n\nAnchor Boxes 也有局限性，对于同一网格有三个及以上目标，或者两个目标的 Anchor Box 高度重合的情况处理不好。\n\nAnchor Box 的形状一般通过人工选取。高级一点的方法是用 k-means 将两类对象形状聚类，选择最具代表性的 Anchor Box。\n\n## R-CNN\n\n前面介绍的滑动窗口目标检测算法对一些明显没有目标的区域也进行了扫描，这降低了算法的运行效率。为了解决这个问题，**R-CNN（Region CNN，带区域的 CNN）** 被提出。通过对输入图片运行 **图像分割算法**，在不同的色块上找出 **候选区域（Region Proposal）**，就只需要在这些区域上运行分类器。\n\n![R-CNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/R-CNN.png)\n\nR-CNN 的缺点是运行速度很慢，所以有一系列后续研究工作改进。例如 Fast R-CNN（与基于卷积的滑动窗口实现相似，但得到候选区域的聚类步骤依然很慢）、Faster R-CNN（使用卷积对图片进行分割）。不过大多数时候还是比 YOLO 算法慢。\n\n相关论文：\n\n* R-CNN：[Girshik et al., 2013. Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf)\n* Fast R-CNN：[Girshik, 2015. Fast R-CNN](https://arxiv.org/pdf/1504.08083.pdf)\n* Faster R-CNN：[Ren et al., 2016. Faster R-CNN: Towards real-time object detection with region proposal networks](https://arxiv.org/pdf/1506.01497v3.pdf)\n","slug":"目标检测","published":1,"updated":"2018-09-02T13:13:55.997Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmk9ds78004mpcvoyrbn4ku8","content":"<p>目标检测是计算机视觉领域中一个新兴的应用方向，其任务是对输入图像进行分类的同时，检测图像中是否包含某些目标，并对他们准确定位并标识。</p>\n<h2 id=\"目标定位\"><a href=\"#目标定位\" class=\"headerlink\" title=\"目标定位\"></a>目标定位</h2><p>定位分类问题不仅要求判断出图片中物体的种类，还要在图片中标记出它的具体位置，用 <strong>边框（Bounding Box，或者称包围盒）</strong> 把物体圈起来。一般来说，定位分类问题通常只有一个较大的对象位于图片中间位置；而在目标检测问题中，图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象。</p>\n<p>为了定位图片中汽车的位置，可以让神经网络多输出 4 个数字，标记为 $b_x$、$b_y$、$b_h$、$b_w$。将图片左上角标记为 (0, 0)，右下角标记为 (1, 1)，则有：</p>\n<ul>\n<li>红色方框的中心点：($b_x$，$b_y$)</li>\n<li>边界框的高度：$b_h$</li>\n<li>边界框的宽度：$b_w$</li>\n</ul>\n<p>因此，训练集不仅包含对象分类标签，还包含表示边界框的四个数字。定义目标标签 Y 如下：</p>\n<p>$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$</p>\n<p>则有：</p>\n<p>$$P_c=1, Y = \\left[\\begin{matrix}1, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$</p>\n<p>其中，$c_n$表示存在第 $n$ 个种类的概率；如果 $P_c=0$，表示没有检测到目标，则输出标签后面的 7 个参数都是无效的，可以忽略（用 ? 来表示）。</p>\n<p>$$P_c=0, Y = \\left[\\begin{matrix}0, ?, ?, ?, ?, ?, ?, ?\\end{matrix}\\right]^T$$</p>\n<p>损失函数可以表示为 $L(\\hat y, y)$，如果使用平方误差形式，对于不同的 $P_c$有不同的损失函数（注意下标 $i$指标签的第 $i$个值）：</p>\n<ol>\n<li><p>$P_c=1$，即$y_1=1$：</p>\n<p> $L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2$</p>\n</li>\n<li><p>$P_c=0$，即$y_1=0$：</p>\n<p> $L(\\hat y,y)=(\\hat y_1-y_1)^2$</p>\n</li>\n</ol>\n<p>除了使用平方误差，也可以使用逻辑回归损失函数，类标签 $c_1,c_2,c_3$ 也可以通过 softmax 输出。相比较而言，平方误差已经能够取得比较好的效果。</p>\n<h2 id=\"特征点检测\"><a href=\"#特征点检测\" class=\"headerlink\" title=\"特征点检测\"></a>特征点检测</h2><p>神经网络可以像标识目标的中心点位置那样，通过输出图片上的特征点，来实现对目标特征的识别。在标签中，这些特征点以多个二维坐标的形式表示。</p>\n<p>通过检测人脸特征点可以进行情绪分类与判断，或者应用于 AR 领域等等。也可以透过检测姿态特征点来进行人体姿态检测。</p>\n<h2 id=\"目标检测\"><a href=\"#目标检测\" class=\"headerlink\" title=\"目标检测\"></a>目标检测</h2><p>想要实现目标检测，可以采用 <strong>基于滑动窗口的目标检测（Sliding Windows Detection）</strong> 算法。该算法的步骤如下：</p>\n<ol>\n<li>训练集上搜集相应的各种目标图片和非目标图片，样本图片要求尺寸较小，相应目标居于图片中心位置并基本占据整张图片。</li>\n<li>使用训练集构建 CNN 模型，使得模型有较高的识别率。</li>\n<li>选择大小适宜的窗口与合适的固定步幅，对测试图片进行从左到右、从上倒下的滑动遍历。每个窗口区域使用已经训练好的 CNN 模型进行识别判断。</li>\n<li>可以选择更大的窗口，然后重复第三步的操作。</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Sliding-windows-detection.png\" alt=\"Sliding-windows-detection\"></p>\n<p>滑动窗口目标检测的 <strong>优点</strong> 是原理简单，且不需要人为选定目标区域；<strong>缺点</strong> 是需要人为直观设定滑动窗口的大小和步幅。滑动窗口过小或过大，步幅过大均会降低目标检测的正确率。另外，每次滑动都要进行一次 CNN 网络计算，如果滑动窗口和步幅较小，计算成本往往很大。</p>\n<p>所以，滑动窗口目标检测算法虽然简单，但是性能不佳，效率较低。</p>\n<h2 id=\"基于卷积的滑动窗口实现\"><a href=\"#基于卷积的滑动窗口实现\" class=\"headerlink\" title=\"基于卷积的滑动窗口实现\"></a>基于卷积的滑动窗口实现</h2><p>相比从较大图片多次截取，在卷积层上应用滑动窗口目标检测算法可以提高运行速度。所要做的仅是将全连接层换成卷积层，即使用与上一层尺寸一致的滤波器进行卷积运算。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Convolution-implementation-of-sliding-windows.png\" alt=\"Convolution-implementation-of-sliding-windows\"></p>\n<p>如图，对于 16x16x3 的图片，步长为 2，CNN 网络得到的输出层为 2x2x4。其中，2x2 表示共有 4 个窗口结果。对于更复杂的 28x28x3 的图片，得到的输出层为 8x8x4，共 64 个窗口结果。最大池化层的宽高和步长相等。</p>\n<p>运行速度提高的原理：在滑动窗口的过程中，需要重复进行 CNN 正向计算。因此，不需要将输入图片分割成多个子集，分别执行向前传播，而是将它们作为一张图片输入给卷积网络进行一次 CNN 正向计算。这样，公共区域的计算可以共享，以降低运算成本。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1312.6229.pdf\" target=\"_blank\" rel=\"noopener\">Sermanet et al., 2014. OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</a></p>\n<h2 id=\"边框预测\"><a href=\"#边框预测\" class=\"headerlink\" title=\"边框预测\"></a>边框预测</h2><p>在上述算法中，边框的位置可能无法完美覆盖目标，或者大小不合适，或者最准确的边框并非正方形，而是长方形。</p>\n<p><strong>YOLO（You Only Look Once）算法</strong> 可以用于得到更精确的边框。YOLO 算法将原始图片划分为 n×n 网格，并将目标定位一节中提到的图像分类和目标定位算法，逐一应用在每个网格中，每个网格都有标签如：</p>\n<p>$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$</p>\n<p>若某个目标的中点落在某个网格，则该网格负责检测该对象。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Bounding-Box-Predictions.png\" alt=\"Bounding-Box-Predictions\"></p>\n<p>如上面的示例中，如果将输入的图片划分为 3×3 的网格、需要检测的目标有 3 类，则每一网格部分图片的标签会是一个 8 维的列矩阵，最终输出的就是大小为 3×3×8 的结果。要得到这个结果，就要训练一个输入大小为 100×100×3，输出大小为 3×3×8 的 CNN。在实践中，可能使用更为精细的 19×19 网格，则两个目标的中点在同一个网格的概率更小。</p>\n<p>YOLO 算法的优点：</p>\n<ol>\n<li>和图像分类和目标定位算法类似，显式输出边框坐标和大小，不会受到滑窗分类器的步长大小限制。</li>\n<li>仍然只进行一次 CNN 正向计算，效率很高，甚至可以达到实时识别。</li>\n</ol>\n<p>如何编码边框 $b_x$、$b_y$、$b_h$、$b_w$？YOLO 算法设 $b_x$、$b_y$、$b_h$、$b_w$ 的值是相对于网格长的比例。则 $b_x$、$b_y$ 在 0 到 1 之间，而 $b_h$、$b_w$ 可以大于 1。当然，也有其他参数化的形式，且效果可能更好。这里只是给出一个通用的表示方法。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1506.02640.pdf\" target=\"_blank\" rel=\"noopener\">Redmon et al., 2015. You Only Look Once: Unified, Real-Time Object Detection</a>。</p>\n<h2 id=\"交互比\"><a href=\"#交互比\" class=\"headerlink\" title=\"交互比\"></a>交互比</h2><p><strong>交互比（IoU, Intersection Over Union）</strong> 函数用于评价对象检测算法，它计算预测边框和实际边框交集（I）与并集（U）之比：</p>\n<p>$$IoU = \\frac{I}{U}$$</p>\n<p>IoU 的值在 0～1 之间，且越接近 1 表示目标的定位越准确。IoU 大于等于 0.5 时，一般可以认为预测边框是正确的，当然也可以更加严格地要求一个更高的阈值。</p>\n<h2 id=\"非极大值抑制\"><a href=\"#非极大值抑制\" class=\"headerlink\" title=\"非极大值抑制\"></a>非极大值抑制</h2><p>YOLO 算法中，可能有很多网格检测到同一目标。<strong>非极大值抑制（Non-max Suppression）</strong> 会通过清理检测结果，找到每个目标中点所位于的网格，确保算法对每个目标只检测一次。</p>\n<p>进行非极大值抑制的步骤如下：</p>\n<ol>\n<li>将包含目标中心坐标的可信度 $P_c$ 小于阈值（例如 0.6）的网格丢弃；</li>\n<li>选取拥有最大 $P_c$ 的网格；</li>\n<li>分别计算该网格和其他所有网格的 IoU，将 IoU 超过预设阈值的网格丢弃；</li>\n<li>重复第 2~3 步，直到不存在未处理的网格。</li>\n</ol>\n<p>上述步骤适用于单类别目标检测。进行多个类别目标检测时，对于每个类别，应该单独做一次非极大值抑制。</p>\n<h2 id=\"Anchor-Boxes\"><a href=\"#Anchor-Boxes\" class=\"headerlink\" title=\"Anchor Boxes\"></a>Anchor Boxes</h2><p>到目前为止，我们讨论的情况都是一个网格只检测一个对象。如果要将算法运用在多目标检测上，需要用到 Anchor Boxes。一个网格的标签中将包含多个 Anchor Box，相当于存在多个用以标识不同目标的边框。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Overlapping-objects.png\" alt=\"Overlapping-objects\"></p>\n<p>在上图示例中，我们希望同时检测人和汽车。因此，每个网格的的标签中含有两个 Anchor Box。输出的标签结果大小从 3×3×8 变为 3×3×16。若两个 $P_c$ 都大于预设阈值，则说明检测到了两个目标。</p>\n<p>在单目标检测中，图像中的目标被分配给了包含该目标中点的那个网格；引入 Anchor Box 进行多目标检测时，图像中的目标则被分配到了包含该目标中点的那个网格以及具有最高 IoU 值的该网格的 Anchor Box。</p>\n<p>Anchor Boxes 也有局限性，对于同一网格有三个及以上目标，或者两个目标的 Anchor Box 高度重合的情况处理不好。</p>\n<p>Anchor Box 的形状一般通过人工选取。高级一点的方法是用 k-means 将两类对象形状聚类，选择最具代表性的 Anchor Box。</p>\n<h2 id=\"R-CNN\"><a href=\"#R-CNN\" class=\"headerlink\" title=\"R-CNN\"></a>R-CNN</h2><p>前面介绍的滑动窗口目标检测算法对一些明显没有目标的区域也进行了扫描，这降低了算法的运行效率。为了解决这个问题，<strong>R-CNN（Region CNN，带区域的 CNN）</strong> 被提出。通过对输入图片运行 <strong>图像分割算法</strong>，在不同的色块上找出 <strong>候选区域（Region Proposal）</strong>，就只需要在这些区域上运行分类器。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/R-CNN.png\" alt=\"R-CNN\"></p>\n<p>R-CNN 的缺点是运行速度很慢，所以有一系列后续研究工作改进。例如 Fast R-CNN（与基于卷积的滑动窗口实现相似，但得到候选区域的聚类步骤依然很慢）、Faster R-CNN（使用卷积对图片进行分割）。不过大多数时候还是比 YOLO 算法慢。</p>\n<p>相关论文：</p>\n<ul>\n<li>R-CNN：<a href=\"https://arxiv.org/pdf/1311.2524.pdf\" target=\"_blank\" rel=\"noopener\">Girshik et al., 2013. Rich feature hierarchies for accurate object detection and semantic segmentation</a></li>\n<li>Fast R-CNN：<a href=\"https://arxiv.org/pdf/1504.08083.pdf\" target=\"_blank\" rel=\"noopener\">Girshik, 2015. Fast R-CNN</a></li>\n<li>Faster R-CNN：<a href=\"https://arxiv.org/pdf/1506.01497v3.pdf\" target=\"_blank\" rel=\"noopener\">Ren et al., 2016. Faster R-CNN: Towards real-time object detection with region proposal networks</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>目标检测是计算机视觉领域中一个新兴的应用方向，其任务是对输入图像进行分类的同时，检测图像中是否包含某些目标，并对他们准确定位并标识。</p>\n<h2 id=\"目标定位\"><a href=\"#目标定位\" class=\"headerlink\" title=\"目标定位\"></a>目标定位</h2><p>定位分类问题不仅要求判断出图片中物体的种类，还要在图片中标记出它的具体位置，用 <strong>边框（Bounding Box，或者称包围盒）</strong> 把物体圈起来。一般来说，定位分类问题通常只有一个较大的对象位于图片中间位置；而在目标检测问题中，图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象。</p>\n<p>为了定位图片中汽车的位置，可以让神经网络多输出 4 个数字，标记为 $b_x$、$b_y$、$b_h$、$b_w$。将图片左上角标记为 (0, 0)，右下角标记为 (1, 1)，则有：</p>\n<ul>\n<li>红色方框的中心点：($b_x$，$b_y$)</li>\n<li>边界框的高度：$b_h$</li>\n<li>边界框的宽度：$b_w$</li>\n</ul>\n<p>因此，训练集不仅包含对象分类标签，还包含表示边界框的四个数字。定义目标标签 Y 如下：</p>\n<p>$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$</p>\n<p>则有：</p>\n<p>$$P_c=1, Y = \\left[\\begin{matrix}1, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$</p>\n<p>其中，$c_n$表示存在第 $n$ 个种类的概率；如果 $P_c=0$，表示没有检测到目标，则输出标签后面的 7 个参数都是无效的，可以忽略（用 ? 来表示）。</p>\n<p>$$P_c=0, Y = \\left[\\begin{matrix}0, ?, ?, ?, ?, ?, ?, ?\\end{matrix}\\right]^T$$</p>\n<p>损失函数可以表示为 $L(\\hat y, y)$，如果使用平方误差形式，对于不同的 $P_c$有不同的损失函数（注意下标 $i$指标签的第 $i$个值）：</p>\n<ol>\n<li><p>$P_c=1$，即$y_1=1$：</p>\n<p> $L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2$</p>\n</li>\n<li><p>$P_c=0$，即$y_1=0$：</p>\n<p> $L(\\hat y,y)=(\\hat y_1-y_1)^2$</p>\n</li>\n</ol>\n<p>除了使用平方误差，也可以使用逻辑回归损失函数，类标签 $c_1,c_2,c_3$ 也可以通过 softmax 输出。相比较而言，平方误差已经能够取得比较好的效果。</p>\n<h2 id=\"特征点检测\"><a href=\"#特征点检测\" class=\"headerlink\" title=\"特征点检测\"></a>特征点检测</h2><p>神经网络可以像标识目标的中心点位置那样，通过输出图片上的特征点，来实现对目标特征的识别。在标签中，这些特征点以多个二维坐标的形式表示。</p>\n<p>通过检测人脸特征点可以进行情绪分类与判断，或者应用于 AR 领域等等。也可以透过检测姿态特征点来进行人体姿态检测。</p>\n<h2 id=\"目标检测\"><a href=\"#目标检测\" class=\"headerlink\" title=\"目标检测\"></a>目标检测</h2><p>想要实现目标检测，可以采用 <strong>基于滑动窗口的目标检测（Sliding Windows Detection）</strong> 算法。该算法的步骤如下：</p>\n<ol>\n<li>训练集上搜集相应的各种目标图片和非目标图片，样本图片要求尺寸较小，相应目标居于图片中心位置并基本占据整张图片。</li>\n<li>使用训练集构建 CNN 模型，使得模型有较高的识别率。</li>\n<li>选择大小适宜的窗口与合适的固定步幅，对测试图片进行从左到右、从上倒下的滑动遍历。每个窗口区域使用已经训练好的 CNN 模型进行识别判断。</li>\n<li>可以选择更大的窗口，然后重复第三步的操作。</li>\n</ol>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Sliding-windows-detection.png\" alt=\"Sliding-windows-detection\"></p>\n<p>滑动窗口目标检测的 <strong>优点</strong> 是原理简单，且不需要人为选定目标区域；<strong>缺点</strong> 是需要人为直观设定滑动窗口的大小和步幅。滑动窗口过小或过大，步幅过大均会降低目标检测的正确率。另外，每次滑动都要进行一次 CNN 网络计算，如果滑动窗口和步幅较小，计算成本往往很大。</p>\n<p>所以，滑动窗口目标检测算法虽然简单，但是性能不佳，效率较低。</p>\n<h2 id=\"基于卷积的滑动窗口实现\"><a href=\"#基于卷积的滑动窗口实现\" class=\"headerlink\" title=\"基于卷积的滑动窗口实现\"></a>基于卷积的滑动窗口实现</h2><p>相比从较大图片多次截取，在卷积层上应用滑动窗口目标检测算法可以提高运行速度。所要做的仅是将全连接层换成卷积层，即使用与上一层尺寸一致的滤波器进行卷积运算。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Convolution-implementation-of-sliding-windows.png\" alt=\"Convolution-implementation-of-sliding-windows\"></p>\n<p>如图，对于 16x16x3 的图片，步长为 2，CNN 网络得到的输出层为 2x2x4。其中，2x2 表示共有 4 个窗口结果。对于更复杂的 28x28x3 的图片，得到的输出层为 8x8x4，共 64 个窗口结果。最大池化层的宽高和步长相等。</p>\n<p>运行速度提高的原理：在滑动窗口的过程中，需要重复进行 CNN 正向计算。因此，不需要将输入图片分割成多个子集，分别执行向前传播，而是将它们作为一张图片输入给卷积网络进行一次 CNN 正向计算。这样，公共区域的计算可以共享，以降低运算成本。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1312.6229.pdf\" target=\"_blank\" rel=\"noopener\">Sermanet et al., 2014. OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</a></p>\n<h2 id=\"边框预测\"><a href=\"#边框预测\" class=\"headerlink\" title=\"边框预测\"></a>边框预测</h2><p>在上述算法中，边框的位置可能无法完美覆盖目标，或者大小不合适，或者最准确的边框并非正方形，而是长方形。</p>\n<p><strong>YOLO（You Only Look Once）算法</strong> 可以用于得到更精确的边框。YOLO 算法将原始图片划分为 n×n 网格，并将目标定位一节中提到的图像分类和目标定位算法，逐一应用在每个网格中，每个网格都有标签如：</p>\n<p>$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$</p>\n<p>若某个目标的中点落在某个网格，则该网格负责检测该对象。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Bounding-Box-Predictions.png\" alt=\"Bounding-Box-Predictions\"></p>\n<p>如上面的示例中，如果将输入的图片划分为 3×3 的网格、需要检测的目标有 3 类，则每一网格部分图片的标签会是一个 8 维的列矩阵，最终输出的就是大小为 3×3×8 的结果。要得到这个结果，就要训练一个输入大小为 100×100×3，输出大小为 3×3×8 的 CNN。在实践中，可能使用更为精细的 19×19 网格，则两个目标的中点在同一个网格的概率更小。</p>\n<p>YOLO 算法的优点：</p>\n<ol>\n<li>和图像分类和目标定位算法类似，显式输出边框坐标和大小，不会受到滑窗分类器的步长大小限制。</li>\n<li>仍然只进行一次 CNN 正向计算，效率很高，甚至可以达到实时识别。</li>\n</ol>\n<p>如何编码边框 $b_x$、$b_y$、$b_h$、$b_w$？YOLO 算法设 $b_x$、$b_y$、$b_h$、$b_w$ 的值是相对于网格长的比例。则 $b_x$、$b_y$ 在 0 到 1 之间，而 $b_h$、$b_w$ 可以大于 1。当然，也有其他参数化的形式，且效果可能更好。这里只是给出一个通用的表示方法。</p>\n<p>相关论文：<a href=\"https://arxiv.org/pdf/1506.02640.pdf\" target=\"_blank\" rel=\"noopener\">Redmon et al., 2015. You Only Look Once: Unified, Real-Time Object Detection</a>。</p>\n<h2 id=\"交互比\"><a href=\"#交互比\" class=\"headerlink\" title=\"交互比\"></a>交互比</h2><p><strong>交互比（IoU, Intersection Over Union）</strong> 函数用于评价对象检测算法，它计算预测边框和实际边框交集（I）与并集（U）之比：</p>\n<p>$$IoU = \\frac{I}{U}$$</p>\n<p>IoU 的值在 0～1 之间，且越接近 1 表示目标的定位越准确。IoU 大于等于 0.5 时，一般可以认为预测边框是正确的，当然也可以更加严格地要求一个更高的阈值。</p>\n<h2 id=\"非极大值抑制\"><a href=\"#非极大值抑制\" class=\"headerlink\" title=\"非极大值抑制\"></a>非极大值抑制</h2><p>YOLO 算法中，可能有很多网格检测到同一目标。<strong>非极大值抑制（Non-max Suppression）</strong> 会通过清理检测结果，找到每个目标中点所位于的网格，确保算法对每个目标只检测一次。</p>\n<p>进行非极大值抑制的步骤如下：</p>\n<ol>\n<li>将包含目标中心坐标的可信度 $P_c$ 小于阈值（例如 0.6）的网格丢弃；</li>\n<li>选取拥有最大 $P_c$ 的网格；</li>\n<li>分别计算该网格和其他所有网格的 IoU，将 IoU 超过预设阈值的网格丢弃；</li>\n<li>重复第 2~3 步，直到不存在未处理的网格。</li>\n</ol>\n<p>上述步骤适用于单类别目标检测。进行多个类别目标检测时，对于每个类别，应该单独做一次非极大值抑制。</p>\n<h2 id=\"Anchor-Boxes\"><a href=\"#Anchor-Boxes\" class=\"headerlink\" title=\"Anchor Boxes\"></a>Anchor Boxes</h2><p>到目前为止，我们讨论的情况都是一个网格只检测一个对象。如果要将算法运用在多目标检测上，需要用到 Anchor Boxes。一个网格的标签中将包含多个 Anchor Box，相当于存在多个用以标识不同目标的边框。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Overlapping-objects.png\" alt=\"Overlapping-objects\"></p>\n<p>在上图示例中，我们希望同时检测人和汽车。因此，每个网格的的标签中含有两个 Anchor Box。输出的标签结果大小从 3×3×8 变为 3×3×16。若两个 $P_c$ 都大于预设阈值，则说明检测到了两个目标。</p>\n<p>在单目标检测中，图像中的目标被分配给了包含该目标中点的那个网格；引入 Anchor Box 进行多目标检测时，图像中的目标则被分配到了包含该目标中点的那个网格以及具有最高 IoU 值的该网格的 Anchor Box。</p>\n<p>Anchor Boxes 也有局限性，对于同一网格有三个及以上目标，或者两个目标的 Anchor Box 高度重合的情况处理不好。</p>\n<p>Anchor Box 的形状一般通过人工选取。高级一点的方法是用 k-means 将两类对象形状聚类，选择最具代表性的 Anchor Box。</p>\n<h2 id=\"R-CNN\"><a href=\"#R-CNN\" class=\"headerlink\" title=\"R-CNN\"></a>R-CNN</h2><p>前面介绍的滑动窗口目标检测算法对一些明显没有目标的区域也进行了扫描，这降低了算法的运行效率。为了解决这个问题，<strong>R-CNN（Region CNN，带区域的 CNN）</strong> 被提出。通过对输入图片运行 <strong>图像分割算法</strong>，在不同的色块上找出 <strong>候选区域（Region Proposal）</strong>，就只需要在这些区域上运行分类器。</p>\n<p><img src=\"https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/R-CNN.png\" alt=\"R-CNN\"></p>\n<p>R-CNN 的缺点是运行速度很慢，所以有一系列后续研究工作改进。例如 Fast R-CNN（与基于卷积的滑动窗口实现相似，但得到候选区域的聚类步骤依然很慢）、Faster R-CNN（使用卷积对图片进行分割）。不过大多数时候还是比 YOLO 算法慢。</p>\n<p>相关论文：</p>\n<ul>\n<li>R-CNN：<a href=\"https://arxiv.org/pdf/1311.2524.pdf\" target=\"_blank\" rel=\"noopener\">Girshik et al., 2013. Rich feature hierarchies for accurate object detection and semantic segmentation</a></li>\n<li>Fast R-CNN：<a href=\"https://arxiv.org/pdf/1504.08083.pdf\" target=\"_blank\" rel=\"noopener\">Girshik, 2015. Fast R-CNN</a></li>\n<li>Faster R-CNN：<a href=\"https://arxiv.org/pdf/1506.01497v3.pdf\" target=\"_blank\" rel=\"noopener\">Ren et al., 2016. Faster R-CNN: Towards real-time object detection with region proposal networks</a></li>\n</ul>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjmk9ds0p0000pcvo29hsc6pb","category_id":"cjmk9ds150004pcvov68k4sc8","_id":"cjmk9ds20000epcvos3yksd5a"},{"post_id":"cjmk9ds0p0002pcvonlykyz9o","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds20000kpcvocr9m3fow"},{"post_id":"cjmk9ds20000dpcvoi43q13lg","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds2g000opcvo4tnpc0ub"},{"post_id":"cjmk9ds150006pcvoiic777q3","category_id":"cjmk9ds20000fpcvo40m2rklu","_id":"cjmk9ds2g000spcvoteylg946"},{"post_id":"cjmk9ds2g000npcvouxxv9u41","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds2v000xpcvow2q0bfns"},{"post_id":"cjmk9ds1l0007pcvoyxj1g1d4","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds2v0011pcvo6pbftbzr"},{"post_id":"cjmk9ds2g000qpcvon2d72175","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds3b0015pcvo9xyeaivd"},{"post_id":"cjmk9ds2g000upcvor9w6x298","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds3b0018pcvo6pazafna"},{"post_id":"cjmk9ds1l0008pcvobv37uzqh","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds3b001bpcvoeqfiz9cz"},{"post_id":"cjmk9ds2v0010pcvovvzvo1nq","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds3r001fpcvo6cn7hsqb"},{"post_id":"cjmk9ds1l000cpcvo52u7grpb","category_id":"cjmk9ds20000fpcvo40m2rklu","_id":"cjmk9ds3r001jpcvo72nvw0bh"},{"post_id":"cjmk9ds3b0017pcvoicsckkqj","category_id":"cjmk9ds3b0016pcvo6qfcsx5i","_id":"cjmk9ds3r001mpcvocnk1nf6f"},{"post_id":"cjmk9ds20000hpcvoat2clcwj","category_id":"cjmk9ds3b0016pcvo6qfcsx5i","_id":"cjmk9ds3r001rpcvolv1bv73y"},{"post_id":"cjmk9ds3b001apcvo43y1gs1f","category_id":"cjmk9ds150004pcvov68k4sc8","_id":"cjmk9ds3r001upcvokhu5l9oz"},{"post_id":"cjmk9ds3r001epcvorq5ejjza","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds46001ypcvoknnroaz7"},{"post_id":"cjmk9ds20000jpcvom2it3i2u","category_id":"cjmk9ds3r001dpcvozzn363hv","_id":"cjmk9ds460022pcvosvowxsvn"},{"post_id":"cjmk9ds3r001lpcvot6j5sa83","category_id":"cjmk9ds150004pcvov68k4sc8","_id":"cjmk9ds460025pcvos7mkhvff"},{"post_id":"cjmk9ds2v000wpcvoa6m6h01e","category_id":"cjmk9ds3r001npcvoxjzvoztl","_id":"cjmk9ds4m0028pcvo349g3rqp"},{"post_id":"cjmk9ds3b0014pcvoiig0jwry","category_id":"cjmk9ds3r001vpcvojunlbyl6","_id":"cjmk9ds4m002cpcvoymx6suq5"},{"post_id":"cjmk9ds460024pcvo4qkm87z0","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds4m002fpcvoj84ik9in"},{"post_id":"cjmk9ds3r001ipcvoe9cme28i","category_id":"cjmk9ds3r001vpcvojunlbyl6","_id":"cjmk9ds4m002jpcvog944m3rc"},{"post_id":"cjmk9ds4m002bpcvo3288fo85","category_id":"cjmk9ds3r001npcvoxjzvoztl","_id":"cjmk9ds4m002mpcvo530fz9bv"},{"post_id":"cjmk9ds3r001qpcvoq1xl4c9h","category_id":"cjmk9ds4m002apcvox71sx5fb","_id":"cjmk9ds52002qpcvotb37gzwt"},{"post_id":"cjmk9ds4m002ipcvoqpuwqqto","category_id":"cjmk9ds3r001npcvoxjzvoztl","_id":"cjmk9ds52002tpcvojc34ls9w"},{"post_id":"cjmk9ds3r001tpcvootry7me7","category_id":"cjmk9ds4m002apcvox71sx5fb","_id":"cjmk9ds52002xpcvoy09hbymg"},{"post_id":"cjmk9ds4m002lpcvo8ha7j3lm","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds520031pcvoe3au1xuv"},{"post_id":"cjmk9ds4m002ppcvop7cdaq7n","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds5h0034pcvor2syfvo8"},{"post_id":"cjmk9ds52002spcvoew94a24z","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds5h0038pcvoqfic3dcl"},{"post_id":"cjmk9ds46001xpcvor6vjil6y","category_id":"cjmk9ds4m002opcvo3cilj6q5","_id":"cjmk9ds5h003bpcvoeg129ljg"},{"post_id":"cjmk9ds520030pcvosm83t500","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds5h003fpcvol2nzqm2f"},{"post_id":"cjmk9ds460021pcvoadujnupl","category_id":"cjmk9ds4m002apcvox71sx5fb","_id":"cjmk9ds5h003jpcvoukyr68nb"},{"post_id":"cjmk9ds520033pcvokom36u84","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds5x003mpcvobo3qzm5s"},{"post_id":"cjmk9ds5h0037pcvo528wkpl3","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds5x003qpcvoweb3jqyn"},{"post_id":"cjmk9ds460027pcvoy2r0028l","category_id":"cjmk9ds5h0035pcvo6vcovkpg","_id":"cjmk9ds5x003tpcvor37kiopw"},{"post_id":"cjmk9ds5h003apcvo9cvrlmpb","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds6c003wpcvogk6g3t1t"},{"post_id":"cjmk9ds52002wpcvoehm7vggp","category_id":"cjmk9ds5h003cpcvo3xx55dg8","_id":"cjmk9ds6c0040pcvow4lhrw7e"},{"post_id":"cjmk9ds5h003ipcvoce83xwfn","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds6c0043pcvo4zidv7zh"},{"post_id":"cjmk9ds5x003lpcvo95t42d21","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds6c0048pcvoo7puu0mj"},{"post_id":"cjmk9ds5x003ppcvorwljm923","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds6s004apcvo6dgas6s2"},{"post_id":"cjmk9ds5x003spcvofcn7dpvg","category_id":"cjmk9ds3r001dpcvozzn363hv","_id":"cjmk9ds6s004dpcvox708xvui"},{"post_id":"cjmk9ds5x003vpcvoodlqserk","category_id":"cjmk9ds5h003cpcvo3xx55dg8","_id":"cjmk9ds6s004gpcvosyb6d6vd"},{"post_id":"cjmk9ds6c0042pcvokftlunnh","category_id":"cjmk9ds3r001npcvoxjzvoztl","_id":"cjmk9ds6s004kpcvojprb4vdl"},{"post_id":"cjmk9ds6c0047pcvolhdvlrpn","category_id":"cjmk9ds4m002opcvo3cilj6q5","_id":"cjmk9ds78004npcvogyz3oyum"},{"post_id":"cjmk9ds6s0049pcvor4x38y4d","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds78004qpcvosu6p0au2"},{"post_id":"cjmk9ds6c003zpcvowteh0pib","category_id":"cjmk9ds6c0045pcvoqrcdgpka","_id":"cjmk9ds78004spcvocga5c7om"},{"post_id":"cjmk9ds6s004cpcvofzjw1hgy","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds78004upcvo4pdoogpk"},{"post_id":"cjmk9ds6s004fpcvo7z2sh4st","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds78004xpcvooe4s6396"},{"post_id":"cjmk9ds6s004jpcvoq9b4rtgm","category_id":"cjmk9ds5h003cpcvo3xx55dg8","_id":"cjmk9ds78004ypcvoy4wk6lo7"},{"post_id":"cjmk9ds78004mpcvoyrbn4ku8","category_id":"cjmk9ds1l0009pcvoqkgt0l64","_id":"cjmk9ds780050pcvo1bva5icw"}],"PostTag":[{"post_id":"cjmk9ds0p0000pcvo29hsc6pb","tag_id":"cjmk9ds150005pcvoj9mm1y37","_id":"cjmk9ds1l000bpcvomofooc4g"},{"post_id":"cjmk9ds0p0002pcvonlykyz9o","tag_id":"cjmk9ds1l000apcvogfas5aqk","_id":"cjmk9ds20000ipcvogqqu89t2"},{"post_id":"cjmk9ds150006pcvoiic777q3","tag_id":"cjmk9ds20000gpcvok0rfgxqg","_id":"cjmk9ds2g000ppcvo2sn1eji5"},{"post_id":"cjmk9ds1l0007pcvoyxj1g1d4","tag_id":"cjmk9ds2g000mpcvo3m28paft","_id":"cjmk9ds2v000vpcvo5vwybnrw"},{"post_id":"cjmk9ds2g000upcvor9w6x298","tag_id":"cjmk9ds1l000apcvogfas5aqk","_id":"cjmk9ds2v000zpcvog1j3pfuh"},{"post_id":"cjmk9ds1l0008pcvobv37uzqh","tag_id":"cjmk9ds2g000tpcvo7kxki61c","_id":"cjmk9ds3b0013pcvol2pzttk8"},{"post_id":"cjmk9ds1l000cpcvo52u7grpb","tag_id":"cjmk9ds2v0012pcvosdy68sb2","_id":"cjmk9ds3b001cpcvondcgh791"},{"post_id":"cjmk9ds3b001apcvo43y1gs1f","tag_id":"cjmk9ds150005pcvoj9mm1y37","_id":"cjmk9ds3r001hpcvow1iqiure"},{"post_id":"cjmk9ds20000dpcvoi43q13lg","tag_id":"cjmk9ds3b0019pcvo0ual6dz8","_id":"cjmk9ds3r001kpcvo9ey0d6zx"},{"post_id":"cjmk9ds3r001ipcvoe9cme28i","tag_id":"cjmk9ds150005pcvoj9mm1y37","_id":"cjmk9ds3r001opcvo19sfxsl5"},{"post_id":"cjmk9ds20000hpcvoat2clcwj","tag_id":"cjmk9ds3r001gpcvoa0qcc8wy","_id":"cjmk9ds3r001spcvoj3qansy9"},{"post_id":"cjmk9ds3r001lpcvot6j5sa83","tag_id":"cjmk9ds150005pcvoj9mm1y37","_id":"cjmk9ds3r001wpcvos6c8v5wz"},{"post_id":"cjmk9ds20000jpcvom2it3i2u","tag_id":"cjmk9ds3r001ppcvodm8i9w3f","_id":"cjmk9ds460020pcvoc8sxske8"},{"post_id":"cjmk9ds2g000npcvouxxv9u41","tag_id":"cjmk9ds46001zpcvoeeomp9n9","_id":"cjmk9ds4m0029pcvo1k419vnb"},{"post_id":"cjmk9ds2g000qpcvon2d72175","tag_id":"cjmk9ds460026pcvo5bmxru00","_id":"cjmk9ds4m002gpcvo4mptzgsx"},{"post_id":"cjmk9ds2v000wpcvoa6m6h01e","tag_id":"cjmk9ds4m002dpcvo1buiudmq","_id":"cjmk9ds4m002npcvo7ql4zz1e"},{"post_id":"cjmk9ds4m002lpcvo8ha7j3lm","tag_id":"cjmk9ds46001zpcvoeeomp9n9","_id":"cjmk9ds52002rpcvogje2dubi"},{"post_id":"cjmk9ds4m002ppcvop7cdaq7n","tag_id":"cjmk9ds460026pcvo5bmxru00","_id":"cjmk9ds52002vpcvogdotn63x"},{"post_id":"cjmk9ds2v0010pcvovvzvo1nq","tag_id":"cjmk9ds4m002kpcvolqk5ylnf","_id":"cjmk9ds52002zpcvotth7zr21"},{"post_id":"cjmk9ds3b0014pcvoiig0jwry","tag_id":"cjmk9ds52002upcvo2wyb2y6g","_id":"cjmk9ds5h0036pcvoq5t0k3p6"},{"post_id":"cjmk9ds3r001epcvorq5ejjza","tag_id":"cjmk9ds520032pcvo55scfa42","_id":"cjmk9ds5h003dpcvom7rz0nks"},{"post_id":"cjmk9ds5h0037pcvo528wkpl3","tag_id":"cjmk9ds46001zpcvoeeomp9n9","_id":"cjmk9ds5h003gpcvolq4nvgnb"},{"post_id":"cjmk9ds5h003apcvo9cvrlmpb","tag_id":"cjmk9ds46001zpcvoeeomp9n9","_id":"cjmk9ds5x003kpcvof7i2j7mx"},{"post_id":"cjmk9ds3r001qpcvoq1xl4c9h","tag_id":"cjmk9ds5h0039pcvof0rvkgdn","_id":"cjmk9ds5x003npcvouxuqle2e"},{"post_id":"cjmk9ds5h003epcvondqcendx","tag_id":"cjmk9ds46001zpcvoeeomp9n9","_id":"cjmk9ds5x003rpcvopsvzavst"},{"post_id":"cjmk9ds5h003ipcvoce83xwfn","tag_id":"cjmk9ds460026pcvo5bmxru00","_id":"cjmk9ds5x003upcvosi3t2gdd"},{"post_id":"cjmk9ds3r001tpcvootry7me7","tag_id":"cjmk9ds5h0039pcvof0rvkgdn","_id":"cjmk9ds6c003ypcvo97vurbex"},{"post_id":"cjmk9ds46001xpcvor6vjil6y","tag_id":"cjmk9ds5x003opcvoomtxnbs3","_id":"cjmk9ds6c0041pcvoj5r9oy9m"},{"post_id":"cjmk9ds460021pcvoadujnupl","tag_id":"cjmk9ds5h0039pcvof0rvkgdn","_id":"cjmk9ds6c0046pcvoadjfvkra"},{"post_id":"cjmk9ds460024pcvo4qkm87z0","tag_id":"cjmk9ds6c0044pcvoeb1n7ldc","_id":"cjmk9ds6s004epcvojeql9pxi"},{"post_id":"cjmk9ds6s0049pcvor4x38y4d","tag_id":"cjmk9ds6c0044pcvoeb1n7ldc","_id":"cjmk9ds6s004hpcvol9e3jrcm"},{"post_id":"cjmk9ds460027pcvoy2r0028l","tag_id":"cjmk9ds6s004bpcvoxgwus7ix","_id":"cjmk9ds6s004lpcvos4vdul4x"},{"post_id":"cjmk9ds6s004fpcvo7z2sh4st","tag_id":"cjmk9ds46001zpcvoeeomp9n9","_id":"cjmk9ds78004opcvoguxrm8aw"},{"post_id":"cjmk9ds4m002bpcvo3288fo85","tag_id":"cjmk9ds6s004ipcvo9edlrky9","_id":"cjmk9ds78004rpcvomxec5apr"},{"post_id":"cjmk9ds78004mpcvoyrbn4ku8","tag_id":"cjmk9ds6c0044pcvoeb1n7ldc","_id":"cjmk9ds78004tpcvo921dhupa"},{"post_id":"cjmk9ds4m002epcvo2wgarlgu","tag_id":"cjmk9ds78004ppcvofw3onulp","_id":"cjmk9ds78004wpcvoe7akdmer"},{"post_id":"cjmk9ds4m002ipcvoqpuwqqto","tag_id":"cjmk9ds78004vpcvoa1u0aln4","_id":"cjmk9ds780051pcvopeyvskyg"},{"post_id":"cjmk9ds52002spcvoew94a24z","tag_id":"cjmk9ds78004zpcvod2ts71b6","_id":"cjmk9ds7n0053pcvohagu7916"},{"post_id":"cjmk9ds52002wpcvoehm7vggp","tag_id":"cjmk9ds780052pcvodh9smlgx","_id":"cjmk9ds7n0055pcvoskowuulx"},{"post_id":"cjmk9ds520030pcvosm83t500","tag_id":"cjmk9ds7n0054pcvo31zun886","_id":"cjmk9ds7n0057pcvo4jm9dtvm"},{"post_id":"cjmk9ds520033pcvokom36u84","tag_id":"cjmk9ds7n0054pcvo31zun886","_id":"cjmk9ds7n0059pcvo0az700bc"},{"post_id":"cjmk9ds5x003lpcvo95t42d21","tag_id":"cjmk9ds7n0058pcvoo0x8tzyi","_id":"cjmk9ds7n005bpcvoscd4zk6w"},{"post_id":"cjmk9ds5x003ppcvorwljm923","tag_id":"cjmk9ds7n005apcvojcyyzmse","_id":"cjmk9ds7n005dpcvot8423wh3"},{"post_id":"cjmk9ds5x003spcvofcn7dpvg","tag_id":"cjmk9ds7n005cpcvor7wbduz7","_id":"cjmk9ds7n005fpcvogxwd975t"},{"post_id":"cjmk9ds5x003vpcvoodlqserk","tag_id":"cjmk9ds780052pcvodh9smlgx","_id":"cjmk9ds7n005hpcvobfektjdn"},{"post_id":"cjmk9ds6c003zpcvowteh0pib","tag_id":"cjmk9ds7n005gpcvo8sj7orh4","_id":"cjmk9ds7n005jpcvo8qx1aap3"},{"post_id":"cjmk9ds6c0042pcvokftlunnh","tag_id":"cjmk9ds6s004ipcvo9edlrky9","_id":"cjmk9ds7n005lpcvoc761mrbi"},{"post_id":"cjmk9ds6c0047pcvolhdvlrpn","tag_id":"cjmk9ds7n005kpcvoja9e22nv","_id":"cjmk9ds83005npcvogv1zsalh"},{"post_id":"cjmk9ds6s004cpcvofzjw1hgy","tag_id":"cjmk9ds83005mpcvokd58jjzo","_id":"cjmk9ds83005ppcvobxztm5vv"},{"post_id":"cjmk9ds6s004jpcvoq9b4rtgm","tag_id":"cjmk9ds780052pcvodh9smlgx","_id":"cjmk9ds83005qpcvo13ajbep9"}],"Tag":[{"name":"python","_id":"cjmk9ds150005pcvoj9mm1y37"},{"name":"数据集","_id":"cjmk9ds1l000apcvogfas5aqk"},{"name":"进化算法","_id":"cjmk9ds20000gpcvok0rfgxqg"},{"name":"FasterR-CNN","_id":"cjmk9ds2g000mpcvo3m28paft"},{"name":"DNN","_id":"cjmk9ds2g000tpcvo7kxki61c"},{"name":"遗传算法","_id":"cjmk9ds2v0012pcvosdy68sb2"},{"name":"ResNet","_id":"cjmk9ds3b0019pcvo0ual6dz8"},{"name":"hexo","_id":"cjmk9ds3r001gpcvoa0qcc8wy"},{"name":"回归","_id":"cjmk9ds3r001ppcvodm8i9w3f"},{"name":"优化算法","_id":"cjmk9ds46001zpcvoeeomp9n9"},{"name":"CNN","_id":"cjmk9ds460026pcvo5bmxru00"},{"name":"Permutation","_id":"cjmk9ds4m002dpcvo1buiudmq"},{"name":"CNN, VGG","_id":"cjmk9ds4m002kpcvolqk5ylnf"},{"name":"git","_id":"cjmk9ds52002upcvo2wyb2y6g"},{"name":"dropout","_id":"cjmk9ds520032pcvo55scfa42"},{"name":"tensorflow_python_API","_id":"cjmk9ds5h0039pcvof0rvkgdn"},{"name":"路遥","_id":"cjmk9ds5x003opcvoomtxnbs3"},{"name":"计算机视觉","_id":"cjmk9ds6c0044pcvoeb1n7ldc"},{"name":"信息简史","_id":"cjmk9ds6s004bpcvoxgwus7ix"},{"name":"动态规划","_id":"cjmk9ds6s004ipcvo9edlrky9"},{"name":"策略游戏","_id":"cjmk9ds78004ppcvofw3onulp"},{"name":"分治策略","_id":"cjmk9ds78004vpcvoa1u0aln4"},{"name":"RNN","_id":"cjmk9ds78004zpcvod2ts71b6"},{"name":"爱情心理学","_id":"cjmk9ds780052pcvodh9smlgx"},{"name":"数据","_id":"cjmk9ds7n0054pcvo31zun886"},{"name":"模型估计","_id":"cjmk9ds7n0058pcvoo0x8tzyi"},{"name":"正则化","_id":"cjmk9ds7n005apcvojcyyzmse"},{"name":"线性代数","_id":"cjmk9ds7n005cpcvor7wbduz7"},{"name":"物理","_id":"cjmk9ds7n005gpcvo8sj7orh4"},{"name":"现代诗","_id":"cjmk9ds7n005kpcvoja9e22nv"},{"name":"神经网络","_id":"cjmk9ds83005mpcvokd58jjzo"}]}}