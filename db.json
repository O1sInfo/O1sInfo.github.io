{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/Convolutions-on-RGB-image.png","path":"images/Convolutions-on-RGB-image.png","modified":0,"renderable":0},{"_id":"source/images/Padding.jpg","path":"images/Padding.jpg","modified":0,"renderable":0},{"_id":"source/images/Stride.jpg","path":"images/Stride.jpg","modified":0,"renderable":0},{"_id":"source/images/adam.PNG","path":"images/adam.PNG","modified":0,"renderable":0},{"_id":"source/images/alexnet_ilsvrc.PNG","path":"images/alexnet_ilsvrc.PNG","modified":0,"renderable":0},{"_id":"source/images/res1.PNG","path":"images/res1.PNG","modified":0,"renderable":0},{"_id":"source/images/vgg_performance_1.PNG","path":"images/vgg_performance_1.PNG","modified":0,"renderable":0},{"_id":"source/images/vgg_performance_2.PNG","path":"images/vgg_performance_2.PNG","modified":0,"renderable":0},{"_id":"source/images/vgg_performance_3.PNG","path":"images/vgg_performance_3.PNG","modified":0,"renderable":0},{"_id":"source/images/eas.png","path":"images/eas.png","modified":0,"renderable":0},{"_id":"source/images/minibatch.png","path":"images/minibatch.png","modified":0,"renderable":0},{"_id":"source/images/my_image.jpg","path":"images/my_image.jpg","modified":0,"renderable":0},{"_id":"source/images/partition.png","path":"images/partition.png","modified":0,"renderable":0},{"_id":"source/images/sgd.png","path":"images/sgd.png","modified":0,"renderable":0},{"_id":"source/images/alexnet_architecture.PNG","path":"images/alexnet_architecture.PNG","modified":0,"renderable":0},{"_id":"source/images/momentum.png","path":"images/momentum.png","modified":0,"renderable":0},{"_id":"source/images/shuffle.png","path":"images/shuffle.png","modified":0,"renderable":0},{"_id":"source/images/vgg_architecture.PNG","path":"images/vgg_architecture.PNG","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.jpeg","path":"images/avatar.jpeg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"source/images/LlayerNN.png","path":"images/LlayerNN.png","modified":0,"renderable":0},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"source/images/动态规划.jpg","path":"images/动态规划.jpg","modified":0,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"source/images/dl_pic9_2.jpg","path":"images/dl_pic9_2.jpg","modified":0,"renderable":0},{"_id":"source/images/dl_pic9_5.jpg","path":"images/dl_pic9_5.jpg","modified":0,"renderable":0},{"_id":"source/images/dl_pic9_8.jpg","path":"images/dl_pic9_8.jpg","modified":0,"renderable":0},{"_id":"source/images/dl_pic9_7.jpg","path":"images/dl_pic9_7.jpg","modified":0,"renderable":0}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"334da94ca6f024d60d012cc26ea655681e724ad8","modified":1534643975928},{"_id":"themes/next/.editorconfig","hash":"211d2c92bfdddb3e81ea946f4ca7a539f150f4da","modified":1534643975928},{"_id":"themes/next/.gitattributes","hash":"8454b9313cb1a97b63fb87e2d29daee497ce6249","modified":1534643975929},{"_id":"themes/next/.gitignore","hash":"ee0b13c268cc8695d3883a5da84930af02d4ed08","modified":1534643975934},{"_id":"themes/next/.hound.yml","hash":"289dcf5bfe92dbd680d54d6e0668f41c9c9c0c78","modified":1534643975935},{"_id":"themes/next/.javascript_ignore","hash":"cd250ad74ca22bd2c054476456a73d9687f05f87","modified":1534643975935},{"_id":"themes/next/.jshintrc","hash":"b7d23f2ce8d99fa073f22f9960605f318acd7710","modified":1534643975936},{"_id":"themes/next/.stylintrc","hash":"3b7f9785e9ad0dab764e1c535b40df02f4ff5fd6","modified":1534643975937},{"_id":"themes/next/.travis.yml","hash":"6674fbdfe0d0c03b8a04527ffb8ab66a94253acd","modified":1534643975938},{"_id":"themes/next/LICENSE","hash":"ec44503d7e617144909e54533754f0147845f0c5","modified":1534643975938},{"_id":"themes/next/README.cn.md","hash":"23e92a2599725db2f8dbd524fbef2087c6d11c7b","modified":1534643975939},{"_id":"themes/next/README.md","hash":"50abff86ffe4113051a409c1ed9261195d2aead0","modified":1534643975940},{"_id":"themes/next/_config.yml","hash":"70a30c95b33b0833feebf579410f2043e1a8fec4","modified":1534643975942},{"_id":"themes/next/bower.json","hash":"486ebd72068848c97def75f36b71cbec9bb359c5","modified":1534643975943},{"_id":"themes/next/gulpfile.coffee","hash":"412defab3d93d404b7c26aaa0279e2e586e97454","modified":1534643975944},{"_id":"themes/next/package.json","hash":"3963ad558a24c78a3fd4ef23cf5f73f421854627","modified":1534643976022},{"_id":"source/categories/index.md","hash":"a8ee8e11f9d453a17eb3467620d7b43ff97856b3","modified":1534643975811},{"_id":"source/_posts/BeautifulSoup.md","hash":"1008211f5e6229cbcb008945f37f9b4bf99e2d08","modified":1535687506501},{"_id":"source/_posts/CIFAR-10.md","hash":"b21b58235f64126869797d922233c5492c71a06e","modified":1537588316207},{"_id":"source/_posts/DNN应用1-识别猫.md","hash":"b1710cf7ffc930619cf1a4e3e32099755527c42c","modified":1535687326687},{"_id":"source/_posts/Evolutionary-Algorithms.md","hash":"ed4b9fa58dce005de7894dfc88b27cdb0cd4a0c7","modified":1534643975787},{"_id":"source/_posts/Genetic-Algorithms.md","hash":"dcdf9134d8883b1761660673c4727eb14fca42ac","modified":1534643975788},{"_id":"source/_posts/Gradient-Descent-Famliy.md","hash":"0629933ed0327d4bf998cc82768e1fe547f88bdd","modified":1534643975789},{"_id":"source/_posts/How-to-set-up-a-blog-with-hexo-on-github-io.md","hash":"b2d62d7d9a8e27d598ac19144990ec4b6e184ab7","modified":1534643975790},{"_id":"source/_posts/ImageNet-Classification-wih-Deep-Convolutional-Neural-Network.md","hash":"3a148b4726ef28f262e7e796f3347a7cfb38e00a","modified":1535441142186},{"_id":"source/_posts/Linear-Models-for-Regression.md","hash":"9a5f71d3fad1a0f9a9acdf2607ac07be6c9d878e","modified":1537593366271},{"_id":"source/_posts/MNIST数据集.md","hash":"3d50656e87b7715aebb35ec70f96078109df82e6","modified":1536315219495},{"_id":"source/_posts/Permutation-generate.md","hash":"376d68fa0b578eb3a4bd75a54b5bc909d66b643d","modified":1536153491624},{"_id":"source/_posts/Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recongnition.md","hash":"adc197ae2d097dbe46eb7aa5325ccad04d04fee4","modified":1535688366157},{"_id":"source/_posts/dropout.md","hash":"6a99f299ac939dd3a41df7835a8a087b927687f9","modified":1535687345231},{"_id":"source/_posts/github使用手册.md","hash":"0a47a341a124c82322d4ad91955e92a6f71856b3","modified":1534643975791},{"_id":"source/_posts/hello-world.md","hash":"b4f283c1f275e64526f5fc48cbe315056937d25b","modified":1534643975792},{"_id":"source/_posts/matplotlib.md","hash":"eba9b1652a8c19b6105ad07694a047dcc0807a80","modified":1535687505318},{"_id":"source/_posts/python内置小工具.md","hash":"ef8b4eb12c79a9dbd58d7b8f336736ae2d803158","modified":1535687502853},{"_id":"source/_posts/requests.md","hash":"59529895800fb8482113452f10018a54111e2e9a","modified":1535687504175},{"_id":"source/_posts/tensorflow-graphs.md","hash":"5de9493554ce7e4f7580063b184677f1fcbe649d","modified":1536141518618},{"_id":"source/_posts/tensorflow-session.md","hash":"b43b084a9d1c3539301e18796bb1e0c6bd4fc7a7","modified":1536139560927},{"_id":"source/_posts/tensorflow-variable.md","hash":"f34e67698402e2faa161e7f959e111d4e9a9042e","modified":1536141449074},{"_id":"source/_posts/人生-路遥.md","hash":"f5d4a086290f8ade7329baa72e8b935674369c12","modified":1535687293715},{"_id":"source/_posts/人脸识别.md","hash":"5626606b93d644538bcf4fc00faa49b76f54651b","modified":1536141721859},{"_id":"source/_posts/信息简史.md","hash":"f4b095a040a68978c3bc14c71884584b0a37c3f8","modified":1537588209092},{"_id":"source/_posts/分治策略.md","hash":"86e533028e27b9ac01a3056f3453bbf31c394629","modified":1537594109852},{"_id":"source/_posts/初始化参数.md","hash":"ef2ef9e89b5e89136093e6ec6f764a7efc06a593","modified":1535687536653},{"_id":"source/_posts/动态规划.md","hash":"56f782a23859556948e065c55632d8801dc29036","modified":1535704152233},{"_id":"source/_posts/十个策略故事.md","hash":"b2a623b9b7c150872b3c66dd7a7b0a9942eed343","modified":1534643975798},{"_id":"source/_posts/卷积神经网络.md","hash":"cb922c50498f59cb74d8ec93d09061dd459c10e9","modified":1535276910935},{"_id":"source/_posts/吴恩达深度学习课程总结.md","hash":"42a19b0002d01c0b58cc7e51e021fd91028eaa74","modified":1537594502561},{"_id":"source/_posts/布雷默曼极限.md","hash":"afbce1ad2cbc988ae99ded453c349980077e09de","modified":1535687596775},{"_id":"source/_posts/循环神经网络.md","hash":"70f368ab83aecfa37b9624a10d04e22b3963abab","modified":1535811314770},{"_id":"source/_posts/恋爱领域中普遍存在的贬低倾向.md","hash":"fa3c3e6eaa81ff2235909606a34ad5588f6874ab","modified":1535687606675},{"_id":"source/_posts/数据划分.md","hash":"83654aaf4f99fcac17baa8c6e66d37e792ffbae3","modified":1535687627798},{"_id":"source/_posts/数据的加载-预处理-可视化.md","hash":"439ff19283a8609dbcf47360d3cb02f425f40cdd","modified":1535687642897},{"_id":"source/_posts/标准化输入.md","hash":"9d482d1a4842e31ebeb7b919203eac7ff0de3d9d","modified":1535687652437},{"_id":"source/_posts/梯度检验.md","hash":"aa5e2f7a95c3a877a6bbc5253c7e6ce0f2166d72","modified":1535687665694},{"_id":"source/_posts/梯度消失和梯度爆炸.md","hash":"7be3d8c157b23cf72a7f1a4ed88a68127662bfc5","modified":1535687676141},{"_id":"source/_posts/模型估计.md","hash":"ec16ec21c42690d5968df84bddb38f7b28ec8227","modified":1535687684876},{"_id":"source/_posts/正则化.md","hash":"260fbe654114812d2997c0bfcac8176bcd5c5d3e","modified":1535687689461},{"_id":"source/_posts/深度卷积神经网络-实例探究.md","hash":"2969f6cc6248d108ccb75a2ba125f812cf5b8540","modified":1535276918084},{"_id":"source/_posts/深度学习中的优化算法.md","hash":"f16e813ad88a268779cc2010e4f1be080e326aa4","modified":1534643975807},{"_id":"source/_posts/男人的对象选择中的一种特殊类型.md","hash":"0c97240879e4daa25f626715bd7fe8e4c25764f1","modified":1535687701946},{"_id":"source/_posts/目标检测.md","hash":"672e3d83d49ed48a507e9a932e3f6db15a801f8e","modified":1535894035997},{"_id":"source/_posts/矩阵链乘法.md","hash":"0589a9189f63c3cb54b03afaef349a7a3ae8fadc","modified":1535852326520},{"_id":"source/_posts/短诗三首.md","hash":"68fdc78b87c059c5298a688f39c513313fd98385","modified":1535687708779},{"_id":"source/_posts/神经网络中的通用函数代码.md","hash":"32f35f0e124c47947232cc4a1f6efa54c4299111","modified":1535687723326},{"_id":"source/_posts/神经风格迁移.md","hash":"121b59631be144faffd8d052cf2a53c1974ba1bb","modified":1536148296557},{"_id":"source/_posts/贞洁禁忌.md","hash":"4f13f4b09d5ec839d729dcbab2b3d2f1dcbd9231","modified":1535687727511},{"_id":"source/images/Convolutions-on-RGB-image.png","hash":"b4de22ca607e562f21ec385e5dd14d8b11a93914","modified":1531227954186},{"_id":"source/images/Padding.jpg","hash":"e53f0396b1e806eeb94effbd33ed1d0ea1977e12","modified":1531227954202},{"_id":"source/images/Stride.jpg","hash":"56c57dbb8d74628ac798fa3c23fa1ec969146576","modified":1531227954214},{"_id":"source/images/adam.PNG","hash":"f2adc403d4012046172c37175835fefb8bec932f","modified":1534643975815},{"_id":"source/images/alexnet_ilsvrc.PNG","hash":"9f57a90d68124ad1290137cf824e9f0485f33bf7","modified":1535439784780},{"_id":"source/images/res1.PNG","hash":"f528eca6822e71539139aa1b2795847135dc2b07","modified":1534643975825},{"_id":"source/images/vgg_performance_1.PNG","hash":"2ecefe1a373a0662f644679281456361f08a2ba7","modified":1535686214202},{"_id":"source/images/vgg_performance_2.PNG","hash":"93cc3cdf6cec1db638feebef7f3ec642cdc4de7e","modified":1535686639375},{"_id":"source/images/vgg_performance_3.PNG","hash":"6f7e807fbfb6518dd4edebaeccc3e57f47a2525c","modified":1535686752411},{"_id":"source/tags/index.md","hash":"a75687420abbf3ff738d0fea7fe2634cbd4340e9","modified":1534643975834},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5adfad3ef1b870063e621bc0838268eb2c7c697a","modified":1534643975930},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"a0a82dbfabdef9a9d7c17a08ceebfb4052d98d81","modified":1534643975931},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1228506a940114288d61812bfe60c045a0abeac1","modified":1534643975932},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1534643975933},{"_id":"themes/next/languages/de.yml","hash":"fd02d9c2035798d5dc7c1a96b4c3e24b05b31a47","modified":1534643975945},{"_id":"themes/next/languages/default.yml","hash":"b3bcd8934327448a43d9bfada5dd11b1b8c1402e","modified":1534643975946},{"_id":"themes/next/languages/en.yml","hash":"2f4b4776ca1a08cc266a19afb0d1350a3926f42c","modified":1534643975947},{"_id":"themes/next/languages/fr-FR.yml","hash":"efeeb55d5c4add54ad59a612fc0630ee1300388c","modified":1534643975948},{"_id":"themes/next/languages/id.yml","hash":"dccae33e2a5b3c9f11c0e05ec4a7201af1b25745","modified":1534643975948},{"_id":"themes/next/languages/it.yml","hash":"a215d016146b1bd92cef046042081cbe0c7f976f","modified":1534643975950},{"_id":"themes/next/languages/ja.yml","hash":"37f954e47a3bc669620ca559e3edb3b0072a4be5","modified":1534643975950},{"_id":"themes/next/languages/ko.yml","hash":"dc8f3e8c64eb7c4bb2385025b3006b8efec8b31d","modified":1534643975951},{"_id":"themes/next/languages/nl-NL.yml","hash":"213e7a002b82fb265f69dabafbbc382cfd460030","modified":1534643975952},{"_id":"themes/next/languages/pt-BR.yml","hash":"568d494a1f37726a5375b11452a45c71c3e2852d","modified":1534643975953},{"_id":"themes/next/languages/pt.yml","hash":"2efcd240c66ab1a122f061505ca0fb1e8819877b","modified":1534643975953},{"_id":"themes/next/languages/ru.yml","hash":"e33ee44e80f82e329900fc41eb0bb6823397a4d6","modified":1534643975954},{"_id":"themes/next/languages/vi.yml","hash":"a9b89ebd3e5933033d1386c7c56b66c44aca299a","modified":1534643975955},{"_id":"themes/next/languages/zh-Hans.yml","hash":"66b9b42f143c3cb2f782a94abd4c4cbd5fd7f55f","modified":1534643975956},{"_id":"themes/next/languages/zh-hk.yml","hash":"fe0d45807d015082049f05b54714988c244888da","modified":1534643975957},{"_id":"themes/next/languages/zh-tw.yml","hash":"432463b481e105073accda16c3e590e54c8e7b74","modified":1534643975958},{"_id":"themes/next/layout/_layout.swig","hash":"2164570bb05db11ee4bcfbbb5d183a759afe9d07","modified":1534643975959},{"_id":"themes/next/layout/archive.swig","hash":"9a2c14874a75c7085d2bada5e39201d3fc4fd2b4","modified":1534643976016},{"_id":"themes/next/layout/category.swig","hash":"3cbb3f72429647411f9e85f2544bdf0e3ad2e6b2","modified":1534643976017},{"_id":"themes/next/layout/index.swig","hash":"555a357ecf17128db4e29346c92bb6298e66547a","modified":1534643976018},{"_id":"themes/next/layout/page.swig","hash":"e8fcaa641d46930237675d2ad4b56964d9e262e9","modified":1534643976019},{"_id":"themes/next/layout/post.swig","hash":"7a6ce102ca82c3a80f776e555dddae1a9981e1ed","modified":1534643976019},{"_id":"themes/next/layout/schedule.swig","hash":"87ad6055df01fa2e63e51887d34a2d8f0fbd2f5a","modified":1534643976020},{"_id":"themes/next/layout/tag.swig","hash":"34e1c016cbdf94a31f9c5d494854ff46b2a182e9","modified":1534643976021},{"_id":"themes/next/scripts/merge-configs.js","hash":"38d86aab4fc12fb741ae52099be475196b9db972","modified":1534643976023},{"_id":"themes/next/scripts/merge.js","hash":"39b84b937b2a9608b94e5872349a47200e1800ff","modified":1534643976024},{"_id":"themes/next/test/.jshintrc","hash":"c9fca43ae0d99718e45a6f5ce736a18ba5fc8fb6","modified":1534643976274},{"_id":"themes/next/test/helpers.js","hash":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1534643976275},{"_id":"themes/next/test/intern.js","hash":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1534643976276},{"_id":"source/images/eas.png","hash":"9d12e21703b5d1dab464bd5f8f0d2f194145b43c","modified":1534643975817},{"_id":"source/images/minibatch.png","hash":"1705433ef878be5688ab474c7f3461c94b224dde","modified":1534643975818},{"_id":"source/images/my_image.jpg","hash":"931bed91b176c20eee98be0a6f0af356d37b2330","modified":1534643975822},{"_id":"source/images/partition.png","hash":"1c29a499253b64f0834f8253ea85efcb716872ac","modified":1534643975824},{"_id":"source/images/sgd.png","hash":"43fac22e9aa802e1fae6e25d791d23d3f82c616f","modified":1534643975826},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976163},{"_id":"source/images/alexnet_architecture.PNG","hash":"b4f692d1b6e69eacbb6e21d20a1a8cb878adf2d7","modified":1535424925483},{"_id":"source/images/momentum.png","hash":"97d12c75f9b2ecd40f0a6d0d47a21f83672ede97","modified":1534643975820},{"_id":"source/images/shuffle.png","hash":"e844a5da26c91ccd40f9c5186a7fd5db7fe4f2b7","modified":1534643975829},{"_id":"source/images/vgg_architecture.PNG","hash":"1af5fe2e5878957ac8d203e712cfe965ab154d3f","modified":1535682585366},{"_id":"themes/next/layout/_custom/header.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1534643975958},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1534643975959},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"8c56dd26157cbc580ae41d97ac34b90ab48ced3f","modified":1534643975960},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"f83befdc740beb8dc88805efd7fbb0fef9ed19be","modified":1534643975961},{"_id":"themes/next/layout/_macro/post.swig","hash":"4ba938822d56c597490f0731893eaa2443942e0f","modified":1534643975962},{"_id":"themes/next/layout/_macro/reward.swig","hash":"357d86ec9586705bfbb2c40a8c7d247a407db21a","modified":1534643975963},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"9c7343fd470e0943ebd75f227a083a980816290b","modified":1534643975964},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"e2e4eae391476da994045ed4c7faf5e05aca2cd7","modified":1534643975965},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4adc65a602d1276615da3b887dcbf2ac68e7382b","modified":1534643975966},{"_id":"themes/next/layout/_partials/footer.swig","hash":"26e93336dc57a39590ba8dc80564a1d2ad5ff93b","modified":1534643975967},{"_id":"themes/next/layout/_partials/head.swig","hash":"f14a39dad1ddd98e6d3ceb25dda092ba80d391b5","modified":1534643975968},{"_id":"themes/next/layout/_partials/header.swig","hash":"c54b32263bc8d75918688fb21f795103b3f57f03","modified":1534643975970},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"77c61e0baea3544df361b7338c3cd13dc84dde22","modified":1534643975971},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1534643975972},{"_id":"themes/next/layout/_partials/search.swig","hash":"b4ebe4a52a3b51efe549dd1cdee846103664f5eb","modified":1534643975974},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"c0f5a0955f69ca4ed9ee64a2d5f8aa75064935ad","modified":1534643975981},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"931808ad9b8d8390c0dcf9bdeb0954eeb9185d68","modified":1534643975982},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9be624634703be496a5d2535228bc568a8373af9","modified":1534643975985},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"ba75672183d94f1de7c8bd0eeee497a58c70e889","modified":1534643976005},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"8301c9600bb3e47f7fb98b0e0332ef3c51bb1688","modified":1534643976006},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"a0bd3388587fd943baae0d84ca779a707fbcad89","modified":1534643976007},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"fa882641da3bd83d9a58a8a97f9d4c62a9ee7b5c","modified":1534643976008},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"554ec568e9d2c71e4a624a8de3cb5929050811d6","modified":1534643976008},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"db15d7e1552aa2d2386a6b8a33b3b3a40bf9e43d","modified":1534643976009},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"9a188938d46931d5f3882a140aa1c48b3a893f0c","modified":1534643976010},{"_id":"themes/next/scripts/tags/button.js","hash":"eddbb612c15ac27faf11c59c019ce188f33dec2c","modified":1534643976025},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"99b66949f18398689b904907af23c013be1b978f","modified":1534643976026},{"_id":"themes/next/scripts/tags/exturl.js","hash":"5022c0ba9f1d13192677cf1fd66005c57c3d0f53","modified":1534643976026},{"_id":"themes/next/scripts/tags/full-image.js","hash":"c9f833158c66bd72f627a0559cf96550e867aa72","modified":1534643976027},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1534643976028},{"_id":"themes/next/scripts/tags/label.js","hash":"6f00952d70aadece844ce7fd27adc52816cc7374","modified":1534643976029},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"bcba2ff25cd7850ce6da322d8bd85a8dd00b5ceb","modified":1534643976030},{"_id":"themes/next/scripts/tags/note.js","hash":"f7eae135f35cdab23728e9d0d88b76e00715faa0","modified":1534643976030},{"_id":"themes/next/scripts/tags/tabs.js","hash":"aa7fc94a5ec27737458d9fe1a75c0db7593352fd","modified":1534643976031},{"_id":"themes/next/source/css/main.styl","hash":"a91dbb7ef799f0a171b5e726c801139efe545176","modified":1534643976163},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1534643976164},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1534643976165},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1534643976166},{"_id":"themes/next/source/images/avatar.jpeg","hash":"f1aa09fc418f5d6f05af58e81a9ca95790a075b0","modified":1534643976167},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1534643976168},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1534643976169},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1534643976169},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1534643976170},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1534643976171},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1534643976171},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1534643976172},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1534643976173},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1534643976174},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1534643976174},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1534643976175},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1534643976176},{"_id":"themes/next/source/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1534643976176},{"_id":"themes/next/source/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1534643976177},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1534643976178},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643975983},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643975983},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976107},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976108},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976111},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976160},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1534643976162},{"_id":"source/images/LlayerNN.png","hash":"939d9808c2d757e7097f22cbb4b4083c40f3da9c","modified":1534643975814},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"a223919d2e1bf17ca4d6abb2c86f2efca9883dc1","modified":1534643975968},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"f5e487b0d213ca0bd94aa30bc23b240d65081627","modified":1534643975969},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"b2f0d247b213e4cf8de47af6a304d98070cc7256","modified":1534643975975},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1534643975976},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a8c7f9ca7c605d039a1f3bf4e4d3183700a3dd62","modified":1534643975976},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"9e3d133ac5bcc6cb51702c83b2611a49811abad1","modified":1534643975977},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"d9e2d9282f9be6e04eae105964abb81e512bffed","modified":1534643975978},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1534643975979},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"0a9cdd6958395fcdffc80ab60f0c6301b63664a5","modified":1534643975980},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"9b84ab576982b2c3bb0291da49143bc77fba3cc6","modified":1534643975982},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1534643975983},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1534643975984},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"ff947f3561b229bc528cb1837d4ca19612219411","modified":1534643975987},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"71397a5823e8ec8aad3b68aace13150623b3e19d","modified":1534643975987},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"753d262911c27baf663fcaf199267133528656af","modified":1534643975988},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"7b11eac3a0685fa1ab2ab6ecff60afc4f15f0d16","modified":1534643975989},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"a10b7f19d7b5725527514622899df413a34a89db","modified":1534643975990},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"7d94845f96197d9d84a405fa5d4ede75fb81b225","modified":1534643975991},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"ccc443b22bd4f8c7ac4145664686c756395b90e0","modified":1534643975992},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b1e13df83fb2b1d5d513b30b7aa6158b0837daab","modified":1534643975992},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"45f3f629c2aacc381095750e1c8649041a71a84b","modified":1534643975993},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"e6d10ee4fb70b3ae1cd37e9e36e000306734aa2e","modified":1534643975994},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"8a399df90dadba5ad4e781445b58f4765aeb701e","modified":1534643975994},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"5a8027328f060f965b3014060bebec1d7cf149c1","modified":1534643975995},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"f9a1647a8f1866deeb94052d1f87a5df99cb1e70","modified":1534643975996},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"4c501ea0b9c494181eb3c607c5526a5754e7fbd8","modified":1534643975997},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b83a51bbe0f1e2ded9819070840b0ea145f003a6","modified":1534643975998},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"1600f340e0225361580c44890568dc07dbcf2c89","modified":1534643975998},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"4dcc3213c033994d342d02b800b6229295433d30","modified":1534643976000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"af7f3e43cbdc4f88c13f101f0f341af96ace3383","modified":1534643976001},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"493bd5999a1061b981922be92d8277a0f9152447","modified":1534643976001},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"9246162d4bc7e949ce1d12d135cbbaf5dc3024ec","modified":1534643976002},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4050553d44ba1396174161c9a6bb0f89fa779eca","modified":1534643976003},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"7e65ff8fe586cd655b0e9d1ad2912663ff9bd36c","modified":1534643976004},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"34599633658f3b0ffb487728b7766e1c7b551f5a","modified":1534643976013},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"93479642fd076a1257fecc25fcf5d20ccdefe509","modified":1534643976013},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1534643976015},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"d8c98938719284fa06492c114d99a1904652a555","modified":1534643976016},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"3403fdd8efde1a0afd11ae8a5a97673f5903087f","modified":1534643976105},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"07f7da320689f828f6e36a6123807964a45157a0","modified":1534643976107},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"7896c3ee107e1a8b9108b6019f1c070600a1e8cc","modified":1534643976109},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0e55cbd93852dc3f8ccb44df74d35d9918f847e0","modified":1534643976110},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"58e7dd5947817d9fc30770712fc39b2f52230d1e","modified":1534643976159},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"a25408534f8fe6e321db4bbf9dd03335d648fe17","modified":1534643976160},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4069f918ccc312da86db6c51205fc6c6eaabb116","modified":1534643976161},{"_id":"themes/next/source/css/_variables/base.styl","hash":"b1f6ea881a4938a54603d68282b0f8efb4d7915d","modified":1534643976162},{"_id":"themes/next/source/js/src/affix.js","hash":"1b509c3b5b290a6f4607f0f06461a0c33acb69b1","modified":1534643976178},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"cb431b54ba9c692165a1f5a12e4c564a560f8058","modified":1534643976179},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"0289031200c3d4c2bdd801ee10fff13bb2c353e4","modified":1534643976180},{"_id":"themes/next/source/js/src/exturl.js","hash":"a2a0f0de07e46211f74942a468f42ee270aa555c","modified":1534643976180},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"b35a7dc47b634197b93487cea8671a40a9fdffce","modified":1534643976181},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"1512c751d219577d338ac0780fb2bbd9075d5298","modified":1534643976182},{"_id":"themes/next/source/js/src/motion.js","hash":"885176ed51d468f662fbf0fc09611f45c7e5a3b1","modified":1534643976182},{"_id":"themes/next/source/js/src/post-details.js","hash":"93a18271b4123dd8f94f09d1439b47c3c19a8712","modified":1534643976183},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"02cf91514e41200bc9df5d8bdbeb58575ec06074","modified":1534643976185},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"b7657be25fc52ec67c75ab5481bdcb483573338b","modified":1534643976185},{"_id":"themes/next/source/js/src/utils.js","hash":"b3e9eca64aba59403334f3fa821f100d98d40337","modified":1534643976186},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1534643976196},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1534643976201},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"b02737510e9b89aeed6b54f89f602a9c24b06ff2","modified":1534643976202},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"bf3eef9d647cd7c9b62feda3bc708c6cdd7c0877","modified":1534643976215},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1534643976215},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1534643976216},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1534643976217},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"b4aefc910578d76b267e86dfffdd5121c8db9aec","modified":1534643976219},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"03ddbf76c1dd1afb93eed0b670d2eee747472ef1","modified":1534643976220},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"c31ff06a740955e44edd4403902e653ccabfd4db","modified":1534643976221},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1534643976222},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1534643976223},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"865d6c1328ab209a4376b9d2b7a7824369565f28","modified":1534643976239},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"90fa628f156d8045357ff11eaf32e61abacf10e8","modified":1534643976241},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4ded6fee668544778e97e38c2b211fc56c848e77","modified":1534643976242},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"b930297cb98b8e1dbd5abe9bc1ed9d5935d18ce8","modified":1534643976242},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"e0acf1db27b0cc16128a59c46db1db406b5c4c58","modified":1534643976243},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"f4a570908f6c89c6edfb1c74959e733eaadea4f2","modified":1534643976244},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"bf773ad48a0b9aa77681a89d7569eefc0f7b7b18","modified":1534643976245},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"14264a210bf94232d58d7599ea2ba93bfa4fb458","modified":1534643976246},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"e33aa8fa48b6639d8d8b937d13261597dd473b3a","modified":1534643976247},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"2ce5f3bf15c523b9bfc97720d8884bb22602a454","modified":1534643976248},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1534643976249},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1534643976249},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1534643976250},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1534643976251},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1534643976251},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1534643976252},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1534643976253},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1534643976253},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1534643976254},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1534643976255},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1534643976255},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1534643976256},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1534643976257},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"8aaa675f577d5501f5f22d5ccb07c2b76310b690","modified":1534643976257},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"2d9a9f38c493fdf7c0b833bb9184b6a1645c11b2","modified":1534643976258},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"46a50b91c98b639c9a2b9265c5a1e66a5c656881","modified":1534643976259},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"8148492dd49aa876d32bb7d5b728d3f5bf6f5074","modified":1534643976260},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"63da5e80ebb61bb66a2794d5936315ca44231f0c","modified":1534643976268},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1534643976268},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1534643976272},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1534643976273},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1534643976274},{"_id":"source/images/动态规划.jpg","hash":"771e3ceb5404dcb7ef349c6aa6e7853a7d61934e","modified":1534643975833},{"_id":"themes/next/source/lib/jquery/index.js","hash":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1534643976240},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"218cc936ba3518a3591b2c9eda46bc701edf7710","modified":1534643976011},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"2530de0f3125a912756f6c0e9090cd012134a4c5","modified":1534643976012},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"8f86f694c0749a18ab3ad6f6df75466ca137a4bc","modified":1534643976032},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"237d185ac62ec9877e300947fa0109c44fb8db19","modified":1534643976033},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"8b32928686c327151e13d3ab100157f9a03cd59f","modified":1534643976034},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1534643976035},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"7ad4081466b397e2a6204141bb7768b7c01bd93c","modified":1534643976036},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"4f2801fc4cf3f31bf2069f41db8c6ce0e3da9e39","modified":1534643976051},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"6eb4bcc3056bd279d000607e8b4dad50d368ca69","modified":1534643976078},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"12662536c7a07fff548abe94171f34b768dd610f","modified":1534643976097},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"24ee4b356ff55fc6e58f26a929fa07750002cf29","modified":1534643976098},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"1da5c800d025345f212a3bf1be035060f4e5e6ed","modified":1534643976098},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"91ca75492cd51f2553f4d294ed2f48239fcd55eb","modified":1534643976100},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1534643976100},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a17e2b871a335f290afb392a08f94fd35f59c715","modified":1534643976102},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"ea9069645696f86c5df64208490876fe150c8cae","modified":1534643976103},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"60fa84aa7731760f05f52dd7d8f79b5f74ac478d","modified":1534643976112},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"25d5e45a355ee2093f3b8b8eeac125ebf3905026","modified":1534643976114},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"d0bfd1bef988c76f7d7dd72d88af6f0908a8b0db","modified":1534643976117},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1534643976119},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"26666c1f472bf5f3fb9bc62081cca22b4de15ccb","modified":1534643976121},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"9c99034f8e00d47e978b3959f51eb4a9ded0fcc8","modified":1534643976123},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1534643976124},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9b913b73d31d21f057f97115ffab93cfa578b884","modified":1534643976125},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"31127dcbf4c7b4ada53ffbf1638b5fe325b7cbc0","modified":1534643976130},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1534643976132},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"e695e58f714129ca292c2e54cd62c251aca7f7fe","modified":1534643976133},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1534643976151},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"5dbc0d0c897e46760e5dbee416530d485c747bba","modified":1534643976152},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"bce344d3a665b4c55230d2a91eac2ad16d6f32fd","modified":1534643976154},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"416988dca389e6e2fdfa51fa7f4ee07eb53f82fb","modified":1534643976155},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"4642e30010af8b2b037f5b43146b10a934941958","modified":1534643976155},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"1f6e2ce674735269599acc6d77b3ea18d31967fc","modified":1534643976157},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"ad2dcedf393ed1f3f5afd2508d24969c916d02fc","modified":1534643976157},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"86197902dfd3bededba10ba62b8f9f22e0420bde","modified":1534643976158},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"f1d0b5d7af32c423eaa8bb93ab6a0b45655645dc","modified":1534643976184},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"6c26cdb36687d4f0a11dabf5290a909c3506be5c","modified":1534643976192},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"6d586bfcfb7ae48f1b12f76eec82d3ad31947501","modified":1534643976194},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"16b03db23a52623348f37c04544f2792032c1fb6","modified":1534643976195},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1534643976203},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1534643976204},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1534643976204},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1534643976205},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1534643976206},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1534643976207},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1534643976212},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1534643976213},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1534643976214},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1534643976218},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1534643976219},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"3655f1fdf1e584c4d8e8d39026093ca306a5a341","modified":1534643976224},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1534643976225},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1534643976226},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"41ea797c68dbcff2f6fb3aba1d1043a22e7cc0f6","modified":1534643976266},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"a817b6c158cbc5bab3582713de9fe18a18a80552","modified":1534643976267},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"4ac683b2bc8531c84d98f51b86957be0e6f830f3","modified":1534643976193},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1534643976237},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1534643976238},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"4237c6e9d59da349639de20e559e87c2c0218cfd","modified":1534643976271},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"9f73c4696f0907aa451a855444f88fc0698fa472","modified":1534643976037},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"53cde051e0337f4bf42fb8d6d7a79fa3fa6d4ef2","modified":1534643976038},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d63e0cacc53dd375fcc113465a4328c59ff5f2c1","modified":1534643976040},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"1a0d059799a298fe17c49a44298d32cebde93785","modified":1534643976041},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"0656e753f182c9f47fef7304c847b7587a85ef0d","modified":1534643976042},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"1727702eac5d326b5c81a667944a245016668231","modified":1534643976043},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"167986d0f649516671ddf7193eebba7b421cd115","modified":1534643976044},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"50450d9fdc8a2b2be8cfca51e3e1a01ffd636c0b","modified":1534643976045},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"7fe4d4d656e86276c17cb4e48a560cb6a4def703","modified":1534643976046},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"b6f3a06a94a6ee5470c956663164d58eda818a64","modified":1534643976047},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"7fb593f90d74a99c21840679933b9ef6fdc16a61","modified":1534643976047},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"f9760ecf186954cee3ba4a149be334e9ba296b89","modified":1534643976048},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"4e3838d7ac81d9ad133960f0f7ed58a44a015285","modified":1534643976049},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"8cf318644acc8b4978537c263290363e21c7f5af","modified":1534643976050},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"62fbbd32cf5a99ae550c45c763a2c4813a138d01","modified":1534643976053},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"875cbe88d5c7f6248990e2beb97c9828920e7e24","modified":1534643976054},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"caf263d1928496688c0e1419801eafd7e6919ce5","modified":1534643976056},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"a200c0a1c5a895ac9dc41e0641a5dfcd766be99b","modified":1534643976057},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"a6c6eb8adba0a090ad1f4b9124e866887f20d10d","modified":1534643976058},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1534643976060},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"d0d7a5c90d62b685520d2b47fea8ba6019ff5402","modified":1534643976061},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"27deb3d3a243d30022055dac7dad851024099a8b","modified":1534643976062},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ca88ea6999a61fb905eb6e72eba5f92d4ee31e6e","modified":1534643976063},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"b2495ae5e04dcca610aacadc47881d9e716cd440","modified":1534643976063},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5a982d8ef3b3623ea5f59e63728990f5623c1b57","modified":1534643976064},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"ccb34c52be8adba5996c6b94f9e723bd07d34c16","modified":1534643976065},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"01567edaea6978628aa5521a122a85434c418bfd","modified":1534643976066},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"7968343e41f8b94b318c36289dff1196c3eb1791","modified":1534643976067},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"89d6c3b697efc63de42afd2e89194b1be14152af","modified":1534643976068},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"39f04c4c7237a4e10acd3002331992b79945d241","modified":1534643976069},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"8dd9a1c6f4f6baa00c2cf01837e7617120cf9660","modified":1534643976071},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"11c22f0fb3f6beb13e5a425ec064a4ff974c13b7","modified":1534643976072},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"61f8cea3c01acd600e90e1bc2a07def405503748","modified":1534643976073},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"1153bb71edf253765145559674390e16dd67c633","modified":1534643976074},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"c8fe49a4bc014c24dead05b782a7082411a4abc5","modified":1534643976075},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a1521d48bb06d8d703753f52a198baa197af7da2","modified":1534643976075},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"5ef6343835f484a2c0770bd1eb9cc443609e4c39","modified":1534643976076},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"761eba9811b050b25d548cc0854de4824b41eb08","modified":1534643976070},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"e71652d3216e289c8548b1ea2357822c1476a425","modified":1534643976077},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"2fe76476432b31993338cb45cdb3b29a518b6379","modified":1534643976079},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"a3bdd71237afc112b2aa255f278cab6baeb25351","modified":1534643976080},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"f825da191816eef69ea8efb498a7f756d5ebb498","modified":1534643976081},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"2ad1a2a9bbf6742d1b0762c4c623b68113d1e0fe","modified":1534643976082},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"2ab1322fe52ab5aafd49e68f5bd890e8380ee927","modified":1534643976083},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"b7076e58d647265ee0ad2b461fe8ce72c9373bc5","modified":1534643976084},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"9a409b798decdefdaf7a23f0b11004a8c27e82f3","modified":1534643976085},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"154a87a32d2fead480d5e909c37f6c476671c5e6","modified":1534643976085},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"b80604868e4f5cf20fccafd7ee415c20c804f700","modified":1534643976086},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"bba4f3bdb7517cd85376df3e1209b570c0548c69","modified":1534643976087},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"5dbeed535d63a50265d96b396a5440f9bb31e4ba","modified":1534643976088},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"a6e7d698702c2e383dde3fde2abde27951679084","modified":1534643976089},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"717cc7f82be9cc151e23a7678601ff2fd3a7fa1d","modified":1534643976090},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"874278147115601d2abf15987f5f7a84ada1ac6b","modified":1534643976091},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"10599e16414a8b7a76c4e79e6617b5fe3d4d1adf","modified":1534643976092},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1534643976093},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"16087276945fa038f199692e3eabb1c52b8ea633","modified":1534643976094},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"28825ae15fa20ae3942cdaa7bcc1f3523ce59acc","modified":1534643976095},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9c8196394a89dfa40b87bf0019e80144365a9c93","modified":1534643976096},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"a07aa12cc36ac5c819670c2a3c17d07ed7a08986","modified":1534643976127},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1534643976128},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1534643976153},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1534643976187},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1534643976188},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1534643976189},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1534643976190},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1534643976191},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1534643976208},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1534643976208},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1534643976209},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1534643976210},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1534643976211},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1534643976211},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1534643976228},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1534643976231},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1534643976236},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"90a1b22129efc172e2dfcceeeb76bff58bc3192f","modified":1534643976200},{"_id":"themes/next/source/lib/three/three.min.js","hash":"26273b1cb4914850a89529b48091dc584f2c57b8","modified":1534643976265},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1534643976234},{"_id":"source/images/dl_pic9_2.jpg","hash":"1de175528c89642a2520d640861ff5237da9aefc","modified":1535080882042},{"_id":"source/images/dl_pic9_5.jpg","hash":"b1ccd9c91f99bf4bb2d0804901a11aa840283c5b","modified":1535081541240},{"_id":"source/images/dl_pic9_8.jpg","hash":"7c99fba6503ff5a23a3d8e39278c5dc2bdd3b9ee","modified":1535082369512},{"_id":"source/images/dl_pic9_7.jpg","hash":"3d8b3e0b5dc8a8a76fb67cd86f23d125c896809f","modified":1535082325324}],"Category":[{"name":"python包和模块","_id":"cjmd19owd000444vogeysilf2"},{"name":"深度学习","_id":"cjmd19ows000944voo7aqq6lh"},{"name":"进化计算","_id":"cjmd19oxl000l44vol4y8hx8h"},{"name":"web","_id":"cjmd19oy1001044vojxxpvfc6"},{"name":"机器学习","_id":"cjmd19oyb001744voubntz5se"},{"name":"算法导论","_id":"cjmd19oyj001g44vopclruv8h"},{"name":"程序员实用工具","_id":"cjmd19oyp001p44votm8ru9f6"},{"name":"Tensorflow","_id":"cjmd19oz1002344vo5ffaysbn"},{"name":"文学","_id":"cjmd19ozm002p44vo2n672n3c"},{"name":"科普读物","_id":"cjmd19ozu002z44vo4fdkn895"},{"name":"计算机科学","_id":"cjmd19p01003644vo8gf6wnb0"},{"name":"心理学","_id":"cjmd19p09003d44vo9u4y80tv"}],"Data":[],"Page":[{"title":"categories","date":"2018-07-18T16:23:02.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-07-19 00:23:02\ntype: \"categories\"\n---\n","updated":"2018-08-19T01:59:35.811Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjmd19ovy000044vo2pa9a9g4","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2018-07-18T16:21:54.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-07-19 00:21:54\ntype: \"tags\"\n---\n","updated":"2018-08-19T01:59:35.834Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjmd19ow7000244vonrn6p68k"}],"Post":[{"title":"BeautifulSoup","date":"2018-08-15T03:40:51.000Z","_content":"## [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html)\n\nYou didn't write that awful page. You're just trying to get some data out of it. Beautiful Soup is here to help. Since 2004, it's been saving programmers hours or days of work on quick-turnaround screen scraping projects.\n\n## 如何使用\n\n```python\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(open('index.html'))\n```\n\n## 对象的种类\n\n### Tag\n\nTag 对象与XML或HTML原生文档中的tag相同:\n\n```python\nsoup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>')\ntag = soup.b\ntype(tag)\n# <class 'bs4.element.Tag'>\n```\n\nTag的属性：`tag.name, tag.attrs`\n\ntag的属性的操作方法与字典相同: `tag['class']`\n\n### 可以遍历的字符串\n\n字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:`tag.string`\n\n`unicode_string = unicode(tag.string)`\n\ntag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法:`tag.string.replace_with(\"No\")`\n\n### BeautifulSoup\n\nBeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.\n\n### 注释及特殊字符串\n\nComment 对象是一个特殊类型的 NavigableString 对象:\n\n```python\nmarkup = \"<b><!--Hey, buddy. Want to buy a used parser?--></b>\"\nsoup = BeautifulSoup(markup)\ncomment = soup.b.string\ntype(comment)\n# <class 'bs4.element.Comment'>\n```\n\n## 遍历文档树\n\n### 子节点\n\n一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.\n\n#### tag的名字\n\n`soup.head, soup.title, soup.body.b, soup.a, soup.find_all('a')`\n\n#### .contents和.children\n\ntag的 .contents 属性可以将tag的子节点以列表的方式输出:\n\n通过tag的 .children 生成器,可以对tag的子节点进行循环:\n\n```python\nfor child in title_tag.children:\n    print(child)\n```\ndescendants 属性可以对所有tag的子孙节点进行递归循环:\n\n```python\nfor child in title_tag.descendants:\n    print(child)\n```\n\n### .string\n\n如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点:`tag.string`\n\n如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同\n\n如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :\n\n### .strings和stripped__strings\n\n如果tag中包含多个字符串 ,可以使用 .strings 来循环获取, 输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容\n\n```python\nfor string in soup.strings:\n    print(repr(string))\n\nfor string in soup.stripped_strings:\n    ...\n```\n\n### 父节点\n\n#### .parent\n\n`tag.parent, tag.string.parent`\n\n#### .parents\n\n```python\nlink = soup.a\nfor parent in link.parents:\n    if parent is None:\n        print(parent)\n    else:\n        print(parent.name)\n```\n\n### 兄弟节点\n\n#### .next_sibling和.previous_sibling\n\n实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白.\n\n#### .next_siblings和.previous_siblings\n\n通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出\n\n```python\nfor sibling in soup.a.next_siblings:\n    print(repr(sibling))\n```\n\n### 回退和前进\n\n```html\n<html><head><title>The Dormouse's story</title></head>\n<p class=\"title\"><b>The Dormouse's story</b></p>\n```\n\nHTML解析器把这段字符串转换成一连串的事件: “打开html标签”,”打开一个head标签”,”打开一个title标签”,”添加一段字符串”,”关闭title标签”,”关闭p标签”,等等.Beautiful Soup提供了重现解析器初始化过程的方法\n\n#### .next_element和.previous_element\n\n.previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象, next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),\n\n#### .next_elements和.previous_elements\n\n通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:\n\n```python\nfor elementin a_tag.next_elements:\n    print(repr(element))\n```\n\n## 搜索文档树\n\n### 过滤器\n\n#### 字符串\n\n最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的\\<b>标签:\n\n`soup.find_all('b')`\n\n#### 正则表达式\n\n如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示\\<body>和\\<b>标签都应该被找到:\n\n```python\nimport re\nfor tag in soup.find_all(re.compile(\"^b\"):\n    print(tag.name)\n```\n\n#### 列表\n\n如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有\\<a>标签和\\<b>标签:\n\n`soup.find_all(['a', 'b'])`\n\n#### True\n\nTrue 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点\n\n```python\nfor tag in soup.find_all(True):\n    print(tag.name)\n```\n\n#### 方法\n\n如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False\n\n下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:\n\n```python\ndef has_class_but_no_id(tag):\n    return tag.has_attr('class') and not tag.has_attr('id')\n```\n\n下面代码找到所有被文字包含的节点内容\n\n```python\nfrom bs4 import NavigableString\n\ndef surrounded_by_strings(tag):\n    return (isinstance(tag.next_element, NavigableString)) and isinstance(tag.previous_element, NavigableString)\n```\n\n### find_all()\n\n`find_all(name, attrs, recursive, text, **kwargs)`\n\nfind_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件\n\n#### name参数\n\n搜索 name 参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .\n\nname 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.\n\n#### keyword参数\n\n`soup.find_all(id='link2')`\n`soup.find_all(href=re.compile('elsie'))`\n`soup.find_all(id=True)`\n`soup.find_all(attrs={'id':'link2'})`\n\n#### 按CSS搜索\n\n通过 \".class__\"_ 参数搜索有指定CSS类名的tag, \".class__\"_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True\n\n`soup.find_all('a', class_='sister')`\n\n#### text参数\n\n通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True.\n\n`soup.find_all(text=re.compile(\"Dormouse\"))`\n\n#### limit参数\n\nfind_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.\n\n`soup.find_all('a', limit=2)`\n\n#### recursive参数\n\n调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False.\n\n`soup.find_all('title', recursive=False)`\n\n### 像调用find_all()一样调用tag\n\nfind_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:\n\n`soup.find_all('a')`\n`soup('a')`\n\n### find()\n\n`find(name, attrs, recursive, text, **kwargs)`\n\n```python\nsoup.find_all('title', limit=1)\n# [<title>The Dormouse's story</title>]\n\nsoup.find('title')\n# <title>The Dormouse's story</title>\n```\n\n唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.\n\nfind_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None.\n\n### find_parents()和find_parent()\n\nfind_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同\n\n### find_next_siblings()和find_next_sibling()\n\n这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.\n\n### find_previous_siblings和find_previous_sibling()\n\nfind_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:\n\n### find_all_next()和find_next()\n\n这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:\n\n### find_all_previous()和find_previous()\n\n这2个方法通过 .previous_elements 属性对当前节点前面的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.\n\n### CSS选择器\n\n通过tag标签逐层查找 `soup.select(\"body a\")`\n\n找到某个tag标签的直接子标签 `soup.select(\"p > #link1\")`\n\n找到兄弟节点标签 `soup.select(\"#link1 + .sister\")`\n\n通过CSS类名查找 `soup.select(\".sister\"), soup.select(\"[class~=sister]\")`\n\n通过tag的id查找 `soup.select(\"#link1\")`\n\n通过是否存在某个属性查找 `soup.slect('a[href]')`\n\n通过属性的值来查找 `soup.select('a[href^=\"https:\"]', [href$='title'], [href*=\".com/\"]`\n\n## 修改文档树\n\n## 输出\n\n### 格式化输出\n\nprettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行\n\n```python\nmarkup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\nsoup = BeautifulSoup(markup)\nsoup.prettify()\n# '<html>\\n <head>\\n </head>\\n <body>\\n  <a href=\"http://example.com/\">\\n...'\n\nprint(soup.prettify())\n# <html>\n#  <head>\n#  </head>\n#  <body>\n#   <a href=\"http://example.com/\">\n#    I linked to\n#    <i>\n#     example.com\n#    </i>\n#   </a>\n#  </body>\n# </html>\n```\n\n### 压缩输出\n\n如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:\n\n`str(soup), Unicode(soup.a)`\n\n### 输出格式\n\nBeautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“\\&lquot;”:\n如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:\n\n### get_text()\n\n如果只想得到tag中包含的文本内容,那么可以用 get_text() 方法,这个方法获取到tag中包含的所有文本内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:\n\n可以通过参数指定tag的文本内容的分隔符, 还可以去除前后空白: `soup.get_text('|', strip=True)`\n\n## 指定文档解析器\n\n## 编码\n","source":"_posts/BeautifulSoup.md","raw":"---\ntitle: BeautifulSoup\ndate: 2018-08-15 11:40:51\ntags: python\ncategories: python包和模块\n---\n## [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html)\n\nYou didn't write that awful page. You're just trying to get some data out of it. Beautiful Soup is here to help. Since 2004, it's been saving programmers hours or days of work on quick-turnaround screen scraping projects.\n\n## 如何使用\n\n```python\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(open('index.html'))\n```\n\n## 对象的种类\n\n### Tag\n\nTag 对象与XML或HTML原生文档中的tag相同:\n\n```python\nsoup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>')\ntag = soup.b\ntype(tag)\n# <class 'bs4.element.Tag'>\n```\n\nTag的属性：`tag.name, tag.attrs`\n\ntag的属性的操作方法与字典相同: `tag['class']`\n\n### 可以遍历的字符串\n\n字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:`tag.string`\n\n`unicode_string = unicode(tag.string)`\n\ntag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法:`tag.string.replace_with(\"No\")`\n\n### BeautifulSoup\n\nBeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.\n\n### 注释及特殊字符串\n\nComment 对象是一个特殊类型的 NavigableString 对象:\n\n```python\nmarkup = \"<b><!--Hey, buddy. Want to buy a used parser?--></b>\"\nsoup = BeautifulSoup(markup)\ncomment = soup.b.string\ntype(comment)\n# <class 'bs4.element.Comment'>\n```\n\n## 遍历文档树\n\n### 子节点\n\n一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.\n\n#### tag的名字\n\n`soup.head, soup.title, soup.body.b, soup.a, soup.find_all('a')`\n\n#### .contents和.children\n\ntag的 .contents 属性可以将tag的子节点以列表的方式输出:\n\n通过tag的 .children 生成器,可以对tag的子节点进行循环:\n\n```python\nfor child in title_tag.children:\n    print(child)\n```\ndescendants 属性可以对所有tag的子孙节点进行递归循环:\n\n```python\nfor child in title_tag.descendants:\n    print(child)\n```\n\n### .string\n\n如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点:`tag.string`\n\n如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同\n\n如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :\n\n### .strings和stripped__strings\n\n如果tag中包含多个字符串 ,可以使用 .strings 来循环获取, 输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容\n\n```python\nfor string in soup.strings:\n    print(repr(string))\n\nfor string in soup.stripped_strings:\n    ...\n```\n\n### 父节点\n\n#### .parent\n\n`tag.parent, tag.string.parent`\n\n#### .parents\n\n```python\nlink = soup.a\nfor parent in link.parents:\n    if parent is None:\n        print(parent)\n    else:\n        print(parent.name)\n```\n\n### 兄弟节点\n\n#### .next_sibling和.previous_sibling\n\n实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白.\n\n#### .next_siblings和.previous_siblings\n\n通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出\n\n```python\nfor sibling in soup.a.next_siblings:\n    print(repr(sibling))\n```\n\n### 回退和前进\n\n```html\n<html><head><title>The Dormouse's story</title></head>\n<p class=\"title\"><b>The Dormouse's story</b></p>\n```\n\nHTML解析器把这段字符串转换成一连串的事件: “打开html标签”,”打开一个head标签”,”打开一个title标签”,”添加一段字符串”,”关闭title标签”,”关闭p标签”,等等.Beautiful Soup提供了重现解析器初始化过程的方法\n\n#### .next_element和.previous_element\n\n.previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象, next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),\n\n#### .next_elements和.previous_elements\n\n通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:\n\n```python\nfor elementin a_tag.next_elements:\n    print(repr(element))\n```\n\n## 搜索文档树\n\n### 过滤器\n\n#### 字符串\n\n最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的\\<b>标签:\n\n`soup.find_all('b')`\n\n#### 正则表达式\n\n如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示\\<body>和\\<b>标签都应该被找到:\n\n```python\nimport re\nfor tag in soup.find_all(re.compile(\"^b\"):\n    print(tag.name)\n```\n\n#### 列表\n\n如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有\\<a>标签和\\<b>标签:\n\n`soup.find_all(['a', 'b'])`\n\n#### True\n\nTrue 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点\n\n```python\nfor tag in soup.find_all(True):\n    print(tag.name)\n```\n\n#### 方法\n\n如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False\n\n下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:\n\n```python\ndef has_class_but_no_id(tag):\n    return tag.has_attr('class') and not tag.has_attr('id')\n```\n\n下面代码找到所有被文字包含的节点内容\n\n```python\nfrom bs4 import NavigableString\n\ndef surrounded_by_strings(tag):\n    return (isinstance(tag.next_element, NavigableString)) and isinstance(tag.previous_element, NavigableString)\n```\n\n### find_all()\n\n`find_all(name, attrs, recursive, text, **kwargs)`\n\nfind_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件\n\n#### name参数\n\n搜索 name 参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .\n\nname 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.\n\n#### keyword参数\n\n`soup.find_all(id='link2')`\n`soup.find_all(href=re.compile('elsie'))`\n`soup.find_all(id=True)`\n`soup.find_all(attrs={'id':'link2'})`\n\n#### 按CSS搜索\n\n通过 \".class__\"_ 参数搜索有指定CSS类名的tag, \".class__\"_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True\n\n`soup.find_all('a', class_='sister')`\n\n#### text参数\n\n通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True.\n\n`soup.find_all(text=re.compile(\"Dormouse\"))`\n\n#### limit参数\n\nfind_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.\n\n`soup.find_all('a', limit=2)`\n\n#### recursive参数\n\n调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False.\n\n`soup.find_all('title', recursive=False)`\n\n### 像调用find_all()一样调用tag\n\nfind_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:\n\n`soup.find_all('a')`\n`soup('a')`\n\n### find()\n\n`find(name, attrs, recursive, text, **kwargs)`\n\n```python\nsoup.find_all('title', limit=1)\n# [<title>The Dormouse's story</title>]\n\nsoup.find('title')\n# <title>The Dormouse's story</title>\n```\n\n唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.\n\nfind_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None.\n\n### find_parents()和find_parent()\n\nfind_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同\n\n### find_next_siblings()和find_next_sibling()\n\n这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.\n\n### find_previous_siblings和find_previous_sibling()\n\nfind_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:\n\n### find_all_next()和find_next()\n\n这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:\n\n### find_all_previous()和find_previous()\n\n这2个方法通过 .previous_elements 属性对当前节点前面的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.\n\n### CSS选择器\n\n通过tag标签逐层查找 `soup.select(\"body a\")`\n\n找到某个tag标签的直接子标签 `soup.select(\"p > #link1\")`\n\n找到兄弟节点标签 `soup.select(\"#link1 + .sister\")`\n\n通过CSS类名查找 `soup.select(\".sister\"), soup.select(\"[class~=sister]\")`\n\n通过tag的id查找 `soup.select(\"#link1\")`\n\n通过是否存在某个属性查找 `soup.slect('a[href]')`\n\n通过属性的值来查找 `soup.select('a[href^=\"https:\"]', [href$='title'], [href*=\".com/\"]`\n\n## 修改文档树\n\n## 输出\n\n### 格式化输出\n\nprettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行\n\n```python\nmarkup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\nsoup = BeautifulSoup(markup)\nsoup.prettify()\n# '<html>\\n <head>\\n </head>\\n <body>\\n  <a href=\"http://example.com/\">\\n...'\n\nprint(soup.prettify())\n# <html>\n#  <head>\n#  </head>\n#  <body>\n#   <a href=\"http://example.com/\">\n#    I linked to\n#    <i>\n#     example.com\n#    </i>\n#   </a>\n#  </body>\n# </html>\n```\n\n### 压缩输出\n\n如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:\n\n`str(soup), Unicode(soup.a)`\n\n### 输出格式\n\nBeautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“\\&lquot;”:\n如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:\n\n### get_text()\n\n如果只想得到tag中包含的文本内容,那么可以用 get_text() 方法,这个方法获取到tag中包含的所有文本内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:\n\n可以通过参数指定tag的文本内容的分隔符, 还可以去除前后空白: `soup.get_text('|', strip=True)`\n\n## 指定文档解析器\n\n## 编码\n","slug":"BeautifulSoup","published":1,"updated":"2018-08-31T03:51:46.501Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ow1000144voegorubd0","content":"<h2 id=\"beautifulsoup\"><a class=\"markdownIt-Anchor\" href=\"#beautifulsoup\"></a> <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html\" target=\"_blank\" rel=\"noopener\">BeautifulSoup</a></h2>\n<p>You didn’t write that awful page. You’re just trying to get some data out of it. Beautiful Soup is here to help. Since 2004, it’s been saving programmers hours or days of work on quick-turnaround screen scraping projects.</p>\n<h2 id=\"如何使用\"><a class=\"markdownIt-Anchor\" href=\"#如何使用\"></a> 如何使用</h2>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup</span><br><span class=\"line\">soup = BeautifulSoup(open(<span class=\"string\">'index.html'</span>))</span><br></pre></td></tr></table></figure>\n<h2 id=\"对象的种类\"><a class=\"markdownIt-Anchor\" href=\"#对象的种类\"></a> 对象的种类</h2>\n<h3 id=\"tag\"><a class=\"markdownIt-Anchor\" href=\"#tag\"></a> Tag</h3>\n<p>Tag 对象与XML或HTML原生文档中的tag相同:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">soup = BeautifulSoup(<span class=\"string\">'&lt;b class=\"boldest\"&gt;Extremely bold&lt;/b&gt;'</span>)</span><br><span class=\"line\">tag = soup.b</span><br><span class=\"line\">type(tag)</span><br><span class=\"line\"><span class=\"comment\"># &lt;class 'bs4.element.Tag'&gt;</span></span><br></pre></td></tr></table></figure>\n<p>Tag的属性：<code>tag.name, tag.attrs</code></p>\n<p>tag的属性的操作方法与字典相同: <code>tag['class']</code></p>\n<h3 id=\"可以遍历的字符串\"><a class=\"markdownIt-Anchor\" href=\"#可以遍历的字符串\"></a> 可以遍历的字符串</h3>\n<p>字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:<code>tag.string</code></p>\n<p><code>unicode_string = unicode(tag.string)</code></p>\n<p>tag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法:<code>tag.string.replace_with(&quot;No&quot;)</code></p>\n<h3 id=\"beautifulsoup-2\"><a class=\"markdownIt-Anchor\" href=\"#beautifulsoup-2\"></a> BeautifulSoup</h3>\n<p>BeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.</p>\n<h3 id=\"注释及特殊字符串\"><a class=\"markdownIt-Anchor\" href=\"#注释及特殊字符串\"></a> 注释及特殊字符串</h3>\n<p>Comment 对象是一个特殊类型的 NavigableString 对象:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">markup = <span class=\"string\">\"&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;\"</span></span><br><span class=\"line\">soup = BeautifulSoup(markup)</span><br><span class=\"line\">comment = soup.b.string</span><br><span class=\"line\">type(comment)</span><br><span class=\"line\"><span class=\"comment\"># &lt;class 'bs4.element.Comment'&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"遍历文档树\"><a class=\"markdownIt-Anchor\" href=\"#遍历文档树\"></a> 遍历文档树</h2>\n<h3 id=\"子节点\"><a class=\"markdownIt-Anchor\" href=\"#子节点\"></a> 子节点</h3>\n<p>一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.</p>\n<h4 id=\"tag的名字\"><a class=\"markdownIt-Anchor\" href=\"#tag的名字\"></a> tag的名字</h4>\n<p><code>soup.head, soup.title, soup.body.b, soup.a, soup.find_all('a')</code></p>\n<h4 id=\"contents和children\"><a class=\"markdownIt-Anchor\" href=\"#contents和children\"></a> .contents和.children</h4>\n<p>tag的 .contents 属性可以将tag的子节点以列表的方式输出:</p>\n<p>通过tag的 .children 生成器,可以对tag的子节点进行循环:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> title_tag.children:</span><br><span class=\"line\">    print(child)</span><br></pre></td></tr></table></figure>\n<p>descendants 属性可以对所有tag的子孙节点进行递归循环:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> title_tag.descendants:</span><br><span class=\"line\">    print(child)</span><br></pre></td></tr></table></figure>\n<h3 id=\"string\"><a class=\"markdownIt-Anchor\" href=\"#string\"></a> .string</h3>\n<p>如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点:<code>tag.string</code></p>\n<p>如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同</p>\n<p>如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :</p>\n<h3 id=\"strings和stripped__strings\"><a class=\"markdownIt-Anchor\" href=\"#strings和stripped__strings\"></a> .strings和stripped__strings</h3>\n<p>如果tag中包含多个字符串 ,可以使用 .strings 来循环获取, 输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> string <span class=\"keyword\">in</span> soup.strings:</span><br><span class=\"line\">    print(repr(string))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> string <span class=\"keyword\">in</span> soup.stripped_strings:</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n<h3 id=\"父节点\"><a class=\"markdownIt-Anchor\" href=\"#父节点\"></a> 父节点</h3>\n<h4 id=\"parent\"><a class=\"markdownIt-Anchor\" href=\"#parent\"></a> .parent</h4>\n<p><code>tag.parent, tag.string.parent</code></p>\n<h4 id=\"parents\"><a class=\"markdownIt-Anchor\" href=\"#parents\"></a> .parents</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">link = soup.a</span><br><span class=\"line\"><span class=\"keyword\">for</span> parent <span class=\"keyword\">in</span> link.parents:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> parent <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        print(parent)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        print(parent.name)</span><br></pre></td></tr></table></figure>\n<h3 id=\"兄弟节点\"><a class=\"markdownIt-Anchor\" href=\"#兄弟节点\"></a> 兄弟节点</h3>\n<h4 id=\"next_sibling和previous_sibling\"><a class=\"markdownIt-Anchor\" href=\"#next_sibling和previous_sibling\"></a> .next_sibling和.previous_sibling</h4>\n<p>实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白.</p>\n<h4 id=\"next_siblings和previous_siblings\"><a class=\"markdownIt-Anchor\" href=\"#next_siblings和previous_siblings\"></a> .next_siblings和.previous_siblings</h4>\n<p>通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> sibling <span class=\"keyword\">in</span> soup.a.next_siblings:</span><br><span class=\"line\">    print(repr(sibling))</span><br></pre></td></tr></table></figure>\n<h3 id=\"回退和前进\"><a class=\"markdownIt-Anchor\" href=\"#回退和前进\"></a> 回退和前进</h3>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>The Dormouse's story<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">class</span>=<span class=\"string\">\"title\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">b</span>&gt;</span>The Dormouse's story<span class=\"tag\">&lt;/<span class=\"name\">b</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>HTML解析器把这段字符串转换成一连串的事件: “打开html标签”,”打开一个head标签”,”打开一个title标签”,”添加一段字符串”,”关闭title标签”,”关闭p标签”,等等.Beautiful Soup提供了重现解析器初始化过程的方法</p>\n<h4 id=\"next_element和previous_element\"><a class=\"markdownIt-Anchor\" href=\"#next_element和previous_element\"></a> .next_element和.previous_element</h4>\n<p>.previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象, next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),</p>\n<h4 id=\"next_elements和previous_elements\"><a class=\"markdownIt-Anchor\" href=\"#next_elements和previous_elements\"></a> .next_elements和.previous_elements</h4>\n<p>通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> elementin a_tag.next_elements:</span><br><span class=\"line\">    print(repr(element))</span><br></pre></td></tr></table></figure>\n<h2 id=\"搜索文档树\"><a class=\"markdownIt-Anchor\" href=\"#搜索文档树\"></a> 搜索文档树</h2>\n<h3 id=\"过滤器\"><a class=\"markdownIt-Anchor\" href=\"#过滤器\"></a> 过滤器</h3>\n<h4 id=\"字符串\"><a class=\"markdownIt-Anchor\" href=\"#字符串\"></a> 字符串</h4>\n<p>最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的&lt;b&gt;标签:</p>\n<p><code>soup.find_all('b')</code></p>\n<h4 id=\"正则表达式\"><a class=\"markdownIt-Anchor\" href=\"#正则表达式\"></a> 正则表达式</h4>\n<p>如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示&lt;body&gt;和&lt;b&gt;标签都应该被找到:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">for</span> tag <span class=\"keyword\">in</span> soup.find_all(re.compile(<span class=\"string\">\"^b\"</span>):</span><br><span class=\"line\">    print(tag.name)</span><br></pre></td></tr></table></figure>\n<h4 id=\"列表\"><a class=\"markdownIt-Anchor\" href=\"#列表\"></a> 列表</h4>\n<p>如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有&lt;a&gt;标签和&lt;b&gt;标签:</p>\n<p><code>soup.find_all(['a', 'b'])</code></p>\n<h4 id=\"true\"><a class=\"markdownIt-Anchor\" href=\"#true\"></a> True</h4>\n<p>True 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> tag <span class=\"keyword\">in</span> soup.find_all(<span class=\"keyword\">True</span>):</span><br><span class=\"line\">    print(tag.name)</span><br></pre></td></tr></table></figure>\n<h4 id=\"方法\"><a class=\"markdownIt-Anchor\" href=\"#方法\"></a> 方法</h4>\n<p>如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False</p>\n<p>下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">has_class_but_no_id</span><span class=\"params\">(tag)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> tag.has_attr(<span class=\"string\">'class'</span>) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> tag.has_attr(<span class=\"string\">'id'</span>)</span><br></pre></td></tr></table></figure>\n<p>下面代码找到所有被文字包含的节点内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> NavigableString</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">surrounded_by_strings</span><span class=\"params\">(tag)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (isinstance(tag.next_element, NavigableString)) <span class=\"keyword\">and</span> isinstance(tag.previous_element, NavigableString)</span><br></pre></td></tr></table></figure>\n<h3 id=\"find_all\"><a class=\"markdownIt-Anchor\" href=\"#find_all\"></a> find_all()</h3>\n<p><code>find_all(name, attrs, recursive, text, **kwargs)</code></p>\n<p>find_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件</p>\n<h4 id=\"name参数\"><a class=\"markdownIt-Anchor\" href=\"#name参数\"></a> name参数</h4>\n<p>搜索 name 参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .</p>\n<p>name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.</p>\n<h4 id=\"keyword参数\"><a class=\"markdownIt-Anchor\" href=\"#keyword参数\"></a> keyword参数</h4>\n<p><code>soup.find_all(id='link2')</code><br>\n<code>soup.find_all(href=re.compile('elsie'))</code><br>\n<code>soup.find_all(id=True)</code><br>\n<code>soup.find_all(attrs={'id':'link2'})</code></p>\n<h4 id=\"按css搜索\"><a class=\"markdownIt-Anchor\" href=\"#按css搜索\"></a> 按CSS搜索</h4>\n<p>通过 “.class__”_ 参数搜索有指定CSS类名的tag, “.class__”_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True</p>\n<p><code>soup.find_all('a', class_='sister')</code></p>\n<h4 id=\"text参数\"><a class=\"markdownIt-Anchor\" href=\"#text参数\"></a> text参数</h4>\n<p>通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True.</p>\n<p><code>soup.find_all(text=re.compile(&quot;Dormouse&quot;))</code></p>\n<h4 id=\"limit参数\"><a class=\"markdownIt-Anchor\" href=\"#limit参数\"></a> limit参数</h4>\n<p>find_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.</p>\n<p><code>soup.find_all('a', limit=2)</code></p>\n<h4 id=\"recursive参数\"><a class=\"markdownIt-Anchor\" href=\"#recursive参数\"></a> recursive参数</h4>\n<p>调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False.</p>\n<p><code>soup.find_all('title', recursive=False)</code></p>\n<h3 id=\"像调用find_all一样调用tag\"><a class=\"markdownIt-Anchor\" href=\"#像调用find_all一样调用tag\"></a> 像调用find_all()一样调用tag</h3>\n<p>find_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:</p>\n<p><code>soup.find_all('a')</code><br>\n<code>soup('a')</code></p>\n<h3 id=\"find\"><a class=\"markdownIt-Anchor\" href=\"#find\"></a> find()</h3>\n<p><code>find(name, attrs, recursive, text, **kwargs)</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">soup.find_all(<span class=\"string\">'title'</span>, limit=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></span><br><span class=\"line\"></span><br><span class=\"line\">soup.find(<span class=\"string\">'title'</span>)</span><br><span class=\"line\"><span class=\"comment\"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></span><br></pre></td></tr></table></figure>\n<p>唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.</p>\n<p>find_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None.</p>\n<h3 id=\"find_parents和find_parent\"><a class=\"markdownIt-Anchor\" href=\"#find_parents和find_parent\"></a> find_parents()和find_parent()</h3>\n<p>find_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同</p>\n<h3 id=\"find_next_siblings和find_next_sibling\"><a class=\"markdownIt-Anchor\" href=\"#find_next_siblings和find_next_sibling\"></a> find_next_siblings()和find_next_sibling()</h3>\n<p>这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.</p>\n<h3 id=\"find_previous_siblings和find_previous_sibling\"><a class=\"markdownIt-Anchor\" href=\"#find_previous_siblings和find_previous_sibling\"></a> find_previous_siblings和find_previous_sibling()</h3>\n<p>find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:</p>\n<h3 id=\"find_all_next和find_next\"><a class=\"markdownIt-Anchor\" href=\"#find_all_next和find_next\"></a> find_all_next()和find_next()</h3>\n<p>这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:</p>\n<h3 id=\"find_all_previous和find_previous\"><a class=\"markdownIt-Anchor\" href=\"#find_all_previous和find_previous\"></a> find_all_previous()和find_previous()</h3>\n<p>这2个方法通过 .previous_elements 属性对当前节点前面的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.</p>\n<h3 id=\"css选择器\"><a class=\"markdownIt-Anchor\" href=\"#css选择器\"></a> CSS选择器</h3>\n<p>通过tag标签逐层查找 <code>soup.select(&quot;body a&quot;)</code></p>\n<p>找到某个tag标签的直接子标签 <code>soup.select(&quot;p &gt; #link1&quot;)</code></p>\n<p>找到兄弟节点标签 <code>soup.select(&quot;#link1 + .sister&quot;)</code></p>\n<p>通过CSS类名查找 <code>soup.select(&quot;.sister&quot;), soup.select(&quot;[class~=sister]&quot;)</code></p>\n<p>通过tag的id查找 <code>soup.select(&quot;#link1&quot;)</code></p>\n<p>通过是否存在某个属性查找 <code>soup.slect('a[href]')</code></p>\n<p>通过属性的值来查找 <code>soup.select('a[href^=&quot;https:&quot;]', [href$='title'], [href*=&quot;.com/&quot;]</code></p>\n<h2 id=\"修改文档树\"><a class=\"markdownIt-Anchor\" href=\"#修改文档树\"></a> 修改文档树</h2>\n<h2 id=\"输出\"><a class=\"markdownIt-Anchor\" href=\"#输出\"></a> 输出</h2>\n<h3 id=\"格式化输出\"><a class=\"markdownIt-Anchor\" href=\"#格式化输出\"></a> 格式化输出</h3>\n<p>prettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">markup = <span class=\"string\">'&lt;a href=\"http://example.com/\"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></span><br><span class=\"line\">soup = BeautifulSoup(markup)</span><br><span class=\"line\">soup.prettify()</span><br><span class=\"line\"><span class=\"comment\"># '&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n  &lt;a href=\"http://example.com/\"&gt;\\n...'</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(soup.prettify())</span><br><span class=\"line\"><span class=\"comment\"># &lt;html&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;head&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;/head&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;body&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#   &lt;a href=\"http://example.com/\"&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#    I linked to</span></span><br><span class=\"line\"><span class=\"comment\">#    &lt;i&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#     example.com</span></span><br><span class=\"line\"><span class=\"comment\">#    &lt;/i&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#   &lt;/a&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;/body&gt;</span></span><br><span class=\"line\"><span class=\"comment\"># &lt;/html&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"压缩输出\"><a class=\"markdownIt-Anchor\" href=\"#压缩输出\"></a> 压缩输出</h3>\n<p>如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:</p>\n<p><code>str(soup), Unicode(soup.a)</code></p>\n<h3 id=\"输出格式\"><a class=\"markdownIt-Anchor\" href=\"#输出格式\"></a> 输出格式</h3>\n<p>Beautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“&amp;lquot;”:<br>\n如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:</p>\n<h3 id=\"get_text\"><a class=\"markdownIt-Anchor\" href=\"#get_text\"></a> get_text()</h3>\n<p>如果只想得到tag中包含的文本内容,那么可以用 get_text() 方法,这个方法获取到tag中包含的所有文本内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:</p>\n<p>可以通过参数指定tag的文本内容的分隔符, 还可以去除前后空白: <code>soup.get_text('|', strip=True)</code></p>\n<h2 id=\"指定文档解析器\"><a class=\"markdownIt-Anchor\" href=\"#指定文档解析器\"></a> 指定文档解析器</h2>\n<h2 id=\"编码\"><a class=\"markdownIt-Anchor\" href=\"#编码\"></a> 编码</h2>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"beautifulsoup\"><a class=\"markdownIt-Anchor\" href=\"#beautifulsoup\"></a> <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html\" target=\"_blank\" rel=\"noopener\">BeautifulSoup</a></h2>\n<p>You didn’t write that awful page. You’re just trying to get some data out of it. Beautiful Soup is here to help. Since 2004, it’s been saving programmers hours or days of work on quick-turnaround screen scraping projects.</p>\n<h2 id=\"如何使用\"><a class=\"markdownIt-Anchor\" href=\"#如何使用\"></a> 如何使用</h2>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup</span><br><span class=\"line\">soup = BeautifulSoup(open(<span class=\"string\">'index.html'</span>))</span><br></pre></td></tr></table></figure>\n<h2 id=\"对象的种类\"><a class=\"markdownIt-Anchor\" href=\"#对象的种类\"></a> 对象的种类</h2>\n<h3 id=\"tag\"><a class=\"markdownIt-Anchor\" href=\"#tag\"></a> Tag</h3>\n<p>Tag 对象与XML或HTML原生文档中的tag相同:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">soup = BeautifulSoup(<span class=\"string\">'&lt;b class=\"boldest\"&gt;Extremely bold&lt;/b&gt;'</span>)</span><br><span class=\"line\">tag = soup.b</span><br><span class=\"line\">type(tag)</span><br><span class=\"line\"><span class=\"comment\"># &lt;class 'bs4.element.Tag'&gt;</span></span><br></pre></td></tr></table></figure>\n<p>Tag的属性：<code>tag.name, tag.attrs</code></p>\n<p>tag的属性的操作方法与字典相同: <code>tag['class']</code></p>\n<h3 id=\"可以遍历的字符串\"><a class=\"markdownIt-Anchor\" href=\"#可以遍历的字符串\"></a> 可以遍历的字符串</h3>\n<p>字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:<code>tag.string</code></p>\n<p><code>unicode_string = unicode(tag.string)</code></p>\n<p>tag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法:<code>tag.string.replace_with(&quot;No&quot;)</code></p>\n<h3 id=\"beautifulsoup-2\"><a class=\"markdownIt-Anchor\" href=\"#beautifulsoup-2\"></a> BeautifulSoup</h3>\n<p>BeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.</p>\n<h3 id=\"注释及特殊字符串\"><a class=\"markdownIt-Anchor\" href=\"#注释及特殊字符串\"></a> 注释及特殊字符串</h3>\n<p>Comment 对象是一个特殊类型的 NavigableString 对象:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">markup = <span class=\"string\">\"&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;\"</span></span><br><span class=\"line\">soup = BeautifulSoup(markup)</span><br><span class=\"line\">comment = soup.b.string</span><br><span class=\"line\">type(comment)</span><br><span class=\"line\"><span class=\"comment\"># &lt;class 'bs4.element.Comment'&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"遍历文档树\"><a class=\"markdownIt-Anchor\" href=\"#遍历文档树\"></a> 遍历文档树</h2>\n<h3 id=\"子节点\"><a class=\"markdownIt-Anchor\" href=\"#子节点\"></a> 子节点</h3>\n<p>一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.</p>\n<h4 id=\"tag的名字\"><a class=\"markdownIt-Anchor\" href=\"#tag的名字\"></a> tag的名字</h4>\n<p><code>soup.head, soup.title, soup.body.b, soup.a, soup.find_all('a')</code></p>\n<h4 id=\"contents和children\"><a class=\"markdownIt-Anchor\" href=\"#contents和children\"></a> .contents和.children</h4>\n<p>tag的 .contents 属性可以将tag的子节点以列表的方式输出:</p>\n<p>通过tag的 .children 生成器,可以对tag的子节点进行循环:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> title_tag.children:</span><br><span class=\"line\">    print(child)</span><br></pre></td></tr></table></figure>\n<p>descendants 属性可以对所有tag的子孙节点进行递归循环:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> child <span class=\"keyword\">in</span> title_tag.descendants:</span><br><span class=\"line\">    print(child)</span><br></pre></td></tr></table></figure>\n<h3 id=\"string\"><a class=\"markdownIt-Anchor\" href=\"#string\"></a> .string</h3>\n<p>如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点:<code>tag.string</code></p>\n<p>如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同</p>\n<p>如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :</p>\n<h3 id=\"strings和stripped__strings\"><a class=\"markdownIt-Anchor\" href=\"#strings和stripped__strings\"></a> .strings和stripped__strings</h3>\n<p>如果tag中包含多个字符串 ,可以使用 .strings 来循环获取, 输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> string <span class=\"keyword\">in</span> soup.strings:</span><br><span class=\"line\">    print(repr(string))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> string <span class=\"keyword\">in</span> soup.stripped_strings:</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n<h3 id=\"父节点\"><a class=\"markdownIt-Anchor\" href=\"#父节点\"></a> 父节点</h3>\n<h4 id=\"parent\"><a class=\"markdownIt-Anchor\" href=\"#parent\"></a> .parent</h4>\n<p><code>tag.parent, tag.string.parent</code></p>\n<h4 id=\"parents\"><a class=\"markdownIt-Anchor\" href=\"#parents\"></a> .parents</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">link = soup.a</span><br><span class=\"line\"><span class=\"keyword\">for</span> parent <span class=\"keyword\">in</span> link.parents:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> parent <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        print(parent)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        print(parent.name)</span><br></pre></td></tr></table></figure>\n<h3 id=\"兄弟节点\"><a class=\"markdownIt-Anchor\" href=\"#兄弟节点\"></a> 兄弟节点</h3>\n<h4 id=\"next_sibling和previous_sibling\"><a class=\"markdownIt-Anchor\" href=\"#next_sibling和previous_sibling\"></a> .next_sibling和.previous_sibling</h4>\n<p>实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白.</p>\n<h4 id=\"next_siblings和previous_siblings\"><a class=\"markdownIt-Anchor\" href=\"#next_siblings和previous_siblings\"></a> .next_siblings和.previous_siblings</h4>\n<p>通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> sibling <span class=\"keyword\">in</span> soup.a.next_siblings:</span><br><span class=\"line\">    print(repr(sibling))</span><br></pre></td></tr></table></figure>\n<h3 id=\"回退和前进\"><a class=\"markdownIt-Anchor\" href=\"#回退和前进\"></a> 回退和前进</h3>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>The Dormouse's story<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">class</span>=<span class=\"string\">\"title\"</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">b</span>&gt;</span>The Dormouse's story<span class=\"tag\">&lt;/<span class=\"name\">b</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>HTML解析器把这段字符串转换成一连串的事件: “打开html标签”,”打开一个head标签”,”打开一个title标签”,”添加一段字符串”,”关闭title标签”,”关闭p标签”,等等.Beautiful Soup提供了重现解析器初始化过程的方法</p>\n<h4 id=\"next_element和previous_element\"><a class=\"markdownIt-Anchor\" href=\"#next_element和previous_element\"></a> .next_element和.previous_element</h4>\n<p>.previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象, next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),</p>\n<h4 id=\"next_elements和previous_elements\"><a class=\"markdownIt-Anchor\" href=\"#next_elements和previous_elements\"></a> .next_elements和.previous_elements</h4>\n<p>通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> elementin a_tag.next_elements:</span><br><span class=\"line\">    print(repr(element))</span><br></pre></td></tr></table></figure>\n<h2 id=\"搜索文档树\"><a class=\"markdownIt-Anchor\" href=\"#搜索文档树\"></a> 搜索文档树</h2>\n<h3 id=\"过滤器\"><a class=\"markdownIt-Anchor\" href=\"#过滤器\"></a> 过滤器</h3>\n<h4 id=\"字符串\"><a class=\"markdownIt-Anchor\" href=\"#字符串\"></a> 字符串</h4>\n<p>最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的&lt;b&gt;标签:</p>\n<p><code>soup.find_all('b')</code></p>\n<h4 id=\"正则表达式\"><a class=\"markdownIt-Anchor\" href=\"#正则表达式\"></a> 正则表达式</h4>\n<p>如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示&lt;body&gt;和&lt;b&gt;标签都应该被找到:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">for</span> tag <span class=\"keyword\">in</span> soup.find_all(re.compile(<span class=\"string\">\"^b\"</span>):</span><br><span class=\"line\">    print(tag.name)</span><br></pre></td></tr></table></figure>\n<h4 id=\"列表\"><a class=\"markdownIt-Anchor\" href=\"#列表\"></a> 列表</h4>\n<p>如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有&lt;a&gt;标签和&lt;b&gt;标签:</p>\n<p><code>soup.find_all(['a', 'b'])</code></p>\n<h4 id=\"true\"><a class=\"markdownIt-Anchor\" href=\"#true\"></a> True</h4>\n<p>True 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> tag <span class=\"keyword\">in</span> soup.find_all(<span class=\"keyword\">True</span>):</span><br><span class=\"line\">    print(tag.name)</span><br></pre></td></tr></table></figure>\n<h4 id=\"方法\"><a class=\"markdownIt-Anchor\" href=\"#方法\"></a> 方法</h4>\n<p>如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False</p>\n<p>下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">has_class_but_no_id</span><span class=\"params\">(tag)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> tag.has_attr(<span class=\"string\">'class'</span>) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> tag.has_attr(<span class=\"string\">'id'</span>)</span><br></pre></td></tr></table></figure>\n<p>下面代码找到所有被文字包含的节点内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> NavigableString</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">surrounded_by_strings</span><span class=\"params\">(tag)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (isinstance(tag.next_element, NavigableString)) <span class=\"keyword\">and</span> isinstance(tag.previous_element, NavigableString)</span><br></pre></td></tr></table></figure>\n<h3 id=\"find_all\"><a class=\"markdownIt-Anchor\" href=\"#find_all\"></a> find_all()</h3>\n<p><code>find_all(name, attrs, recursive, text, **kwargs)</code></p>\n<p>find_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件</p>\n<h4 id=\"name参数\"><a class=\"markdownIt-Anchor\" href=\"#name参数\"></a> name参数</h4>\n<p>搜索 name 参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .</p>\n<p>name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.</p>\n<h4 id=\"keyword参数\"><a class=\"markdownIt-Anchor\" href=\"#keyword参数\"></a> keyword参数</h4>\n<p><code>soup.find_all(id='link2')</code><br>\n<code>soup.find_all(href=re.compile('elsie'))</code><br>\n<code>soup.find_all(id=True)</code><br>\n<code>soup.find_all(attrs={'id':'link2'})</code></p>\n<h4 id=\"按css搜索\"><a class=\"markdownIt-Anchor\" href=\"#按css搜索\"></a> 按CSS搜索</h4>\n<p>通过 “.class__”_ 参数搜索有指定CSS类名的tag, “.class__”_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True</p>\n<p><code>soup.find_all('a', class_='sister')</code></p>\n<h4 id=\"text参数\"><a class=\"markdownIt-Anchor\" href=\"#text参数\"></a> text参数</h4>\n<p>通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True.</p>\n<p><code>soup.find_all(text=re.compile(&quot;Dormouse&quot;))</code></p>\n<h4 id=\"limit参数\"><a class=\"markdownIt-Anchor\" href=\"#limit参数\"></a> limit参数</h4>\n<p>find_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.</p>\n<p><code>soup.find_all('a', limit=2)</code></p>\n<h4 id=\"recursive参数\"><a class=\"markdownIt-Anchor\" href=\"#recursive参数\"></a> recursive参数</h4>\n<p>调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False.</p>\n<p><code>soup.find_all('title', recursive=False)</code></p>\n<h3 id=\"像调用find_all一样调用tag\"><a class=\"markdownIt-Anchor\" href=\"#像调用find_all一样调用tag\"></a> 像调用find_all()一样调用tag</h3>\n<p>find_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:</p>\n<p><code>soup.find_all('a')</code><br>\n<code>soup('a')</code></p>\n<h3 id=\"find\"><a class=\"markdownIt-Anchor\" href=\"#find\"></a> find()</h3>\n<p><code>find(name, attrs, recursive, text, **kwargs)</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">soup.find_all(<span class=\"string\">'title'</span>, limit=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># [&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></span><br><span class=\"line\"></span><br><span class=\"line\">soup.find(<span class=\"string\">'title'</span>)</span><br><span class=\"line\"><span class=\"comment\"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></span><br></pre></td></tr></table></figure>\n<p>唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.</p>\n<p>find_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None.</p>\n<h3 id=\"find_parents和find_parent\"><a class=\"markdownIt-Anchor\" href=\"#find_parents和find_parent\"></a> find_parents()和find_parent()</h3>\n<p>find_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同</p>\n<h3 id=\"find_next_siblings和find_next_sibling\"><a class=\"markdownIt-Anchor\" href=\"#find_next_siblings和find_next_sibling\"></a> find_next_siblings()和find_next_sibling()</h3>\n<p>这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.</p>\n<h3 id=\"find_previous_siblings和find_previous_sibling\"><a class=\"markdownIt-Anchor\" href=\"#find_previous_siblings和find_previous_sibling\"></a> find_previous_siblings和find_previous_sibling()</h3>\n<p>find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:</p>\n<h3 id=\"find_all_next和find_next\"><a class=\"markdownIt-Anchor\" href=\"#find_all_next和find_next\"></a> find_all_next()和find_next()</h3>\n<p>这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:</p>\n<h3 id=\"find_all_previous和find_previous\"><a class=\"markdownIt-Anchor\" href=\"#find_all_previous和find_previous\"></a> find_all_previous()和find_previous()</h3>\n<p>这2个方法通过 .previous_elements 属性对当前节点前面的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点.</p>\n<h3 id=\"css选择器\"><a class=\"markdownIt-Anchor\" href=\"#css选择器\"></a> CSS选择器</h3>\n<p>通过tag标签逐层查找 <code>soup.select(&quot;body a&quot;)</code></p>\n<p>找到某个tag标签的直接子标签 <code>soup.select(&quot;p &gt; #link1&quot;)</code></p>\n<p>找到兄弟节点标签 <code>soup.select(&quot;#link1 + .sister&quot;)</code></p>\n<p>通过CSS类名查找 <code>soup.select(&quot;.sister&quot;), soup.select(&quot;[class~=sister]&quot;)</code></p>\n<p>通过tag的id查找 <code>soup.select(&quot;#link1&quot;)</code></p>\n<p>通过是否存在某个属性查找 <code>soup.slect('a[href]')</code></p>\n<p>通过属性的值来查找 <code>soup.select('a[href^=&quot;https:&quot;]', [href$='title'], [href*=&quot;.com/&quot;]</code></p>\n<h2 id=\"修改文档树\"><a class=\"markdownIt-Anchor\" href=\"#修改文档树\"></a> 修改文档树</h2>\n<h2 id=\"输出\"><a class=\"markdownIt-Anchor\" href=\"#输出\"></a> 输出</h2>\n<h3 id=\"格式化输出\"><a class=\"markdownIt-Anchor\" href=\"#格式化输出\"></a> 格式化输出</h3>\n<p>prettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">markup = <span class=\"string\">'&lt;a href=\"http://example.com/\"&gt;I linked to &lt;i&gt;example.com&lt;/i&gt;&lt;/a&gt;'</span></span><br><span class=\"line\">soup = BeautifulSoup(markup)</span><br><span class=\"line\">soup.prettify()</span><br><span class=\"line\"><span class=\"comment\"># '&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n  &lt;a href=\"http://example.com/\"&gt;\\n...'</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(soup.prettify())</span><br><span class=\"line\"><span class=\"comment\"># &lt;html&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;head&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;/head&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;body&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#   &lt;a href=\"http://example.com/\"&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#    I linked to</span></span><br><span class=\"line\"><span class=\"comment\">#    &lt;i&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#     example.com</span></span><br><span class=\"line\"><span class=\"comment\">#    &lt;/i&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#   &lt;/a&gt;</span></span><br><span class=\"line\"><span class=\"comment\">#  &lt;/body&gt;</span></span><br><span class=\"line\"><span class=\"comment\"># &lt;/html&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"压缩输出\"><a class=\"markdownIt-Anchor\" href=\"#压缩输出\"></a> 压缩输出</h3>\n<p>如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:</p>\n<p><code>str(soup), Unicode(soup.a)</code></p>\n<h3 id=\"输出格式\"><a class=\"markdownIt-Anchor\" href=\"#输出格式\"></a> 输出格式</h3>\n<p>Beautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“&amp;lquot;”:<br>\n如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:</p>\n<h3 id=\"get_text\"><a class=\"markdownIt-Anchor\" href=\"#get_text\"></a> get_text()</h3>\n<p>如果只想得到tag中包含的文本内容,那么可以用 get_text() 方法,这个方法获取到tag中包含的所有文本内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:</p>\n<p>可以通过参数指定tag的文本内容的分隔符, 还可以去除前后空白: <code>soup.get_text('|', strip=True)</code></p>\n<h2 id=\"指定文档解析器\"><a class=\"markdownIt-Anchor\" href=\"#指定文档解析器\"></a> 指定文档解析器</h2>\n<h2 id=\"编码\"><a class=\"markdownIt-Anchor\" href=\"#编码\"></a> 编码</h2>\n"},{"title":"CIFAR-10","date":"2018-09-15T05:02:14.000Z","_content":"The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n\n## [The CIFAR-10 dataset](http://www.cs.toronto.edu/~kriz/cifar.html)\n\nThe CIFAR-10 dataset consists of **60000 32x32** colour images in **10 classes**, with 6000 images per class. There are **50000 training** images and **10000 test** images.\n\nThe dataset is divided into **five training batches** and **one test batch**, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n\n## Dataset layout (python/matlab version)\n\nThe archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object\n\n```python\ndef unpickle(file):  # python2\n    import cPickle\n    with open(file, 'rb') as fo:\n        dict = cPickle.load(fo)\n    return dict\n\ndef unpickle(file):  # python3\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n```\n\nLoaded in this way, each of the batch files contains a dictionary with the following elements:\n\n    data --\n    a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image.\n    The first 1024 entries contain the red channel values,\n    the next 1024 the green, and the final 1024 the blue.\n    The image is stored in row-major order, so that the first 32 entries of\n    the array are the red channel values of the first row of the image.\n\n    labels --\n    a list of 10000 numbers in the range 0-9.\n    The number at index i indicates the label of the ith image in the array data.\n\nThe dataset contains another file, called **batches.meta**. It too contains a Python dictionary object. It has the following entries:\n\n    label_names --\n    a 10-element list which gives meaningful names to the numeric labels in the labels array described above.\n     For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\n","source":"_posts/CIFAR-10.md","raw":"---\ntitle: CIFAR-10\ndate: 2018-09-15 13:02:14\ntags: 数据集\ncategories: 深度学习\n---\nThe CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n\n## [The CIFAR-10 dataset](http://www.cs.toronto.edu/~kriz/cifar.html)\n\nThe CIFAR-10 dataset consists of **60000 32x32** colour images in **10 classes**, with 6000 images per class. There are **50000 training** images and **10000 test** images.\n\nThe dataset is divided into **five training batches** and **one test batch**, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n\n## Dataset layout (python/matlab version)\n\nThe archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object\n\n```python\ndef unpickle(file):  # python2\n    import cPickle\n    with open(file, 'rb') as fo:\n        dict = cPickle.load(fo)\n    return dict\n\ndef unpickle(file):  # python3\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n```\n\nLoaded in this way, each of the batch files contains a dictionary with the following elements:\n\n    data --\n    a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image.\n    The first 1024 entries contain the red channel values,\n    the next 1024 the green, and the final 1024 the blue.\n    The image is stored in row-major order, so that the first 32 entries of\n    the array are the red channel values of the first row of the image.\n\n    labels --\n    a list of 10000 numbers in the range 0-9.\n    The number at index i indicates the label of the ith image in the array data.\n\nThe dataset contains another file, called **batches.meta**. It too contains a Python dictionary object. It has the following entries:\n\n    label_names --\n    a 10-element list which gives meaningful names to the numeric labels in the labels array described above.\n     For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\n","slug":"CIFAR-10","published":1,"updated":"2018-09-22T03:51:56.207Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ow9000344voc93n9d4y","content":"<p>The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.</p>\n<h2 id=\"the-cifar-10-dataset\"><a class=\"markdownIt-Anchor\" href=\"#the-cifar-10-dataset\"></a> <a href=\"http://www.cs.toronto.edu/~kriz/cifar.html\" target=\"_blank\" rel=\"noopener\">The CIFAR-10 dataset</a></h2>\n<p>The CIFAR-10 dataset consists of <strong>60000 32x32</strong> colour images in <strong>10 classes</strong>, with 6000 images per class. There are <strong>50000 training</strong> images and <strong>10000 test</strong> images.</p>\n<p>The dataset is divided into <strong>five training batches</strong> and <strong>one test batch</strong>, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.</p>\n<h2 id=\"dataset-layout-pythonmatlab-version\"><a class=\"markdownIt-Anchor\" href=\"#dataset-layout-pythonmatlab-version\"></a> Dataset layout (python/matlab version)</h2>\n<p>The archive contains the files data_batch_1, data_batch_2, …, data_batch_5, as well as test_batch. Each of these files is a Python “pickled” object</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">unpickle</span><span class=\"params\">(file)</span>:</span>  <span class=\"comment\"># python2</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> cPickle</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> fo:</span><br><span class=\"line\">        dict = cPickle.load(fo)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dict</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">unpickle</span><span class=\"params\">(file)</span>:</span>  <span class=\"comment\"># python3</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> pickle</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> fo:</span><br><span class=\"line\">        dict = pickle.load(fo, encoding=<span class=\"string\">'bytes'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dict</span><br></pre></td></tr></table></figure>\n<p>Loaded in this way, each of the batch files contains a dictionary with the following elements:</p>\n<pre><code>data --\na 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image.\nThe first 1024 entries contain the red channel values,\nthe next 1024 the green, and the final 1024 the blue.\nThe image is stored in row-major order, so that the first 32 entries of\nthe array are the red channel values of the first row of the image.\n\nlabels --\na list of 10000 numbers in the range 0-9.\nThe number at index i indicates the label of the ith image in the array data.\n</code></pre>\n<p>The dataset contains another file, called <strong>batches.meta</strong>. It too contains a Python dictionary object. It has the following entries:</p>\n<pre><code>label_names --\na 10-element list which gives meaningful names to the numeric labels in the labels array described above.\n For example, label_names[0] == &quot;airplane&quot;, label_names[1] == &quot;automobile&quot;, etc.\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<p>The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.</p>\n<h2 id=\"the-cifar-10-dataset\"><a class=\"markdownIt-Anchor\" href=\"#the-cifar-10-dataset\"></a> <a href=\"http://www.cs.toronto.edu/~kriz/cifar.html\" target=\"_blank\" rel=\"noopener\">The CIFAR-10 dataset</a></h2>\n<p>The CIFAR-10 dataset consists of <strong>60000 32x32</strong> colour images in <strong>10 classes</strong>, with 6000 images per class. There are <strong>50000 training</strong> images and <strong>10000 test</strong> images.</p>\n<p>The dataset is divided into <strong>five training batches</strong> and <strong>one test batch</strong>, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.</p>\n<h2 id=\"dataset-layout-pythonmatlab-version\"><a class=\"markdownIt-Anchor\" href=\"#dataset-layout-pythonmatlab-version\"></a> Dataset layout (python/matlab version)</h2>\n<p>The archive contains the files data_batch_1, data_batch_2, …, data_batch_5, as well as test_batch. Each of these files is a Python “pickled” object</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">unpickle</span><span class=\"params\">(file)</span>:</span>  <span class=\"comment\"># python2</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> cPickle</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> fo:</span><br><span class=\"line\">        dict = cPickle.load(fo)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dict</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">unpickle</span><span class=\"params\">(file)</span>:</span>  <span class=\"comment\"># python3</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> pickle</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> fo:</span><br><span class=\"line\">        dict = pickle.load(fo, encoding=<span class=\"string\">'bytes'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dict</span><br></pre></td></tr></table></figure>\n<p>Loaded in this way, each of the batch files contains a dictionary with the following elements:</p>\n<pre><code>data --\na 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image.\nThe first 1024 entries contain the red channel values,\nthe next 1024 the green, and the final 1024 the blue.\nThe image is stored in row-major order, so that the first 32 entries of\nthe array are the red channel values of the first row of the image.\n\nlabels --\na list of 10000 numbers in the range 0-9.\nThe number at index i indicates the label of the ith image in the array data.\n</code></pre>\n<p>The dataset contains another file, called <strong>batches.meta</strong>. It too contains a Python dictionary object. It has the following entries:</p>\n<pre><code>label_names --\na 10-element list which gives meaningful names to the numeric labels in the labels array described above.\n For example, label_names[0] == &quot;airplane&quot;, label_names[1] == &quot;automobile&quot;, etc.\n</code></pre>\n"},{"title":"DNN应用1--识别猫","date":"2018-08-03T00:52:05.000Z","_content":"## 实验目的\n\n使用深层全连接神经网络识别一副图片是否为猫，并将网络层数及每层单元数设为超参数。\n\n## 实验方案\n\n- 使用python自行编码各运算单元，主要借助numpy库的数据结构和运算函数。\n- 各个隐藏层采用Relu激活函数，输出层采用Sigmod激活函数，隐藏层使用dropout处理\n- 损失函数采用交叉熵，并使用L2正则化\n- 网络架构\n ![](/images/LlayerNN.png)\n\n## 详细设计\n\n### 数据预处理\n\n#### 加载数据\n\n```python\nimport numpy as np\nimport h5py\n\ndef load_data():\n    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])  # your train set features\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])  # your train set labels\n\n    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])  # your test set features\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])  # your test set labels\n\n    classes = np.array(test_dataset[\"list_classes\"][:])  # the list of classes\n    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n```\n\n```python\ntrain_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n```\n\n#### 数据集形状\n\n>Number of training examples: 209\nNumber of testing examples: 50\nEach image is of size: (64, 64, 3)\ntrain_x_orig shape: (209, 64, 64, 3)\ntrain_y shape: (1, 209)\ntest_x_orig shape: (50, 64, 64, 3)\ntest_y shape: (1, 50)\n\n#### 展示数据图片\n\n```python\nimport matplotlib.pyplot as plt\n\nindex = 7\nplt.imshow(train_x_orig[index])\nprint (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")\nplt.show()\n```\n\n#### 图像矩阵向量化\n\n```python\n# Reshape the training and test examples\ntrain_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\ntest_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n\n# Standardize data to have feature values between 0 and 1.\ntrain_x = train_x_flatten/255.\ntest_x = test_x_flatten/255.\n```\n\n#### 数据集最终形状\n\n>train_x's shape: (12288, 209)\ntest_x's shape: (12288, 50)\n\n### 网络设计\n\n1. 初始化参数 / 定义超参数\n2. 迭代循环:\n    a. 前向传播\n    b. 计算代价函数\n    c. 反向传播\n    d. 更新参数\n3. 使用训练的参数去预测新的数据标签\n\n网络主框架代码，其他细节函数参见“神经网络中的通用函数代码”\n\n```python\ndef L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False):  # lr was 0.009\n    \"\"\"\n    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n\n    Arguments:\n    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    costs = []                         # keep track of cost\n    # Parameters initialization.\n    parameters = initialize_parameters_deep(layers_dims)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n        AL, caches = L_model_forward(X, parameters)\n        # Compute cost.\n        cost = compute_cost(AL, Y)\n        # Backward propagation.\n        grads = L_model_backward(AL, Y, caches)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads, learning_rate=0.0075)\n        # Print the cost every 100 training example\n        if print_cost and i % 100 == 0:\n            print(\"Cost after iteration %i: %f\" % (i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)\n    # plot the cost\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Learning rate =\" + str(learning_rate))\n    plt.show()\n    return parameters\n```\n\n## 实验结果\n\n### 训练集结果\n\n```python\nlayers_dims = [12288, 20, 7, 5, 1] #  5-layer model\nparameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)\n```\n\n![](/images/res1.PNG)\n\n```python\npred_train = predict(train_x, train_y, parameters)\n```\n\n>Accuracy: 0.9856459330143539\n\n### 测试集结果\n\n```python\npred_test = predict(test_x, test_y, parameters)\n```\n\n>Accuracy: 0.8\n\n### 数据集外结果\n\n```python\nfrom scipy import ndimage\nimport scipy.misc\n\nmy_image = \"my_image.jpg\"\nmy_label_y = [0]\nfname = \"images/\" + my_image\nimage = np.array(ndimage.imread(fname, flatten=False))\nmy_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((num_px * num_px * 3, 1))\nmy_predicted_image = predict(my_image, my_label_y, parameters)\nplt.imshow(image)\nprint(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)), ].decode(\"utf-8\") + \"\\\" picture.\")\n```\n\n>Accuracy: 1.0\n>y = 1.0, your L-layer model predicts a \"cat\" picture.\n\n![](/images/my_image.jpg)\n","source":"_posts/DNN应用1-识别猫.md","raw":"---\ntitle: DNN应用1--识别猫\ndate: 2018-08-03 08:52:05\ntags: DNN\ncategories: 深度学习\n---\n## 实验目的\n\n使用深层全连接神经网络识别一副图片是否为猫，并将网络层数及每层单元数设为超参数。\n\n## 实验方案\n\n- 使用python自行编码各运算单元，主要借助numpy库的数据结构和运算函数。\n- 各个隐藏层采用Relu激活函数，输出层采用Sigmod激活函数，隐藏层使用dropout处理\n- 损失函数采用交叉熵，并使用L2正则化\n- 网络架构\n ![](/images/LlayerNN.png)\n\n## 详细设计\n\n### 数据预处理\n\n#### 加载数据\n\n```python\nimport numpy as np\nimport h5py\n\ndef load_data():\n    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])  # your train set features\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])  # your train set labels\n\n    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])  # your test set features\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])  # your test set labels\n\n    classes = np.array(test_dataset[\"list_classes\"][:])  # the list of classes\n    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n```\n\n```python\ntrain_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n```\n\n#### 数据集形状\n\n>Number of training examples: 209\nNumber of testing examples: 50\nEach image is of size: (64, 64, 3)\ntrain_x_orig shape: (209, 64, 64, 3)\ntrain_y shape: (1, 209)\ntest_x_orig shape: (50, 64, 64, 3)\ntest_y shape: (1, 50)\n\n#### 展示数据图片\n\n```python\nimport matplotlib.pyplot as plt\n\nindex = 7\nplt.imshow(train_x_orig[index])\nprint (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")\nplt.show()\n```\n\n#### 图像矩阵向量化\n\n```python\n# Reshape the training and test examples\ntrain_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\ntest_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n\n# Standardize data to have feature values between 0 and 1.\ntrain_x = train_x_flatten/255.\ntest_x = test_x_flatten/255.\n```\n\n#### 数据集最终形状\n\n>train_x's shape: (12288, 209)\ntest_x's shape: (12288, 50)\n\n### 网络设计\n\n1. 初始化参数 / 定义超参数\n2. 迭代循环:\n    a. 前向传播\n    b. 计算代价函数\n    c. 反向传播\n    d. 更新参数\n3. 使用训练的参数去预测新的数据标签\n\n网络主框架代码，其他细节函数参见“神经网络中的通用函数代码”\n\n```python\ndef L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False):  # lr was 0.009\n    \"\"\"\n    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n\n    Arguments:\n    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    costs = []                         # keep track of cost\n    # Parameters initialization.\n    parameters = initialize_parameters_deep(layers_dims)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n        AL, caches = L_model_forward(X, parameters)\n        # Compute cost.\n        cost = compute_cost(AL, Y)\n        # Backward propagation.\n        grads = L_model_backward(AL, Y, caches)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads, learning_rate=0.0075)\n        # Print the cost every 100 training example\n        if print_cost and i % 100 == 0:\n            print(\"Cost after iteration %i: %f\" % (i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)\n    # plot the cost\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Learning rate =\" + str(learning_rate))\n    plt.show()\n    return parameters\n```\n\n## 实验结果\n\n### 训练集结果\n\n```python\nlayers_dims = [12288, 20, 7, 5, 1] #  5-layer model\nparameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)\n```\n\n![](/images/res1.PNG)\n\n```python\npred_train = predict(train_x, train_y, parameters)\n```\n\n>Accuracy: 0.9856459330143539\n\n### 测试集结果\n\n```python\npred_test = predict(test_x, test_y, parameters)\n```\n\n>Accuracy: 0.8\n\n### 数据集外结果\n\n```python\nfrom scipy import ndimage\nimport scipy.misc\n\nmy_image = \"my_image.jpg\"\nmy_label_y = [0]\nfname = \"images/\" + my_image\nimage = np.array(ndimage.imread(fname, flatten=False))\nmy_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((num_px * num_px * 3, 1))\nmy_predicted_image = predict(my_image, my_label_y, parameters)\nplt.imshow(image)\nprint(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)), ].decode(\"utf-8\") + \"\\\" picture.\")\n```\n\n>Accuracy: 1.0\n>y = 1.0, your L-layer model predicts a \"cat\" picture.\n\n![](/images/my_image.jpg)\n","slug":"DNN应用1-识别猫","published":1,"updated":"2018-08-31T03:48:46.687Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19owg000644vok5gflb02"},{"title":"Evolutionary Algorithms","date":"2018-08-05T09:12:46.000Z","_content":"\n>It is not strongest of the species that survives, nor the most intelligent that survives. It is the one that is the most adaptable to change. -- Charles Darwin\n\n## Motivation of EAs\n\n1. What can EAs do for us?\n\t- Optimization\n\t- Help people understand the evolution in nature.\n\n2. What is optimizatin?\n\t- The process of searching for the optimal solution from a set of candidates to the problem of interest based on certrain **performance criteria**\n\n3. Produce maximum yields given litmited resources.\n\n## Key Concepts\n\n- Population-Based Stochastic Optimization Methods\n- Inherently Parallel\n- A Good Example of Bionics in Engineering\n- Survival of the Fittest\n- Chromosome, Crossover, Mutation\n- Metaheuristics\n- Bio-/Nature Inspired Computing\n\n## The Big Picture\n\n![](/images/eas.png)\n\n## EA Family\n\n- GA: Genetic Algorithm\n- GP: Genetic Programming\n- ES: Evolution Strategies\n- EP: Evolution Programming\n- EDA: Estimation of Distribution Algorithm\n- PSO: Particle Swarm Optimization\n- ACO: Ant Colony Optimization\n- DE: Differential Evolution\n\n## Optimization Problem Set\n\n- Portfolio Optimization\n- Travelling Salesman Problem\n- Knapsack Problem\n- Machine Learing Problems\n\n![](/images/local_optima.png)\n\nMany interesting optimization problems are not trivial.The optimal solution cannot always be found in polynomial time.\n\n## Solution: Parallel Search\n\n- Conduct searching in different areas simultaneously.\n\t- Population Based\n\t- Avoid unfortunate starting positions.\n- Employ heuristic methods to effectively explore the space.\n\t- Focus on promising areas.\n\t- Also keep an eye on other regions.\n\t- More than random restart strategies.\n\n## Publications\n\nTop Journals:\n- IEEE Transactions On Evolutionary Computation.\n- Evolutionary Compution Journal\n\nMajor Conference:\n- IEEE Congress On Evolution Computation(CEC)\n- Genetic and Evolution Computation Conference(GECCO)\n- Parallel Problem Solving from Nature(PPSN)\n\nGame:\n\t- Blondie24: Playing at the Edge of AI\n\nBook:\n\t- How to Solve It: Modern Heuristics\n","source":"_posts/Evolutionary-Algorithms.md","raw":"---\ntitle: Evolutionary Algorithms\ndate: 2018-08-05 17:12:46\ntags: 进化算法\ncategories: 进化计算\n---\n\n>It is not strongest of the species that survives, nor the most intelligent that survives. It is the one that is the most adaptable to change. -- Charles Darwin\n\n## Motivation of EAs\n\n1. What can EAs do for us?\n\t- Optimization\n\t- Help people understand the evolution in nature.\n\n2. What is optimizatin?\n\t- The process of searching for the optimal solution from a set of candidates to the problem of interest based on certrain **performance criteria**\n\n3. Produce maximum yields given litmited resources.\n\n## Key Concepts\n\n- Population-Based Stochastic Optimization Methods\n- Inherently Parallel\n- A Good Example of Bionics in Engineering\n- Survival of the Fittest\n- Chromosome, Crossover, Mutation\n- Metaheuristics\n- Bio-/Nature Inspired Computing\n\n## The Big Picture\n\n![](/images/eas.png)\n\n## EA Family\n\n- GA: Genetic Algorithm\n- GP: Genetic Programming\n- ES: Evolution Strategies\n- EP: Evolution Programming\n- EDA: Estimation of Distribution Algorithm\n- PSO: Particle Swarm Optimization\n- ACO: Ant Colony Optimization\n- DE: Differential Evolution\n\n## Optimization Problem Set\n\n- Portfolio Optimization\n- Travelling Salesman Problem\n- Knapsack Problem\n- Machine Learing Problems\n\n![](/images/local_optima.png)\n\nMany interesting optimization problems are not trivial.The optimal solution cannot always be found in polynomial time.\n\n## Solution: Parallel Search\n\n- Conduct searching in different areas simultaneously.\n\t- Population Based\n\t- Avoid unfortunate starting positions.\n- Employ heuristic methods to effectively explore the space.\n\t- Focus on promising areas.\n\t- Also keep an eye on other regions.\n\t- More than random restart strategies.\n\n## Publications\n\nTop Journals:\n- IEEE Transactions On Evolutionary Computation.\n- Evolutionary Compution Journal\n\nMajor Conference:\n- IEEE Congress On Evolution Computation(CEC)\n- Genetic and Evolution Computation Conference(GECCO)\n- Parallel Problem Solving from Nature(PPSN)\n\nGame:\n\t- Blondie24: Playing at the Edge of AI\n\nBook:\n\t- How to Solve It: Modern Heuristics\n","slug":"Evolutionary-Algorithms","published":1,"updated":"2018-08-19T01:59:35.787Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19owk000744von0qfgscn"},{"title":"Genetic Algorithms","date":"2018-08-05T14:14:07.000Z","_content":"\n## Biology Background\n\n- Gene: A working subunit of DNA\n- Gene Trait(性状基因): For example colour of eyes\n- Allele(等位基因): Possible settings for a trait\n- Genotype(基因型): The actual genes carried by an individual\n- Phenotype(性状型): The physical characteristics into which genes are translated\n\n## Genetic Algorithms\n\nBy John Holland: \"Adaptation in Natural and Artificial Systems\"\n\n### Inspired by and (loosely) based on Darwin's Theory\n\n- Chromosome(染色体)\n- Crossover(交叉)\n- Mutation(变异)\n- Selection(Survival of the Fittest)\n\n### Basic Ideas\n\n- Each solution to the problem is represented as a chromosome.\n- The initial solutions may be randomly generated.\n- Solution are evolved during generations.\n- Improved gradually based on the principle of natural evolution.\n\n### Basic Components\n\n#### Representation\n\n- How to encode the parameters of the problem?\n- Binary Problems\n- Continuous Problems\n\n1. Individual(Chromosome)\n\nA vector that represents a specific solution to the problem.Each element on the vector corresponds to a certain variable/parameter.\n\n2. Population\n\nA set of individuals, GAs maintain and evolve a population of individuals, Parallel Search to get Global Optimization.\n\n3. Offspring\n\nNew individuals generated via genetic operators. Hopefully contain better solutions.\n\n4. Encoding\n\nBinary vs. Gray. How to encode TSP problems?\n\n#### Genetic Operators\n\n1. Crossover:\n\tExchange genetic materials between two chromosomes.\n\t- One Point Crossover\n\t- Two Point Crossover\n\t- Uniform Crossover\n \n2. Mutation:\n\tRandomly modify gene values at selected locations.Mutation is mainly used to maintain the genetiv divesity.Loss of genetic diversity will result in Permature Convergence.\n\n#### Selection Strategy\n\n- Which chromosomes should be involved in reproduction?\n- Which offspring should be able to survive?\n\n1. Roulette Wheel Selection: 根据适应度的高低按比例选择\n2. Rank Selection： 根据排名按固定比例选择\n3. Tournament Selection: 两两及以上互相竞争\n4. Elitism: 精英保留直接拷贝到下一代\n5. Offspring Selection: 子代直接进入下一代还是与父代一起竞争\n\n### Selection vs. Crossover vs. Mutation\n\n- Selection:\n\t- Bias the search effort towards promising individuals.\n\t- Loss of genetic diversity\n\n- Cossover:\n\t- Create better individuals by combining genes from good individuals\n\t- Building Block Hypothesis\n\t- Major search power of GAs\n\t- No effect on genetic diversity\n\n- Mutation:\n\t- Increase genetic diversity\n\t- Force the algorithm to search areas other than the current focus.\n\n**It is a trade off about Exploration vs. Exploitation**\n\n## GA Framework\n\n1. Intialization: Generate a random population P of M individuals\n2. Evaluation: Evaluate the fitness f(x) of each individual\n3. Repeat until the stopping criteria are met:\n\t1. Reproduction: Repeat the following steps until all offspring are generated\n\t\t1. Paraent Selection: Select two parents from P\n\t\t2. Crossover: Apply crossover on the parents with probability P_c\n\t\t3. Mutation: Apply mutation on offspring with probability P_m\n\t\t4. Evaluation: Evaluate the newly generated offspring\n\t2. Offspring Selection: Create a new population from oddspring and P\n\t3. Output: Return the best individual found\n\n## Parameters\n\n- Population Size:\n\tToo big: Slow convergence rate. Too small: Premature convergence\n\n- Crossover Rate:\n\tRecommended value: 0.8\n\n- Mutation Rate:\n\tRecommeded value: 1/L. Too big: Disrupt the evolution process. Too small: Not enough to maintain diversity.\n\n- Selection Strategy:\n\tTournament Selection. Truncation Selection(Select top T individuals). Need to be careful about the selection pressure.\n","source":"_posts/Genetic-Algorithms.md","raw":"---\ntitle: Genetic Algorithms\ndate: 2018-08-05 22:14:07\ntags: 遗传算法\ncategories: 进化计算\n---\n\n## Biology Background\n\n- Gene: A working subunit of DNA\n- Gene Trait(性状基因): For example colour of eyes\n- Allele(等位基因): Possible settings for a trait\n- Genotype(基因型): The actual genes carried by an individual\n- Phenotype(性状型): The physical characteristics into which genes are translated\n\n## Genetic Algorithms\n\nBy John Holland: \"Adaptation in Natural and Artificial Systems\"\n\n### Inspired by and (loosely) based on Darwin's Theory\n\n- Chromosome(染色体)\n- Crossover(交叉)\n- Mutation(变异)\n- Selection(Survival of the Fittest)\n\n### Basic Ideas\n\n- Each solution to the problem is represented as a chromosome.\n- The initial solutions may be randomly generated.\n- Solution are evolved during generations.\n- Improved gradually based on the principle of natural evolution.\n\n### Basic Components\n\n#### Representation\n\n- How to encode the parameters of the problem?\n- Binary Problems\n- Continuous Problems\n\n1. Individual(Chromosome)\n\nA vector that represents a specific solution to the problem.Each element on the vector corresponds to a certain variable/parameter.\n\n2. Population\n\nA set of individuals, GAs maintain and evolve a population of individuals, Parallel Search to get Global Optimization.\n\n3. Offspring\n\nNew individuals generated via genetic operators. Hopefully contain better solutions.\n\n4. Encoding\n\nBinary vs. Gray. How to encode TSP problems?\n\n#### Genetic Operators\n\n1. Crossover:\n\tExchange genetic materials between two chromosomes.\n\t- One Point Crossover\n\t- Two Point Crossover\n\t- Uniform Crossover\n \n2. Mutation:\n\tRandomly modify gene values at selected locations.Mutation is mainly used to maintain the genetiv divesity.Loss of genetic diversity will result in Permature Convergence.\n\n#### Selection Strategy\n\n- Which chromosomes should be involved in reproduction?\n- Which offspring should be able to survive?\n\n1. Roulette Wheel Selection: 根据适应度的高低按比例选择\n2. Rank Selection： 根据排名按固定比例选择\n3. Tournament Selection: 两两及以上互相竞争\n4. Elitism: 精英保留直接拷贝到下一代\n5. Offspring Selection: 子代直接进入下一代还是与父代一起竞争\n\n### Selection vs. Crossover vs. Mutation\n\n- Selection:\n\t- Bias the search effort towards promising individuals.\n\t- Loss of genetic diversity\n\n- Cossover:\n\t- Create better individuals by combining genes from good individuals\n\t- Building Block Hypothesis\n\t- Major search power of GAs\n\t- No effect on genetic diversity\n\n- Mutation:\n\t- Increase genetic diversity\n\t- Force the algorithm to search areas other than the current focus.\n\n**It is a trade off about Exploration vs. Exploitation**\n\n## GA Framework\n\n1. Intialization: Generate a random population P of M individuals\n2. Evaluation: Evaluate the fitness f(x) of each individual\n3. Repeat until the stopping criteria are met:\n\t1. Reproduction: Repeat the following steps until all offspring are generated\n\t\t1. Paraent Selection: Select two parents from P\n\t\t2. Crossover: Apply crossover on the parents with probability P_c\n\t\t3. Mutation: Apply mutation on offspring with probability P_m\n\t\t4. Evaluation: Evaluate the newly generated offspring\n\t2. Offspring Selection: Create a new population from oddspring and P\n\t3. Output: Return the best individual found\n\n## Parameters\n\n- Population Size:\n\tToo big: Slow convergence rate. Too small: Premature convergence\n\n- Crossover Rate:\n\tRecommended value: 0.8\n\n- Mutation Rate:\n\tRecommeded value: 1/L. Too big: Disrupt the evolution process. Too small: Not enough to maintain diversity.\n\n- Selection Strategy:\n\tTournament Selection. Truncation Selection(Select top T individuals). Need to be careful about the selection pressure.\n","slug":"Genetic-Algorithms","published":1,"updated":"2018-08-19T01:59:35.788Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19owp000844vo31q1h3r6"},{"title":"Gradient Descent Famliy","date":"2018-08-07T00:59:26.000Z","mathjax":true,"_content":"## (Batch) Gradient Descent\n\n``` python\nX = data_input\nY = labels\nparameters = initialize_parameters(layers_dims)\nfor i in range(0, num_iterations):\n    # Forward propagation\n    a, caches = forward_propagation(X, parameters)\n    # Compute cost.\n    cost = compute_cost(a, Y)\n    # Backward propagation.\n    grads = backward_propagation(a, caches, parameters)\n    # Update parameters.\n    parameters = update_parameters(parameters, grads)     \n```\n\n## Stochastic Gradient Descent\n\n```python\nX = data_input\nY = labels\nparameters = initialize_parameters(layers_dims)\nfor i in range(0, num_iterations):\n    for j in range(0, m):\n        # Forward propagation\n        a, caches = forward_propagation(X[:,j], parameters)\n        # Compute cost\n        cost = compute_cost(a, Y[:,j])\n        # Backward propagation\n        grads = backward_propagation(a, caches, parameters)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads)\n```\n\n## Mini-Batch Gradient descent\n\n- **Shuffle**:\n\n<img src=\"/images/shuffle.png\" style=\"width:550px;height:300px;\">\n\n- **Partition**:\n\n<img src=\"/images/partition.png\" style=\"width:550px;height:300px;\">\n\nNote that the last mini-batch might end up smaller than `mini_batch_size=64`. Let $\\lfloor s \\rfloor$ represents $s$ rounded down to the nearest integer (this is `math.floor(s)` in Python). If the total number of examples is not a multiple of `mini_batch_size=64` then there will be $\\lfloor \\frac{m}{mini_batch_size}\\rfloor$ mini-batches with a full 64 examples, and the number of examples in the final mini-batch will be ($m-mini_batch_size \\times \\lfloor \\frac{m}{mini_batch_size}\\rfloor$). \n\n```python\ndef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    Arguments:\n    X -- input data, of shape (input size, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    mini_batch_size -- size of the mini-batches, integer\n    \n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    \n    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n    m = X.shape[1]                  # number of training examples\n    mini_batches = []\n        \n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[:, permutation]\n    shuffled_Y = Y[:, permutation].reshape((1,m))\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k+1) * mini_batch_size]\n        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k+1) * mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size: ]\n        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size: ]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    return mini_batches\n```\n\n## Momentum\n\nBecause mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will \"oscillate\" toward convergence. Using momentum can reduce these oscillations. \n\nMomentum takes into account the past gradients to smooth out the update. We will store the 'direction' of the previous gradients in the variable $v$. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of $v$ as the \"velocity\" of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill. \n\n<img src=\"/images/momentum.png\" style=\"width:400px;height:250px;\">\n<caption><center> <u><font color='purple'>**Figure 3**</u><font color='purple'>: The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence $v$ and then take a step in the direction of $v$.<br> <font color='black'> </center>\n\n```python\ndef initialize_velocity(parameters):\n    \"\"\"\n    Initializes the velocity as a python dictionary with:\n                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n    Arguments:\n    parameters -- python dictionary containing your parameters.\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    \n    Returns:\n    v -- python dictionary containing the current velocity.\n                    v['dW' + str(l)] = velocity of dWl\n                    v['db' + str(l)] = velocity of dbl\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks\n    v = {}    \n    # Initialize velocity\n    for l in range(L):\n        v[\"dW\" + str(l+1)] = np.zeros((parameters['W' + str(l+1)].shape[0], parameters['W' + str(l+1)].shape[1]))\n        v[\"db\" + str(l+1)] = np.zeros((parameters['b' + str(l+1)].shape[0], parameters['b' + str(l+1)].shape[1]))\n        \n    return v\n```\n\n$$\\begin{cases}\nv_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]} \\\\\nW^{[l]} = W^{[l]} - \\alpha v_{dW^{[l]}}\n\\end{cases}\\tag{3}$$\n\n$$\\begin{cases}\nv_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]} \\\\\nb^{[l]} = b^{[l]} - \\alpha v_{db^{[l]}} \n\\end{cases}\\tag{4}$$\n\nwhere L is the number of layers, $\\beta$ is the momentum and $\\alpha$ is the learning rate. All parameters should be stored in the `parameters` dictionary.  Note that the iterator `l` starts at 0 in the `for` loop while the first parameters are $W^{[1]}$ and $b^{[1]}$ (that's a \"one\" on the superscript). So you will need to shift `l` to `l+1` when coding.\n\n```python\ndef update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n    \"\"\"\n    Update parameters using Momentum\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters:\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    grads -- python dictionary containing your gradients for each parameters:\n                    grads['dW' + str(l)] = dWl\n                    grads['db' + str(l)] = dbl\n    v -- python dictionary containing the current velocity:\n                    v['dW' + str(l)] = ...\n                    v['db' + str(l)] = ...\n    beta -- the momentum hyperparameter, scalar\n    learning_rate -- the learning rate, scalar\n    \n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    v -- python dictionary containing your updated velocities\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks    \n    # Momentum update for each parameter\n    for l in range(L):        \n        # compute velocities\n        v[\"dW\" + str(l+1)] = beta * v['dW' + str(l+1)] + (1 - beta) * grads['dW' + str(l+1)]\n        v[\"db\" + str(l+1)] = beta * v['db' + str(l+1)] + (1 - beta) * grads['db' + str(l+1)]\n        # update parameters\n        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v[\"dW\" + str(l+1)]\n        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v[\"db\" + str(l+1)]\n    return parameters, v\n```\n\n\n**How do you choose $\\beta$?**\n\n- The larger the momentum $\\beta$ is, the smoother the update because the more we take the past gradients into account. But if $\\beta$ is too big, it could also smooth out the updates too much. \n- Common values for $\\beta$ range from 0.8 to 0.999. If you don't feel inclined to tune this, $\\beta = 0.9$ is often a reasonable default. \n- Tuning the optimal $\\beta$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$. \n\n## Adam\n\nAdam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum. \n\n**How does Adam work?**\n1. It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction). \n2. It calculates an exponentially weighted average of the squares of the past gradients, and  stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction). \n3. It updates parameters in a direction based on combining information from \"1\" and \"2\".\n\nThe update rule is, for $l = 1, ..., L$: \n\n<img src=\"/images/adam.PNG\" style=\"width:550px;height:300px;\">\n\nwhere:\n- t counts the number of steps taken of Adam \n- L is the number of layers\n- $\\beta_1$ and $\\beta_2$ are hyperparameters that control the two exponentially weighted averages. \n- $\\alpha$ is the learning rate\n- $\\varepsilon$ is a very small number to avoid dividing by zero\n\nAs usual, we will store all parameters in the `parameters` dictionary\n\n```python\ndef initialize_adam(parameters) :\n    \"\"\"\n    Initializes v and s as two python dictionaries with:\n                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters.\n                    parameters[\"W\" + str(l)] = Wl\n                    parameters[\"b\" + str(l)] = bl\n    \n    Returns: \n    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n                    v[\"dW\" + str(l)] = ...\n                    v[\"db\" + str(l)] = ...\n    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n                    s[\"dW\" + str(l)] = ...\n                    s[\"db\" + str(l)] = ...\n\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks\n    v = {}\n    s = {}    \n    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n    for l in range(L):\n        v[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0], parameters[\"W\" + str(l+1)].shape[1]))\n        v[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0], parameters[\"b\" + str(l+1)].shape[1]))\n        s[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0], parameters[\"W\" + str(l+1)].shape[1]))\n        s[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0], parameters[\"b\" + str(l+1)].shape[1]))\n    return v, s\n```\n\n```python\ndef update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n    \"\"\"\n    Update parameters using Adam\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters:\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    grads -- python dictionary containing your gradients for each parameters:\n                    grads['dW' + str(l)] = dWl\n                    grads['db' + str(l)] = dbl\n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\n    learning_rate -- the learning rate, scalar.\n    beta1 -- Exponential decay hyperparameter for the first moment estimates \n    beta2 -- Exponential decay hyperparameter for the second moment estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\n    \"\"\"\n    L = len(parameters) // 2                 # number of layers in the neural networks\n    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n    s_corrected = {}                         # Initializing second moment estimate, python dictionary    \n    # Perform Adam update on all parameters\n    for l in range(L):\n        # Moving average of the gradients.\n        v[\"dW\" + str(l+1)] = beta1 * v[\"dW\" + str(l+1)] + (1 - beta1) * grads['dW' + str(l+1)]\n        v[\"db\" + str(l+1)] = beta1 * v[\"db\" + str(l+1)] + (1 - beta1) * grads['db' + str(l+1)]\n        # Compute bias-corrected first moment estimate.\n        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)] / (1 - beta1 ** t)\n        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)] / (1 - beta1 ** t)\n        # Moving average of the squared gradients.\n        s[\"dW\" + str(l+1)] = beta2 * s[\"dW\" + str(l+1)] + (1 - beta2) * (grads['dW' + str(l+1)] ** 2)\n        s[\"db\" + str(l+1)] = beta2 * s[\"db\" + str(l+1)] + (1 - beta2) * (grads['db' + str(l+1)] ** 2)\n        # Compute bias-corrected second raw moment estimate.\n        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)] / (1 - beta2 ** t)\n        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)] / (1 - beta2 ** t)\n        # Update parameters. \n        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v_corrected[\"dW\" + str(l+1)] / (np.sqrt(s_corrected[\"dW\" + str(l+1)]) + epsilon)\n        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v_corrected[\"db\" + str(l+1)] / (np.sqrt(s_corrected[\"db\" + str(l+1)]) + epsilon)\n    return parameters, v, s\n```\n\n## Model with different optimization algorithms\n\n```python\ndef model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9,\n          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 10000, print_cost = True):\n    \"\"\"\n    3-layer neural network model which can be run in different optimizer modes.\n    \n    Arguments:\n    X -- input data, of shape (2, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    layers_dims -- python list, containing the size of each layer\n    learning_rate -- the learning rate, scalar.\n    mini_batch_size -- the size of a mini batch\n    beta -- Momentum hyperparameter\n    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n    num_epochs -- number of epochs\n    print_cost -- True to print the cost every 1000 epochs\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    \"\"\"\n\n    L = len(layers_dims)             # number of layers in the neural networks\n    costs = []                       # to keep track of the cost\n    t = 0                            # initializing the counter required for Adam update\n    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n    \n    # Initialize parameters\n    parameters = initialize_parameters(layers_dims)\n\n    # Initialize the optimizer\n    if optimizer == \"gd\":\n        pass # no initialization required for gradient descent\n    elif optimizer == \"momentum\":\n        v = initialize_velocity(parameters)\n    elif optimizer == \"adam\":\n        v, s = initialize_adam(parameters)\n    \n    # Optimization loop\n    for i in range(num_epochs):\n        \n        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n        seed = seed + 1\n        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n\n        for minibatch in minibatches:\n\n            # Select a minibatch\n            (minibatch_X, minibatch_Y) = minibatch\n\n            # Forward propagation\n            a3, caches = forward_propagation(minibatch_X, parameters)\n\n            # Compute cost\n            cost = compute_cost(a3, minibatch_Y)\n\n            # Backward propagation\n            grads = backward_propagation(minibatch_X, minibatch_Y, caches)\n\n            # Update parameters\n            if optimizer == \"gd\":\n                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n            elif optimizer == \"momentum\":\n                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n            elif optimizer == \"adam\":\n                t = t + 1 # Adam counter\n                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t, learning_rate, beta1, beta2,  epsilon)\n        # Print the cost every 1000 epoch\n        if print_cost and i % 1000 == 0:\n            print (\"Cost after epoch %i: %f\" %(i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)  \n    # plot the cost\n    plt.plot(costs)\n    plt.ylabel('cost')\n    plt.xlabel('epochs (per 100)')\n    plt.title(\"Learning rate = \" + str(learning_rate))\n    plt.show()\n    return parameters\n\ntrain_X, train_Y = load_dataset()\n\n# train 3-layer model\nlayers_dims = [train_X.shape[0], 5, 2, 1]\nparameters = model(train_X, train_Y, layers_dims, optimizer = \"gd\")\n\n# Predict\npredictions = predict(train_X, train_Y, parameters)\n\n# Plot decision boundary\nplt.title(\"Model with Gradient Descent optimization\")\naxes = plt.gca()\naxes.set_xlim([-1.5,2.5])\naxes.set_ylim([-1,1.5])\nplot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)\n```\n## Summary\n\n![](/images/sgd.png)\n![](/images/minibatch.png)\n\n- **The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.**\n- **You have to tune a learning rate hyperparameter $\\alpha$.**\n- **With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).**\n- **Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.**\n\n- **Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.**\n\n- **Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you've seen that Adam converges a lot faster.**\n\n**Some advantages of Adam include:**\n- Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum) \n- Usually works well even with little tuning of hyperparameters (except $\\alpha$)","source":"_posts/Gradient-Descent-Famliy.md","raw":"---\ntitle: Gradient Descent Famliy\ndate: 2018-08-07 08:59:26\ntags: 优化算法\ncategories: 深度学习\nmathjax: true\n---\n## (Batch) Gradient Descent\n\n``` python\nX = data_input\nY = labels\nparameters = initialize_parameters(layers_dims)\nfor i in range(0, num_iterations):\n    # Forward propagation\n    a, caches = forward_propagation(X, parameters)\n    # Compute cost.\n    cost = compute_cost(a, Y)\n    # Backward propagation.\n    grads = backward_propagation(a, caches, parameters)\n    # Update parameters.\n    parameters = update_parameters(parameters, grads)     \n```\n\n## Stochastic Gradient Descent\n\n```python\nX = data_input\nY = labels\nparameters = initialize_parameters(layers_dims)\nfor i in range(0, num_iterations):\n    for j in range(0, m):\n        # Forward propagation\n        a, caches = forward_propagation(X[:,j], parameters)\n        # Compute cost\n        cost = compute_cost(a, Y[:,j])\n        # Backward propagation\n        grads = backward_propagation(a, caches, parameters)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads)\n```\n\n## Mini-Batch Gradient descent\n\n- **Shuffle**:\n\n<img src=\"/images/shuffle.png\" style=\"width:550px;height:300px;\">\n\n- **Partition**:\n\n<img src=\"/images/partition.png\" style=\"width:550px;height:300px;\">\n\nNote that the last mini-batch might end up smaller than `mini_batch_size=64`. Let $\\lfloor s \\rfloor$ represents $s$ rounded down to the nearest integer (this is `math.floor(s)` in Python). If the total number of examples is not a multiple of `mini_batch_size=64` then there will be $\\lfloor \\frac{m}{mini_batch_size}\\rfloor$ mini-batches with a full 64 examples, and the number of examples in the final mini-batch will be ($m-mini_batch_size \\times \\lfloor \\frac{m}{mini_batch_size}\\rfloor$). \n\n```python\ndef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    Arguments:\n    X -- input data, of shape (input size, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    mini_batch_size -- size of the mini-batches, integer\n    \n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    \n    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n    m = X.shape[1]                  # number of training examples\n    mini_batches = []\n        \n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[:, permutation]\n    shuffled_Y = Y[:, permutation].reshape((1,m))\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k+1) * mini_batch_size]\n        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k+1) * mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size: ]\n        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size: ]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    return mini_batches\n```\n\n## Momentum\n\nBecause mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will \"oscillate\" toward convergence. Using momentum can reduce these oscillations. \n\nMomentum takes into account the past gradients to smooth out the update. We will store the 'direction' of the previous gradients in the variable $v$. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of $v$ as the \"velocity\" of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill. \n\n<img src=\"/images/momentum.png\" style=\"width:400px;height:250px;\">\n<caption><center> <u><font color='purple'>**Figure 3**</u><font color='purple'>: The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence $v$ and then take a step in the direction of $v$.<br> <font color='black'> </center>\n\n```python\ndef initialize_velocity(parameters):\n    \"\"\"\n    Initializes the velocity as a python dictionary with:\n                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n    Arguments:\n    parameters -- python dictionary containing your parameters.\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    \n    Returns:\n    v -- python dictionary containing the current velocity.\n                    v['dW' + str(l)] = velocity of dWl\n                    v['db' + str(l)] = velocity of dbl\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks\n    v = {}    \n    # Initialize velocity\n    for l in range(L):\n        v[\"dW\" + str(l+1)] = np.zeros((parameters['W' + str(l+1)].shape[0], parameters['W' + str(l+1)].shape[1]))\n        v[\"db\" + str(l+1)] = np.zeros((parameters['b' + str(l+1)].shape[0], parameters['b' + str(l+1)].shape[1]))\n        \n    return v\n```\n\n$$\\begin{cases}\nv_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]} \\\\\nW^{[l]} = W^{[l]} - \\alpha v_{dW^{[l]}}\n\\end{cases}\\tag{3}$$\n\n$$\\begin{cases}\nv_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]} \\\\\nb^{[l]} = b^{[l]} - \\alpha v_{db^{[l]}} \n\\end{cases}\\tag{4}$$\n\nwhere L is the number of layers, $\\beta$ is the momentum and $\\alpha$ is the learning rate. All parameters should be stored in the `parameters` dictionary.  Note that the iterator `l` starts at 0 in the `for` loop while the first parameters are $W^{[1]}$ and $b^{[1]}$ (that's a \"one\" on the superscript). So you will need to shift `l` to `l+1` when coding.\n\n```python\ndef update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n    \"\"\"\n    Update parameters using Momentum\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters:\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    grads -- python dictionary containing your gradients for each parameters:\n                    grads['dW' + str(l)] = dWl\n                    grads['db' + str(l)] = dbl\n    v -- python dictionary containing the current velocity:\n                    v['dW' + str(l)] = ...\n                    v['db' + str(l)] = ...\n    beta -- the momentum hyperparameter, scalar\n    learning_rate -- the learning rate, scalar\n    \n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    v -- python dictionary containing your updated velocities\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks    \n    # Momentum update for each parameter\n    for l in range(L):        \n        # compute velocities\n        v[\"dW\" + str(l+1)] = beta * v['dW' + str(l+1)] + (1 - beta) * grads['dW' + str(l+1)]\n        v[\"db\" + str(l+1)] = beta * v['db' + str(l+1)] + (1 - beta) * grads['db' + str(l+1)]\n        # update parameters\n        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v[\"dW\" + str(l+1)]\n        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v[\"db\" + str(l+1)]\n    return parameters, v\n```\n\n\n**How do you choose $\\beta$?**\n\n- The larger the momentum $\\beta$ is, the smoother the update because the more we take the past gradients into account. But if $\\beta$ is too big, it could also smooth out the updates too much. \n- Common values for $\\beta$ range from 0.8 to 0.999. If you don't feel inclined to tune this, $\\beta = 0.9$ is often a reasonable default. \n- Tuning the optimal $\\beta$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$. \n\n## Adam\n\nAdam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum. \n\n**How does Adam work?**\n1. It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction). \n2. It calculates an exponentially weighted average of the squares of the past gradients, and  stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction). \n3. It updates parameters in a direction based on combining information from \"1\" and \"2\".\n\nThe update rule is, for $l = 1, ..., L$: \n\n<img src=\"/images/adam.PNG\" style=\"width:550px;height:300px;\">\n\nwhere:\n- t counts the number of steps taken of Adam \n- L is the number of layers\n- $\\beta_1$ and $\\beta_2$ are hyperparameters that control the two exponentially weighted averages. \n- $\\alpha$ is the learning rate\n- $\\varepsilon$ is a very small number to avoid dividing by zero\n\nAs usual, we will store all parameters in the `parameters` dictionary\n\n```python\ndef initialize_adam(parameters) :\n    \"\"\"\n    Initializes v and s as two python dictionaries with:\n                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters.\n                    parameters[\"W\" + str(l)] = Wl\n                    parameters[\"b\" + str(l)] = bl\n    \n    Returns: \n    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n                    v[\"dW\" + str(l)] = ...\n                    v[\"db\" + str(l)] = ...\n    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n                    s[\"dW\" + str(l)] = ...\n                    s[\"db\" + str(l)] = ...\n\n    \"\"\"\n    L = len(parameters) // 2 # number of layers in the neural networks\n    v = {}\n    s = {}    \n    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n    for l in range(L):\n        v[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0], parameters[\"W\" + str(l+1)].shape[1]))\n        v[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0], parameters[\"b\" + str(l+1)].shape[1]))\n        s[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0], parameters[\"W\" + str(l+1)].shape[1]))\n        s[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0], parameters[\"b\" + str(l+1)].shape[1]))\n    return v, s\n```\n\n```python\ndef update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n    \"\"\"\n    Update parameters using Adam\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters:\n                    parameters['W' + str(l)] = Wl\n                    parameters['b' + str(l)] = bl\n    grads -- python dictionary containing your gradients for each parameters:\n                    grads['dW' + str(l)] = dWl\n                    grads['db' + str(l)] = dbl\n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\n    learning_rate -- the learning rate, scalar.\n    beta1 -- Exponential decay hyperparameter for the first moment estimates \n    beta2 -- Exponential decay hyperparameter for the second moment estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\n    \"\"\"\n    L = len(parameters) // 2                 # number of layers in the neural networks\n    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n    s_corrected = {}                         # Initializing second moment estimate, python dictionary    \n    # Perform Adam update on all parameters\n    for l in range(L):\n        # Moving average of the gradients.\n        v[\"dW\" + str(l+1)] = beta1 * v[\"dW\" + str(l+1)] + (1 - beta1) * grads['dW' + str(l+1)]\n        v[\"db\" + str(l+1)] = beta1 * v[\"db\" + str(l+1)] + (1 - beta1) * grads['db' + str(l+1)]\n        # Compute bias-corrected first moment estimate.\n        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)] / (1 - beta1 ** t)\n        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)] / (1 - beta1 ** t)\n        # Moving average of the squared gradients.\n        s[\"dW\" + str(l+1)] = beta2 * s[\"dW\" + str(l+1)] + (1 - beta2) * (grads['dW' + str(l+1)] ** 2)\n        s[\"db\" + str(l+1)] = beta2 * s[\"db\" + str(l+1)] + (1 - beta2) * (grads['db' + str(l+1)] ** 2)\n        # Compute bias-corrected second raw moment estimate.\n        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)] / (1 - beta2 ** t)\n        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)] / (1 - beta2 ** t)\n        # Update parameters. \n        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v_corrected[\"dW\" + str(l+1)] / (np.sqrt(s_corrected[\"dW\" + str(l+1)]) + epsilon)\n        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v_corrected[\"db\" + str(l+1)] / (np.sqrt(s_corrected[\"db\" + str(l+1)]) + epsilon)\n    return parameters, v, s\n```\n\n## Model with different optimization algorithms\n\n```python\ndef model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9,\n          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 10000, print_cost = True):\n    \"\"\"\n    3-layer neural network model which can be run in different optimizer modes.\n    \n    Arguments:\n    X -- input data, of shape (2, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    layers_dims -- python list, containing the size of each layer\n    learning_rate -- the learning rate, scalar.\n    mini_batch_size -- the size of a mini batch\n    beta -- Momentum hyperparameter\n    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n    num_epochs -- number of epochs\n    print_cost -- True to print the cost every 1000 epochs\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    \"\"\"\n\n    L = len(layers_dims)             # number of layers in the neural networks\n    costs = []                       # to keep track of the cost\n    t = 0                            # initializing the counter required for Adam update\n    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n    \n    # Initialize parameters\n    parameters = initialize_parameters(layers_dims)\n\n    # Initialize the optimizer\n    if optimizer == \"gd\":\n        pass # no initialization required for gradient descent\n    elif optimizer == \"momentum\":\n        v = initialize_velocity(parameters)\n    elif optimizer == \"adam\":\n        v, s = initialize_adam(parameters)\n    \n    # Optimization loop\n    for i in range(num_epochs):\n        \n        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n        seed = seed + 1\n        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n\n        for minibatch in minibatches:\n\n            # Select a minibatch\n            (minibatch_X, minibatch_Y) = minibatch\n\n            # Forward propagation\n            a3, caches = forward_propagation(minibatch_X, parameters)\n\n            # Compute cost\n            cost = compute_cost(a3, minibatch_Y)\n\n            # Backward propagation\n            grads = backward_propagation(minibatch_X, minibatch_Y, caches)\n\n            # Update parameters\n            if optimizer == \"gd\":\n                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n            elif optimizer == \"momentum\":\n                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n            elif optimizer == \"adam\":\n                t = t + 1 # Adam counter\n                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t, learning_rate, beta1, beta2,  epsilon)\n        # Print the cost every 1000 epoch\n        if print_cost and i % 1000 == 0:\n            print (\"Cost after epoch %i: %f\" %(i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)  \n    # plot the cost\n    plt.plot(costs)\n    plt.ylabel('cost')\n    plt.xlabel('epochs (per 100)')\n    plt.title(\"Learning rate = \" + str(learning_rate))\n    plt.show()\n    return parameters\n\ntrain_X, train_Y = load_dataset()\n\n# train 3-layer model\nlayers_dims = [train_X.shape[0], 5, 2, 1]\nparameters = model(train_X, train_Y, layers_dims, optimizer = \"gd\")\n\n# Predict\npredictions = predict(train_X, train_Y, parameters)\n\n# Plot decision boundary\nplt.title(\"Model with Gradient Descent optimization\")\naxes = plt.gca()\naxes.set_xlim([-1.5,2.5])\naxes.set_ylim([-1,1.5])\nplot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)\n```\n## Summary\n\n![](/images/sgd.png)\n![](/images/minibatch.png)\n\n- **The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.**\n- **You have to tune a learning rate hyperparameter $\\alpha$.**\n- **With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).**\n- **Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.**\n\n- **Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.**\n\n- **Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you've seen that Adam converges a lot faster.**\n\n**Some advantages of Adam include:**\n- Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum) \n- Usually works well even with little tuning of hyperparameters (except $\\alpha$)","slug":"Gradient-Descent-Famliy","published":1,"updated":"2018-08-19T01:59:35.789Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19owv000c44vok75ao4za"},{"title":"How to set up a blog with hexo on github.io","date":"2018-07-18T10:17:31.000Z","_content":"### Install Git (https://git-scm.com/)\n\n* If you have a git, you can check it by `git -v`\n\n### Install node.js envornment \n\n* Download from [https://nodejs.org/en/](https://nodejs.org/en/)\n* Install as the default(make sure the envorment path is collected)\n* When you finsh, you can check it by `node -v`\n\n###  Make a new repository named \"<your_username>.github.io\"\n\n### Install Hexo\n\n* `npm install hexo-cli -g`\n* `hexo init blog`(that folder you wanted to store your webpage)\n* `cd blog`\n* `npm install`\n* `hexo server`\n\n### Connect hexo with github\n\n* `cd blog`\n* `git config --global user.name \"<your_username>\"`\n* `git config --global user.email \"<your_email>\"`\n\nCheck if you have a ssh keygen. If not you can do as following\n\n* `cd ~/.ssh`\n* generate key: `ssh-kengen -t rsa -C \"<your_email>\"` (choice default setting)\n* add key to ssh-agent: `eval \"$(ssh-agent -s)\"`\n* `ssh-add ~/.ssh/id_rsa`\n\n### Sign in the github, in settings, add a new ssh key, copy the `id_rsa.pub` to key options. check if it's ok by `ssh -T git@github.com`. If you get a hi message, it is ok.\n\n### In your blog folder, edit the _config.yml file like this.\n\n```\n(in the end)\ndeploy:\n    type: git\n    repository: git@github.com:<your_username>/<your_username>.github.io.git\n    branch: master\n```\n\n### Before deploy the blog website, you should install a plug\n\n* `cd blog`\n* `npm install hexo-deployer-git --save`\n\n### Run it online.\n\n* `hexo clean`\n* `hexo g`\n* `hexo d`\n\n","source":"_posts/How-to-set-up-a-blog-with-hexo-on-github-io.md","raw":"---\ntitle: How to set up a blog with hexo on github.io\ndate: 2018-07-18 18:17:31\ntags: hexo\ncategories: web\n---\n### Install Git (https://git-scm.com/)\n\n* If you have a git, you can check it by `git -v`\n\n### Install node.js envornment \n\n* Download from [https://nodejs.org/en/](https://nodejs.org/en/)\n* Install as the default(make sure the envorment path is collected)\n* When you finsh, you can check it by `node -v`\n\n###  Make a new repository named \"<your_username>.github.io\"\n\n### Install Hexo\n\n* `npm install hexo-cli -g`\n* `hexo init blog`(that folder you wanted to store your webpage)\n* `cd blog`\n* `npm install`\n* `hexo server`\n\n### Connect hexo with github\n\n* `cd blog`\n* `git config --global user.name \"<your_username>\"`\n* `git config --global user.email \"<your_email>\"`\n\nCheck if you have a ssh keygen. If not you can do as following\n\n* `cd ~/.ssh`\n* generate key: `ssh-kengen -t rsa -C \"<your_email>\"` (choice default setting)\n* add key to ssh-agent: `eval \"$(ssh-agent -s)\"`\n* `ssh-add ~/.ssh/id_rsa`\n\n### Sign in the github, in settings, add a new ssh key, copy the `id_rsa.pub` to key options. check if it's ok by `ssh -T git@github.com`. If you get a hi message, it is ok.\n\n### In your blog folder, edit the _config.yml file like this.\n\n```\n(in the end)\ndeploy:\n    type: git\n    repository: git@github.com:<your_username>/<your_username>.github.io.git\n    branch: master\n```\n\n### Before deploy the blog website, you should install a plug\n\n* `cd blog`\n* `npm install hexo-deployer-git --save`\n\n### Run it online.\n\n* `hexo clean`\n* `hexo g`\n* `hexo d`\n\n","slug":"How-to-set-up-a-blog-with-hexo-on-github-io","published":1,"updated":"2018-08-19T01:59:35.790Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19owy000d44vo2ekzhm18"},{"title":"ImageNet Classification wih Deep Convolutional Neural Network","date":"2018-08-28T07:07:25.000Z","mathjax":true,"_content":"这是一篇由Alex Krizhevsky, Ilya Sutskever, Geoffrey E.Hinton发表在NIPS上的[Paper](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。该论文中提出了一种新型网络架构即 **AlexNet**.\n\n## AlexNet\n\nAlexNet首次在大规模图像数据集实现了深层卷积神经网络结构，点燃了深度学习应用在计算机视觉领域的这把火。其在 *ImageNet LSVRC-2012* $^{[1]}$ 目标识别竞赛的 *top-5 error* $^{[2]}$ 为15.3%，同期第二名仅为26.2%，碾压其他传统的hand-craft 特征方法，使得计算机视觉从业者从繁重的特征工程中解脱出来，转向思考能够从数据中自动提取需要的特征，做到数据驱动。\n\n### 数据集\n\n对原始高清图像进行下采样得到固定的256\\*256的图像。具体方法是，给一个矩形图像，先调整短边长度为256然后裁剪出中间部分256\\*256的图片。最后按RGB像素值减去训练集中所有图像的均值图像像素。\n\n### 架构\n\n![](/images/alexnet_architecture.PNG)\n\n第二、第四和第五卷积层的内核只连接到位于同一GPU上的前一层内核映射。第三个卷积层的内核连接到第二层的所有内核映射。完全连接层的神经元与前一层的所有神经元连接。局部响应归一化接在第一，第二个卷积层后面。最大池化层跟随着局部响应层和第五个卷积层。\n\n#### ReLU Nonlinearity\n\n标准的神经元模型输出是sigmoid, tanh这些的函数。用梯度下降训练时在训练时间上，这些饱和非线性函数比非饱和非线性函数需要的时间要多得多。相比于tanh单元，深度卷积网络使用ReLU训练得更快。\n\n#### 在多个GPU上训练\n\n当前的gpu特别适合于cross-gpu并行化，因为它们能够直接从彼此的内存中读取和写入，而无需通过主机内存。并行化方案实际上是将一半的内核(或神经元)放在每个GPU上，还有一个额外的技巧:GPU只在特定层进行通信。这个方案使top-1和top-5的错误率分别降低了1.7%和1.2%。\n\n#### 局部响应归一化\n\n$$b^{i}\\_{x, y} = a^{i}\\_{x, y} / (k + \\alpha \\sum_{j = max(0, i - n/2)}^{min(N - 1, i + n/2)} (a^{i}_{x, y})^2)^{\\beta}$$\n\n$a^{i}\\_{x, y}$ 是应用卷积(包括非线性单元)操作后第i个通道位于(x, y)的值, $b^{i}\\_{x, y}$ 是应用局部响应归一化后的同一位置上值。常数$k, n, \\alpha, \\beta$ 是超参数。这里设置为$k = 2, n = 5, \\alpha=10^{-4}, \\beta=0.75$\n\n来源于生物学上的概念: **侧抑制**, 指被激化的神经元抑制相邻神经元的现象。这使得响应比较大的值相对更大，提高了模型的泛化能力。这个方案使top-1和top-5的错误率分别降低了1.4%和1.2%。\n\n#### 重叠池化\n\nCNNs中的池化层汇总了同一核映射中相邻神经元群的输出。传统的池化，相邻池单元不会重叠，即步长$s=z$ 池化单元大小。如果$s < z$则得到重叠的池化。在整个网络中使用$s = 2, z=3$。这个方案使top-1和top-5的错误率分别降低了0.4%和0.3%。\n\n### 降低过拟合\n\n#### 数据增强\n\n关于图像数据最简单也最常用的降低过拟合的方法是通过保留标签对图像进行简单变换的方法人为地扩大数据集。\n\n第一种形式是：将图像进行水平翻转。通过从256\\*256的图像中随机抽取227\\*227的块，还有它们的水平翻转，用这些图像去训练网络。在测试时，通过抽取测试图像的四个角落和中间227\\*227的块，以及它们的水平翻转，一共10个块来输入进网络，最后以它们的平均值作为预测结果。\n\n第二种形式是：改变RGB通道的强度。具体来说，在整个训练集中对RGB像素值集执行PCA。对于每个训练图像，添加已找到的主成分的倍数。与对应的特征值成正比的大小乘以均值为0和标准差为0.1的高斯随机变量。\n\n对每个像素值 $I\\_{xy} = [I^{R}\\_{xy}, I^{G}\\_{xy}, I^{B}\\_{xy}]^T$ 加上以下数量：\n$$[p_1, p_2, p_3][\\alpha_1 \\lambda_1, \\alpha_2 \\lambda_2, \\alpha_3 \\lambda_3]^T$$\n$p_i, \\lambda_i$ 分别是RGB像素协方差矩阵的第i个特征向量和特征值, $\\alpha_i$ 是随机变量，每个 $\\alpha_i$ 只一个训练图像的一个像素。这个方案使top-1降低了1%。\n\n#### Dropout\n\n以一定概率使神经元的输出置为0。这种技术减少了神经元复杂的协同适应，因为神经元不能依赖于特定的其他神经元的存在。因此，它不得不学习更健壮的特性，这些特性与其他神经元的许多不同随机子集一起使用。\n\n### 注解\n\n[1]: ImageNet数据集大约包含2.2万种不同种类的1500万张高清图像。年度的图像识别竞赛**the ImageNet Large-Scale Visual Recognition Challenge\n(ILSVRC)** 从2010开始举行。 ILSVRC 使用大约1000种类每类1000张图片的数据集。\n\n[2]: the top-5 错误率是：测试图像的预测结果前五位不包含真实标签的比例。\n\n[3]: The model result in ILSVRC-2010\n\n![](/images/alexnet_ilsvrc.PNG)\n","source":"_posts/ImageNet-Classification-wih-Deep-Convolutional-Neural-Network.md","raw":"---\ntitle: ImageNet Classification wih Deep Convolutional Neural Network\ndate: 2018-08-28 15:07:25\ntags: CNN\ncategories: 深度学习\nmathjax: true\n---\n这是一篇由Alex Krizhevsky, Ilya Sutskever, Geoffrey E.Hinton发表在NIPS上的[Paper](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。该论文中提出了一种新型网络架构即 **AlexNet**.\n\n## AlexNet\n\nAlexNet首次在大规模图像数据集实现了深层卷积神经网络结构，点燃了深度学习应用在计算机视觉领域的这把火。其在 *ImageNet LSVRC-2012* $^{[1]}$ 目标识别竞赛的 *top-5 error* $^{[2]}$ 为15.3%，同期第二名仅为26.2%，碾压其他传统的hand-craft 特征方法，使得计算机视觉从业者从繁重的特征工程中解脱出来，转向思考能够从数据中自动提取需要的特征，做到数据驱动。\n\n### 数据集\n\n对原始高清图像进行下采样得到固定的256\\*256的图像。具体方法是，给一个矩形图像，先调整短边长度为256然后裁剪出中间部分256\\*256的图片。最后按RGB像素值减去训练集中所有图像的均值图像像素。\n\n### 架构\n\n![](/images/alexnet_architecture.PNG)\n\n第二、第四和第五卷积层的内核只连接到位于同一GPU上的前一层内核映射。第三个卷积层的内核连接到第二层的所有内核映射。完全连接层的神经元与前一层的所有神经元连接。局部响应归一化接在第一，第二个卷积层后面。最大池化层跟随着局部响应层和第五个卷积层。\n\n#### ReLU Nonlinearity\n\n标准的神经元模型输出是sigmoid, tanh这些的函数。用梯度下降训练时在训练时间上，这些饱和非线性函数比非饱和非线性函数需要的时间要多得多。相比于tanh单元，深度卷积网络使用ReLU训练得更快。\n\n#### 在多个GPU上训练\n\n当前的gpu特别适合于cross-gpu并行化，因为它们能够直接从彼此的内存中读取和写入，而无需通过主机内存。并行化方案实际上是将一半的内核(或神经元)放在每个GPU上，还有一个额外的技巧:GPU只在特定层进行通信。这个方案使top-1和top-5的错误率分别降低了1.7%和1.2%。\n\n#### 局部响应归一化\n\n$$b^{i}\\_{x, y} = a^{i}\\_{x, y} / (k + \\alpha \\sum_{j = max(0, i - n/2)}^{min(N - 1, i + n/2)} (a^{i}_{x, y})^2)^{\\beta}$$\n\n$a^{i}\\_{x, y}$ 是应用卷积(包括非线性单元)操作后第i个通道位于(x, y)的值, $b^{i}\\_{x, y}$ 是应用局部响应归一化后的同一位置上值。常数$k, n, \\alpha, \\beta$ 是超参数。这里设置为$k = 2, n = 5, \\alpha=10^{-4}, \\beta=0.75$\n\n来源于生物学上的概念: **侧抑制**, 指被激化的神经元抑制相邻神经元的现象。这使得响应比较大的值相对更大，提高了模型的泛化能力。这个方案使top-1和top-5的错误率分别降低了1.4%和1.2%。\n\n#### 重叠池化\n\nCNNs中的池化层汇总了同一核映射中相邻神经元群的输出。传统的池化，相邻池单元不会重叠，即步长$s=z$ 池化单元大小。如果$s < z$则得到重叠的池化。在整个网络中使用$s = 2, z=3$。这个方案使top-1和top-5的错误率分别降低了0.4%和0.3%。\n\n### 降低过拟合\n\n#### 数据增强\n\n关于图像数据最简单也最常用的降低过拟合的方法是通过保留标签对图像进行简单变换的方法人为地扩大数据集。\n\n第一种形式是：将图像进行水平翻转。通过从256\\*256的图像中随机抽取227\\*227的块，还有它们的水平翻转，用这些图像去训练网络。在测试时，通过抽取测试图像的四个角落和中间227\\*227的块，以及它们的水平翻转，一共10个块来输入进网络，最后以它们的平均值作为预测结果。\n\n第二种形式是：改变RGB通道的强度。具体来说，在整个训练集中对RGB像素值集执行PCA。对于每个训练图像，添加已找到的主成分的倍数。与对应的特征值成正比的大小乘以均值为0和标准差为0.1的高斯随机变量。\n\n对每个像素值 $I\\_{xy} = [I^{R}\\_{xy}, I^{G}\\_{xy}, I^{B}\\_{xy}]^T$ 加上以下数量：\n$$[p_1, p_2, p_3][\\alpha_1 \\lambda_1, \\alpha_2 \\lambda_2, \\alpha_3 \\lambda_3]^T$$\n$p_i, \\lambda_i$ 分别是RGB像素协方差矩阵的第i个特征向量和特征值, $\\alpha_i$ 是随机变量，每个 $\\alpha_i$ 只一个训练图像的一个像素。这个方案使top-1降低了1%。\n\n#### Dropout\n\n以一定概率使神经元的输出置为0。这种技术减少了神经元复杂的协同适应，因为神经元不能依赖于特定的其他神经元的存在。因此，它不得不学习更健壮的特性，这些特性与其他神经元的许多不同随机子集一起使用。\n\n### 注解\n\n[1]: ImageNet数据集大约包含2.2万种不同种类的1500万张高清图像。年度的图像识别竞赛**the ImageNet Large-Scale Visual Recognition Challenge\n(ILSVRC)** 从2010开始举行。 ILSVRC 使用大约1000种类每类1000张图片的数据集。\n\n[2]: the top-5 错误率是：测试图像的预测结果前五位不包含真实标签的比例。\n\n[3]: The model result in ILSVRC-2010\n\n![](/images/alexnet_ilsvrc.PNG)\n","slug":"ImageNet-Classification-wih-Deep-Convolutional-Neural-Network","published":1,"updated":"2018-08-28T07:25:42.186Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ox9000h44voba7cemgi"},{"title":"Linear Models for Regression","date":"2018-09-21T12:10:45.000Z","mathjax":true,"_content":"## 1. Linear Basis Function Models\n\n对于回归任务最简单的线性模型是：输入变量的线性组合。\n$$y(\\vec x, \\vec w) = w_0+ w_1x_1 + ... + w_Dx_D \\tag{3.1}$$\n这就是我们所说的线性回归。\n\n这个模型既是参数的线性函数也是输入的线性函数，然而这会带来很多限制。因此我们对输入变量进行一个非线性处理。\n$$y(\\vec x, \\vec w) = w_0 + \\sum_{j=1}^{M-1}w_j\\phi_j(\\vec x) = \\sum_{j=0}^{M-1}w_j\\phi_j(\\vec x) = \\vec w^T \\phi(\\vec x) \\tag{3.2}$$\n这里的 $\\phi_j(\\vec x)$ 就是所说 **基函数（basis function）** , 其中 $\\phi_0(\\vec x) = 1$, 注意 $\\vec w, \\vec \\phi$ 均为列向量。\n\n在一些实际的模式识别应用中，我们将会对原始输入变量应用一些形式的预处理或者特征提取，例如这里的 $\\{\\phi_j(\\vec x)\\}$。\n\n基函数的选择有很多种形式，比如：\n\n$$\\phi_j(x) = exp\\{-\\frac{(x - \\mu_j)^2}{2s^2}\\} \\tag{3.3}$$\n$\\mu_j$ 决定了基函数在输入空间的位置，$s$决定了空间的范围. 但这些参数都不是重要的，因为它们还要乘以一个自适应的系数 $w_j$.\n\n$$\\phi_j = \\sigma(\\frac{x- \\mu_j}{s}) \\tag{3.4}\\\\ \\sigma(a) = \\frac{1}{1 + exp(-a)}$$\n\n除此之外还有傅里叶基函数，比如对sin函数的扩展。每一个基函数表示一个具体的频率，并且在空间上是无限的。相对地，被限定在有限的输入空间上的基函数由多个频率组合而成。在信号处理领域，考虑在空间和频率上都是有限的基函数是很有用的，它们被称为 **小波(waveles)**。\n\n### 1.1 Maximum likelihood and least squares\n\n我们假设目标变量t由下式得到\n$$t = y(\\vec x, \\vec w) + \\epsilon \\tag{3.5}$$\n$\\epsilon$ 是一个零均值的高斯随机变量，其精度为 $\\beta = \\frac{1}{\\sigma ^2}$\n因此\n$$p(t|\\vec x, \\vec w, \\beta) = \\mathcal N(t|y(\\vec x, \\vec w), \\beta^{-1}) \\tag{3.6}$$\n\n如果我们的损失函数是平方损失，那么最优的预测就是目标变量的条件期望。在（3.6）式的高斯条件分布下，它的条件期望为\n$$\\mathbb E[t|\\vec x] = \\int tp(t|\\vec x)dt = y(\\vec x, \\vec w) \\tag{3.7}$$\n注意，高斯噪声这样的假设暗示着给定x下t的条件期望是单峰的，这可能在一些应用上不适用。\n\n现在假设我们由N个观察到的输入数据 $\\mathbf X = \\{\\vec x_1, ..., \\vec x_N\\}$ 相对应的目标值是 $t_1, ..., t_N$. 这里把（3.6）写成矩阵形式得到的似然函数为：\n$$p(t|\\mathbf x, \\vec w, \\beta) = \\prod_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1}) \\tag{3.8}$$\n\n注意在监督学习问题中（分类和回归），我们并不要求对输入变量的分布建模。因此x可能不会出现在条件变量上。例如 $p(t|\\vec w, \\beta)$\n\n对式（3.8）取对数有：\n$$\\ln p(t|w, \\beta) = \\sum_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1})\\\\= \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln(2\\pi) - \\beta E_D(\\vec w) \\tag{3.8}$$\n\n这里平方和误差为\n$$E_D(\\vec w) = \\frac{1}{2} \\sum_{n=1}^{N} \\{t_n - \\vec w^T \\phi(\\vec x_n)\\}^2 \\tag{3.9}$$\n\n最大化似然函数可通过对似然函数求导：\n$$\\frac{\\partial \\ln p(\\vec t |\\vec w, \\beta)}{\\partial \\vec w} = \\sum_{n=1}^{N} \\{t_n - \\vec w^T \\phi(\\vec x_n)\\} \\phi(\\vec x_n)^T \\tag{3.10}$$\n\n令导数为0得到：\n$$\\vec w_{ML} = (\\Phi ^T \\Phi)^{-1} \\Phi ^T \\vec t \\tag{3.11}$$\n这个方程被称为 **正则方程(normal equations)** .\n\n$$\\Phi = \\left [ \\begin{matrix} \\phi_0(\\vec x_1) & \\phi_1(\\vec x_1) ... \\phi_{M-1}(\\vec x_1)\\\\\\phi_0(\\vec x_2) & \\phi_1(\\vec x_2) ... \\phi_{M-1}(\\vec x_2)\\\\... & ...\\\\\\phi_0(\\vec x_N) & \\phi_1(\\vec x_N) ... \\phi_{M-1}(\\vec x_N)\\end{matrix}\\right] \\tag{3.12}$$\n\n$\\Phi ^+ = ((\\Phi ^T \\Phi)^{-1} \\Phi ^T)$ 被称为矩阵 $\\Phi$ 的 **Moor-Penrose pseudo-inverse**\n\n同样我们也能得到 $\\beta$ 的最大似然估计量。\n$$\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}\\{t_n - \\vec w_{ML}^T \\phi(\\vec x_n)\\}^2$$\n\n### 1.2 Geometry of least squares\n\n考虑这样一个N维空间，其以$t_n$为坐标轴，因此 $\\vec t = (t_1, ..., t_N)^T$ 是该空间的一个向量。在N个数据上的每一个基函数 $\\phi_j(\\vec x_n)$ 也能表示为相同空间中的向量。我们定义 $\\vec y$ 是一个N维向量，它的第n个元素是 $y(\\vec x_n, \\vec w)$. 由于 $\\vec y$ 是 $\\phi_j(\\vec x_n)$ 在M维空间的任意线性组合。误差平方和等价于 $\\vec y$和 $t$ 之间的欧几里得距离。 因此最小二乘解就是选择在子空间中最接近 $\\vec t$的 $\\vec y$.\n","source":"_posts/Linear-Models-for-Regression.md","raw":"---\ntitle: Linear Models for Regression\ndate: 2018-09-21 20:10:45\ntags: 回归\ncategories: 机器学习\nmathjax: true\n---\n## 1. Linear Basis Function Models\n\n对于回归任务最简单的线性模型是：输入变量的线性组合。\n$$y(\\vec x, \\vec w) = w_0+ w_1x_1 + ... + w_Dx_D \\tag{3.1}$$\n这就是我们所说的线性回归。\n\n这个模型既是参数的线性函数也是输入的线性函数，然而这会带来很多限制。因此我们对输入变量进行一个非线性处理。\n$$y(\\vec x, \\vec w) = w_0 + \\sum_{j=1}^{M-1}w_j\\phi_j(\\vec x) = \\sum_{j=0}^{M-1}w_j\\phi_j(\\vec x) = \\vec w^T \\phi(\\vec x) \\tag{3.2}$$\n这里的 $\\phi_j(\\vec x)$ 就是所说 **基函数（basis function）** , 其中 $\\phi_0(\\vec x) = 1$, 注意 $\\vec w, \\vec \\phi$ 均为列向量。\n\n在一些实际的模式识别应用中，我们将会对原始输入变量应用一些形式的预处理或者特征提取，例如这里的 $\\{\\phi_j(\\vec x)\\}$。\n\n基函数的选择有很多种形式，比如：\n\n$$\\phi_j(x) = exp\\{-\\frac{(x - \\mu_j)^2}{2s^2}\\} \\tag{3.3}$$\n$\\mu_j$ 决定了基函数在输入空间的位置，$s$决定了空间的范围. 但这些参数都不是重要的，因为它们还要乘以一个自适应的系数 $w_j$.\n\n$$\\phi_j = \\sigma(\\frac{x- \\mu_j}{s}) \\tag{3.4}\\\\ \\sigma(a) = \\frac{1}{1 + exp(-a)}$$\n\n除此之外还有傅里叶基函数，比如对sin函数的扩展。每一个基函数表示一个具体的频率，并且在空间上是无限的。相对地，被限定在有限的输入空间上的基函数由多个频率组合而成。在信号处理领域，考虑在空间和频率上都是有限的基函数是很有用的，它们被称为 **小波(waveles)**。\n\n### 1.1 Maximum likelihood and least squares\n\n我们假设目标变量t由下式得到\n$$t = y(\\vec x, \\vec w) + \\epsilon \\tag{3.5}$$\n$\\epsilon$ 是一个零均值的高斯随机变量，其精度为 $\\beta = \\frac{1}{\\sigma ^2}$\n因此\n$$p(t|\\vec x, \\vec w, \\beta) = \\mathcal N(t|y(\\vec x, \\vec w), \\beta^{-1}) \\tag{3.6}$$\n\n如果我们的损失函数是平方损失，那么最优的预测就是目标变量的条件期望。在（3.6）式的高斯条件分布下，它的条件期望为\n$$\\mathbb E[t|\\vec x] = \\int tp(t|\\vec x)dt = y(\\vec x, \\vec w) \\tag{3.7}$$\n注意，高斯噪声这样的假设暗示着给定x下t的条件期望是单峰的，这可能在一些应用上不适用。\n\n现在假设我们由N个观察到的输入数据 $\\mathbf X = \\{\\vec x_1, ..., \\vec x_N\\}$ 相对应的目标值是 $t_1, ..., t_N$. 这里把（3.6）写成矩阵形式得到的似然函数为：\n$$p(t|\\mathbf x, \\vec w, \\beta) = \\prod_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1}) \\tag{3.8}$$\n\n注意在监督学习问题中（分类和回归），我们并不要求对输入变量的分布建模。因此x可能不会出现在条件变量上。例如 $p(t|\\vec w, \\beta)$\n\n对式（3.8）取对数有：\n$$\\ln p(t|w, \\beta) = \\sum_{n=1}^{N}\\mathcal N(t_n|\\vec W^T \\phi(\\vec x_n), \\beta^{-1})\\\\= \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln(2\\pi) - \\beta E_D(\\vec w) \\tag{3.8}$$\n\n这里平方和误差为\n$$E_D(\\vec w) = \\frac{1}{2} \\sum_{n=1}^{N} \\{t_n - \\vec w^T \\phi(\\vec x_n)\\}^2 \\tag{3.9}$$\n\n最大化似然函数可通过对似然函数求导：\n$$\\frac{\\partial \\ln p(\\vec t |\\vec w, \\beta)}{\\partial \\vec w} = \\sum_{n=1}^{N} \\{t_n - \\vec w^T \\phi(\\vec x_n)\\} \\phi(\\vec x_n)^T \\tag{3.10}$$\n\n令导数为0得到：\n$$\\vec w_{ML} = (\\Phi ^T \\Phi)^{-1} \\Phi ^T \\vec t \\tag{3.11}$$\n这个方程被称为 **正则方程(normal equations)** .\n\n$$\\Phi = \\left [ \\begin{matrix} \\phi_0(\\vec x_1) & \\phi_1(\\vec x_1) ... \\phi_{M-1}(\\vec x_1)\\\\\\phi_0(\\vec x_2) & \\phi_1(\\vec x_2) ... \\phi_{M-1}(\\vec x_2)\\\\... & ...\\\\\\phi_0(\\vec x_N) & \\phi_1(\\vec x_N) ... \\phi_{M-1}(\\vec x_N)\\end{matrix}\\right] \\tag{3.12}$$\n\n$\\Phi ^+ = ((\\Phi ^T \\Phi)^{-1} \\Phi ^T)$ 被称为矩阵 $\\Phi$ 的 **Moor-Penrose pseudo-inverse**\n\n同样我们也能得到 $\\beta$ 的最大似然估计量。\n$$\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}\\{t_n - \\vec w_{ML}^T \\phi(\\vec x_n)\\}^2$$\n\n### 1.2 Geometry of least squares\n\n考虑这样一个N维空间，其以$t_n$为坐标轴，因此 $\\vec t = (t_1, ..., t_N)^T$ 是该空间的一个向量。在N个数据上的每一个基函数 $\\phi_j(\\vec x_n)$ 也能表示为相同空间中的向量。我们定义 $\\vec y$ 是一个N维向量，它的第n个元素是 $y(\\vec x_n, \\vec w)$. 由于 $\\vec y$ 是 $\\phi_j(\\vec x_n)$ 在M维空间的任意线性组合。误差平方和等价于 $\\vec y$和 $t$ 之间的欧几里得距离。 因此最小二乘解就是选择在子空间中最接近 $\\vec t$的 $\\vec y$.\n","slug":"Linear-Models-for-Regression","published":1,"updated":"2018-09-22T05:16:06.271Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oxe000j44voo24ekut5"},{"title":"MNIST数据集","date":"2018-09-04T13:21:44.000Z","_content":"### [MNIST](http://yann.lecun.com/exdb/mnist/)\n\nThe MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n\n### Tensorflow `v1.10` API\n\n```python\nmnist = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n# type(mnist) is Tuple of Numpy arrays:\n# `(x_train, y_train), (x_test, y_test)`.\n(x_train, y_train), (x_test, y_test) = mnist\nx_train.shape == (60000, 28, 28)\nx_test.shape == (10000, 28, 28)\ny_train.shape == (60000,)\ny_test.shape == (10000,)\n# x_train[0, :, :] (0, 255) uint8\n# y_train[0] (0, 10) uint8\n\n# show the pic\nfrom PIL import Image\nim = Image.fromarray(x_train[0,:,:])\nim.show()\n```\n\nOther Low-level API\n```python\nfrom tensorflow.examples.tutorials.mnist import input_data\n# Or use following import method\n# from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\nmnist = input_data.read_data_sets('./mnist/', one_hot=True)\nmnist.train.images.shape == (55000, 784) # normalized to (0, 1) float32\nmnist.test.images.shape == (10000, 784)\nmnist.train.labels.shape == (55000, 10) # one_hot vector\n# if one_hot is False(default) the axis 1 will be removed and label is (0, 10)\nmnist.test.labels.shape == (10000, 10)\nmnist.validation.images.shape == (5000, 784)\nmnist.validation.labels.shape == (5000, 10)\n\nx, y = mnist.train.next_batch(batch_size)\n# x.shape == (batch_size, 784)\n# y.shape == (batch_size, 10)\n```\n\n### scikit-learn\n\n```python\n#sklearn.datasets.fetch_mldata(dataname, target_name=’label’, data_name=’data’, transpose_data=True, data_home=None)\n# Fetch an mldata.org data set\n\nfrom sklearn.datasets import fetch_mldata\nmnist = fetch_mldata('MNIST original', data_home='./')\n# you should put the mnist_original.mat in ./mldata\n\nmnist.data.shape == (70000, 784) # scalar (0, 255) uint8\nmnist.target.shape == (70000,) # scalar (0, 10) with increasing order\n```\n\n[mldata.org](ml.data.org) a machine learning data set repository\n","source":"_posts/MNIST数据集.md","raw":"---\ntitle: MNIST数据集\ndate: 2018-09-04 21:21:44\ntags: 数据集\ncategories: 深度学习\n---\n### [MNIST](http://yann.lecun.com/exdb/mnist/)\n\nThe MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n\n### Tensorflow `v1.10` API\n\n```python\nmnist = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n# type(mnist) is Tuple of Numpy arrays:\n# `(x_train, y_train), (x_test, y_test)`.\n(x_train, y_train), (x_test, y_test) = mnist\nx_train.shape == (60000, 28, 28)\nx_test.shape == (10000, 28, 28)\ny_train.shape == (60000,)\ny_test.shape == (10000,)\n# x_train[0, :, :] (0, 255) uint8\n# y_train[0] (0, 10) uint8\n\n# show the pic\nfrom PIL import Image\nim = Image.fromarray(x_train[0,:,:])\nim.show()\n```\n\nOther Low-level API\n```python\nfrom tensorflow.examples.tutorials.mnist import input_data\n# Or use following import method\n# from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\nmnist = input_data.read_data_sets('./mnist/', one_hot=True)\nmnist.train.images.shape == (55000, 784) # normalized to (0, 1) float32\nmnist.test.images.shape == (10000, 784)\nmnist.train.labels.shape == (55000, 10) # one_hot vector\n# if one_hot is False(default) the axis 1 will be removed and label is (0, 10)\nmnist.test.labels.shape == (10000, 10)\nmnist.validation.images.shape == (5000, 784)\nmnist.validation.labels.shape == (5000, 10)\n\nx, y = mnist.train.next_batch(batch_size)\n# x.shape == (batch_size, 784)\n# y.shape == (batch_size, 10)\n```\n\n### scikit-learn\n\n```python\n#sklearn.datasets.fetch_mldata(dataname, target_name=’label’, data_name=’data’, transpose_data=True, data_home=None)\n# Fetch an mldata.org data set\n\nfrom sklearn.datasets import fetch_mldata\nmnist = fetch_mldata('MNIST original', data_home='./')\n# you should put the mnist_original.mat in ./mldata\n\nmnist.data.shape == (70000, 784) # scalar (0, 255) uint8\nmnist.target.shape == (70000,) # scalar (0, 10) with increasing order\n```\n\n[mldata.org](ml.data.org) a machine learning data set repository\n","slug":"MNIST数据集","published":1,"updated":"2018-09-07T10:13:39.495Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oxn000n44vom138wkku"},{"title":"Permutation generate","date":"2018-09-04T01:49:58.000Z","_content":"\n### Permutation\n\nIn mathematics, the notion of permutation relates to the act of arranging all the members of a set into some sequence or order, or if the set is already ordered, rearranging (reordering) its elements, a process called permuting. These differ from combinations, which are selections of some members of a set where order is disregarded.\n\n### Algorithms to generate permutations\n\n#### Random generation of permutations\n\nThe **Fisher–Yates shuffle** is an algorithm for generating a random permutation of a finite sequence—in plain terms, the algorithm shuffles the sequence. The algorithm effectively puts all the elements into a hat; it continually determines the next element by randomly drawing an element from the hat until no elements remain. The algorithm produces an unbiased permutation: every permutation is equally likely.\n\nThe basic method given for generating a random permutation of the numbers 1 through N goes as follows:\n\n```python\n# 1. Write down the numbers from 1 through N.\n# 2. Pick a random number k between one and the number of unstruck numbers remaining (inclusive).\n# 3. Counting from the low end, strike out the kth number not yet struck out, and write it down at the end of a separate list.\n# 4. Repeat from step 2 until all the numbers have been struck out.\n# 5. The sequence of numbers written down in step 3 is now a random permutation of the original numbers.\n\nscatch = [1, 2, 3, 4, 5]\nresult = []\nfor i in range(len(scatch)):\n    roll = random.randint(1, len(scatch))\n    struck = scatch.pop(roll-1)\n    result.append(struck)\n```\n\n**The modern version of the algorithm** is efficient: it takes time proportional to the number of items being shuffled and shuffles them in place. The modern version of the Fisher–Yates shuffle, designed for computer use, was introduced by Richard Durstenfeld in 1964[2] and popularized by Donald E. Knuth in **The Art of Computer Programming** as \"Algorithm P (Shuffling)\".\n\n```python\n# To shuffle an array a of n elements (indices 0..n-1):\nfor i from n−1 downto 1 do\n     j ← random integer such that 0 ≤ j ≤ i\n     exchange a[j] and a[i]\n\n# An equivalent version which shuffles the array in the opposite direction (from lowest index to highest) is:\n\nfor i from 0 to n−2 do\n     j ← random integer such that i ≤ j < n\n     exchange a[i] and a[j]\n```\n\n**Sattolo's algorithm**\n\nA very similar algorithm was published in 1986 by Sandra Sattolo for generating uniformly distributed cycles of (maximal) length n.[6][7] The only difference between Durstenfeld's and Sattolo's algorithms is that in the latter, in step 2 above, the random number j is chosen from the range between 1 and i−1 (rather than between 1 and i) inclusive. This simple change modifies the algorithm so that the resulting permutation always consists of a single cycle.\n\n```python\nfrom random import randrange\n\ndef sattoloCycle(items):\n    i = len(items)\n    while i > 1:\n        i = i - 1\n        j = randrange(i)  # 0 <= j <= i-1\n        items[j], items[i] = items[i], items[j]\n```\n\n#### Generation in lexicographic order\n\nThe following algorithm generates the next permutation lexicographically after a given permutation. It changes the given permutation in-place.\n\n```python\n# 1. Find the largest index k such that a[k] < a[k + 1]. If no such index exists, the permutation is the last permutation.\n# 2. Find the largest index l greater than k such that a[k] < a[l].\n# 3. Swap the value of a[k] with that of a[l].\n# 4. Reverse the sequence from a[k + 1] up to and including the final element a[n].\n\nk = -1\nl = -1\nfor i in reversed(range(len(a) - 1)):\n    if a[i] < a[i + 1]:\n        k = i\n        break\nif k == -1:\n    return\nfor j in reversed(range(len(a))):\n    if a[j] > a[k]:\n        l = j\n        break\na[k], a[l] = a[l], a[k]\na= a[:k + 1] + list(reversed(a[k + 1:]))\n```\n\n#### Generation with minimal changes\n\n**Heap's algorithm** generates all possible permutations of n objects. It was first proposed by B. R. Heap in 1963.[1] The algorithm minimizes movement: it generates each permutation from the previous one by interchanging a single pair of elements; the other n−2 elements are not disturbed.\n\nSuppose we have a permutation containing n different elements. Heap found a systematic method for choosing at each step a pair of elements to switch, in order to produce every possible permutation of these elements exactly once. Let us describe Heap's method in a recursive way. First we set a counter i to 0. Now we perform the following steps repeatedly until i is equal to n. We use the algorithm to generate the (n−1)! permutations of the first n−1 elements, adjoining the last element to each of these. This generates all of the permutations that end with the last element. Then if n is odd, we switch the first element and the last one, while if n is even we can switch the ith element and the last one (there is no difference between n even and odd in the first iteration). We add one to the counter i and repeat. In each iteration, the algorithm will produce all of the permutations that end with the element that has just been moved to the \"last\" position. The following pseudocode outputs all permutations of a data array of length n.\n\n```python\ndef generate(n, A):\n    if n == 1:\n          return A\n    else:\n        for i in range(n-1):\n            generate(n - 1, A)\n            if n % 2 == 0:\n                A[n-1], A[i] = A[i], A[n-1]\n            else:\n                A[n-1], A[0] = A[0], A[n-1]\n        generate(n - 1, A)\n\n# a non-recursive format\ndef generate(n, A):\n    c = []\n    for i in range(n):\n        c[i] = 0\n    print(A)\n    i = 0\n    while i < n:\n        if  c[i] < i:\n            if i % 2 == 0:\n                A[i], A[0] = A[0], A[i]\n            else:\n                A[i], A[c[i]] = A[c[i]], A[i]\n            print(A)\n            c[i] = c[i] + 1\n            i = 0\n        else:\n            c[i] = 0\n            i = i + 1\n```\n","source":"_posts/Permutation-generate.md","raw":"---\ntitle: Permutation generate\ndate: 2018-09-04 09:49:58\ntags: Permutation\ncategories: 算法导论\n---\n\n### Permutation\n\nIn mathematics, the notion of permutation relates to the act of arranging all the members of a set into some sequence or order, or if the set is already ordered, rearranging (reordering) its elements, a process called permuting. These differ from combinations, which are selections of some members of a set where order is disregarded.\n\n### Algorithms to generate permutations\n\n#### Random generation of permutations\n\nThe **Fisher–Yates shuffle** is an algorithm for generating a random permutation of a finite sequence—in plain terms, the algorithm shuffles the sequence. The algorithm effectively puts all the elements into a hat; it continually determines the next element by randomly drawing an element from the hat until no elements remain. The algorithm produces an unbiased permutation: every permutation is equally likely.\n\nThe basic method given for generating a random permutation of the numbers 1 through N goes as follows:\n\n```python\n# 1. Write down the numbers from 1 through N.\n# 2. Pick a random number k between one and the number of unstruck numbers remaining (inclusive).\n# 3. Counting from the low end, strike out the kth number not yet struck out, and write it down at the end of a separate list.\n# 4. Repeat from step 2 until all the numbers have been struck out.\n# 5. The sequence of numbers written down in step 3 is now a random permutation of the original numbers.\n\nscatch = [1, 2, 3, 4, 5]\nresult = []\nfor i in range(len(scatch)):\n    roll = random.randint(1, len(scatch))\n    struck = scatch.pop(roll-1)\n    result.append(struck)\n```\n\n**The modern version of the algorithm** is efficient: it takes time proportional to the number of items being shuffled and shuffles them in place. The modern version of the Fisher–Yates shuffle, designed for computer use, was introduced by Richard Durstenfeld in 1964[2] and popularized by Donald E. Knuth in **The Art of Computer Programming** as \"Algorithm P (Shuffling)\".\n\n```python\n# To shuffle an array a of n elements (indices 0..n-1):\nfor i from n−1 downto 1 do\n     j ← random integer such that 0 ≤ j ≤ i\n     exchange a[j] and a[i]\n\n# An equivalent version which shuffles the array in the opposite direction (from lowest index to highest) is:\n\nfor i from 0 to n−2 do\n     j ← random integer such that i ≤ j < n\n     exchange a[i] and a[j]\n```\n\n**Sattolo's algorithm**\n\nA very similar algorithm was published in 1986 by Sandra Sattolo for generating uniformly distributed cycles of (maximal) length n.[6][7] The only difference between Durstenfeld's and Sattolo's algorithms is that in the latter, in step 2 above, the random number j is chosen from the range between 1 and i−1 (rather than between 1 and i) inclusive. This simple change modifies the algorithm so that the resulting permutation always consists of a single cycle.\n\n```python\nfrom random import randrange\n\ndef sattoloCycle(items):\n    i = len(items)\n    while i > 1:\n        i = i - 1\n        j = randrange(i)  # 0 <= j <= i-1\n        items[j], items[i] = items[i], items[j]\n```\n\n#### Generation in lexicographic order\n\nThe following algorithm generates the next permutation lexicographically after a given permutation. It changes the given permutation in-place.\n\n```python\n# 1. Find the largest index k such that a[k] < a[k + 1]. If no such index exists, the permutation is the last permutation.\n# 2. Find the largest index l greater than k such that a[k] < a[l].\n# 3. Swap the value of a[k] with that of a[l].\n# 4. Reverse the sequence from a[k + 1] up to and including the final element a[n].\n\nk = -1\nl = -1\nfor i in reversed(range(len(a) - 1)):\n    if a[i] < a[i + 1]:\n        k = i\n        break\nif k == -1:\n    return\nfor j in reversed(range(len(a))):\n    if a[j] > a[k]:\n        l = j\n        break\na[k], a[l] = a[l], a[k]\na= a[:k + 1] + list(reversed(a[k + 1:]))\n```\n\n#### Generation with minimal changes\n\n**Heap's algorithm** generates all possible permutations of n objects. It was first proposed by B. R. Heap in 1963.[1] The algorithm minimizes movement: it generates each permutation from the previous one by interchanging a single pair of elements; the other n−2 elements are not disturbed.\n\nSuppose we have a permutation containing n different elements. Heap found a systematic method for choosing at each step a pair of elements to switch, in order to produce every possible permutation of these elements exactly once. Let us describe Heap's method in a recursive way. First we set a counter i to 0. Now we perform the following steps repeatedly until i is equal to n. We use the algorithm to generate the (n−1)! permutations of the first n−1 elements, adjoining the last element to each of these. This generates all of the permutations that end with the last element. Then if n is odd, we switch the first element and the last one, while if n is even we can switch the ith element and the last one (there is no difference between n even and odd in the first iteration). We add one to the counter i and repeat. In each iteration, the algorithm will produce all of the permutations that end with the element that has just been moved to the \"last\" position. The following pseudocode outputs all permutations of a data array of length n.\n\n```python\ndef generate(n, A):\n    if n == 1:\n          return A\n    else:\n        for i in range(n-1):\n            generate(n - 1, A)\n            if n % 2 == 0:\n                A[n-1], A[i] = A[i], A[n-1]\n            else:\n                A[n-1], A[0] = A[0], A[n-1]\n        generate(n - 1, A)\n\n# a non-recursive format\ndef generate(n, A):\n    c = []\n    for i in range(n):\n        c[i] = 0\n    print(A)\n    i = 0\n    while i < n:\n        if  c[i] < i:\n            if i % 2 == 0:\n                A[i], A[0] = A[0], A[i]\n            else:\n                A[i], A[c[i]] = A[c[i]], A[i]\n            print(A)\n            c[i] = c[i] + 1\n            i = 0\n        else:\n            c[i] = 0\n            i = i + 1\n```\n","slug":"Permutation-generate","published":1,"updated":"2018-09-05T13:18:11.624Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oxr000q44vom7pkorvt"},{"title":"Very Deep Convolutional Networks for Large-Scale Image Recongnition","date":"2018-08-31T02:08:37.000Z","mathjax":true,"_content":"## 概述\n\n这是一篇由牛津大学视觉几何组(VGG)2015年发表在ICLR上的论文。该论文中，他们主要研究了卷积网络深度对大尺度图像识别精度的影响。主要的贡献是，对使用同一小卷积核但深度不同的网络性能的完整评估，当把深度加到16-19层时，它相对于先前技术在性能上有了很大改善。文中的网络架构被称为 **VGG**, 它也在ImageNet Challenge 2014上取得了定位第一，分类第二的好成绩。\n\n## 网络配置\n\n所有的网络使用相同的卷积池化操作只是深度不同。使用'SAME'卷积, 卷积核大小均为 $3 \\times 3$ , 步长为1. 使用最大池化, 池化单元大小均为 $2 \\times 2$, 步长为2. 卷积核个数(通道数)从64开始以2倍增长直到512. 每层卷积层的非线性函数为ReLU. 最后三个全连接层的大小分别为4096, 4096, 1000.\n\n![](/images/vgg_architecture.PNG)\n\n亮点：**使用3个堆叠的3\\*3卷积而不是采样像alexnet中的7\\*7卷积.**\n\n理由：在3个堆叠的卷积层中都包含了ReLU非线性单元，这使决策函数更具有分辨力；其次减少了参数，相比于7\\*7的卷积需要参数( $7 \\times7 C^2$ ), 3个3\\*3卷积层需要更少的参数( $3\\times 3 \\times 3 C^2$ )\n\n## 分类任务的训练和测试\n\n### 训练阶段\n\n利用带动量的小批量梯度下降法优化多项逻辑回归目标。$batch size=256, momentum=0.9, L2=5*10^{-4}, dropout=0.5, learning\\_rate=0.01$\n先训练小网络A, 再将训练后A的权重给其他网络初始化, 其他还未初始化的层，权重使用均值为0方差为0.01的正态分布初始化，偏差初始化为0.\n在每个SGD迭代过程，对每幅输入图像进行随机裁剪到固定大小224\\*224.\n\n训练图像的大小(S: 是经过各向同性调整后的最小边长)：\n\n方法一：单尺度训练，固定S=256/S=384. 先用S=256训练，将参数保留然后再用S=384进行微调(学习率下降到0.001)。\n\n方法二：多尺度训练，S从[256, 512]中随机取值，先用S=384训练再将其参数保留用多尺度方法训练。\n\n### 测试阶段\n\n给一个测试图像，先将其进行各向同性调整到预定义的最小尺寸Q. 将全连接层转换为卷积层(第一个全连接层变为7\\*7的卷积层，第二，三个全连接层变为1\\*1的卷积层，核的大小均与之前全连接层的单元数相等)。将整个未裁剪的图像应用在整个卷积网络上。结果是一个类的得分映射，通道数等于类数，以及一个可变的空间分辨率，取决于输入的图像大小。最后，为了获得图像的类分数的固定大小向量，类分数被进行空间平均（一个类的得分为该通道上像素的平均值）。还能通过水平翻转的方式来增强测试集。\n\n亮点：**测试时将全连接层转换为卷积层。**\n\n理由：在测试时不需要生成多个裁剪的图像重复进行计算。对输入图像的大小没有限制。\n\n## 分类任务的评估\n\n该数据集包含1000个类的图像，并分为三组:训练(130万张图像)、验证(50K图像)和测试(100K带有提示标签的图像)。\n\n### 单尺度评估(Q不变)\n\n$对于固定的S, Q=S; 对于 S \\in [S_{min}, S_{max}], Q = 0.5(S_{min} + S_{max})$\n![](/images/vgg_performance_1.PNG)\n\n### 多尺度评估(Q变化)\n\n$对于固定的S, Q=\\{S-32, S, S+32\\}; 对于 S \\in [S_{min}, S_{max}], Q = \\{S_{min}, 0.5(S_{min} + S_{max}), S_{max}\\}$\n![](/images/vgg_performance_2.PNG)\n\n### Multi-crop 评估(S变化)\n\n![](/images/vgg_performance_3.PNG)\n","source":"_posts/Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recongnition.md","raw":"---\ntitle: Very Deep Convolutional Networks for Large-Scale Image Recongnition\ndate: 2018-08-31 10:08:37\ntags: CNN, VGG\ncategories: 深度学习\nmathjax: true\n---\n## 概述\n\n这是一篇由牛津大学视觉几何组(VGG)2015年发表在ICLR上的论文。该论文中，他们主要研究了卷积网络深度对大尺度图像识别精度的影响。主要的贡献是，对使用同一小卷积核但深度不同的网络性能的完整评估，当把深度加到16-19层时，它相对于先前技术在性能上有了很大改善。文中的网络架构被称为 **VGG**, 它也在ImageNet Challenge 2014上取得了定位第一，分类第二的好成绩。\n\n## 网络配置\n\n所有的网络使用相同的卷积池化操作只是深度不同。使用'SAME'卷积, 卷积核大小均为 $3 \\times 3$ , 步长为1. 使用最大池化, 池化单元大小均为 $2 \\times 2$, 步长为2. 卷积核个数(通道数)从64开始以2倍增长直到512. 每层卷积层的非线性函数为ReLU. 最后三个全连接层的大小分别为4096, 4096, 1000.\n\n![](/images/vgg_architecture.PNG)\n\n亮点：**使用3个堆叠的3\\*3卷积而不是采样像alexnet中的7\\*7卷积.**\n\n理由：在3个堆叠的卷积层中都包含了ReLU非线性单元，这使决策函数更具有分辨力；其次减少了参数，相比于7\\*7的卷积需要参数( $7 \\times7 C^2$ ), 3个3\\*3卷积层需要更少的参数( $3\\times 3 \\times 3 C^2$ )\n\n## 分类任务的训练和测试\n\n### 训练阶段\n\n利用带动量的小批量梯度下降法优化多项逻辑回归目标。$batch size=256, momentum=0.9, L2=5*10^{-4}, dropout=0.5, learning\\_rate=0.01$\n先训练小网络A, 再将训练后A的权重给其他网络初始化, 其他还未初始化的层，权重使用均值为0方差为0.01的正态分布初始化，偏差初始化为0.\n在每个SGD迭代过程，对每幅输入图像进行随机裁剪到固定大小224\\*224.\n\n训练图像的大小(S: 是经过各向同性调整后的最小边长)：\n\n方法一：单尺度训练，固定S=256/S=384. 先用S=256训练，将参数保留然后再用S=384进行微调(学习率下降到0.001)。\n\n方法二：多尺度训练，S从[256, 512]中随机取值，先用S=384训练再将其参数保留用多尺度方法训练。\n\n### 测试阶段\n\n给一个测试图像，先将其进行各向同性调整到预定义的最小尺寸Q. 将全连接层转换为卷积层(第一个全连接层变为7\\*7的卷积层，第二，三个全连接层变为1\\*1的卷积层，核的大小均与之前全连接层的单元数相等)。将整个未裁剪的图像应用在整个卷积网络上。结果是一个类的得分映射，通道数等于类数，以及一个可变的空间分辨率，取决于输入的图像大小。最后，为了获得图像的类分数的固定大小向量，类分数被进行空间平均（一个类的得分为该通道上像素的平均值）。还能通过水平翻转的方式来增强测试集。\n\n亮点：**测试时将全连接层转换为卷积层。**\n\n理由：在测试时不需要生成多个裁剪的图像重复进行计算。对输入图像的大小没有限制。\n\n## 分类任务的评估\n\n该数据集包含1000个类的图像，并分为三组:训练(130万张图像)、验证(50K图像)和测试(100K带有提示标签的图像)。\n\n### 单尺度评估(Q不变)\n\n$对于固定的S, Q=S; 对于 S \\in [S_{min}, S_{max}], Q = 0.5(S_{min} + S_{max})$\n![](/images/vgg_performance_1.PNG)\n\n### 多尺度评估(Q变化)\n\n$对于固定的S, Q=\\{S-32, S, S+32\\}; 对于 S \\in [S_{min}, S_{max}], Q = \\{S_{min}, 0.5(S_{min} + S_{max}), S_{max}\\}$\n![](/images/vgg_performance_2.PNG)\n\n### Multi-crop 评估(S变化)\n\n![](/images/vgg_performance_3.PNG)\n","slug":"Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recongnition","published":1,"updated":"2018-08-31T04:06:06.157Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oxx000v44vosmftr0cq"},{"title":"dropout 正则化","date":"2018-07-20T08:18:24.000Z","mathjax":true,"_content":"## dropout 正则化\n\n**dropout（随机失活）**是在神经网络的隐藏层为每个神经元结点设置一个随机消除的概率，保留下来的神经元形成一个结点较少、规模较小的网络用于训练。dropout 正则化较多地被使用在**计算机视觉（Computer Vision）**领域。\n\n![dropout_regularization](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dropout_regularization.png)\n\n### 反向随机失活（Inverted dropout）\n\n反向随机失活是实现 dropout 的方法。对第`l`层进行 dropout：\n\n```python\nkeep_prob = 0.8    # 设置神经元保留概率\ndl = np.random.rand(al.shape[0], al.shape[1]) < keep_prob\nal = np.multiply(al, dl)\nal /= keep_prob\n\n# 反向传播过程为\ndal = dal * dl\ndal /= keep_prob\n```\n\n最后一步`al /= keep_prob`是因为 $a^{[l]}$中的一部分元素失活（相当于被归零），为了在下一层计算时不影响 $Z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$的期望值，因此除以一个`keep_prob`。\n\n**注意**，在**测试阶段不要使用 dropout**，因为那样会使得预测结果变得随机。\n\n### 理解 dropout\n\n对于单个神经元，其工作是接收输入并产生一些有意义的输出。但是加入了 dropout 后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征，即不会给任何一个输入特征设置太大的权重。\n\n因此，通过传播过程，dropout 将产生和 L2 正则化相同的**收缩权重**的效果。\n\n对于不同的层，设置的`keep_prob`也不同。一般来说，神经元较少的层，会设`keep_prob`为 1.0，而神经元多的层则会设置比较小的`keep_prob`。\n\ndropout 的一大**缺点**是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将`keep_prob`全部设置为 1.0 后运行代码，确保 $J(w, b)$函数单调递减，再打开 dropout。\n\n## 其他正则化方法\n\n* 数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。\n* 早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，在两者开始发生较大偏差时及时停止迭代，避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。\n","source":"_posts/dropout.md","raw":"---\ntitle: dropout 正则化\ndate: 2018-07-20 16:18:24\ntags: dropout\ncategories: 深度学习\nmathjax: true\n---\n## dropout 正则化\n\n**dropout（随机失活）**是在神经网络的隐藏层为每个神经元结点设置一个随机消除的概率，保留下来的神经元形成一个结点较少、规模较小的网络用于训练。dropout 正则化较多地被使用在**计算机视觉（Computer Vision）**领域。\n\n![dropout_regularization](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dropout_regularization.png)\n\n### 反向随机失活（Inverted dropout）\n\n反向随机失活是实现 dropout 的方法。对第`l`层进行 dropout：\n\n```python\nkeep_prob = 0.8    # 设置神经元保留概率\ndl = np.random.rand(al.shape[0], al.shape[1]) < keep_prob\nal = np.multiply(al, dl)\nal /= keep_prob\n\n# 反向传播过程为\ndal = dal * dl\ndal /= keep_prob\n```\n\n最后一步`al /= keep_prob`是因为 $a^{[l]}$中的一部分元素失活（相当于被归零），为了在下一层计算时不影响 $Z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$的期望值，因此除以一个`keep_prob`。\n\n**注意**，在**测试阶段不要使用 dropout**，因为那样会使得预测结果变得随机。\n\n### 理解 dropout\n\n对于单个神经元，其工作是接收输入并产生一些有意义的输出。但是加入了 dropout 后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征，即不会给任何一个输入特征设置太大的权重。\n\n因此，通过传播过程，dropout 将产生和 L2 正则化相同的**收缩权重**的效果。\n\n对于不同的层，设置的`keep_prob`也不同。一般来说，神经元较少的层，会设`keep_prob`为 1.0，而神经元多的层则会设置比较小的`keep_prob`。\n\ndropout 的一大**缺点**是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将`keep_prob`全部设置为 1.0 后运行代码，确保 $J(w, b)$函数单调递减，再打开 dropout。\n\n## 其他正则化方法\n\n* 数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。\n* 早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，在两者开始发生较大偏差时及时停止迭代，避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。\n","slug":"dropout","published":1,"updated":"2018-08-31T03:49:05.231Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oxz000y44vo638yoqrh"},{"title":"github使用手册","date":"2018-08-05T02:45:20.000Z","_content":"## git clone\n\n### clone地址https和SSH的区别\n\n前者可以随意克隆github上的项目，而不管是谁的；而后者则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。\n\nhttps url 在push的时候是需要验证用户名和密码的；而 SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。\n\n### 在github上添加ssh key的方法\n\n1. \t首先需要检查你电脑是否已经有 SSH key \n\n`cd ~/.ssh/ | ls` 检查是否有文件id_rsa.pub, 若存在则跳过第二步\n\n2. 创建一个ssh key\n\n`ssh-keygen -t rsa -C \"your_email@example.com\"` 使用默认设置，可设置密码用于push操作。完成后将得到两个文件，放在./ssh目录下，分别为id_rsa和id_rsa.pub\n\n3. 添加ssh key到github\n\n拷贝id_rsa.pub文件的内容，复制到github账户的sshkey设置页面处。\n\n4. 测试ssh key\n\n`ssh -T git@github.com`\n\n### clone指定分支\n\n`git clone -b <分支名> <address.git>`\n\n## 添加新的分支\n\n1. 先将仓库克隆到本地\n2. `git branch`查看分支。`git branch <分支名>` 新建分支\n3. `git checkout <分支名>` 切换到新分支\n4. `git push -u origin <分支名>` 同步分支到github\n","source":"_posts/github使用手册.md","raw":"---\ntitle: github使用手册\ndate: 2018-08-05 10:45:20\ntags: git\ncategories: 程序员实用工具\n---\n## git clone\n\n### clone地址https和SSH的区别\n\n前者可以随意克隆github上的项目，而不管是谁的；而后者则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。\n\nhttps url 在push的时候是需要验证用户名和密码的；而 SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。\n\n### 在github上添加ssh key的方法\n\n1. \t首先需要检查你电脑是否已经有 SSH key \n\n`cd ~/.ssh/ | ls` 检查是否有文件id_rsa.pub, 若存在则跳过第二步\n\n2. 创建一个ssh key\n\n`ssh-keygen -t rsa -C \"your_email@example.com\"` 使用默认设置，可设置密码用于push操作。完成后将得到两个文件，放在./ssh目录下，分别为id_rsa和id_rsa.pub\n\n3. 添加ssh key到github\n\n拷贝id_rsa.pub文件的内容，复制到github账户的sshkey设置页面处。\n\n4. 测试ssh key\n\n`ssh -T git@github.com`\n\n### clone指定分支\n\n`git clone -b <分支名> <address.git>`\n\n## 添加新的分支\n\n1. 先将仓库克隆到本地\n2. `git branch`查看分支。`git branch <分支名>` 新建分支\n3. `git checkout <分支名>` 切换到新分支\n4. `git push -u origin <分支名>` 同步分支到github\n","slug":"github使用手册","published":1,"updated":"2018-08-19T01:59:35.791Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oy2001144vo0njy7dc6"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ncategories: web\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2018-08-19T01:59:35.792Z","updated":"2018-08-19T01:59:35.792Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oy6001544vofj349hkm"},{"title":"matplotlib","date":"2018-08-15T23:51:58.000Z","_content":"\n## 快速绘图\n\n### 使用pyplot模块绘图\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.figure(figsize=(8,4))\nplt.plot(x, y, label=\"$sin(x)$\", color=\"red\", linewidth=2)\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Volt\")\nplt.title(\"pyplot first example\")\nplt.ylim(-1.2, 1.2)\nplt.legend()\nplt.show()\n```\n\n保存图片`plt.savefig('test.png', dpi=120)`的像素值由参数`matplotlib.rcParams[\"savefig.dpi\"]`决定，默认为100.\n保存对象不一定是文件，还可是和文件对象有相同调用接口的对象.\n\n```python\nfrom StringIO import StringIO\nbuf = StringIO()\nplt.savefig(buf, fmt='png')\nbuf.getvalue()[:20]\n```\n\n### 以面向对象方式绘图\n\n```python\nfig = plt.gcf()  # get current figure\naxes = plt.gca()  # get current axes\n```\n\n在pyplot模块中，许多函数都是对当前的Figure和Axes对象进行处理.\n\n### 配置属性\n\n使用matplotlib绘制的图表的每个组成部分都和一个对象对应，可以通过调用这些对象的属性设置方法`set_*()`或pyplot模块的属性设置函数`setp()`来设它们的属性值.\n\n```\nx = np.arange(0, 5, 0.1)\nline = plt.plot(x, x*x)[0]\nline.set_antialiased(False)\n\nlines = plt.plot(x, np.sin(x), x, np.cos(x))\nplt.setp(lines, color=\"r\", linewidth=2.0)\n```\n\n同样可以调用Line2D对象的`get_*()`或`plt.getp()`来获取对象的属性值.\n\n```python\nline.get_linewidth()\n\n# getp()只能对一个对象操作\nplt.getp(lines[0], \"color\")\nplt.getp(lines[1])  # 输出全部属性\n\nf = plt.gcf()\nplt.getp(f)\n\nallines = plt.getp(plt.gca(), \"lines\")\nallines = f.axes[0].lines\n```\n\n### 绘制多个子图\n\n一个Figure对象可以包含多个子图Axes.\n\n`subplot(numRows, numCols, plotNum)`\n\n`subplot(323), subplot(3, 2, 3)`\n\n```python\n# 绘制6个子图并设置不同的背景颜色\nfor idx, color in enumerate(\"rgbyck\"):\n    plt.subplot(321 + idx, axisbg=color)\nplt.show()\n```\n\n`plt.subplot(212)  # 占据第二整行`\n\n```python\n同时在多幅图表、多个子图中进行绘制\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(1)  # 创建图表1\nplt.figure(2)\nax1 = plt.subplot(211)  # 在图表2中创建子图1\nax2 = plt.subplot(212)\n\nx = np.linspace(0, 3, 100)\nfor i in xrange(5):\n    plt.figure(1)  # 选择图表1\n    plt.plot(x, np.exp(i * x / 3)\n    plt.sca(ax1)  # 选择图表2的子图1\n    plt.plot(x, np.sin(x * i))\n    plt.sca(ax2)  # 选择图表2的子图2\n    plt.plot(x, np.cos(i * x))\nplt.show()\n```\n\n### 配置文件\n\n绘制一幅图表要对许多对象的属性进行配置。我们通常采用了默认配置，matplotlib将这些默认配置保存在一个名为“matplotlibrc”的配置文件中。\n\n```python\nmatplotlib.get_configdir()  # 获取用户配置路径\nmatplotlib.matplotlib_fname()  # 获得目前使用的配置文件的路径\nmatplotlib.rc_params()  # 配置文件的读入，返回字典\nmatplotlib.rc(\"lines\", marker='x', linewidth=2, color=\"red\")  # 对配置字典进行设置\nmatplotlib.rcdefaults()  # 回复默认配置\n``````\n\n### 在图表中显示中文\n\n```pythno\nfrom matplotlib.font_manager import fontManager\n# 获得所有可用的字体列表\nfontManager.ttflist\n\n# 获得字体文件的全路径和字体名\nfontManager.ttflist[0].name\nfontManager.ttflist[0].fname\n\n\n```python\n# 显示所有的中文字体\nfrom matplotlib.font_manager import fontManager\nimport matplotlib.pyplot as plt\nimport os\n\nfig = plt.figure(figsize=(12, 6))\nax = fig.add_subplot(111)\nplt.subplot_adjust(0, 0, 1, 1, 0, 0)\nplt.xticks([])\nplt.yticks([])\nx, y = 0.05, 0.08\nfonts = [font.name for font in fontManager.ttflist if os.path.exists(font.fname) and os.stat(font.fname).st_size>1e6]\nfont = set(fonts)\ndy = (1.0 - y) / (len(fonts) / 4 + (len(fonts) % 4 != 0))\nfor font in fonts:\n    t = ax.text(x, y, u\"中文字体\", {'fontname': font, 'fontsize': 14}, transform=ax.transAxes)\n    ax.test(x, y - dy / 2, font, transform=ax.transAxes)\n    x += 0.25\n    if x >= 1.0:\n        y += dy\n        x = 0.05\nplt.show()\n```\n\n```python\n# 使用ttc字体文件\nfrom matplotlib.font_Manager import FontProperties\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfont = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)\nt = np.linspace(0, 10, 100)\ny = np.sin(t)\nplt.plot(t, y)\nplt.title(u\"正弦波\", fontproperties=font)\nplt.show()\n```\n\n直接修改配置文件，设置默认字体。\n\n`plt.rcParams[\"font.family\"] = \"SimHei\"`\n\n## Artist对象\n","source":"_posts/matplotlib.md","raw":"---\ntitle: matplotlib\ndate: 2018-08-16 07:51:58\ntags: python\ncategories: python包和模块\n---\n\n## 快速绘图\n\n### 使用pyplot模块绘图\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.figure(figsize=(8,4))\nplt.plot(x, y, label=\"$sin(x)$\", color=\"red\", linewidth=2)\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Volt\")\nplt.title(\"pyplot first example\")\nplt.ylim(-1.2, 1.2)\nplt.legend()\nplt.show()\n```\n\n保存图片`plt.savefig('test.png', dpi=120)`的像素值由参数`matplotlib.rcParams[\"savefig.dpi\"]`决定，默认为100.\n保存对象不一定是文件，还可是和文件对象有相同调用接口的对象.\n\n```python\nfrom StringIO import StringIO\nbuf = StringIO()\nplt.savefig(buf, fmt='png')\nbuf.getvalue()[:20]\n```\n\n### 以面向对象方式绘图\n\n```python\nfig = plt.gcf()  # get current figure\naxes = plt.gca()  # get current axes\n```\n\n在pyplot模块中，许多函数都是对当前的Figure和Axes对象进行处理.\n\n### 配置属性\n\n使用matplotlib绘制的图表的每个组成部分都和一个对象对应，可以通过调用这些对象的属性设置方法`set_*()`或pyplot模块的属性设置函数`setp()`来设它们的属性值.\n\n```\nx = np.arange(0, 5, 0.1)\nline = plt.plot(x, x*x)[0]\nline.set_antialiased(False)\n\nlines = plt.plot(x, np.sin(x), x, np.cos(x))\nplt.setp(lines, color=\"r\", linewidth=2.0)\n```\n\n同样可以调用Line2D对象的`get_*()`或`plt.getp()`来获取对象的属性值.\n\n```python\nline.get_linewidth()\n\n# getp()只能对一个对象操作\nplt.getp(lines[0], \"color\")\nplt.getp(lines[1])  # 输出全部属性\n\nf = plt.gcf()\nplt.getp(f)\n\nallines = plt.getp(plt.gca(), \"lines\")\nallines = f.axes[0].lines\n```\n\n### 绘制多个子图\n\n一个Figure对象可以包含多个子图Axes.\n\n`subplot(numRows, numCols, plotNum)`\n\n`subplot(323), subplot(3, 2, 3)`\n\n```python\n# 绘制6个子图并设置不同的背景颜色\nfor idx, color in enumerate(\"rgbyck\"):\n    plt.subplot(321 + idx, axisbg=color)\nplt.show()\n```\n\n`plt.subplot(212)  # 占据第二整行`\n\n```python\n同时在多幅图表、多个子图中进行绘制\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(1)  # 创建图表1\nplt.figure(2)\nax1 = plt.subplot(211)  # 在图表2中创建子图1\nax2 = plt.subplot(212)\n\nx = np.linspace(0, 3, 100)\nfor i in xrange(5):\n    plt.figure(1)  # 选择图表1\n    plt.plot(x, np.exp(i * x / 3)\n    plt.sca(ax1)  # 选择图表2的子图1\n    plt.plot(x, np.sin(x * i))\n    plt.sca(ax2)  # 选择图表2的子图2\n    plt.plot(x, np.cos(i * x))\nplt.show()\n```\n\n### 配置文件\n\n绘制一幅图表要对许多对象的属性进行配置。我们通常采用了默认配置，matplotlib将这些默认配置保存在一个名为“matplotlibrc”的配置文件中。\n\n```python\nmatplotlib.get_configdir()  # 获取用户配置路径\nmatplotlib.matplotlib_fname()  # 获得目前使用的配置文件的路径\nmatplotlib.rc_params()  # 配置文件的读入，返回字典\nmatplotlib.rc(\"lines\", marker='x', linewidth=2, color=\"red\")  # 对配置字典进行设置\nmatplotlib.rcdefaults()  # 回复默认配置\n``````\n\n### 在图表中显示中文\n\n```pythno\nfrom matplotlib.font_manager import fontManager\n# 获得所有可用的字体列表\nfontManager.ttflist\n\n# 获得字体文件的全路径和字体名\nfontManager.ttflist[0].name\nfontManager.ttflist[0].fname\n\n\n```python\n# 显示所有的中文字体\nfrom matplotlib.font_manager import fontManager\nimport matplotlib.pyplot as plt\nimport os\n\nfig = plt.figure(figsize=(12, 6))\nax = fig.add_subplot(111)\nplt.subplot_adjust(0, 0, 1, 1, 0, 0)\nplt.xticks([])\nplt.yticks([])\nx, y = 0.05, 0.08\nfonts = [font.name for font in fontManager.ttflist if os.path.exists(font.fname) and os.stat(font.fname).st_size>1e6]\nfont = set(fonts)\ndy = (1.0 - y) / (len(fonts) / 4 + (len(fonts) % 4 != 0))\nfor font in fonts:\n    t = ax.text(x, y, u\"中文字体\", {'fontname': font, 'fontsize': 14}, transform=ax.transAxes)\n    ax.test(x, y - dy / 2, font, transform=ax.transAxes)\n    x += 0.25\n    if x >= 1.0:\n        y += dy\n        x = 0.05\nplt.show()\n```\n\n```python\n# 使用ttc字体文件\nfrom matplotlib.font_Manager import FontProperties\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfont = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)\nt = np.linspace(0, 10, 100)\ny = np.sin(t)\nplt.plot(t, y)\nplt.title(u\"正弦波\", fontproperties=font)\nplt.show()\n```\n\n直接修改配置文件，设置默认字体。\n\n`plt.rcParams[\"font.family\"] = \"SimHei\"`\n\n## Artist对象\n","slug":"matplotlib","published":1,"updated":"2018-08-31T03:51:45.318Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oyc001844voacobmjjr"},{"title":"python内置小工具","date":"2018-08-04T23:24:47.000Z","_content":"\n## 极简文件下载（Web）服务器\n\n### 作用\n\n快速共享文件\n\n### 实用方法\n\nIn python2：\n\n`python -m SimpleHttpServer`\n\nIn python3:\n\n`python -m http.server`\n\n执行上述命令会在当前目录启动一个文件下载服务器，默认端口8000。**若当前目录存在一个名为`index.html`的文件，则默认会显示该文件的内容**\n\n## 使用python解压zip压缩包\n\n`$ python -m zipfile\nUsage:\n    zipfile.py -l zipfile.zip        # Show listing of a zipfile\n    zipfile.py -t zipfile.zip        # Test if a zipfile is valid\n    zipfile.py -e zipfile.zip target # Extract zipfile into target dir\n    zipfile.py -c zipfile.zip src ... # Create zipfile from sources\n`\n","source":"_posts/python内置小工具.md","raw":"---\ntitle: python内置小工具\ndate: 2018-08-05 07:24:47\ntags: python\ncategories: 程序员实用工具\n---\n\n## 极简文件下载（Web）服务器\n\n### 作用\n\n快速共享文件\n\n### 实用方法\n\nIn python2：\n\n`python -m SimpleHttpServer`\n\nIn python3:\n\n`python -m http.server`\n\n执行上述命令会在当前目录启动一个文件下载服务器，默认端口8000。**若当前目录存在一个名为`index.html`的文件，则默认会显示该文件的内容**\n\n## 使用python解压zip压缩包\n\n`$ python -m zipfile\nUsage:\n    zipfile.py -l zipfile.zip        # Show listing of a zipfile\n    zipfile.py -t zipfile.zip        # Test if a zipfile is valid\n    zipfile.py -e zipfile.zip target # Extract zipfile into target dir\n    zipfile.py -c zipfile.zip src ... # Create zipfile from sources\n`\n","slug":"python内置小工具","published":1,"updated":"2018-08-31T03:51:42.853Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oyg001b44vo4utvm089"},{"title":"Requests","date":"2018-08-14T00:15:18.000Z","_content":"\n## [Requests](cn.python-requests.org)\n\nRequests is an elegant and simple HTTP library for python, built for human beings.\n\n## Beloved Features\n\n* Keep-Alive & Connection Pooling\n* International Domains and URLs\n* Session with Cookie Persistence\n* Browser-style SSL Verification\n* Automatic Content Decoding\n* Basic/Digest Authentication\n* Elegant Key/Value Cookie\n* Automatic Decompression\n* Unicode Response Bodies\n* HTTP(S) Proxy Support\n* Multipart File Uploads\n* Streaming Downloads\n* Connection Timeouts\n* Chunked Requests\n* `.netrc` Support\n\n## 快速上手\n\n### 发送请求\n\n```python\nimport requests\nr = requests.get(url)\n```\n`r`为Response对象，requests的方法还有`put, delete, head, options`\n\n### 传递URL参数\n\n如url为`http://httpbin.org/get?key2=value2&key1=value1`\n```python\npayload = {'key1':'value1', 'key2':'value2'}\nr = requests.get(\"http://httpbin.org/get\", params=payload)\n```\n\n### 响应内容\n\n`r.text` 响应文本\n`r.encoding` 编码格式\n\n### 二进制响应内容\n\n`r.content` 以字节的方式访问响应体\n\n```python\nfrom PIL import Image\nfrom io import BytesIO\ni = Image.open(BytesIO(r.content))\n```\n\n### JSON响应内容\n\n`r.josn()`\n\n### 原始响应内容\n\n```python\nr = requests.get(url, stream=True)\nr.raw\nr.raw.read(10)\n\nwith open(filename, 'wb') as fd:\n    for chunk in r.iter_content(chunk_size):\n        fd.write(chunk)\n```\n\n### 定制请求头\n\n`headers = {'user-agent': 'my_-app/0.0.1'}`\n`r = requests.get(url, headers=headers)`\n\n### 更复杂的POST请求\n\n```python\npayload = {'key1':'value1', 'key2':'value2'}\nr = requests.post(\"http://httpbin.org/get\", data=payload)\n\npayload = (('key1', 'value1'), ('key2', 'value2'))\nr = requests.post(\"http://httpbin.org/get\", data=payload)\n\nr = requests.post(url, json=payload)\n```\n\n### POST一个多部分编码的文件\n\n```python\nfiles = {'file': open('report.xls', 'rb')}\nr = requests.post(url, files=files)\n\n# 你还可以显式地设置文件名，文件类型和请求头\nfiles = {'file': ('report.xls', open('report.xls', 'rb'), 'application/vnd.ms-excel', {'Expires': '0'})}\n```\n\n### 响应状态码\n\n`r.status_code` 检查响应状态码\n`r.status_code == requests.codes.ok` 内置的状态码查询对象\n`r.raise_for_status()` 抛出异常\n\n### 响应头\n\n`r.headers`\n```json\n{\n    'content-encoding': 'gzip',\n    'transfer-encoding': 'chunked',\n    'connection': 'close',\n    'server': 'nginx/1.0.4',\n    'x-runtime': '148ms',\n    'etag': '\"e1ca502697e5c9317743dc078f67693f\"',\n    'content-type': 'application/json'\n}\n```\n\n### Cookie\n\n`r.cookies`\n```python\ncookies = dict(cookies_are='working')\nr = requests.get(url, cookies=cookies)\n```\n\nCookie 的返回对象为 RequestsCookieJar，它的行为和字典类似，但接口更为完整，适合跨域名跨路径使用。你还可以把 Cookie Jar 传到 Requests 中：\n\n```python\njar = requests.cookies.RequestsCookieJar()\njar.set('tasty_cookie', 'yum', domain='httpbin.org', path='/cookies')\nr = requests.get(url, cookies=jar)\n```\n\n### 重定向和请求历史\n\nResponse.history 是一个 Response 对象的列表，为了完成请求而创建了这些对象。这个对象列表按照从最老到最近的请求进行排序。\n\n```python\nr = requests.get(url, allow_redirects=False)\nr.history\n```\n\n### 超时\n\n`r = requests.get(url, timeouts=0.01)`\n\n### 错误与异常\n\n遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出一个 ConnectionError 异常\n\n如果 HTTP 请求返回了不成功的状态码， Response.raise_for_status() 会抛出一个 HTTPError 异常\n\n若请求超时，则抛出一个 Timeout 异常。\n\n若请求超过了设定的最大重定向次数，则会抛出一个 TooManyRedirects 异常。\n\n所有Requests显式抛出的异常都继承自 requests.exceptions.RequestException 。\n","source":"_posts/requests.md","raw":"---\ntitle: Requests\ndate: 2018-08-14 08:15:18\ntags: python\ncategories: python包和模块\n---\n\n## [Requests](cn.python-requests.org)\n\nRequests is an elegant and simple HTTP library for python, built for human beings.\n\n## Beloved Features\n\n* Keep-Alive & Connection Pooling\n* International Domains and URLs\n* Session with Cookie Persistence\n* Browser-style SSL Verification\n* Automatic Content Decoding\n* Basic/Digest Authentication\n* Elegant Key/Value Cookie\n* Automatic Decompression\n* Unicode Response Bodies\n* HTTP(S) Proxy Support\n* Multipart File Uploads\n* Streaming Downloads\n* Connection Timeouts\n* Chunked Requests\n* `.netrc` Support\n\n## 快速上手\n\n### 发送请求\n\n```python\nimport requests\nr = requests.get(url)\n```\n`r`为Response对象，requests的方法还有`put, delete, head, options`\n\n### 传递URL参数\n\n如url为`http://httpbin.org/get?key2=value2&key1=value1`\n```python\npayload = {'key1':'value1', 'key2':'value2'}\nr = requests.get(\"http://httpbin.org/get\", params=payload)\n```\n\n### 响应内容\n\n`r.text` 响应文本\n`r.encoding` 编码格式\n\n### 二进制响应内容\n\n`r.content` 以字节的方式访问响应体\n\n```python\nfrom PIL import Image\nfrom io import BytesIO\ni = Image.open(BytesIO(r.content))\n```\n\n### JSON响应内容\n\n`r.josn()`\n\n### 原始响应内容\n\n```python\nr = requests.get(url, stream=True)\nr.raw\nr.raw.read(10)\n\nwith open(filename, 'wb') as fd:\n    for chunk in r.iter_content(chunk_size):\n        fd.write(chunk)\n```\n\n### 定制请求头\n\n`headers = {'user-agent': 'my_-app/0.0.1'}`\n`r = requests.get(url, headers=headers)`\n\n### 更复杂的POST请求\n\n```python\npayload = {'key1':'value1', 'key2':'value2'}\nr = requests.post(\"http://httpbin.org/get\", data=payload)\n\npayload = (('key1', 'value1'), ('key2', 'value2'))\nr = requests.post(\"http://httpbin.org/get\", data=payload)\n\nr = requests.post(url, json=payload)\n```\n\n### POST一个多部分编码的文件\n\n```python\nfiles = {'file': open('report.xls', 'rb')}\nr = requests.post(url, files=files)\n\n# 你还可以显式地设置文件名，文件类型和请求头\nfiles = {'file': ('report.xls', open('report.xls', 'rb'), 'application/vnd.ms-excel', {'Expires': '0'})}\n```\n\n### 响应状态码\n\n`r.status_code` 检查响应状态码\n`r.status_code == requests.codes.ok` 内置的状态码查询对象\n`r.raise_for_status()` 抛出异常\n\n### 响应头\n\n`r.headers`\n```json\n{\n    'content-encoding': 'gzip',\n    'transfer-encoding': 'chunked',\n    'connection': 'close',\n    'server': 'nginx/1.0.4',\n    'x-runtime': '148ms',\n    'etag': '\"e1ca502697e5c9317743dc078f67693f\"',\n    'content-type': 'application/json'\n}\n```\n\n### Cookie\n\n`r.cookies`\n```python\ncookies = dict(cookies_are='working')\nr = requests.get(url, cookies=cookies)\n```\n\nCookie 的返回对象为 RequestsCookieJar，它的行为和字典类似，但接口更为完整，适合跨域名跨路径使用。你还可以把 Cookie Jar 传到 Requests 中：\n\n```python\njar = requests.cookies.RequestsCookieJar()\njar.set('tasty_cookie', 'yum', domain='httpbin.org', path='/cookies')\nr = requests.get(url, cookies=jar)\n```\n\n### 重定向和请求历史\n\nResponse.history 是一个 Response 对象的列表，为了完成请求而创建了这些对象。这个对象列表按照从最老到最近的请求进行排序。\n\n```python\nr = requests.get(url, allow_redirects=False)\nr.history\n```\n\n### 超时\n\n`r = requests.get(url, timeouts=0.01)`\n\n### 错误与异常\n\n遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出一个 ConnectionError 异常\n\n如果 HTTP 请求返回了不成功的状态码， Response.raise_for_status() 会抛出一个 HTTPError 异常\n\n若请求超时，则抛出一个 Timeout 异常。\n\n若请求超过了设定的最大重定向次数，则会抛出一个 TooManyRedirects 异常。\n\n所有Requests显式抛出的异常都继承自 requests.exceptions.RequestException 。\n","slug":"requests","published":1,"updated":"2018-08-31T03:51:44.175Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oyi001e44voop6urdgo"},{"title":"tensorflow graphs","date":"2018-09-05T09:03:01.000Z","_content":"TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.\n\n### Dataflow\n![](https://tensorflow.google.cn/images/tensors_flowing.gif)\n\nDataflow is a common programming model for parallel computing. In a dataflow graph, the nodes represent units of computation, and the edges represent the data consumed or produced by a computation\n\nDataflow has several advantages that TensorFlow leverages when executing your programs:\n\n * **Parallelism**. By using explicit edges to represent dependencies between operations, it is easy for the system to identify operations that can execute in parallel.\n\n * **Distributed execution**. By using explicit edges to represent the values that flow between operations, it is possible for TensorFlow to partition your program across multiple devices (CPUs, GPUs, and TPUs) attached to different machines. TensorFlow inserts the necessary communication and coordination between devices.\n\n * **Compilation**. TensorFlow's XLA compiler can use the information in your dataflow graph to generate faster code, for example, by fusing together adjacent operations.\n\n * **Portability**. The dataflow graph is a language-independent representation of the code in your model. You can build a dataflow graph in Python, store it in a SavedModel, and restore it in a C++ program for low-latency inference.\n\n### What is a tf.Graph?\n\n A tf.Graph contains two relevant kinds of information:\n\n  * **Graph structure**. The nodes and edges of the graph, indicating how individual operations are composed together, but not prescribing how they should be used. The graph structure is like assembly code: inspecting it can convey some useful information, but it does not contain all of the useful context that source code conveys.\n\n  * **Graph collections**. TensorFlow provides a general mechanism for storing collections of metadata in a tf.Graph. The **tf.add_to_collection** function enables you to associate a list of objects with a key (where **tf.GraphKeys** defines some of the standard keys), and **tf.get_collection** enables you to look up all objects associated with a key. Many parts of the TensorFlow library use this facility: for example, when you create a tf.Variable, it is added by default to collections representing \"global variables\" and \"trainable variables\". When you later come to create a tf.train.Saver or tf.train.Optimizer, the variables in these collections are used as the default arguments.\n\n### Building a tf.Graph\n\n  Most TensorFlow programs start with a dataflow graph construction phase. In this phase, you invoke TensorFlow API functions that construct new **tf.Operation (node)** and **tf.Tensor (edge)** objects and add them to a **tf.Graph instance**. TensorFlow provides a default graph that is an implicit argument to all API functions in the same context.\n\n### Naming operations\n A tf.Graph object defines a namespace for the tf.Operation objects it contains. TensorFlow automatically chooses a unique name for each operation in your graph, but giving operations descriptive names can make your program easier to read and debug. The TensorFlow API provides two ways to override the name of an operation:\n\n * Each API function that creates a new tf.Operation or returns a new tf.Tensor accepts an optional name argument. For example, tf.constant(42.0, name=\"answer\") creates a new tf.Operation named \"answer\" and returns a tf.Tensor named \"answer:0\". If the default graph already contains an operation named \"answer\", then TensorFlow would append \"\\_1\", \"\\_2\", and so on to the name, in order to make it unique.\n\n * The **tf.name_scope** function makes it possible to add a name scope prefix to all operations created in a particular context. The current name scope prefix is a \"/\"-delimited list of the names of all active tf.name_scope context managers. If a name scope has already been used in the current context, TensorFlow appends \"\\_1\", \"\\_2\", and so on. For example:\n\n```python\n c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n # Already-used names will be \"uniquified\".\n c_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n # Name scopes add a prefix to all operations created in the same context.\n with tf.name_scope(\"outer\"):\n     c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n     # Name scopes nest like paths in a hierarchical file system.\n     with tf.name_scope(\"inner\"):\n         c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n     # Already-used name scopes will be \"uniquified\".\n     with tf.name_scope(\"inner\"):\n         c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\"\n```\n\n### Placing operations on different devices\n\nIf you want your TensorFlow program to use multiple different devices, the tf.device function provides a convenient way to request that all operations created in a particular context are placed on the same device (or type of device).\n\nA device specification has the following form:\n\n    /job:<JOB_NAME>/task:<TASK_INDEX>/device:<DEVICE_TYPE>:<DEVICE_INDEX>\n    where:\n        <JOB_NAME> is an alpha-numeric string that does not start with a number.\n        <DEVICE_TYPE> is a registered device type (such as GPU or CPU).\n        <TASK_INDEX> is a non-negative integer representing the index of the task in the job named <JOB_NAME>. See tf.train.ClusterSpec for an explanation of jobs and tasks.\n        <DEVICE_INDEX> is a non-negative integer representing the index of the device, for example, to distinguish between different GPU devices used in the same process.\n\n```python\n# Operations created outside either context will run on the \"best possible\"\n# device. For example, if you have a GPU and a CPU available, and the operation\n# has a GPU implementation, TensorFlow will choose the GPU.\nweights = tf.random_normal(...)\n\nwith tf.device(\"/device:CPU:0\"):\n  # Operations created in this context will be pinned to the CPU.\n  img = tf.decode_jpeg(tf.read_file(\"img.jpg\"))\n\nwith tf.device(\"/device:GPU:0\"):\n  # Operations created in this context will be pinned to the GPU.\n  result = tf.matmul(weights, img)\n```\n\n### Visualizing your graph\nTensorFlow includes tools that can help you to understand the code in a graph. The graph visualizer is a component of TensorBoard that renders the structure of your graph visually in a browser. The easiest way to create a visualization is to pass a tf.Graph when creating the **tf.summary.FileWriter**:\n\n```python\n# Build your graph.\nx = tf.constant([[37.0, -23.0], [1.0, 4.0]])\nw = tf.Variable(tf.random_uniform([2, 2]))\ny = tf.matmul(x, w)\n# ...\nloss = ...\ntrain_op = tf.train.AdagradOptimizer(0.01).minimize(loss)\n\nwith tf.Session() as sess:\n  writer = tf.summary.FileWriter(\"/tmp/log/...\", sess.graph)\n  # Perform your computation...\n  for i in range(1000):\n    sess.run(train_op)\n    # ...\n  writer.close()\n```\n\n### Programming with multiple graphs\n\nYou can install a different tf.Graph as the default graph, using the tf.Graph.as_default context manager:\n```python\ng_1 = tf.Graph()\nwith g_1.as_default():\n  # Operations created in this scope will be added to `g_1`.\n  c = tf.constant(\"Node in g_1\")\n  # Sessions created in this scope will run operations from `g_1`.\n  sess_1 = tf.Session()\n\ng_2 = tf.Graph()\nwith g_2.as_default():\n  # Operations created in this scope will be added to `g_2`.\n  d = tf.constant(\"Node in g_2\")\n\n# `sess_2` will run operations from `g_2`.\nsess_2 = tf.Session(graph=g_2)\n\nassert c.graph is g_1\nassert sess_1.graph is g_1\n\nassert d.graph is g_2\nassert sess_2.graph is g_2\n```\n\nTo inspect the current default graph, call tf.get_default_graph, which returns a tf.Graph object:\n```python\n# Print all of the operations in the default graph.\ng = tf.get_default_graph()\nprint(g.get_operations())\n```\n","source":"_posts/tensorflow-graphs.md","raw":"---\ntitle: tensorflow graphs\ndate: 2018-09-05 17:03:01\ntags: tensorflow_python_API\ncategories: Tensorflow\n---\nTensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.\n\n### Dataflow\n![](https://tensorflow.google.cn/images/tensors_flowing.gif)\n\nDataflow is a common programming model for parallel computing. In a dataflow graph, the nodes represent units of computation, and the edges represent the data consumed or produced by a computation\n\nDataflow has several advantages that TensorFlow leverages when executing your programs:\n\n * **Parallelism**. By using explicit edges to represent dependencies between operations, it is easy for the system to identify operations that can execute in parallel.\n\n * **Distributed execution**. By using explicit edges to represent the values that flow between operations, it is possible for TensorFlow to partition your program across multiple devices (CPUs, GPUs, and TPUs) attached to different machines. TensorFlow inserts the necessary communication and coordination between devices.\n\n * **Compilation**. TensorFlow's XLA compiler can use the information in your dataflow graph to generate faster code, for example, by fusing together adjacent operations.\n\n * **Portability**. The dataflow graph is a language-independent representation of the code in your model. You can build a dataflow graph in Python, store it in a SavedModel, and restore it in a C++ program for low-latency inference.\n\n### What is a tf.Graph?\n\n A tf.Graph contains two relevant kinds of information:\n\n  * **Graph structure**. The nodes and edges of the graph, indicating how individual operations are composed together, but not prescribing how they should be used. The graph structure is like assembly code: inspecting it can convey some useful information, but it does not contain all of the useful context that source code conveys.\n\n  * **Graph collections**. TensorFlow provides a general mechanism for storing collections of metadata in a tf.Graph. The **tf.add_to_collection** function enables you to associate a list of objects with a key (where **tf.GraphKeys** defines some of the standard keys), and **tf.get_collection** enables you to look up all objects associated with a key. Many parts of the TensorFlow library use this facility: for example, when you create a tf.Variable, it is added by default to collections representing \"global variables\" and \"trainable variables\". When you later come to create a tf.train.Saver or tf.train.Optimizer, the variables in these collections are used as the default arguments.\n\n### Building a tf.Graph\n\n  Most TensorFlow programs start with a dataflow graph construction phase. In this phase, you invoke TensorFlow API functions that construct new **tf.Operation (node)** and **tf.Tensor (edge)** objects and add them to a **tf.Graph instance**. TensorFlow provides a default graph that is an implicit argument to all API functions in the same context.\n\n### Naming operations\n A tf.Graph object defines a namespace for the tf.Operation objects it contains. TensorFlow automatically chooses a unique name for each operation in your graph, but giving operations descriptive names can make your program easier to read and debug. The TensorFlow API provides two ways to override the name of an operation:\n\n * Each API function that creates a new tf.Operation or returns a new tf.Tensor accepts an optional name argument. For example, tf.constant(42.0, name=\"answer\") creates a new tf.Operation named \"answer\" and returns a tf.Tensor named \"answer:0\". If the default graph already contains an operation named \"answer\", then TensorFlow would append \"\\_1\", \"\\_2\", and so on to the name, in order to make it unique.\n\n * The **tf.name_scope** function makes it possible to add a name scope prefix to all operations created in a particular context. The current name scope prefix is a \"/\"-delimited list of the names of all active tf.name_scope context managers. If a name scope has already been used in the current context, TensorFlow appends \"\\_1\", \"\\_2\", and so on. For example:\n\n```python\n c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n # Already-used names will be \"uniquified\".\n c_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n # Name scopes add a prefix to all operations created in the same context.\n with tf.name_scope(\"outer\"):\n     c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n     # Name scopes nest like paths in a hierarchical file system.\n     with tf.name_scope(\"inner\"):\n         c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n     # Already-used name scopes will be \"uniquified\".\n     with tf.name_scope(\"inner\"):\n         c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\"\n```\n\n### Placing operations on different devices\n\nIf you want your TensorFlow program to use multiple different devices, the tf.device function provides a convenient way to request that all operations created in a particular context are placed on the same device (or type of device).\n\nA device specification has the following form:\n\n    /job:<JOB_NAME>/task:<TASK_INDEX>/device:<DEVICE_TYPE>:<DEVICE_INDEX>\n    where:\n        <JOB_NAME> is an alpha-numeric string that does not start with a number.\n        <DEVICE_TYPE> is a registered device type (such as GPU or CPU).\n        <TASK_INDEX> is a non-negative integer representing the index of the task in the job named <JOB_NAME>. See tf.train.ClusterSpec for an explanation of jobs and tasks.\n        <DEVICE_INDEX> is a non-negative integer representing the index of the device, for example, to distinguish between different GPU devices used in the same process.\n\n```python\n# Operations created outside either context will run on the \"best possible\"\n# device. For example, if you have a GPU and a CPU available, and the operation\n# has a GPU implementation, TensorFlow will choose the GPU.\nweights = tf.random_normal(...)\n\nwith tf.device(\"/device:CPU:0\"):\n  # Operations created in this context will be pinned to the CPU.\n  img = tf.decode_jpeg(tf.read_file(\"img.jpg\"))\n\nwith tf.device(\"/device:GPU:0\"):\n  # Operations created in this context will be pinned to the GPU.\n  result = tf.matmul(weights, img)\n```\n\n### Visualizing your graph\nTensorFlow includes tools that can help you to understand the code in a graph. The graph visualizer is a component of TensorBoard that renders the structure of your graph visually in a browser. The easiest way to create a visualization is to pass a tf.Graph when creating the **tf.summary.FileWriter**:\n\n```python\n# Build your graph.\nx = tf.constant([[37.0, -23.0], [1.0, 4.0]])\nw = tf.Variable(tf.random_uniform([2, 2]))\ny = tf.matmul(x, w)\n# ...\nloss = ...\ntrain_op = tf.train.AdagradOptimizer(0.01).minimize(loss)\n\nwith tf.Session() as sess:\n  writer = tf.summary.FileWriter(\"/tmp/log/...\", sess.graph)\n  # Perform your computation...\n  for i in range(1000):\n    sess.run(train_op)\n    # ...\n  writer.close()\n```\n\n### Programming with multiple graphs\n\nYou can install a different tf.Graph as the default graph, using the tf.Graph.as_default context manager:\n```python\ng_1 = tf.Graph()\nwith g_1.as_default():\n  # Operations created in this scope will be added to `g_1`.\n  c = tf.constant(\"Node in g_1\")\n  # Sessions created in this scope will run operations from `g_1`.\n  sess_1 = tf.Session()\n\ng_2 = tf.Graph()\nwith g_2.as_default():\n  # Operations created in this scope will be added to `g_2`.\n  d = tf.constant(\"Node in g_2\")\n\n# `sess_2` will run operations from `g_2`.\nsess_2 = tf.Session(graph=g_2)\n\nassert c.graph is g_1\nassert sess_1.graph is g_1\n\nassert d.graph is g_2\nassert sess_2.graph is g_2\n```\n\nTo inspect the current default graph, call tf.get_default_graph, which returns a tf.Graph object:\n```python\n# Print all of the operations in the default graph.\ng = tf.get_default_graph()\nprint(g.get_operations())\n```\n","slug":"tensorflow-graphs","published":1,"updated":"2018-09-05T09:58:38.618Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oyl001j44vo7ch7isvx"},{"title":"tensorflow session","date":"2018-09-05T09:03:16.000Z","_content":"### Executing a graph in a tf.Session\nTensorFlow uses the tf.Session class to represent a connection between the client program---typically a Python program, although a similar interface is available in other languages---and the C++ runtime. A tf.Session object provides access to devices in the local machine, and remote devices using the distributed TensorFlow runtime. It also caches information about your tf.Graph so that you can efficiently run the same computation multiple times.\n\n### Creating a tf.Session\n\n```python\n# Create a default in-process session.\nwith tf.Session() as sess:\n  # ...\n# Create a remote session.\nwith tf.Session(\"grpc://example.org:2222\"):\n  # ...\n```\n\n### Using tf.Session.run to execute operations\nThe tf.Session.run method is the main mechanism for running a tf.Operation or evaluating a tf.Tensor. You can pass one or more tf.Operation or tf.Tensor objects to tf.Session.run, and TensorFlow will execute the operations that are needed to compute the result.\n\n```python\n# Define a placeholder that expects a vector of three floating-point values,\n# and a computation that depends on it.\nx = tf.placeholder(tf.float32, shape=[3])\ny = tf.square(x)\n\nwith tf.Session() as sess:\n  # Feeding a value changes the result that is returned when you evaluate `y`.\n  print(sess.run(y, {x: [1.0, 2.0, 3.0]}))  # => \"[1.0, 4.0, 9.0]\"\n  print(sess.run(y, {x: [0.0, 0.0, 5.0]}))  # => \"[0.0, 0.0, 25.0]\"\n ```\n","source":"_posts/tensorflow-session.md","raw":"---\ntitle: tensorflow session\ndate: 2018-09-05 17:03:16\ntags: tensorflow_python_API\ncategories: Tensorflow\n---\n### Executing a graph in a tf.Session\nTensorFlow uses the tf.Session class to represent a connection between the client program---typically a Python program, although a similar interface is available in other languages---and the C++ runtime. A tf.Session object provides access to devices in the local machine, and remote devices using the distributed TensorFlow runtime. It also caches information about your tf.Graph so that you can efficiently run the same computation multiple times.\n\n### Creating a tf.Session\n\n```python\n# Create a default in-process session.\nwith tf.Session() as sess:\n  # ...\n# Create a remote session.\nwith tf.Session(\"grpc://example.org:2222\"):\n  # ...\n```\n\n### Using tf.Session.run to execute operations\nThe tf.Session.run method is the main mechanism for running a tf.Operation or evaluating a tf.Tensor. You can pass one or more tf.Operation or tf.Tensor objects to tf.Session.run, and TensorFlow will execute the operations that are needed to compute the result.\n\n```python\n# Define a placeholder that expects a vector of three floating-point values,\n# and a computation that depends on it.\nx = tf.placeholder(tf.float32, shape=[3])\ny = tf.square(x)\n\nwith tf.Session() as sess:\n  # Feeding a value changes the result that is returned when you evaluate `y`.\n  print(sess.run(y, {x: [1.0, 2.0, 3.0]}))  # => \"[1.0, 4.0, 9.0]\"\n  print(sess.run(y, {x: [0.0, 0.0, 5.0]}))  # => \"[0.0, 0.0, 25.0]\"\n ```\n","slug":"tensorflow-session","published":1,"updated":"2018-09-05T09:26:00.927Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oyn001m44vo39nls8l9"},{"title":"tensorflow variable","date":"2018-09-05T02:50:55.000Z","_content":"A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.\n\n### Create a variable\n\n```python\nmy_int_variable = tf.get_variable(\"my_int_variable\", [1, 2, 3], dtype=tf.int32,\n  initializer=tf.zeros_initializer)\n```\n\n**tf.get_variable**\n\n* 构造函数\n    ```python\n    tf.get_variable(\n    name,\n    shape=None,\n    dtype=None,\n    initializer=None,\n    regularizer=None,\n    trainable=None,\n    collections=None,\n    caching_device=None,\n    partitioner=None,\n    validate_shape=True,\n    use_resource=None,\n    custom_getter=None,\n    constraint=None,\n    synchronization=tf.VariableSynchronization.AUTO,\n    aggregation=tf.VariableAggregation.NONE\n    )\n    ```\n\n* **initializer:** Initializer for the variable if one is created. Can either be an initializer object or a Tensor. If it's a Tensor, its shape must be known unless validate_shape is False.\n\n* **regularizer:** A (Tensor -> Tensor or None) function; the result of applying it on a newly created variable will be added to the collection *tf.GraphKeys.REGULARIZATION_LOSSES* and can be used for regularization.\n\n* **trainable:** If True also add the variable to the graph collection *GraphKeys.TRAINABLE_VARIABLES* (see tf.Variable). collections: List of graph collections keys to add the Variable to. Defaults to *[GraphKeys.GLOBAL_VARIABLES]* (see tf.Variable).\n\n### Variable collections\n\nBecause disconnected parts of a TensorFlow program might want to create variables, it is sometimes useful to have a single way to access all of them.For this reason TensorFlow provides collections, which are named lists of tensors or other objects, such as tf.Variable instances\n\nBy default every tf.Variable gets placed in the following two collections:\n\n    tf.GraphKeys.GLOBAL_VARIABLES --- variables that can be shared across multiple devices,\n    tf.GraphKeys.TRAINABLE_VARIABLES --- variables for which TensorFlow will calculate gradients.\n\nIf you don't want a variable to be trainable, add it to the **tf.GraphKeys.LOCAL_VARIABLES** collection instead.\n\n```python\nmy_local = tf.get_variable(\"my_local\", shape=(),\ncollections=[tf.GraphKeys.LOCAL_VARIABLES])\n\nmy_non_trainable = tf.get_variable(\"my_non_trainable\",\n                                   shape=(),\n                                   trainable=False)\n\ntf.add_to_collection(\"my_collection_name\", my_local)\n#  retrieve a list of all the variables\ntf.get_collection(\"my_collection_name\")                               \n```\n\n### Initializing variables\n\nTo initialize all trainable variables in one go, before training starts, call **tf.global_variables_initializer()**. This function returns a single operation responsible for initializing all variables in the **tf.GraphKeys.GLOBAL_VARIABLES** collection.\n\n```python\nsession.run(tf.global_variables_initializer())\n# Now all variables are initialized.\nsession.run(my_variable.initializer)\n```\n\nNote that by default tf.global_variables_initializer does not specify the order in which variables are initialized. Therefore, if the initial value of a variable depends on another variable's value, it's likely that you'll get an error. Any time you use the value of a variable in a context in which not all variables are initialized (say, if you use a variable's value while initializing another variable), it is best to use **variable.initialized_value()** instead of variable:\n\n```python\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n```\n\n### Using variable\n\nTo use the value of a tf.Variable in a TensorFlow graph, simply treat it like a normal tf.Tensor:\n\n```python\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n           # Any time a variable is used in an expression it gets automatically\n           # converted to a tf.Tensor representing its value.\n```\n\n### Sharing variables\n\nTensorFlow supports two ways of sharing variables:\n\n    Explicitly passing tf.Variable objects around.\n    Implicitly wrapping tf.Variable objects within tf.variable_scope objects.\n\nVariable scopes allow you to control variable reuse when calling functions which implicitly create and use variables. They also allow you to name your variables in a hierarchical and understandable way.\n\n```python\ndef conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name, padding='SAME'):\n    # Get number of input channels\n    input_channels = int(x.get_shape()[-1])\n    # create lambda function for the convolution\n    convolve = lambda i, k: tf.nn.conv2d(i, k, strides=[1, stride_y, stride_x, 1], padding=padding)\n    with tf.variable_scope(name) as scope:\n        weights = tf.get_variable('weights', shape=[filter_height, filter_width, input_channels, num_filters])\n        biases = tf.get_variable('biases', shape=[num_filters])\n        conv = convolve(x, weights)\n        bias = tf.reshape(tf.nn.bias_add(conv, biases))\n        # Apply relu function\n        relu = tf.nn.relu(bias, name=scope.name)\n        return relu\n```\n","source":"_posts/tensorflow-variable.md","raw":"---\ntitle: tensorflow variable\ndate: 2018-09-05 10:50:55\ntags: tensorflow_python_API\ncategories: Tensorflow\n---\nA TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.\n\n### Create a variable\n\n```python\nmy_int_variable = tf.get_variable(\"my_int_variable\", [1, 2, 3], dtype=tf.int32,\n  initializer=tf.zeros_initializer)\n```\n\n**tf.get_variable**\n\n* 构造函数\n    ```python\n    tf.get_variable(\n    name,\n    shape=None,\n    dtype=None,\n    initializer=None,\n    regularizer=None,\n    trainable=None,\n    collections=None,\n    caching_device=None,\n    partitioner=None,\n    validate_shape=True,\n    use_resource=None,\n    custom_getter=None,\n    constraint=None,\n    synchronization=tf.VariableSynchronization.AUTO,\n    aggregation=tf.VariableAggregation.NONE\n    )\n    ```\n\n* **initializer:** Initializer for the variable if one is created. Can either be an initializer object or a Tensor. If it's a Tensor, its shape must be known unless validate_shape is False.\n\n* **regularizer:** A (Tensor -> Tensor or None) function; the result of applying it on a newly created variable will be added to the collection *tf.GraphKeys.REGULARIZATION_LOSSES* and can be used for regularization.\n\n* **trainable:** If True also add the variable to the graph collection *GraphKeys.TRAINABLE_VARIABLES* (see tf.Variable). collections: List of graph collections keys to add the Variable to. Defaults to *[GraphKeys.GLOBAL_VARIABLES]* (see tf.Variable).\n\n### Variable collections\n\nBecause disconnected parts of a TensorFlow program might want to create variables, it is sometimes useful to have a single way to access all of them.For this reason TensorFlow provides collections, which are named lists of tensors or other objects, such as tf.Variable instances\n\nBy default every tf.Variable gets placed in the following two collections:\n\n    tf.GraphKeys.GLOBAL_VARIABLES --- variables that can be shared across multiple devices,\n    tf.GraphKeys.TRAINABLE_VARIABLES --- variables for which TensorFlow will calculate gradients.\n\nIf you don't want a variable to be trainable, add it to the **tf.GraphKeys.LOCAL_VARIABLES** collection instead.\n\n```python\nmy_local = tf.get_variable(\"my_local\", shape=(),\ncollections=[tf.GraphKeys.LOCAL_VARIABLES])\n\nmy_non_trainable = tf.get_variable(\"my_non_trainable\",\n                                   shape=(),\n                                   trainable=False)\n\ntf.add_to_collection(\"my_collection_name\", my_local)\n#  retrieve a list of all the variables\ntf.get_collection(\"my_collection_name\")                               \n```\n\n### Initializing variables\n\nTo initialize all trainable variables in one go, before training starts, call **tf.global_variables_initializer()**. This function returns a single operation responsible for initializing all variables in the **tf.GraphKeys.GLOBAL_VARIABLES** collection.\n\n```python\nsession.run(tf.global_variables_initializer())\n# Now all variables are initialized.\nsession.run(my_variable.initializer)\n```\n\nNote that by default tf.global_variables_initializer does not specify the order in which variables are initialized. Therefore, if the initial value of a variable depends on another variable's value, it's likely that you'll get an error. Any time you use the value of a variable in a context in which not all variables are initialized (say, if you use a variable's value while initializing another variable), it is best to use **variable.initialized_value()** instead of variable:\n\n```python\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n```\n\n### Using variable\n\nTo use the value of a tf.Variable in a TensorFlow graph, simply treat it like a normal tf.Tensor:\n\n```python\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n           # Any time a variable is used in an expression it gets automatically\n           # converted to a tf.Tensor representing its value.\n```\n\n### Sharing variables\n\nTensorFlow supports two ways of sharing variables:\n\n    Explicitly passing tf.Variable objects around.\n    Implicitly wrapping tf.Variable objects within tf.variable_scope objects.\n\nVariable scopes allow you to control variable reuse when calling functions which implicitly create and use variables. They also allow you to name your variables in a hierarchical and understandable way.\n\n```python\ndef conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name, padding='SAME'):\n    # Get number of input channels\n    input_channels = int(x.get_shape()[-1])\n    # create lambda function for the convolution\n    convolve = lambda i, k: tf.nn.conv2d(i, k, strides=[1, stride_y, stride_x, 1], padding=padding)\n    with tf.variable_scope(name) as scope:\n        weights = tf.get_variable('weights', shape=[filter_height, filter_width, input_channels, num_filters])\n        biases = tf.get_variable('biases', shape=[num_filters])\n        conv = convolve(x, weights)\n        bias = tf.reshape(tf.nn.bias_add(conv, biases))\n        # Apply relu function\n        relu = tf.nn.relu(bias, name=scope.name)\n        return relu\n```\n","slug":"tensorflow-variable","published":1,"updated":"2018-09-05T09:57:29.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oyq001r44vo73bfobfy"},{"title":"人生--路遥","date":"2018-07-19T15:20:58.000Z","_content":"\n### 故事梗概\n\n小说以改革时期陕北高原的城乡生活为时空背景，描写了高中毕业生高加林回到土地又离开土地，再离开土地，再回到土地这样人生的变化过程构成了其故事构架。高加林同农村姑娘刘巧珍，城市姑娘黄亚萍之间的感情纠葛构成了故事发展的矛盾，也正是体现那种艰难选择的悲剧。\n\n### 内容简介\n\n#### 回到土地\n\n主人公是高加林，他高中毕业回到村里后当上了民办小学的教师，很满足这个既能体现他的才能而又对他充满希望的职业，但是好景不长，他就被有权有势的大队书记高明楼的儿子顶替了，他重新回到了土地。正当他失意无奈，甚至有些绝望的时候，善良美丽的农村姑娘刘巧珍闯进了他的生活，刘巧珍虽然没有文化，但是却真心真意地爱上了高加林这个\n“文化人”，她的爱质朴纯真，她以她的那种充满激情而又实际的作法表白了她的炽烈的爱。而实际上她所得到的爱从一开始就是不平等，高加林在她的眼中是完美的，而她对于高加林来说只是在他失意时找到了精神上的慰藉。当机遇再次降临到了高加林身上，他终于抓住了这次机会，重新回到了城市。\n\n#### 离开土地\n\n城市生活给了高加林大显身手的机会，又让他重新遇到了他的同学黄亚萍。与巧珍相比，黄亚萍无疑是位现代女性，她开朗活泼，却又任性专横，她对高加林的爱炽烈大胆又有一种征服欲。高加林的确与她有许多相似的地方，他们有相同的知识背景，又有许多感兴趣的话题，当他们俩口若悬河、侃侃而谈时，高加林已经进入了一种艰难的选择之中。当高加林隐隐地有了这种想法时，他的念头很快便被另一种感情压下去了，他想起了巧珍那亲切可爱的脸庞，想起了巧珍那种无私而温柔的爱。当巧珍带着狗皮褥子来看他时，巧珍去县城看了好几次加林，加林都有事下乡采访了，终于有一次他俩有机会见面了，加林看到日思夜想的巧珍，心情很是激动，巧珍看他的被褥那么单薄，就说下次去给他带去她自己铺的狗皮褥子，高加林一下子不高兴了，因为城里人没有人用狗皮褥子，而且那狗皮褥子跟他生活的环境一点都不相称，他怕被别人笑话，而当巧珍给他讲的都是些家长里短的小事的时候，他一下子觉得很失落，他跟黄亚萍谈论的都是时事政治、国家大事！那才是他想要的，他的远大抱负。这种反差让高加林很是纠结。他的那种难以言说的复杂的感情一下子表现了出来。在经过反复考虑后，他接受了黄亚萍的爱，可同时意味着这种选择会无情地伤害巧珍，当他委婉地对巧珍表达了他的这种选择后，巧珍含泪接受了，但她却并没有过多地责怪高加林，反而更担心高加林以后的生活，劝他到外地多操心。但是泪水却在她脸上刷刷地淌着。\n\n#### 回到土地\n\n但是好梦难圆，高加林通过关系得到城内工作这件事终于被人告发了，他要面对的是重新回到生他养他的那片土地，他所有的理想和抱负如同过眼云烟难以挽留了。难以承受的是这份打击更难以面对的是生他养他的那片土地，（他本以为村里人都等着看他的笑话呢！可他万万没想到，当他灰头土脸地出现在家乡人面前的时候，家乡人给他的是各种安慰的话语，他感动的不知说什么了，只是拿出他随身带着的烟散给乡亲们。而此时他也得知巧珍已嫁作他人妇，即便如此，她依然去求她姐姐的公公、村支书——高明楼，求他给高加林安排去教学，因为据说家乡的那所学校因为学生增多要新添一个老师。德顺爷爷感慨地说道：“多好的娃娃啊！”此时的高加林已经泣不成声，趴在热情的乡土上大声痛苦......）他褪去了骄傲，认清了现实，接受了德顺爷爷的一番话，而后懊悔的扑倒在了地上。\n\n### 创作背景\n\n20世纪80年代的中国，商品经济的活跃打破了农村的僵持与保守，具有现代文明的城市开始对一直困守在土地的农民产生强烈的诱惑。特别是在青年心中引起巨大的骚动，他们开始对自己的生活及周围的世界产生怀疑与不满。\n\n20世纪80年代，中国户籍制度清晰地将公民分为农业户口和非农业户口，在这种固态格式化的身份制度下，中国社会形成了独特的社会地理景观：乡村景观和城市景观；与这两种景观相对应的是两种截然不同的经济制度和生存方式、文化特征、价值观念。由此导致了中国社会最重要的社会差异；城乡差别。同时，国家还通过各种举措在主观上强化这种差异。臂如在劳动分配制度上，城市工作的工人、教师、职员每月有固定的工资收入，有相对完善的医疗制度、退休制度，同时还可以享受国家各种福利待遇。而在乡村，农民不仅要按时按量向国家交纳粮食，在很长的时期内只能有限度地支配自己的劳动产品。并且，农民还要完成国家规定的各种税费。参与无偿的劳作（例如大规模强制性的农田水利建设）。而国家采取的各种政策将农民强制性地限制在土地上。这些政策的实施直接导致了农民在整个社会发展中长时间处于相对贫困的状态中。因此，可以说在这种基本的身份差异之下，城市和乡村作为两个基本对立的概念被凸显了出来。这是一个作为卑贱农民和一个高贵知识分子的对立，普通百姓和达官显贵的对立。\n\n《人生》就是在城市的场景中展开，似乎一切都处于城市的控制下，甚至乡下人天生就应该在城里人面前低人一等。这种强烈的等级观念、城乡差异在小说中被强化。\n\n当路遥年轻时不停地奔波在城市与乡村时，他最为熟悉的生活即是“城市交叉地带”，充满生气和机遇的城市生活对于像他那样的身处封闭而又贫困的农村知识青年构成了一种双重的刺激，不论在物质还是在精神上。路遥思考并理解了这一现象，在城市化的浪潮汹涌而来的种种冲击中，他提出了农村知识青年该如何做出选择。\n\n早在大学读书时，路遥阅读了大量的经典名著，并对新中国的文学成就进行了一翻巡视。他发现以前的小说带有某种脸谱化的倾向，正如儿童眼中将电影中的人物形象简单分为“好人”和“坏蛋“，而人的思想是复杂的、多变的，绝对不能将复杂的人性这样简单的划分，这种思考体现在《人生》的主人公高加林身上。\n\n### 人物介绍\n\n#### 高加林\n\n高加林是作者着力塑造的复杂的人物。他身上既体现了现代青年那种不断向命运挑战，自信坚毅的品质，又同时具有辛勤、朴实的传统美德。他热爱生活，心性极高，有着远大的理想和抱负。关心国际问题，爱好打篮球，并融入时代的潮流。他不像他的父亲那样忍气吞声、安守本分，而是有更高的精神追求，但是他的现实与他心中的理想总是相差极远，正是这样反差构成了他的复杂的性格特征。\n\n#### 刘巧珍\n\n巧珍美丽善良，爱情真诚。但她把自己置于高加林的附属地位，理想之光幻灭后，她以无爱的婚姻表示对命运的抗争，恰恰重陷传统道德观念的桎梏。\n\n---\n摘自《百度百科词条：人生》\n","source":"_posts/人生-路遥.md","raw":"---\ntitle: 人生--路遥\ndate: 2018-07-19 23:20:58\ntags: 路遥\ncategories: 文学\n---\n\n### 故事梗概\n\n小说以改革时期陕北高原的城乡生活为时空背景，描写了高中毕业生高加林回到土地又离开土地，再离开土地，再回到土地这样人生的变化过程构成了其故事构架。高加林同农村姑娘刘巧珍，城市姑娘黄亚萍之间的感情纠葛构成了故事发展的矛盾，也正是体现那种艰难选择的悲剧。\n\n### 内容简介\n\n#### 回到土地\n\n主人公是高加林，他高中毕业回到村里后当上了民办小学的教师，很满足这个既能体现他的才能而又对他充满希望的职业，但是好景不长，他就被有权有势的大队书记高明楼的儿子顶替了，他重新回到了土地。正当他失意无奈，甚至有些绝望的时候，善良美丽的农村姑娘刘巧珍闯进了他的生活，刘巧珍虽然没有文化，但是却真心真意地爱上了高加林这个\n“文化人”，她的爱质朴纯真，她以她的那种充满激情而又实际的作法表白了她的炽烈的爱。而实际上她所得到的爱从一开始就是不平等，高加林在她的眼中是完美的，而她对于高加林来说只是在他失意时找到了精神上的慰藉。当机遇再次降临到了高加林身上，他终于抓住了这次机会，重新回到了城市。\n\n#### 离开土地\n\n城市生活给了高加林大显身手的机会，又让他重新遇到了他的同学黄亚萍。与巧珍相比，黄亚萍无疑是位现代女性，她开朗活泼，却又任性专横，她对高加林的爱炽烈大胆又有一种征服欲。高加林的确与她有许多相似的地方，他们有相同的知识背景，又有许多感兴趣的话题，当他们俩口若悬河、侃侃而谈时，高加林已经进入了一种艰难的选择之中。当高加林隐隐地有了这种想法时，他的念头很快便被另一种感情压下去了，他想起了巧珍那亲切可爱的脸庞，想起了巧珍那种无私而温柔的爱。当巧珍带着狗皮褥子来看他时，巧珍去县城看了好几次加林，加林都有事下乡采访了，终于有一次他俩有机会见面了，加林看到日思夜想的巧珍，心情很是激动，巧珍看他的被褥那么单薄，就说下次去给他带去她自己铺的狗皮褥子，高加林一下子不高兴了，因为城里人没有人用狗皮褥子，而且那狗皮褥子跟他生活的环境一点都不相称，他怕被别人笑话，而当巧珍给他讲的都是些家长里短的小事的时候，他一下子觉得很失落，他跟黄亚萍谈论的都是时事政治、国家大事！那才是他想要的，他的远大抱负。这种反差让高加林很是纠结。他的那种难以言说的复杂的感情一下子表现了出来。在经过反复考虑后，他接受了黄亚萍的爱，可同时意味着这种选择会无情地伤害巧珍，当他委婉地对巧珍表达了他的这种选择后，巧珍含泪接受了，但她却并没有过多地责怪高加林，反而更担心高加林以后的生活，劝他到外地多操心。但是泪水却在她脸上刷刷地淌着。\n\n#### 回到土地\n\n但是好梦难圆，高加林通过关系得到城内工作这件事终于被人告发了，他要面对的是重新回到生他养他的那片土地，他所有的理想和抱负如同过眼云烟难以挽留了。难以承受的是这份打击更难以面对的是生他养他的那片土地，（他本以为村里人都等着看他的笑话呢！可他万万没想到，当他灰头土脸地出现在家乡人面前的时候，家乡人给他的是各种安慰的话语，他感动的不知说什么了，只是拿出他随身带着的烟散给乡亲们。而此时他也得知巧珍已嫁作他人妇，即便如此，她依然去求她姐姐的公公、村支书——高明楼，求他给高加林安排去教学，因为据说家乡的那所学校因为学生增多要新添一个老师。德顺爷爷感慨地说道：“多好的娃娃啊！”此时的高加林已经泣不成声，趴在热情的乡土上大声痛苦......）他褪去了骄傲，认清了现实，接受了德顺爷爷的一番话，而后懊悔的扑倒在了地上。\n\n### 创作背景\n\n20世纪80年代的中国，商品经济的活跃打破了农村的僵持与保守，具有现代文明的城市开始对一直困守在土地的农民产生强烈的诱惑。特别是在青年心中引起巨大的骚动，他们开始对自己的生活及周围的世界产生怀疑与不满。\n\n20世纪80年代，中国户籍制度清晰地将公民分为农业户口和非农业户口，在这种固态格式化的身份制度下，中国社会形成了独特的社会地理景观：乡村景观和城市景观；与这两种景观相对应的是两种截然不同的经济制度和生存方式、文化特征、价值观念。由此导致了中国社会最重要的社会差异；城乡差别。同时，国家还通过各种举措在主观上强化这种差异。臂如在劳动分配制度上，城市工作的工人、教师、职员每月有固定的工资收入，有相对完善的医疗制度、退休制度，同时还可以享受国家各种福利待遇。而在乡村，农民不仅要按时按量向国家交纳粮食，在很长的时期内只能有限度地支配自己的劳动产品。并且，农民还要完成国家规定的各种税费。参与无偿的劳作（例如大规模强制性的农田水利建设）。而国家采取的各种政策将农民强制性地限制在土地上。这些政策的实施直接导致了农民在整个社会发展中长时间处于相对贫困的状态中。因此，可以说在这种基本的身份差异之下，城市和乡村作为两个基本对立的概念被凸显了出来。这是一个作为卑贱农民和一个高贵知识分子的对立，普通百姓和达官显贵的对立。\n\n《人生》就是在城市的场景中展开，似乎一切都处于城市的控制下，甚至乡下人天生就应该在城里人面前低人一等。这种强烈的等级观念、城乡差异在小说中被强化。\n\n当路遥年轻时不停地奔波在城市与乡村时，他最为熟悉的生活即是“城市交叉地带”，充满生气和机遇的城市生活对于像他那样的身处封闭而又贫困的农村知识青年构成了一种双重的刺激，不论在物质还是在精神上。路遥思考并理解了这一现象，在城市化的浪潮汹涌而来的种种冲击中，他提出了农村知识青年该如何做出选择。\n\n早在大学读书时，路遥阅读了大量的经典名著，并对新中国的文学成就进行了一翻巡视。他发现以前的小说带有某种脸谱化的倾向，正如儿童眼中将电影中的人物形象简单分为“好人”和“坏蛋“，而人的思想是复杂的、多变的，绝对不能将复杂的人性这样简单的划分，这种思考体现在《人生》的主人公高加林身上。\n\n### 人物介绍\n\n#### 高加林\n\n高加林是作者着力塑造的复杂的人物。他身上既体现了现代青年那种不断向命运挑战，自信坚毅的品质，又同时具有辛勤、朴实的传统美德。他热爱生活，心性极高，有着远大的理想和抱负。关心国际问题，爱好打篮球，并融入时代的潮流。他不像他的父亲那样忍气吞声、安守本分，而是有更高的精神追求，但是他的现实与他心中的理想总是相差极远，正是这样反差构成了他的复杂的性格特征。\n\n#### 刘巧珍\n\n巧珍美丽善良，爱情真诚。但她把自己置于高加林的附属地位，理想之光幻灭后，她以无爱的婚姻表示对命运的抗争，恰恰重陷传统道德观念的桎梏。\n\n---\n摘自《百度百科词条：人生》\n","slug":"人生-路遥","published":1,"updated":"2018-08-31T03:48:13.715Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oys001u44voq4j1b3f3"},{"title":"人脸识别","date":"2018-09-02T13:13:33.000Z","mathjax":true,"_content":"**人脸验证（Face Verification）** 和 **人脸识别（Face Recognition）** 的区别：\n\n* 人脸验证：一般指一个一对一问题，只需要验证输入的人脸图像是否与某个已知的身份信息对应；\n* 人脸识别：一个更为复杂的一对多问题，需要验证输入的人脸图像是否与多个已知身份信息中的某一个匹配。\n\n一般来说，由于需要匹配的身份信息更多导致错误率增加，人脸识别比人脸验证更难一些。\n\n### One-Shot 学习\n\n人脸识别所面临的一个挑战是要求系统只采集某人的一个面部样本，就能快速准确地识别出这个人，即只用一个训练样本来获得准确的预测结果。这被称为 **One-Shot 学习**。\n\n有一种方法是假设数据库中存有 N 个人的身份信息，对于每张输入图像，用 Softmax 输出 N+1 种标签，分别对应每个人以及都不是。然而这种方法的实际效果很差，因为过小的训练集不足以训练出一个稳健的神经网络；并且如果有新的身份信息入库，需要重新训练神经网络，不够灵活。\n\n因此，我们通过学习一个 Similarity 函数来实现 One-Shot 学习过程。Similarity 函数定义了输入的两幅图像的差异度，其公式如下：\n\n$$Similarity  = d(img1, img2)$$\n\n可以设置一个超参数 $τ$ 作为阈值，作为判断两幅图片是否为同一个人的依据。\n\n### Siamese 网络\n\n实现 Similarity 函数的一种方式是使用 **Siamese 网络**，它是一种对两个不同输入运行相同的卷积网络，然后对它们的结果进行比较的神经网络。\n\n![Siamese](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Siamese.png)\n\n如上图示例，将图片 $x^{(1)}$、$x^{(2)}$ 分别输入两个相同的卷积网络中，经过全连接层后不再进行 Softmax，而是得到特征向量 $f(x^{(1)})$、$f(x^{(2)})$。这时，Similarity 函数就被定义为两个特征向量之差的 L2 范数：\n\n$$d(x^{(1)}, x^{(2)}) = ||f(x^{(1)}) - f(x^{(2)})||^2_2$$\n\n相关论文：[Taigman et al., 2014, DeepFace closing the gap to human level performance](http://www.cs.wayne.edu/~mdong/taigman_cvpr14.pdf)\n\n### Triplet 损失\n\n**Triplet 损失函数** 用于训练出合适的参数，以获得高质量的人脸图像编码。“Triplet”一词来源于训练这个神经网络需要大量包含 Anchor（靶目标）、Positive（正例）、Negative（反例）的图片组，其中 Anchor 和 Positive 需要是同一个人的人脸图像。\n\n![Training-set-using-triplet-loss](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Training-set-using-triplet-loss.png)\n\n对于这三张图片，应该有：\n\n$$||f(A) - f(P)||^2_2 + \\alpha \\le ||f(A) - f(N)||^2_2$$\n\n其中，$\\alpha$ 被称为 **间隔（margin）**，用于确保 $f()$ 不会总是输出零向量（或者一个恒定的值）。\n\nTriplet 损失函数的定义：\n\n$$L(A, P, N) = max(||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha, 0)$$\n\n其中，因为 $||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha$ 的值需要小于等于 0，因此取它和 0 的更大值。\n\n对于大小为 $m$ 的训练集，代价函数为：\n\n$$J = \\sum^m_{i=1}L(A^{(i)}, P^{(i)}, N^{(i)})$$\n\n通过梯度下降最小化代价函数。\n\n在选择训练样本时，随机选择容易使 Anchor 和 Positive 极为接近，而 Anchor 和 Negative 相差较大，以致训练出来的模型容易抓不到关键的区别。因此，最好的做法是人为增加 Anchor 和 Positive 的区别，缩小 Anchor 和 Negative 的区别，促使模型去学习不同人脸之间的关键差异。\n\n相关论文：[Schroff et al., 2015,  FaceNet: A unified embedding for face recognition and clustering](https://arxiv.org/pdf/1503.03832.pdf)\n\n### 二分类结构\n\n除了 Triplet 损失函数，二分类结构也可用于学习参数以解决人脸识别问题。其做法是输入一对图片，将两个 Siamese 网络产生的特征向量输入至同一个 Sigmoid 单元，输出 1 则表示是识别为同一人，输出 0 则表示识别为不同的人。\n\nSigmoid 单元对应的表达式为：\n$$\\hat y = \\sigma (\\sum^K_{k=1}w_k|f(x^{(i)})\\_{k} - x^{(j)}_{k}| + b)$$\n\n其中，$w_k$ 和 $b$ 都是通过梯度下降算法迭代训练得到的参数。上述计算表达式也可以用另一种表达式代替：\n\n$$\\hat y = \\sigma (\\sum^K_{k=1}w_k\n\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k} + b)$$\n\n其中，$\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k}$ 被称为 $\\chi$ 方相似度。\n\n无论是对于使用 Triplet 损失函数的网络，还是二分类结构，为了减少计算量，可以提前计算好编码输出 $f(x)$ 并保存。这样就不必存储原始图片，并且每次进行人脸识别时只需要计算测试图片的编码输出。\n","source":"_posts/人脸识别.md","raw":"---\ntitle: 人脸识别\ndate: 2018-09-02 21:13:33\ntags: 计算机视觉\ncategories: 深度学习\nmathjax: true\n---\n**人脸验证（Face Verification）** 和 **人脸识别（Face Recognition）** 的区别：\n\n* 人脸验证：一般指一个一对一问题，只需要验证输入的人脸图像是否与某个已知的身份信息对应；\n* 人脸识别：一个更为复杂的一对多问题，需要验证输入的人脸图像是否与多个已知身份信息中的某一个匹配。\n\n一般来说，由于需要匹配的身份信息更多导致错误率增加，人脸识别比人脸验证更难一些。\n\n### One-Shot 学习\n\n人脸识别所面临的一个挑战是要求系统只采集某人的一个面部样本，就能快速准确地识别出这个人，即只用一个训练样本来获得准确的预测结果。这被称为 **One-Shot 学习**。\n\n有一种方法是假设数据库中存有 N 个人的身份信息，对于每张输入图像，用 Softmax 输出 N+1 种标签，分别对应每个人以及都不是。然而这种方法的实际效果很差，因为过小的训练集不足以训练出一个稳健的神经网络；并且如果有新的身份信息入库，需要重新训练神经网络，不够灵活。\n\n因此，我们通过学习一个 Similarity 函数来实现 One-Shot 学习过程。Similarity 函数定义了输入的两幅图像的差异度，其公式如下：\n\n$$Similarity  = d(img1, img2)$$\n\n可以设置一个超参数 $τ$ 作为阈值，作为判断两幅图片是否为同一个人的依据。\n\n### Siamese 网络\n\n实现 Similarity 函数的一种方式是使用 **Siamese 网络**，它是一种对两个不同输入运行相同的卷积网络，然后对它们的结果进行比较的神经网络。\n\n![Siamese](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Siamese.png)\n\n如上图示例，将图片 $x^{(1)}$、$x^{(2)}$ 分别输入两个相同的卷积网络中，经过全连接层后不再进行 Softmax，而是得到特征向量 $f(x^{(1)})$、$f(x^{(2)})$。这时，Similarity 函数就被定义为两个特征向量之差的 L2 范数：\n\n$$d(x^{(1)}, x^{(2)}) = ||f(x^{(1)}) - f(x^{(2)})||^2_2$$\n\n相关论文：[Taigman et al., 2014, DeepFace closing the gap to human level performance](http://www.cs.wayne.edu/~mdong/taigman_cvpr14.pdf)\n\n### Triplet 损失\n\n**Triplet 损失函数** 用于训练出合适的参数，以获得高质量的人脸图像编码。“Triplet”一词来源于训练这个神经网络需要大量包含 Anchor（靶目标）、Positive（正例）、Negative（反例）的图片组，其中 Anchor 和 Positive 需要是同一个人的人脸图像。\n\n![Training-set-using-triplet-loss](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Training-set-using-triplet-loss.png)\n\n对于这三张图片，应该有：\n\n$$||f(A) - f(P)||^2_2 + \\alpha \\le ||f(A) - f(N)||^2_2$$\n\n其中，$\\alpha$ 被称为 **间隔（margin）**，用于确保 $f()$ 不会总是输出零向量（或者一个恒定的值）。\n\nTriplet 损失函数的定义：\n\n$$L(A, P, N) = max(||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha, 0)$$\n\n其中，因为 $||f(A) - f(P)||^2_2 - ||f(A) - f(N)||^2_2 + \\alpha$ 的值需要小于等于 0，因此取它和 0 的更大值。\n\n对于大小为 $m$ 的训练集，代价函数为：\n\n$$J = \\sum^m_{i=1}L(A^{(i)}, P^{(i)}, N^{(i)})$$\n\n通过梯度下降最小化代价函数。\n\n在选择训练样本时，随机选择容易使 Anchor 和 Positive 极为接近，而 Anchor 和 Negative 相差较大，以致训练出来的模型容易抓不到关键的区别。因此，最好的做法是人为增加 Anchor 和 Positive 的区别，缩小 Anchor 和 Negative 的区别，促使模型去学习不同人脸之间的关键差异。\n\n相关论文：[Schroff et al., 2015,  FaceNet: A unified embedding for face recognition and clustering](https://arxiv.org/pdf/1503.03832.pdf)\n\n### 二分类结构\n\n除了 Triplet 损失函数，二分类结构也可用于学习参数以解决人脸识别问题。其做法是输入一对图片，将两个 Siamese 网络产生的特征向量输入至同一个 Sigmoid 单元，输出 1 则表示是识别为同一人，输出 0 则表示识别为不同的人。\n\nSigmoid 单元对应的表达式为：\n$$\\hat y = \\sigma (\\sum^K_{k=1}w_k|f(x^{(i)})\\_{k} - x^{(j)}_{k}| + b)$$\n\n其中，$w_k$ 和 $b$ 都是通过梯度下降算法迭代训练得到的参数。上述计算表达式也可以用另一种表达式代替：\n\n$$\\hat y = \\sigma (\\sum^K_{k=1}w_k\n\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k} + b)$$\n\n其中，$\\frac{(f(x^{(i)})_k - f(x^{(j)})_k)^2}{f(x^{(i)})_k + f(x^{(j)})_k}$ 被称为 $\\chi$ 方相似度。\n\n无论是对于使用 Triplet 损失函数的网络，还是二分类结构，为了减少计算量，可以提前计算好编码输出 $f(x)$ 并保存。这样就不必存储原始图片，并且每次进行人脸识别时只需要计算测试图片的编码输出。\n","slug":"人脸识别","published":1,"updated":"2018-09-05T10:02:01.859Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oyv001y44vob5alyo8u"},{"title":"信息简史","date":"2018-09-17T11:46:41.000Z","_content":">通信的基本问题是，在一点精确地或近似地复现在另一点所选取的讯息。这些讯息往往都带有意义。-- 克劳德.香龙, 《通信的数学理论》\n\n生物体中的所有细胞都是一个错综复杂的通信网络中的节点，它们一刻不停地传输和接受信息，不停地编码和解码。进化本身正是生物体与环境之间持续不断的信息交换的具体表现。\n\n>万物源自比特。(It from Bit)。未来我们将用信息的语言去理解和表达全部物理学。--物理学家约翰.阿奇博尔德.惠勒。\n\n当光子、电子以及其他基本粒子发生相互作用时，它们实际在做什么呢？其实是在交换比特、转换量子态以及处理信息，而物理定律就是处理信息时所用的算法。\n\n\n### 会说话的鼓\n\n在非洲，很早以前的一种通信工具是鼓，人们用鼓来传递消息，每个村庄都有鼓。鼓声沿村庄一个接一个地传递，可以传到很远的地方。为什么他们能听出鼓声所代表的消息呢？这要从非洲语言的核心特点说起。就像汉语一样，非洲语言也是一些声调语言，同一个单词不同的声调会带来不同的读音，也代表着不同的意思。鼓语就是借着这样的特点，将不同的音调转换成高低音的不同来编码口语的。然而有一些词的读音相同但意思不同，这又是怎样区分的呢？这就要考虑上下文的语境了。所以人们在表达一个词时，会加上很多修饰来丰富它的语境。这种 **为避免语言歧义而添加冗余信息** 的例子还在很多地方可见，比如另一种专业化的语言--航空通信的语言。\n\n摩尔斯电码的4个基本元素：点（点击），点击之间的停顿，线（电路的闭合时间比发送一个点更长），停顿（用来间隔词与词，句子与句子）\n\n实际上每一种自然语言都内在地包含冗余，这也是为什么人们可以读懂错别字连篇的文章。“if u cn rd ths, u cn gt a gd jb w hi pa!”\n","source":"_posts/信息简史.md","raw":"---\ntitle: 信息简史\ndate: 2018-09-17 19:46:41\ntags: 信息简史\ncategories: 科普读物\n---\n>通信的基本问题是，在一点精确地或近似地复现在另一点所选取的讯息。这些讯息往往都带有意义。-- 克劳德.香龙, 《通信的数学理论》\n\n生物体中的所有细胞都是一个错综复杂的通信网络中的节点，它们一刻不停地传输和接受信息，不停地编码和解码。进化本身正是生物体与环境之间持续不断的信息交换的具体表现。\n\n>万物源自比特。(It from Bit)。未来我们将用信息的语言去理解和表达全部物理学。--物理学家约翰.阿奇博尔德.惠勒。\n\n当光子、电子以及其他基本粒子发生相互作用时，它们实际在做什么呢？其实是在交换比特、转换量子态以及处理信息，而物理定律就是处理信息时所用的算法。\n\n\n### 会说话的鼓\n\n在非洲，很早以前的一种通信工具是鼓，人们用鼓来传递消息，每个村庄都有鼓。鼓声沿村庄一个接一个地传递，可以传到很远的地方。为什么他们能听出鼓声所代表的消息呢？这要从非洲语言的核心特点说起。就像汉语一样，非洲语言也是一些声调语言，同一个单词不同的声调会带来不同的读音，也代表着不同的意思。鼓语就是借着这样的特点，将不同的音调转换成高低音的不同来编码口语的。然而有一些词的读音相同但意思不同，这又是怎样区分的呢？这就要考虑上下文的语境了。所以人们在表达一个词时，会加上很多修饰来丰富它的语境。这种 **为避免语言歧义而添加冗余信息** 的例子还在很多地方可见，比如另一种专业化的语言--航空通信的语言。\n\n摩尔斯电码的4个基本元素：点（点击），点击之间的停顿，线（电路的闭合时间比发送一个点更长），停顿（用来间隔词与词，句子与句子）\n\n实际上每一种自然语言都内在地包含冗余，这也是为什么人们可以读懂错别字连篇的文章。“if u cn rd ths, u cn gt a gd jb w hi pa!”\n","slug":"信息简史","published":1,"updated":"2018-09-22T03:50:09.092Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oyz002244vo1te5lr90"},{"title":"分治策略","date":"2018-09-08T14:46:06.000Z","mathjax":true,"_content":"\n## 最大子数组问题\n\n### 问题描述\n\n给定一数组A, 寻找A的和最大的非空连续子数组。我们称这样的连续子数组为 **最大子数组(maximum subarray)**. 只有当数组中包含负数时，最大子数组问题才有意义。常见的实际问题有股票的买卖，从买入到卖出我们希望股票的价格净变值最大。\n\n### 使用分治策略的求解方法\n\n假定我们要寻找子数组A[low...high]的最大子数组。使用分治技术意味着我们要将子数组划分为两个规模尽量相等的子数组（比如从中央位置划分），然后考虑求解两个子数组A[low...mid]和A[mid+1...high]。A[low...high]的一个任何连续子数组所处的位置必然是这三种情况之一：\n* 完全位于子数组A[low...mid]中，\n$low \\le i \\le j \\le mid$\n* 完全位于子数组A[mid+1...high]中，\n$mid+1 \\le i \\le j \\le high$\n* 跨越了中点，\n$low \\le i \\le mid \\le j \\le high$\n\n实际上，A[low...high]的一个最大子数组必然是上述三种情况的所有子数组中和的最大者。\n\n### 代码实现\n\n**求解跨越中点的最大子数组**\n```python\ndef find_max_crossing_subarray(A, low, mid, high):\n    \"\"\"\n    Arguments:\n        A: a not empty array with index (low mid hight)\n    Return:\n        (i, j, sum): the index of the maximum subarray which crosses the mid.\n    \"\"\"\n    left_sum = -float('inf')\n    sum = 0\n    for i in range(mid, low-1, -1):\n        sum = sum + A[i]\n        if sum > left_sum:\n            left_sum = sum\n            max_left = i\n    right_sum = -float('inf')\n    sum = 0\n    for j in range(mid+1, high+1):\n        sum = sum + A[j]\n        if sum > right_sum:\n            right_sum = sum\n            max_right = j\n    return (max_left, max_right, left_sum + right_sum)\n```\n\n**求解最大子数组**\n```python\ndef find_maximum_subarray(A, low, high):\n    if high == low:\n        return (low, high, A[low])\n    else:\n        mid = round((low + high) / 2)\n        (left_low, left_high, left_sum) = find_maximum_subarray(A, low, mid)\n        (right_low, right_high, right_sum) = find_maximum_subarray(A, mid+1, high)\n        (cross_low, cross_high, cross_sum) = find_max_crossing_subarray(A, low, mid, high)\n        if left_sum >= right_sum and left_sum >= cross_sum:\n            return (left_low, left_high, left_sum)\n        elif right_sum >= left_sum and right_sum >= cross_sum:\n            return (right_low, right_high, right_sum)\n        else:\n            return (cross_low, cross_high, cross_sum)\n```\n\n### 算法分析\n\n假设原问题的规模是2的幂，这样所有子问题的规模均为整数。我们用T(n)表示求解n个元素的最大子数组的运行时间。\n\n$$T(n) = \\begin{cases}\\Theta(1)&& n=1\\\\2T(n/2) + \\Theta(n)&& n>1 \\end{cases}$$\n\n$T(n) = \\Theta(nlgn)$\n","source":"_posts/分治策略.md","raw":"---\ntitle: 分治策略\ndate: 2018-09-08 22:46:06\ntags: 分治策略\ncategories: 算法导论\nmathjax: true\n---\n\n## 最大子数组问题\n\n### 问题描述\n\n给定一数组A, 寻找A的和最大的非空连续子数组。我们称这样的连续子数组为 **最大子数组(maximum subarray)**. 只有当数组中包含负数时，最大子数组问题才有意义。常见的实际问题有股票的买卖，从买入到卖出我们希望股票的价格净变值最大。\n\n### 使用分治策略的求解方法\n\n假定我们要寻找子数组A[low...high]的最大子数组。使用分治技术意味着我们要将子数组划分为两个规模尽量相等的子数组（比如从中央位置划分），然后考虑求解两个子数组A[low...mid]和A[mid+1...high]。A[low...high]的一个任何连续子数组所处的位置必然是这三种情况之一：\n* 完全位于子数组A[low...mid]中，\n$low \\le i \\le j \\le mid$\n* 完全位于子数组A[mid+1...high]中，\n$mid+1 \\le i \\le j \\le high$\n* 跨越了中点，\n$low \\le i \\le mid \\le j \\le high$\n\n实际上，A[low...high]的一个最大子数组必然是上述三种情况的所有子数组中和的最大者。\n\n### 代码实现\n\n**求解跨越中点的最大子数组**\n```python\ndef find_max_crossing_subarray(A, low, mid, high):\n    \"\"\"\n    Arguments:\n        A: a not empty array with index (low mid hight)\n    Return:\n        (i, j, sum): the index of the maximum subarray which crosses the mid.\n    \"\"\"\n    left_sum = -float('inf')\n    sum = 0\n    for i in range(mid, low-1, -1):\n        sum = sum + A[i]\n        if sum > left_sum:\n            left_sum = sum\n            max_left = i\n    right_sum = -float('inf')\n    sum = 0\n    for j in range(mid+1, high+1):\n        sum = sum + A[j]\n        if sum > right_sum:\n            right_sum = sum\n            max_right = j\n    return (max_left, max_right, left_sum + right_sum)\n```\n\n**求解最大子数组**\n```python\ndef find_maximum_subarray(A, low, high):\n    if high == low:\n        return (low, high, A[low])\n    else:\n        mid = round((low + high) / 2)\n        (left_low, left_high, left_sum) = find_maximum_subarray(A, low, mid)\n        (right_low, right_high, right_sum) = find_maximum_subarray(A, mid+1, high)\n        (cross_low, cross_high, cross_sum) = find_max_crossing_subarray(A, low, mid, high)\n        if left_sum >= right_sum and left_sum >= cross_sum:\n            return (left_low, left_high, left_sum)\n        elif right_sum >= left_sum and right_sum >= cross_sum:\n            return (right_low, right_high, right_sum)\n        else:\n            return (cross_low, cross_high, cross_sum)\n```\n\n### 算法分析\n\n假设原问题的规模是2的幂，这样所有子问题的规模均为整数。我们用T(n)表示求解n个元素的最大子数组的运行时间。\n\n$$T(n) = \\begin{cases}\\Theta(1)&& n=1\\\\2T(n/2) + \\Theta(n)&& n>1 \\end{cases}$$\n\n$T(n) = \\Theta(nlgn)$\n","slug":"分治策略","published":1,"updated":"2018-09-22T05:28:29.852Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oz3002544vo5tpqfit3"},{"title":"初始化参数","date":"2018-07-22T05:22:45.000Z","_content":"\n## Initialization\n\nTraining your neural network requires specifying an initial value of the weights. A well chosen initialization method will help learning.  \n\nA well chosen initialization can:\n- Speed up the convergence of gradient descent\n- Increase the odds of gradient descent converging to a lower training (and generalization) error\n\n## Random initialization\n\n```python\nparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * 0.01\nparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n```\n\n## He initialization\n\n```python\nparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * np.sqrt(2 / layers_dims[l-1])\nparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n```\n\n\n**What you should remember from this artical**:\n- Different initializations lead to different results\n- Random initialization is used to break symmetry and make sure different hidden units can learn different things\n- Don't intialize to values that are too large\n- He initialization works well for networks with ReLU activations.\n","source":"_posts/初始化参数.md","raw":"---\ntitle: 初始化参数\ndate: 2018-07-22 13:22:45\ntags: 优化算法\ncategories: 深度学习\n---\n\n## Initialization\n\nTraining your neural network requires specifying an initial value of the weights. A well chosen initialization method will help learning.  \n\nA well chosen initialization can:\n- Speed up the convergence of gradient descent\n- Increase the odds of gradient descent converging to a lower training (and generalization) error\n\n## Random initialization\n\n```python\nparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * 0.01\nparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n```\n\n## He initialization\n\n```python\nparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * np.sqrt(2 / layers_dims[l-1])\nparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n```\n\n\n**What you should remember from this artical**:\n- Different initializations lead to different results\n- Random initialization is used to break symmetry and make sure different hidden units can learn different things\n- Don't intialize to values that are too large\n- He initialization works well for networks with ReLU activations.\n","slug":"初始化参数","published":1,"updated":"2018-08-31T03:52:16.653Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oz8002744vonb7bs9jr"},{"title":"动态规划","date":"2018-07-21T14:47:53.000Z","mathjax":true,"_content":"## 动态规划（dynamic programming）\n\n与分治法相似，都是通过组合子问题的解来求解原问题。不同的是，动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题。在这种情况下，动态规划算法对每个子子问题只求解一次，将其保存在一个表格中，减少了计算量。\n\n通常用来求解最优化问题。\n\n我们通常按如下4个步骤来设计一个动态规划算法：\n\n* 刻画一个最优解的结构特征\n* 递归地定义最优解的值\n* 计算最优解的值，通常采用自底向上的方法\n* 利用计算出的信息构造一个最优解\n\n## 钢条切割问题\n\n### 问题定义\n\n给定一段长度为$n$英寸的钢条（长度均为整英寸，切割后也必须是整英寸）和一个价格表$p_i(i=1, 2, ..., n)$, 求解切割钢条的方案（方案也可以是不切割），使收益$r_n$最大。\n\n### 问题分析\n\n长度为$n$英寸的钢条共有$2^{n-1}$种不同的切割方案，如果一个最优解将钢条切割为$k$段，那么最优切割方案为\n\n$$n = i_1 + i_2 + ... + i_k$$\n\n得到的最大收益为\n\n$$r_n = p_{i_1} + p_{i_2} + ... + p_{i_k}$$\n\n当完成首次切割后，我们将两段钢条看成两个独立的钢条切割问题实例。我们通过组合两个相关子问题的最优解，并在所有可能的两段切割方案种选取组合收益最大者，构成原问题的最优解。\n\n则最优切割收益为\n\n$$r_n = max(p_n, r_1 + r_{n-1}, r_2 + r_{n-2}, ..., r_{n-1} + r_1)$$\n\n除上述求解方法外，钢条切割问题还存在一种相似的但更为简单的递归求解方法：我们将钢条从左边切割下长度为$i$的一段，只对右边剩下的长度为$n-i$的一段继续进行切割（递归求解）。\n\n这样我们得到上述式子的简化版本\n\n$$r_n = \\mathop {\\max}_{1 \\le i \\le n}(p_i + r_{n-i})$$\n\n### 代码实现\n\n#### 自顶向下递归实现\n\n```python\ndef cut_rod(p, n):\n    \"\"\"\n    Arguments:\n    p -- the table of prices.\n    n -- the total length of steel rod.\n    \"\"\"\n    if n == 0:\n        return 0\n    q = -1\n    for i in range(1, n+1):\n        q = max(q, p[i] + cut_rod(p, n-i))\n    return q\n```\n\n#### 代码分析\n\n![](/images/动态规划.jpg)\n\n令$T(n)$表示cut_rod的调用次数\n\n$$T(n) = 1 + \\sum_{j=0}^{n-1} T(j) = 2^n$$\n\n第一项“1”表示函数的额第一次调用，$T(j)$为调用cut_rod(p, n-i)所产生的所有调用$(j = n-i)$\n\n#### 使用动态规划求解\n\n朴素递归算法之所以效率低，是因为它反复求解相同的子问题。因此，动态规划方法仔细安排求解顺序，对每个子问题只求解一次，并将结果保存下来。如果随后再次需要此子问题的解，只需查找保存的结果。\n\n动态规划有两种等价的实现。**带备忘的自顶向下**、**自底向上**。这里只给出第二种的代码。\n\n```python\ndef bottom_up_cut_rod(p, n):\n    \"\"\"\n    Arguments:\n    p -- the table of prices.\n    n -- the total length of steel rod.\n    \"\"\"\n    r = list(range(n + 1))  # to save subproblem's result\n    r[0] = 0\n    for j in range(1, n + 1):\n        q = -1\n        for i in range(1, j + 1):\n            q = max(q, p[i] + r[j - i])\n            r[j] = q\n    return r[n]\n```\n\n#### 代码分析\n\n自底向上版本采用子问题的自然顺序，一次求解规模为$j = 0, 1, 2, ..., n$的子问题。时间复杂度为$\\Theta(n^2)$\n\n#### 扩展代码\n\n前文给出的钢条切割问题的动态规划算法返回最优解的收益值，但未返回解本身。我们可以扩展动态规划算法，使之对每个子问题不仅保存最优收益值，还保存对应的切割方案。\n\n```python\ndef externed_bottom_up_cut_rod(p, n):\n    r = list(range(n + 1))  # 长度为j的钢条的最大收益值r_j\n    s = list(range(n + 1))  # 最优解对应的第一条钢条的长度s_j\n    r[0] = 0\n    for j in range(1, n + 1):\n        q = -1\n        for i in range(1, j + 1):\n            if q < p[i] + r[j - i]:\n                q = p[i] + r[j - i]\n                s[j] = i\n        r[j] = q\n    return r[n]\n\ndef print_cut_rod_solution(p, n):\n    (r, s) = externed_bottom_up_cut_rod(p, n)\n    print(r)\n    while n > 0:\n        print(s[n], end=' ')\n        n = n - s[n]\n```\n","source":"_posts/动态规划.md","raw":"---\ntitle: 动态规划\ndate: 2018-07-21 22:47:53\ntags: 动态规划\ncategories: 算法导论\nmathjax: true\n---\n## 动态规划（dynamic programming）\n\n与分治法相似，都是通过组合子问题的解来求解原问题。不同的是，动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题。在这种情况下，动态规划算法对每个子子问题只求解一次，将其保存在一个表格中，减少了计算量。\n\n通常用来求解最优化问题。\n\n我们通常按如下4个步骤来设计一个动态规划算法：\n\n* 刻画一个最优解的结构特征\n* 递归地定义最优解的值\n* 计算最优解的值，通常采用自底向上的方法\n* 利用计算出的信息构造一个最优解\n\n## 钢条切割问题\n\n### 问题定义\n\n给定一段长度为$n$英寸的钢条（长度均为整英寸，切割后也必须是整英寸）和一个价格表$p_i(i=1, 2, ..., n)$, 求解切割钢条的方案（方案也可以是不切割），使收益$r_n$最大。\n\n### 问题分析\n\n长度为$n$英寸的钢条共有$2^{n-1}$种不同的切割方案，如果一个最优解将钢条切割为$k$段，那么最优切割方案为\n\n$$n = i_1 + i_2 + ... + i_k$$\n\n得到的最大收益为\n\n$$r_n = p_{i_1} + p_{i_2} + ... + p_{i_k}$$\n\n当完成首次切割后，我们将两段钢条看成两个独立的钢条切割问题实例。我们通过组合两个相关子问题的最优解，并在所有可能的两段切割方案种选取组合收益最大者，构成原问题的最优解。\n\n则最优切割收益为\n\n$$r_n = max(p_n, r_1 + r_{n-1}, r_2 + r_{n-2}, ..., r_{n-1} + r_1)$$\n\n除上述求解方法外，钢条切割问题还存在一种相似的但更为简单的递归求解方法：我们将钢条从左边切割下长度为$i$的一段，只对右边剩下的长度为$n-i$的一段继续进行切割（递归求解）。\n\n这样我们得到上述式子的简化版本\n\n$$r_n = \\mathop {\\max}_{1 \\le i \\le n}(p_i + r_{n-i})$$\n\n### 代码实现\n\n#### 自顶向下递归实现\n\n```python\ndef cut_rod(p, n):\n    \"\"\"\n    Arguments:\n    p -- the table of prices.\n    n -- the total length of steel rod.\n    \"\"\"\n    if n == 0:\n        return 0\n    q = -1\n    for i in range(1, n+1):\n        q = max(q, p[i] + cut_rod(p, n-i))\n    return q\n```\n\n#### 代码分析\n\n![](/images/动态规划.jpg)\n\n令$T(n)$表示cut_rod的调用次数\n\n$$T(n) = 1 + \\sum_{j=0}^{n-1} T(j) = 2^n$$\n\n第一项“1”表示函数的额第一次调用，$T(j)$为调用cut_rod(p, n-i)所产生的所有调用$(j = n-i)$\n\n#### 使用动态规划求解\n\n朴素递归算法之所以效率低，是因为它反复求解相同的子问题。因此，动态规划方法仔细安排求解顺序，对每个子问题只求解一次，并将结果保存下来。如果随后再次需要此子问题的解，只需查找保存的结果。\n\n动态规划有两种等价的实现。**带备忘的自顶向下**、**自底向上**。这里只给出第二种的代码。\n\n```python\ndef bottom_up_cut_rod(p, n):\n    \"\"\"\n    Arguments:\n    p -- the table of prices.\n    n -- the total length of steel rod.\n    \"\"\"\n    r = list(range(n + 1))  # to save subproblem's result\n    r[0] = 0\n    for j in range(1, n + 1):\n        q = -1\n        for i in range(1, j + 1):\n            q = max(q, p[i] + r[j - i])\n            r[j] = q\n    return r[n]\n```\n\n#### 代码分析\n\n自底向上版本采用子问题的自然顺序，一次求解规模为$j = 0, 1, 2, ..., n$的子问题。时间复杂度为$\\Theta(n^2)$\n\n#### 扩展代码\n\n前文给出的钢条切割问题的动态规划算法返回最优解的收益值，但未返回解本身。我们可以扩展动态规划算法，使之对每个子问题不仅保存最优收益值，还保存对应的切割方案。\n\n```python\ndef externed_bottom_up_cut_rod(p, n):\n    r = list(range(n + 1))  # 长度为j的钢条的最大收益值r_j\n    s = list(range(n + 1))  # 最优解对应的第一条钢条的长度s_j\n    r[0] = 0\n    for j in range(1, n + 1):\n        q = -1\n        for i in range(1, j + 1):\n            if q < p[i] + r[j - i]:\n                q = p[i] + r[j - i]\n                s[j] = i\n        r[j] = q\n    return r[n]\n\ndef print_cut_rod_solution(p, n):\n    (r, s) = externed_bottom_up_cut_rod(p, n)\n    print(r)\n    while n > 0:\n        print(s[n], end=' ')\n        n = n - s[n]\n```\n","slug":"动态规划","published":1,"updated":"2018-08-31T08:29:12.233Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ozb002b44vofv6fsirp"},{"title":"十个策略故事","date":"2018-07-19T16:59:24.000Z","catrgories":"博弈论","_content":"\n### 1. 选数游戏\n\n游戏的参与者：你和一位面试官\n\n游戏的内容：面试官从1到100之间随机挑选一个整数，你有5次机会猜出它。每猜一次，面试官会提供给你所猜数与结果的大小信息\n\n游戏的收益：如果你第一次就猜对，你将获得100元，之后每次收益递减20元。面试官相应地损失这么多收益。\n\n模拟游戏的程序\n\n```python\nimport random\n\nres = random.randint(1, 100)\n\nfor i in range(5):\n    guess = int(input(\"Epoch {}: \".format(i + 1)))\n    if guess < res:\n        print(\"your guess is lower than the key.\")\n    elif guess > res:\n        print(\"your guess is greater than the key.\")\n    else:\n        print(\"Bingo, you will get {} dollars.\".format(100 - 20 * i))\nprint(\"The key is {}\".format(res))\n```\n\n#### 总结\n\n这场游戏揭示了是什么使用得某些事件成为一场博弈：你必须考虑到其他与参与人得目标及策略。在猜测一个随机挑选得数字时，这个数字不会被刻意掩饰。你可以用工程师得思维将区间一分为二，尽可能做得最好。但在博弈对局中，你需要考虑其他参与人将如何行动，以及那些人的决策将如何影响你的策略。\n\n","source":"_posts/十个策略故事.md","raw":"---\ntitle: 十个策略故事\ndate: 2018-07-20 00:59:24\ntags: 策略游戏\ncatrgories: 博弈论\n---\n\n### 1. 选数游戏\n\n游戏的参与者：你和一位面试官\n\n游戏的内容：面试官从1到100之间随机挑选一个整数，你有5次机会猜出它。每猜一次，面试官会提供给你所猜数与结果的大小信息\n\n游戏的收益：如果你第一次就猜对，你将获得100元，之后每次收益递减20元。面试官相应地损失这么多收益。\n\n模拟游戏的程序\n\n```python\nimport random\n\nres = random.randint(1, 100)\n\nfor i in range(5):\n    guess = int(input(\"Epoch {}: \".format(i + 1)))\n    if guess < res:\n        print(\"your guess is lower than the key.\")\n    elif guess > res:\n        print(\"your guess is greater than the key.\")\n    else:\n        print(\"Bingo, you will get {} dollars.\".format(100 - 20 * i))\nprint(\"The key is {}\".format(res))\n```\n\n#### 总结\n\n这场游戏揭示了是什么使用得某些事件成为一场博弈：你必须考虑到其他与参与人得目标及策略。在猜测一个随机挑选得数字时，这个数字不会被刻意掩饰。你可以用工程师得思维将区间一分为二，尽可能做得最好。但在博弈对局中，你需要考虑其他参与人将如何行动，以及那些人的决策将如何影响你的策略。\n\n","slug":"十个策略故事","published":1,"updated":"2018-08-19T01:59:35.798Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19oze002f44voxyihp0rl"},{"title":"卷积神经网络","date":"2018-08-26T09:20:05.000Z","mathjax":true,"_content":"\n## Convolution neural network(CNN)\n\n是一种专门用来处理**具有类似网格结构的数据**的神经网络。例如时间序列数据(可以认为在时间轴上有规律的采样形成的一维网格)和图像数据(可以看作二维的像素网格)。\n\n## 卷积运算\n\n数学定义\n$$f(t) = f_1(t) \\ast f_2(t) = \\int_{-\\infty}^{\\infty} f_1(\\tau)f_2(t - \\tau)d\\tau$$\n\n$$y(k) = f(k) \\ast h(k) = \\sum_{i = -\\infty}^{\\infty} f(i) h(k - i)$$\n\n二维图像的卷积表示\n$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(m, n)K(i - m, j - n)$$\n\n神经网络中实现的卷积运算实际上是**互相关函数**\n$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(i + m, j + n)K(m, n)$$\n\n## 三个重要思想\n\n### 稀疏交互(sparse interactions)\n\n**在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。**\n\n![](/images/dl_pic9_2.jpg)\n\n传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。其中，参数矩阵中的每一个单独的参数都描述了一个输入单元与一个输出单元间的交互。这意味着每一个输出单元与每一个输入单元都产生交互。然而卷积网络具有稀疏交互的特征，这是使核的大小远小于输入的大小来达到的。当处理一张图像时，输入的图像可能包含成千上万个像素点，但我们可以通过只占用几十到几百个像素点的核来检测一些小的有意义的特征，例如图像的边缘。\n\n### 参数共享(parameter sharing)\n\n特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。**即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。**\n\n在传统的神经网络中，当计算一层的输出时，权重矩阵的每个元素只使用一次，当它乘以输入的一个元素后就再也不会用到了。在卷积神经网络中，核的每一个元素都作用在输入的每一个位置上。卷积运算中的参数共享保证了我们只需要学习一个参数集合，而不是对每一个位置都需要学习一个单独的参数集合。\n\n![](/images/dl_pic9_5.jpg)\n\n### 等变表示(equivarient representations)\n\n等变的数学概念\n$$如果函数f(x), g(x)满足 f(g(x)) = g(f(x)) 我们就说f(x)对于变换g具有等变性 $$\n\n对于卷积来说，**如果令g是输入的任意平移函数，那么卷积函数对于g具有等变性。**\n在图像处理中，卷积产生了一个二维映射来表明某些特征在输入中出现的位置。如果我们移动输入中的对象，它的表示也会在输出中移动同样的量。\n\n## 池化(pooling)\n\n卷积网络中一个典型层包含三级\n![](/images/dl_pic9_7.jpg)\n\n**池化层**的作用是在卷积后很好地聚合了特征，通过降维来减少运算量, 缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。\n\n**池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。** 例如最大池化函数给出相邻区域内的最大值。\n\n**不管采用什么样的池化函数，当输入做出少量平移时，池化能够帮助输入的表示近似不变**。局部平移不变性是一个很有用的性质，尤其当我们关心某个特征是否出现而不关心它出现的具体位置时。\n\n在很多任务中，池化对于处理不同大小的输入具有重要作用。例如我们想对不同大小的图像进行分类时，分类层的输入必须是固定大小，而这通常通过调整池化区域的偏置大小来实现，这样分类层总是能接收到相同数量的统计特征而不管最初的输入大小。例如最终的池化层可能会输入4组综合统计特征，每组对于着图像的一个象限。\n\n## 卷积与池化作为一种无限强的先验\n\n>先验概率分布。这是一个模型参数的概率分布，它刻画了我们在看到数据之前认为什么样的模型是合理的信念。先验被认为强或者弱取决于先验中概率密度的集中程度。一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值。\n\n我们可以把卷积网络类比成全连接网络，但对于这个全连接网络的权重有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权重必须和它邻居的权重相同，但可以在空间上移动。这个先验也要求那些处于隐藏单元的小的空间连续的接受域内的权重以外，其余权重都为零。\n\n类似地使用池化也是一个无限强的先验：每一个单元都具有对少量平移的不变性。\n\n## 填充(Padding)\n\n假设输入图片的大小为 $n \\times n$，而滤波器的大小为 $f \\times f$，则卷积后的输出图片大小为 $(n-f+1) \\times (n-f+1)$。\n\n这样就有两个问题：\n\n* 每次卷积运算后，输出图片的尺寸缩小；\n* 原始图片的角落、边缘区像素点在输出中采用较少，输出图片丢失边缘位置的很多信息。\n\n为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行 **填充（Padding）**，以增加矩阵的大小。通常将 0 作为填充值。\n\n![](/images/Padding.jpg)\n\n设每个方向扩展像素点数量为 $p$，则填充后原始图片的大小为 $(n+2p) \\times (n+2p)$，滤波器大小保持 $f \\times f$不变，则输出图片大小为 $(n+2p-f+1) \\times (n+2p-f+1)$。\n\n因此，在进行卷积运算时，我们有两种选择：\n\n* **Valid 卷积**：不填充，直接卷积。结果大小为 $(n-f+1) \\times (n-f+1)$；\n* **Same 卷积**：进行填充，并使得卷积后结果大小与输入一致，这样 $p = \\frac{f-1}{2}$。\n\n在计算机视觉领域，$f$通常为奇数。原因包括 Same 卷积中 $p = \\frac{f-1}{2}$ 能得到自然数结果，并且滤波器有一个便于表示其所在位置的中心点。\n\n## 卷积步长(Stride)\n\n卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置 **步长（Stride）** 来压缩一部分信息。\n\n步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。之前，步长被默认为 1。而如果我们设置步长为 2，则卷积过程如下图所示：\n\n![](/images/Stride.jpg)\n\n设步长为 $s$，填充长度为 $p$，输入图片大小为 $n \\times n$，滤波器大小为 $f \\times f$，则卷积后图片的尺寸为：\n\n$$\\biggl\\lfloor \\frac{n+2p-f}{s}+1   \\biggr\\rfloor \\times \\biggl\\lfloor \\frac{n+2p-f}{s}+1 \\biggr\\rfloor$$\n\n## 高维卷积\n\n如果我们想要对三通道的 RGB 图片进行卷积运算，那么其对应的滤波器组也同样是三通道的。过程是将每个单通道（R，G，B）与对应的滤波器进行卷积运算求和，然后再将三个通道的和相加，将 27 个乘积的和作为输出图片的一个像素值。\n\n![](/images/Convolutions-on-RGB-image.png)\n\n设输入图片的尺寸为 $n \\times n \\times n_c$（$n_c$为通道数），滤波器尺寸为 $f \\times f \\times n_c$，则卷积后的输出图片尺寸为 $(n-f+1) \\times (n-f+1) \\times n^{'}_c$，$n^{'}_c$为滤波器组的个数。\n\n### 符号总结\n\n设 $l$ 层为卷积层：\n\n* $f^{[l]}$：**滤波器的高（或宽）**\n* $p^{[l]}$：**填充长度**\n* $s^{[l]}$：**步长**\n* $n^{[l]}_c$：**滤波器组的数量**\n\n* **输入维度**：$n^{[l-1]}_H \\times n^{[l-1]}_W \\times n^{[l-1]}_c$ 。其中 $n^{[l-1]}_H$表示输入图片的高，$n^{[l-1]}_W$表示输入图片的宽。之前的示例中输入图片的高和宽都相同，但是实际中也可能不同，因此加上下标予以区分。\n\n* **输出维度**：$n^{[l]}_H \\times n^{[l]}_W \\times n^{[l]}_c$ 。其中\n\n$$n^{[l]}_H = \\biggl\\lfloor \\frac{n^{[l-1]}_H+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$\n\n$$n^{[l]}_W = \\biggl\\lfloor \\frac{n^{[l-1]}_W+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$\n\n* **每个滤波器组的维度**：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c$ 。其中$n^{[l-1]}_c$ 为输入图片通道数（也称深度）。\n* **权重维度**：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c$\n* **偏置维度**：$1 \\times 1 \\times 1 \\times n^{[l]}_c$\n","source":"_posts/卷积神经网络.md","raw":"---\ntitle: 卷积神经网络\ndate: 2018-08-26 17:20:05\ntags: CNN\ncategories: 深度学习\nmathjax: true\n---\n\n## Convolution neural network(CNN)\n\n是一种专门用来处理**具有类似网格结构的数据**的神经网络。例如时间序列数据(可以认为在时间轴上有规律的采样形成的一维网格)和图像数据(可以看作二维的像素网格)。\n\n## 卷积运算\n\n数学定义\n$$f(t) = f_1(t) \\ast f_2(t) = \\int_{-\\infty}^{\\infty} f_1(\\tau)f_2(t - \\tau)d\\tau$$\n\n$$y(k) = f(k) \\ast h(k) = \\sum_{i = -\\infty}^{\\infty} f(i) h(k - i)$$\n\n二维图像的卷积表示\n$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(m, n)K(i - m, j - n)$$\n\n神经网络中实现的卷积运算实际上是**互相关函数**\n$$S(i, j) = I(i, j) \\ast K(i, j) = \\sum_{m}\\sum_{n}I(i + m, j + n)K(m, n)$$\n\n## 三个重要思想\n\n### 稀疏交互(sparse interactions)\n\n**在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。**\n\n![](/images/dl_pic9_2.jpg)\n\n传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。其中，参数矩阵中的每一个单独的参数都描述了一个输入单元与一个输出单元间的交互。这意味着每一个输出单元与每一个输入单元都产生交互。然而卷积网络具有稀疏交互的特征，这是使核的大小远小于输入的大小来达到的。当处理一张图像时，输入的图像可能包含成千上万个像素点，但我们可以通过只占用几十到几百个像素点的核来检测一些小的有意义的特征，例如图像的边缘。\n\n### 参数共享(parameter sharing)\n\n特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。**即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。**\n\n在传统的神经网络中，当计算一层的输出时，权重矩阵的每个元素只使用一次，当它乘以输入的一个元素后就再也不会用到了。在卷积神经网络中，核的每一个元素都作用在输入的每一个位置上。卷积运算中的参数共享保证了我们只需要学习一个参数集合，而不是对每一个位置都需要学习一个单独的参数集合。\n\n![](/images/dl_pic9_5.jpg)\n\n### 等变表示(equivarient representations)\n\n等变的数学概念\n$$如果函数f(x), g(x)满足 f(g(x)) = g(f(x)) 我们就说f(x)对于变换g具有等变性 $$\n\n对于卷积来说，**如果令g是输入的任意平移函数，那么卷积函数对于g具有等变性。**\n在图像处理中，卷积产生了一个二维映射来表明某些特征在输入中出现的位置。如果我们移动输入中的对象，它的表示也会在输出中移动同样的量。\n\n## 池化(pooling)\n\n卷积网络中一个典型层包含三级\n![](/images/dl_pic9_7.jpg)\n\n**池化层**的作用是在卷积后很好地聚合了特征，通过降维来减少运算量, 缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。\n\n**池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。** 例如最大池化函数给出相邻区域内的最大值。\n\n**不管采用什么样的池化函数，当输入做出少量平移时，池化能够帮助输入的表示近似不变**。局部平移不变性是一个很有用的性质，尤其当我们关心某个特征是否出现而不关心它出现的具体位置时。\n\n在很多任务中，池化对于处理不同大小的输入具有重要作用。例如我们想对不同大小的图像进行分类时，分类层的输入必须是固定大小，而这通常通过调整池化区域的偏置大小来实现，这样分类层总是能接收到相同数量的统计特征而不管最初的输入大小。例如最终的池化层可能会输入4组综合统计特征，每组对于着图像的一个象限。\n\n## 卷积与池化作为一种无限强的先验\n\n>先验概率分布。这是一个模型参数的概率分布，它刻画了我们在看到数据之前认为什么样的模型是合理的信念。先验被认为强或者弱取决于先验中概率密度的集中程度。一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值。\n\n我们可以把卷积网络类比成全连接网络，但对于这个全连接网络的权重有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权重必须和它邻居的权重相同，但可以在空间上移动。这个先验也要求那些处于隐藏单元的小的空间连续的接受域内的权重以外，其余权重都为零。\n\n类似地使用池化也是一个无限强的先验：每一个单元都具有对少量平移的不变性。\n\n## 填充(Padding)\n\n假设输入图片的大小为 $n \\times n$，而滤波器的大小为 $f \\times f$，则卷积后的输出图片大小为 $(n-f+1) \\times (n-f+1)$。\n\n这样就有两个问题：\n\n* 每次卷积运算后，输出图片的尺寸缩小；\n* 原始图片的角落、边缘区像素点在输出中采用较少，输出图片丢失边缘位置的很多信息。\n\n为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行 **填充（Padding）**，以增加矩阵的大小。通常将 0 作为填充值。\n\n![](/images/Padding.jpg)\n\n设每个方向扩展像素点数量为 $p$，则填充后原始图片的大小为 $(n+2p) \\times (n+2p)$，滤波器大小保持 $f \\times f$不变，则输出图片大小为 $(n+2p-f+1) \\times (n+2p-f+1)$。\n\n因此，在进行卷积运算时，我们有两种选择：\n\n* **Valid 卷积**：不填充，直接卷积。结果大小为 $(n-f+1) \\times (n-f+1)$；\n* **Same 卷积**：进行填充，并使得卷积后结果大小与输入一致，这样 $p = \\frac{f-1}{2}$。\n\n在计算机视觉领域，$f$通常为奇数。原因包括 Same 卷积中 $p = \\frac{f-1}{2}$ 能得到自然数结果，并且滤波器有一个便于表示其所在位置的中心点。\n\n## 卷积步长(Stride)\n\n卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置 **步长（Stride）** 来压缩一部分信息。\n\n步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。之前，步长被默认为 1。而如果我们设置步长为 2，则卷积过程如下图所示：\n\n![](/images/Stride.jpg)\n\n设步长为 $s$，填充长度为 $p$，输入图片大小为 $n \\times n$，滤波器大小为 $f \\times f$，则卷积后图片的尺寸为：\n\n$$\\biggl\\lfloor \\frac{n+2p-f}{s}+1   \\biggr\\rfloor \\times \\biggl\\lfloor \\frac{n+2p-f}{s}+1 \\biggr\\rfloor$$\n\n## 高维卷积\n\n如果我们想要对三通道的 RGB 图片进行卷积运算，那么其对应的滤波器组也同样是三通道的。过程是将每个单通道（R，G，B）与对应的滤波器进行卷积运算求和，然后再将三个通道的和相加，将 27 个乘积的和作为输出图片的一个像素值。\n\n![](/images/Convolutions-on-RGB-image.png)\n\n设输入图片的尺寸为 $n \\times n \\times n_c$（$n_c$为通道数），滤波器尺寸为 $f \\times f \\times n_c$，则卷积后的输出图片尺寸为 $(n-f+1) \\times (n-f+1) \\times n^{'}_c$，$n^{'}_c$为滤波器组的个数。\n\n### 符号总结\n\n设 $l$ 层为卷积层：\n\n* $f^{[l]}$：**滤波器的高（或宽）**\n* $p^{[l]}$：**填充长度**\n* $s^{[l]}$：**步长**\n* $n^{[l]}_c$：**滤波器组的数量**\n\n* **输入维度**：$n^{[l-1]}_H \\times n^{[l-1]}_W \\times n^{[l-1]}_c$ 。其中 $n^{[l-1]}_H$表示输入图片的高，$n^{[l-1]}_W$表示输入图片的宽。之前的示例中输入图片的高和宽都相同，但是实际中也可能不同，因此加上下标予以区分。\n\n* **输出维度**：$n^{[l]}_H \\times n^{[l]}_W \\times n^{[l]}_c$ 。其中\n\n$$n^{[l]}_H = \\biggl\\lfloor \\frac{n^{[l-1]}_H+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$\n\n$$n^{[l]}_W = \\biggl\\lfloor \\frac{n^{[l-1]}_W+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \\biggr\\rfloor$$\n\n* **每个滤波器组的维度**：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c$ 。其中$n^{[l-1]}_c$ 为输入图片通道数（也称深度）。\n* **权重维度**：$f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c$\n* **偏置维度**：$1 \\times 1 \\times 1 \\times n^{[l]}_c$\n","slug":"卷积神经网络","published":1,"updated":"2018-08-26T09:48:30.935Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ozh002j44vonw60neyw"},{"title":"吴恩达深度学习课程总结","date":"2018-09-22T03:43:27.000Z","_content":"吴恩达深度学习课程学习心得\n\n这门课程由五个章节组成，分别是：\n* 神经网络和深度学习\n* 超参数调试，正则化和优化算法\n* 结构化机器学习项目\n* 卷积神经网络\n* 自然语言处理：构建序列模型\n\n### 神经网络和深度学习\n\n**什么是神经网络？**\n\n人工神经网络的研究在一定程度上受到生物学的启发，因为人的学习系统是由相互连接的神经元组成的异常复杂的网络。而人工神经网络与此大体相似，它是由一系列简单的神经元相互密集连接构成的，它尝试去发现信息处理过程中的数学表示。在大多数神经网络的实现中，神经元之间的信号是实值，每一个神经元的输出是它的所有输入信号强度和的非线性函数。连接神经元的边通常有一个权重，在学习过程中不断调整它。这个权重可以影响神经元之间传递的信号强度。神经元还可能有一个阈值来控制信号的传递。简而言之它是一个通用的函数逼近机器。\n\n\n**结构化数据和非结构化数据的区别？**\n\n- 结构化数据：由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范。\n\n- 非结构化数据：数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维逻辑表来表现的数据。包括所有格式的办公文档、文本、图片、XML, HTML、各类报表、图像和音频/视频信息等等。\n\n\n**What is Logistic Regression?**\n\nlogistic回归是监督学习中用在当输出数据是0或1时的一个学习算法。它的目标是最小化预测和真实标签之间的误差。\n\n**损失函数与代价函数的区别？**\n\n损失函数：用于衡量预测结果与真实结果之间的误差。在单个训练样本中定义。\n代价函数：衡量学习到的模型在全体样本上的表现。\n\n**什么是全连接网络的前向传播过程和反向传播过程？**\n\nforward propagation:\n$$Z^{[l]} = {W^{[l]}}A^{[l-1]} + b^{[l]}$$\n$$A^{[l]} = g(Z^{[l]})$$\n\nbackward propagation:\n$$Denotion: dA^{[l]} = \\frac{\\partial J}{\\partial A^{[l]}}\\\\dZ^{[l]} = dA^{[l]} * g'(Z^{[l]})\\\\dW^{[l]} = \\frac{1}{m}dZ^{[l]}\\cdot {A^{[l]}}^T\\\\db^{[l]} = \\frac{1}{m}np.sum(dZ^{[l]}, axis=1, keepdim=True)\\\\dA^{[l-1]} = {W^{[l]}}^T\\cdot dZ^{[l]}$$\n\n\n向量化实现：$A^{[l-1]}: (n_{l-1}, m)\\\\W^{[l]}: (n_{l}, n_{l-1})\\\\b^{[l]}: (n_l, 1)\\\\Z^{[l]}: (n_l, m)\\\\A^{[l]}: (n_l, m)$\n\n**有哪些激活函数？**\n\n- sigmoid\n    $$\\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n- tanh\n    $$tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}$$\n- relu\n    $$relu(z) = max(z, 0)$$\n- leaky\n    $$leakyRelu(z) = max(0.01z, 0)\n\n**参数和超参数的区别？**\n\n- 参数：是我们在过程中想要模型学习到的信息\n\n- 超参数：为控制参数的输出值的一些网络信息（需要人经验判断）。超参数的改变会导致最终得到的参数。\n\n\n### 超参数调试，正则化和优化算法\n\n**训练集/验证集/测试集该怎么划分？**\n\n* 训练集（train set）：用训练集对算法或模型进行 **训练** 过程；\n* 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行**交叉验证**，**选择出最好的模型**；\n* 测试集（test set）：最后利用测试集对模型进行测试，**获取模型运行的无偏估计**（对学习方法进行评估）。\n\n* 对小数据量数据集，如 100、1000、10000 的数据量大小。无验证集的情况：70% / 30%；有验证集的情况：60% / 20% / 20%；\n\n* 对于大数据量数据集： 100 万数据量：98% / 1% / 1%；超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）\n\n**验证集要和训练集来自于同一个分布**（数据来源一致），如果不需要用**无偏估计**来评估模型的性能，则可以不需要测试集。\n\n\n**什么是偏差，方差，噪声？**\n\n* **偏差**：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了**学习算法本身的拟合能力**\n* **方差**：度量了同样大小的训练集的变动导致的学习性能的变化，即刻画了**数据扰动所造成的影响**\n* **噪声**：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了**学习问题本身的难度**\n\n* 训练集的错误率较小，而验证集的错误率却较大，说明模型存在较大方差，可能出现了过拟合；\n* 训练集和测试集的错误率都较大，且两者相当，说明模型存在较大偏差，可能出现了欠拟合；\n* 训练集错误率较大，且测试集的错误率远较训练集大，说明方差和偏差都较大，模型很差；\n* 训练集和测试集的错误率都较小，且两者的相差也较小，说明方差和偏差都较小，这个模型效果比较好。\n\n**如何应对高偏差和高方差？**\n\n存在高偏差：**扩大网络规模，寻找合适的网络架构，训练更多次**\n\n存在高方差：**获取更多的数据，正则化，寻找更合适的网络架构**\n\n**什么是正则化？**\n\n正则化是在代价函数中加入一个正则化项，惩罚模型的复杂度，可用于解决高方差问题。\n* L2 正则化：\n$$\\frac{\\lambda}{2m}{||w||}^2_2 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}w^2_j = \\frac{\\lambda}{2m}w^Tw$$\n\n* L1 正则化：\n$$\\frac{\\lambda}{2m}{||w||}_1 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}{|w_j|}$$\n\n**神经网络中的正则化如何表示？**\n\n对于神经网络，加入正则化的成本函数：\n\n$$J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum_{l=1}^L{||w^{[l]}||}^2_F$$\n\n因为 $w^{[l]}$ 的大小为 ($n^{[l−1]}$, $n^{[l]}$)，因此\n\n$${||w^{[l]}||}^2_F = \\sum^{n^{[l-1]}}_{i=1}\\sum^{n^{[l]}}_{j=1}(w^{[l]}_{ij})^2$$\n\n该矩阵范数被称为 **弗罗贝尼乌斯范数（Frobenius Norm）**，所以神经网络中的正则化项被称为弗罗贝尼乌斯范数矩阵。\n\n对权重的影响：\n$$dW^{[l]}= \\frac{\\partial L}{\\partial w^{[l]}} +\\frac{\\lambda}{m}W^{[l]}$$\n$$W^{[l]} := W^{[l]} - \\alpha [\\frac{\\partial L}{\\partial w^{[l]}} + \\frac{\\lambda}{m}W^{[l]}]$$\n$$= (1 - \\frac{\\alpha\\lambda}{m})W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n其中，因为 $1 - \\frac{\\alpha\\lambda}{m}<1$，会给原来的 $W^{[l]}$ 一个衰减的参数，因此 L2 正则化项也被称为**权重衰减（Weight Decay）**\n\n**什么是dropout正则化？**\n\n**dropout(随机失活)**：是在神经网络的隐藏层为每个神经元结点设置一个随机消除的概率。对于单个神经元，其工作是接收输入并产生一些有意义的输出。但是加入了 dropout 后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征，即不会给任何一个输入特征设置太大的权重。因此，通过传播过程，dropout 将产生和 L2 正则化相同的**收缩权重**的效果。\n\n**dropout的缺点，该怎么训练它？**\n\ndropout 的一大是**成本函数无法被明确定义**。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将`keep_prob`全部设置为 1.0 后运行代码，确保 $J(w, b)$ 函数单调递减，再打开 dropout。\n\n**还有什么其他的正则化方法？**\n\n* 数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。\n* 早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，在两者开始发生较大偏差时及时停止迭代，避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。\n\n**如何对输入做正则化处理？**\n\n使用正则化输入能够有效加速收敛。正则化公式：\n$$x = \\frac{x - \\mu}{\\sigma}$$\n$$\\mu = \\frac{1}{m}\\sum^m_{i=1}x^{(i)}$$\n$$\\sigma = \\sqrt{\\frac{1}{m}\\sum^m_{i=1}x^{{(i)}^2}}$$\n\n在不使用正则化的代价函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了正则化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。\n\n**什么是梯度消失和梯度爆炸？**\n\n在梯度函数上出现的以指数级递增或递减的情况分别是**梯度爆炸**和**梯度消失**\n\n**如何利用初始化缓解梯度消失和梯度爆炸？**\n\n根据\n$$z={w}_1{x}_1+{w}_2{x}_2 + ... + {w}_n{x}_n + b$$\n可知，当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。\n为了得到较小的 wi，设置`Var(wi)=1/n`，这里称为 **Xavier initialization**。同理，也有 **He Initialization**。它和  Xavier initialization 唯一的区别是`Var(wi)=2/n`，适用于 **ReLU** 作为激活函数时。\n当激活函数使用 ReLU 时，`Var(wi)=2/n`；当激活函数使用 tanh 时，`Var(wi)=1/n`。\n\n**batch/mini-batch/stochastic gradient descent三者区别？**\n\n* **Batch GD**: 是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。成本函数总是向减小的方向下降。\n* **Mini-Batch GD**: 每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。成本函数带振荡地向减小的方向下降。\n* **Stochastic GD**: 即mini-batch的size为1， 对每一个训练样本执行一次梯度下降，训练速度快，但丢失了向量化带来的计算加速。成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。\n\n**什么是指数加权平均？**\n\n**指数加权平均（Exponentially Weight Average）** 是一种常用的序列数据处理方式，计算公式为：\n\n$$S_t = \\begin{cases} Y_1, &t = 1 \\\\ \\beta S_{t-1} + (1-\\beta)Y_t, &t > 1 \\end{cases}$$\n\n其中 $Y_t$ 为 t 下的实际值，$S_t$ 为 t 下加权平均后的值，β 为权重值。\n由极限定理：\n$${\\lim_{\\beta\\to 0}}(1 - \\beta)^{\\frac{1}{\\beta}} = \\frac{1}{e} \\approx 0.368$$\n可知，指数加权平均相当于平均了前 $\\frac{1}{1-\\beta}$ 天的数据。\n\n**什么是动量梯度下降法？**\n\n**动量梯度下降（Gradient Descent with Momentum）** 是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：\n\n$$v_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]}$$\n$$v_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]}$$\n$$W^{[l]} := W^{[l]} - \\alpha v_{dW^{[l]}}$$\n$$b^{[l]} := b^{[l]} - \\alpha v_{db^{[l]}}$$\n\n通常 $\\beta = 0.9$ 将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v_{dw}$、$v_{db}$ 相当于速度。\n小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。\n\n**什么是RMSProp算法？**\n\n**RMSProp（Root Mean Square Prop，均方根支）** 算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为：\n\n$$s_{dw} = \\beta s_{dw} + (1 - \\beta)(dw)^2$$\n$$s_{db} = \\beta s_{db} + (1 - \\beta)(db)^2$$\n$$w := w - \\alpha \\frac{dw}{\\sqrt{s_{dw} + \\epsilon}}$$\n$$b := b - \\alpha \\frac{db}{\\sqrt{s_{db} + \\epsilon}}$$\n\n其中，ϵ 是一个实际操作时加上的较小数（例如10^-8），为了防止分母太小而导致的数值不稳定。RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。\n\n**什么是Adam算法？**\n\n**Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）** 基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。具体过程如下：\n\n首先进行初始化：\n\n$$v_{dW} = 0, s_{dW} = 0, v_{db} = 0, s_{db} = 0$$\n\n用每一个 mini-batch 计算 dW、db，第 t 次迭代时：\n\n$$v_{dW} = \\beta_1 v_{dW} + (1 - \\beta_1) dW$$\n$$v_{db} = \\beta_1 v_{db} + (1 - \\beta_1) db$$\n$$s_{dW} = \\beta_2 s_{dW} + (1 - \\beta_2) {(dW)}^2$$\n$$s_{db} = \\beta_2 s_{db} + (1 - \\beta_2) {(db)}^2$$\n\n一般使用 Adam 算法时需要计算偏差修正：\n\n$$v^{corrected}_{dW} = \\frac{v_{dW}}{1-{\\beta_1}^t}$$\n$$v^{corrected}_{db} = \\frac{v_{db}}{1-{\\beta_1}^t}$$\n$$s^{corrected}_{dW} = \\frac{s_{dW}}{1-{\\beta_2}^t}$$\n$$s^{corrected}_{db} = \\frac{s_{db}}{1-{\\beta_2}^t}$$\n\n所以，更新 W、b 时有：\n\n$$W := W - \\alpha \\frac{v^{corrected}_{dW}}{{\\sqrt{s^{corrected}_{dW}} + \\epsilon}}$$\n\n$$b := b - \\alpha \\frac{v^{corrected}_{db}}{{\\sqrt{s^{corrected}_{db}} + \\epsilon}}$$\n\nAdam 优化算法有很多的超参数，其中\n\n* 学习率 α：需要尝试一系列的值，来寻找比较合适的；\n* β1：常用的缺省值为 0.9；\n* β2：Adam 算法的作者建议为 0.999；\n* ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；\n\n**为什么要使用学习率衰减？**\n\n如果设置一个固定的学习率 α，在最小值点附近，由于不同的 batch 中存在一定的噪声，因此不会精确收敛，而是始终在最小值周围一个较大的范围内波动。\n而如果随着时间慢慢减少学习率 α 的大小，在初期 α 较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小 α 的值，即减小步长，有助于算法的收敛，更容易接近最优解。\n\n最常用的学习率衰减方法：\n$$\\alpha = \\frac{1}{1 + decay\\_rate \\times epoch\\_num} \\times \\alpha_0$$\n\n其中，`decay_rate`为衰减率（超参数），`epoch_num`为将所有的训练样本完整过一遍的次数。\n\n**为什么神经网络不容易陷入局部最优问题以及鞍点对学习的影响？**\n\n![saddle](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/saddle.png)\n\n**鞍点（saddle）** 是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。\n\n鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。\n\n**如何调试超参数？**\n\n* **随机选择** 点（而非均匀选取），用这些点实验超参数的效果。这样做的原因是我们提前很难知道超参数的重要程度，可以通过选择更多值来进行更多实验；\n* 由粗糙到精细：聚焦效果不错的点组成的小区域，在其中更密集地取值，以此类推；\n\n**什么是Batch Normalization?**\n\n**批标准化（Batch Normalization，经常简称为 BN）** 会使参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更庞大，工作效果也很好，也会使训练更容易。\n\n用和处理输入特征X同样的思路处理 **隐藏层** 的激活值 $a^{[l]}$，以加速 $W^{[l+1]}$ 和 $b^{[l+1]}$ 的训练。在实践中，经常选择标准化 $Z^{[l]}$\n\n$$\\mu = \\frac{1}{m} \\sum_i z^{(i)}$$\n$$\\sigma^2 = \\frac{1}{m} \\sum_i {(z_i - \\mu)}^2$$\n$$z_{norm}^{(i)} = \\frac{z^{(i)} - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$$\n\n其中，m 是单个 mini-batch 所包含的样本个数，ϵ 是为了防止分母为零，通常取 $10^{-8}$。\n\n这样，我们使得所有的输入 $z^{(i)}$ 均值为 0，方差为 1。但我们不想让隐藏层单元总是含有平均值 0 和方差 1，也许隐藏层单元有了不同的分布会更有意义。因此，我们计算\n\n$$\\tilde z^{(i)} = \\gamma z^{(i)}_{norm} + \\beta$$\n\n其中，γ 和 β 都是模型的学习参数，所以可以用各种梯度下降算法来更新 γ 和 β 的值，如同更新神经网络的权重一样。\n\n通过对 γ 和 β 的合理设置，可以让 $\\tilde z^{(i)}$ 的均值和方差为任意值。\n\n**设置 γ 和 β 的原因是**，如果各隐藏层的输入均值在靠近 0 的区域，即处于激活函数的线性区域，不利于训练非线性神经网络，从而得到效果较差的模型。因此，需要用 γ 和 β 对标准化后的结果做进一步处理。\n\n\n**为什么使用Batch Normalization？**\n\nBatch Normalization 效果很好的原因有以下两点：\n\n1. 通过对隐藏层各神经元的输入做类似的标准化处理，提高神经网络训练速度；\n2. 可以使前面层的权重变化对后面层造成的影响减小，整体网络更加健壮。\n\n即使输入的值改变了，由于 Batch Normalization 的作用，使得均值和方差保持不变（由 γ 和 β 决定），限制了在前层的参数更新对数值分布的影响程度，因此后层的学习变得更容易一些。Batch Normalization 减少了各层 W 和 b 之间的耦合性，让各层更加独立，实现自我训练学习的效果。\n\n另外，Batch Normalization 也**起到微弱的正则化**（regularization）效果。因为在每个 mini-batch 而非整个数据集上计算均值和方差，只由这一小部分数据估计得出的均值和方差会有一些噪声，因此最终计算出的 $\\tilde z^{(i)}$ 也有一定噪声。类似于 dropout，这种噪声会使得神经元不会再特别依赖于任何一个输入特征。\n\n因为 Batch Normalization 只有微弱的正则化效果，因此可以和 dropout 一起使用，以获得更强大的正则化效果。通过应用更大的 mini-batch 大小，可以减少噪声，从而减少这种正则化效果。\n\n最后，不要将 Batch Normalization 作为正则化的手段，而是当作加速学习的方式。正则化只是一种非期望的副作用，Batch Normalization 解决的还是反向传播过程中的梯度问题（梯度消失和爆炸）。\n\n### 卷积神经网络\n\n**用传统神经网络处理计算机视觉问题的缺点？**\n\n计算机视觉时要面临的一个挑战是数据的输入可能会非常大。例如一张 1000x1000x3 的图片，神经网络输入层的维度将高达三百万，使得网络权重 W 非常庞大。这样会造成两个后果：\n\n1. 神经网络结构复杂，数据量相对较少，容易出现过拟合；\n2. 所需内存和计算量巨大。\n\n因此，一般的神经网络很难处理蕴含着大量数据的图像。解决这一问题的方法就是使用**卷积神经网络（Convolutional Neural Network, CNN）**。\n\n**什么是图像的卷积运算？**\n\n卷积运算的求解过程是从左到右，由上到下，每次在原始图片矩阵中取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘后求和，将结果组成一个矩阵。滤波器中的值还可以设置为**参数**，通过模型训练来得到。在进行卷积运算时，我们有两种选择：\n\n* **Valid 卷积**：不填充，直接卷积。结果大小为 $(n-f+1) \\times (n-f+1)$；\n* **Same 卷积**：进行填充，并使得卷积后结果大小与输入一致，这样 $p = \\frac{f-1}{2}$。\n\n目前为止我们学习的“卷积”实际上被称为 **互相关（cross-correlation）**，而非数学意义上的卷积。真正的卷积操作在做元素乘积求和之前，要将滤波器沿水平和垂直轴翻转（相当于旋转 180 度）。因为这种翻转对一般为水平或垂直对称的滤波器影响不大，按照机器学习的惯例，我们通常不进行翻转操作，在简化代码的同时使神经网络能够正常工作。\n\n**什么是卷积步长？**\n\n卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置 **步长（Stride）** 来压缩一部分信息。\n\n步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。\n设步长为 $s$，填充长度为 $p$，输入图片大小为 $n \\times n$，滤波器大小为 $f \\times f$，则卷积后图片的尺寸为：\n\n$$\\biggl\\lfloor \\frac{n+2p-f}{s}+1   \\biggr\\rfloor \\times \\biggl\\lfloor \\frac{n+2p-f}{s}+1 \\biggr\\rfloor$$\n\n**什么是池化操作及它有什么作用？**\n\n与卷积操作类似，池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。池化层的作用是在卷积后很好地聚合了特征，通过降维来减少运算量, 缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。池化过程的特点之一是，它有一组超参数，但是并**没有参数需要学习**。池化过程的超参数包括滤波器的大小 $f$、步长 $s$，以及选用最大池化还是平均池化。而填充 $p$则很少用到。\n\n**为什么使用卷积？**\n\n相比标准神经网络，对于大量的输入数据，卷积过程有效地减少了 CNN 的参数数量，原因有以下两点：\n\n* **参数共享（Parameter sharing）**：特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。\n* **稀疏连接（Sparsity of connections）**：在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。\n\n由于 CNN 参数数量较小，所需的训练样本就相对较少，因此在一定程度上不容易发生过拟合现象。并且 CNN 比较擅长捕捉区域位置偏移。即进行物体检测时，不太受物体在图片中位置的影响，增加检测的准确性和系统的健壮性。\n","source":"_posts/吴恩达深度学习课程总结.md","raw":"---\ntitle: 吴恩达深度学习课程总结\ndate: 2018-09-22 11:43:27\ntags: 总结\ncategories: 深度学习\n---\n吴恩达深度学习课程学习心得\n\n这门课程由五个章节组成，分别是：\n* 神经网络和深度学习\n* 超参数调试，正则化和优化算法\n* 结构化机器学习项目\n* 卷积神经网络\n* 自然语言处理：构建序列模型\n\n### 神经网络和深度学习\n\n**什么是神经网络？**\n\n人工神经网络的研究在一定程度上受到生物学的启发，因为人的学习系统是由相互连接的神经元组成的异常复杂的网络。而人工神经网络与此大体相似，它是由一系列简单的神经元相互密集连接构成的，它尝试去发现信息处理过程中的数学表示。在大多数神经网络的实现中，神经元之间的信号是实值，每一个神经元的输出是它的所有输入信号强度和的非线性函数。连接神经元的边通常有一个权重，在学习过程中不断调整它。这个权重可以影响神经元之间传递的信号强度。神经元还可能有一个阈值来控制信号的传递。简而言之它是一个通用的函数逼近机器。\n\n\n**结构化数据和非结构化数据的区别？**\n\n- 结构化数据：由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范。\n\n- 非结构化数据：数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维逻辑表来表现的数据。包括所有格式的办公文档、文本、图片、XML, HTML、各类报表、图像和音频/视频信息等等。\n\n\n**What is Logistic Regression?**\n\nlogistic回归是监督学习中用在当输出数据是0或1时的一个学习算法。它的目标是最小化预测和真实标签之间的误差。\n\n**损失函数与代价函数的区别？**\n\n损失函数：用于衡量预测结果与真实结果之间的误差。在单个训练样本中定义。\n代价函数：衡量学习到的模型在全体样本上的表现。\n\n**什么是全连接网络的前向传播过程和反向传播过程？**\n\nforward propagation:\n$$Z^{[l]} = {W^{[l]}}A^{[l-1]} + b^{[l]}$$\n$$A^{[l]} = g(Z^{[l]})$$\n\nbackward propagation:\n$$Denotion: dA^{[l]} = \\frac{\\partial J}{\\partial A^{[l]}}\\\\dZ^{[l]} = dA^{[l]} * g'(Z^{[l]})\\\\dW^{[l]} = \\frac{1}{m}dZ^{[l]}\\cdot {A^{[l]}}^T\\\\db^{[l]} = \\frac{1}{m}np.sum(dZ^{[l]}, axis=1, keepdim=True)\\\\dA^{[l-1]} = {W^{[l]}}^T\\cdot dZ^{[l]}$$\n\n\n向量化实现：$A^{[l-1]}: (n_{l-1}, m)\\\\W^{[l]}: (n_{l}, n_{l-1})\\\\b^{[l]}: (n_l, 1)\\\\Z^{[l]}: (n_l, m)\\\\A^{[l]}: (n_l, m)$\n\n**有哪些激活函数？**\n\n- sigmoid\n    $$\\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n- tanh\n    $$tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}$$\n- relu\n    $$relu(z) = max(z, 0)$$\n- leaky\n    $$leakyRelu(z) = max(0.01z, 0)\n\n**参数和超参数的区别？**\n\n- 参数：是我们在过程中想要模型学习到的信息\n\n- 超参数：为控制参数的输出值的一些网络信息（需要人经验判断）。超参数的改变会导致最终得到的参数。\n\n\n### 超参数调试，正则化和优化算法\n\n**训练集/验证集/测试集该怎么划分？**\n\n* 训练集（train set）：用训练集对算法或模型进行 **训练** 过程；\n* 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行**交叉验证**，**选择出最好的模型**；\n* 测试集（test set）：最后利用测试集对模型进行测试，**获取模型运行的无偏估计**（对学习方法进行评估）。\n\n* 对小数据量数据集，如 100、1000、10000 的数据量大小。无验证集的情况：70% / 30%；有验证集的情况：60% / 20% / 20%；\n\n* 对于大数据量数据集： 100 万数据量：98% / 1% / 1%；超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）\n\n**验证集要和训练集来自于同一个分布**（数据来源一致），如果不需要用**无偏估计**来评估模型的性能，则可以不需要测试集。\n\n\n**什么是偏差，方差，噪声？**\n\n* **偏差**：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了**学习算法本身的拟合能力**\n* **方差**：度量了同样大小的训练集的变动导致的学习性能的变化，即刻画了**数据扰动所造成的影响**\n* **噪声**：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了**学习问题本身的难度**\n\n* 训练集的错误率较小，而验证集的错误率却较大，说明模型存在较大方差，可能出现了过拟合；\n* 训练集和测试集的错误率都较大，且两者相当，说明模型存在较大偏差，可能出现了欠拟合；\n* 训练集错误率较大，且测试集的错误率远较训练集大，说明方差和偏差都较大，模型很差；\n* 训练集和测试集的错误率都较小，且两者的相差也较小，说明方差和偏差都较小，这个模型效果比较好。\n\n**如何应对高偏差和高方差？**\n\n存在高偏差：**扩大网络规模，寻找合适的网络架构，训练更多次**\n\n存在高方差：**获取更多的数据，正则化，寻找更合适的网络架构**\n\n**什么是正则化？**\n\n正则化是在代价函数中加入一个正则化项，惩罚模型的复杂度，可用于解决高方差问题。\n* L2 正则化：\n$$\\frac{\\lambda}{2m}{||w||}^2_2 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}w^2_j = \\frac{\\lambda}{2m}w^Tw$$\n\n* L1 正则化：\n$$\\frac{\\lambda}{2m}{||w||}_1 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}{|w_j|}$$\n\n**神经网络中的正则化如何表示？**\n\n对于神经网络，加入正则化的成本函数：\n\n$$J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum_{l=1}^L{||w^{[l]}||}^2_F$$\n\n因为 $w^{[l]}$ 的大小为 ($n^{[l−1]}$, $n^{[l]}$)，因此\n\n$${||w^{[l]}||}^2_F = \\sum^{n^{[l-1]}}_{i=1}\\sum^{n^{[l]}}_{j=1}(w^{[l]}_{ij})^2$$\n\n该矩阵范数被称为 **弗罗贝尼乌斯范数（Frobenius Norm）**，所以神经网络中的正则化项被称为弗罗贝尼乌斯范数矩阵。\n\n对权重的影响：\n$$dW^{[l]}= \\frac{\\partial L}{\\partial w^{[l]}} +\\frac{\\lambda}{m}W^{[l]}$$\n$$W^{[l]} := W^{[l]} - \\alpha [\\frac{\\partial L}{\\partial w^{[l]}} + \\frac{\\lambda}{m}W^{[l]}]$$\n$$= (1 - \\frac{\\alpha\\lambda}{m})W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n其中，因为 $1 - \\frac{\\alpha\\lambda}{m}<1$，会给原来的 $W^{[l]}$ 一个衰减的参数，因此 L2 正则化项也被称为**权重衰减（Weight Decay）**\n\n**什么是dropout正则化？**\n\n**dropout(随机失活)**：是在神经网络的隐藏层为每个神经元结点设置一个随机消除的概率。对于单个神经元，其工作是接收输入并产生一些有意义的输出。但是加入了 dropout 后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征，即不会给任何一个输入特征设置太大的权重。因此，通过传播过程，dropout 将产生和 L2 正则化相同的**收缩权重**的效果。\n\n**dropout的缺点，该怎么训练它？**\n\ndropout 的一大是**成本函数无法被明确定义**。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将`keep_prob`全部设置为 1.0 后运行代码，确保 $J(w, b)$ 函数单调递减，再打开 dropout。\n\n**还有什么其他的正则化方法？**\n\n* 数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。\n* 早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，在两者开始发生较大偏差时及时停止迭代，避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。\n\n**如何对输入做正则化处理？**\n\n使用正则化输入能够有效加速收敛。正则化公式：\n$$x = \\frac{x - \\mu}{\\sigma}$$\n$$\\mu = \\frac{1}{m}\\sum^m_{i=1}x^{(i)}$$\n$$\\sigma = \\sqrt{\\frac{1}{m}\\sum^m_{i=1}x^{{(i)}^2}}$$\n\n在不使用正则化的代价函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了正则化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。\n\n**什么是梯度消失和梯度爆炸？**\n\n在梯度函数上出现的以指数级递增或递减的情况分别是**梯度爆炸**和**梯度消失**\n\n**如何利用初始化缓解梯度消失和梯度爆炸？**\n\n根据\n$$z={w}_1{x}_1+{w}_2{x}_2 + ... + {w}_n{x}_n + b$$\n可知，当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。\n为了得到较小的 wi，设置`Var(wi)=1/n`，这里称为 **Xavier initialization**。同理，也有 **He Initialization**。它和  Xavier initialization 唯一的区别是`Var(wi)=2/n`，适用于 **ReLU** 作为激活函数时。\n当激活函数使用 ReLU 时，`Var(wi)=2/n`；当激活函数使用 tanh 时，`Var(wi)=1/n`。\n\n**batch/mini-batch/stochastic gradient descent三者区别？**\n\n* **Batch GD**: 是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。成本函数总是向减小的方向下降。\n* **Mini-Batch GD**: 每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。成本函数带振荡地向减小的方向下降。\n* **Stochastic GD**: 即mini-batch的size为1， 对每一个训练样本执行一次梯度下降，训练速度快，但丢失了向量化带来的计算加速。成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。\n\n**什么是指数加权平均？**\n\n**指数加权平均（Exponentially Weight Average）** 是一种常用的序列数据处理方式，计算公式为：\n\n$$S_t = \\begin{cases} Y_1, &t = 1 \\\\ \\beta S_{t-1} + (1-\\beta)Y_t, &t > 1 \\end{cases}$$\n\n其中 $Y_t$ 为 t 下的实际值，$S_t$ 为 t 下加权平均后的值，β 为权重值。\n由极限定理：\n$${\\lim_{\\beta\\to 0}}(1 - \\beta)^{\\frac{1}{\\beta}} = \\frac{1}{e} \\approx 0.368$$\n可知，指数加权平均相当于平均了前 $\\frac{1}{1-\\beta}$ 天的数据。\n\n**什么是动量梯度下降法？**\n\n**动量梯度下降（Gradient Descent with Momentum）** 是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：\n\n$$v_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]}$$\n$$v_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]}$$\n$$W^{[l]} := W^{[l]} - \\alpha v_{dW^{[l]}}$$\n$$b^{[l]} := b^{[l]} - \\alpha v_{db^{[l]}}$$\n\n通常 $\\beta = 0.9$ 将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v_{dw}$、$v_{db}$ 相当于速度。\n小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。\n\n**什么是RMSProp算法？**\n\n**RMSProp（Root Mean Square Prop，均方根支）** 算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为：\n\n$$s_{dw} = \\beta s_{dw} + (1 - \\beta)(dw)^2$$\n$$s_{db} = \\beta s_{db} + (1 - \\beta)(db)^2$$\n$$w := w - \\alpha \\frac{dw}{\\sqrt{s_{dw} + \\epsilon}}$$\n$$b := b - \\alpha \\frac{db}{\\sqrt{s_{db} + \\epsilon}}$$\n\n其中，ϵ 是一个实际操作时加上的较小数（例如10^-8），为了防止分母太小而导致的数值不稳定。RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。\n\n**什么是Adam算法？**\n\n**Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）** 基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。具体过程如下：\n\n首先进行初始化：\n\n$$v_{dW} = 0, s_{dW} = 0, v_{db} = 0, s_{db} = 0$$\n\n用每一个 mini-batch 计算 dW、db，第 t 次迭代时：\n\n$$v_{dW} = \\beta_1 v_{dW} + (1 - \\beta_1) dW$$\n$$v_{db} = \\beta_1 v_{db} + (1 - \\beta_1) db$$\n$$s_{dW} = \\beta_2 s_{dW} + (1 - \\beta_2) {(dW)}^2$$\n$$s_{db} = \\beta_2 s_{db} + (1 - \\beta_2) {(db)}^2$$\n\n一般使用 Adam 算法时需要计算偏差修正：\n\n$$v^{corrected}_{dW} = \\frac{v_{dW}}{1-{\\beta_1}^t}$$\n$$v^{corrected}_{db} = \\frac{v_{db}}{1-{\\beta_1}^t}$$\n$$s^{corrected}_{dW} = \\frac{s_{dW}}{1-{\\beta_2}^t}$$\n$$s^{corrected}_{db} = \\frac{s_{db}}{1-{\\beta_2}^t}$$\n\n所以，更新 W、b 时有：\n\n$$W := W - \\alpha \\frac{v^{corrected}_{dW}}{{\\sqrt{s^{corrected}_{dW}} + \\epsilon}}$$\n\n$$b := b - \\alpha \\frac{v^{corrected}_{db}}{{\\sqrt{s^{corrected}_{db}} + \\epsilon}}$$\n\nAdam 优化算法有很多的超参数，其中\n\n* 学习率 α：需要尝试一系列的值，来寻找比较合适的；\n* β1：常用的缺省值为 0.9；\n* β2：Adam 算法的作者建议为 0.999；\n* ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；\n\n**为什么要使用学习率衰减？**\n\n如果设置一个固定的学习率 α，在最小值点附近，由于不同的 batch 中存在一定的噪声，因此不会精确收敛，而是始终在最小值周围一个较大的范围内波动。\n而如果随着时间慢慢减少学习率 α 的大小，在初期 α 较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小 α 的值，即减小步长，有助于算法的收敛，更容易接近最优解。\n\n最常用的学习率衰减方法：\n$$\\alpha = \\frac{1}{1 + decay\\_rate \\times epoch\\_num} \\times \\alpha_0$$\n\n其中，`decay_rate`为衰减率（超参数），`epoch_num`为将所有的训练样本完整过一遍的次数。\n\n**为什么神经网络不容易陷入局部最优问题以及鞍点对学习的影响？**\n\n![saddle](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/saddle.png)\n\n**鞍点（saddle）** 是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。\n\n鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。\n\n**如何调试超参数？**\n\n* **随机选择** 点（而非均匀选取），用这些点实验超参数的效果。这样做的原因是我们提前很难知道超参数的重要程度，可以通过选择更多值来进行更多实验；\n* 由粗糙到精细：聚焦效果不错的点组成的小区域，在其中更密集地取值，以此类推；\n\n**什么是Batch Normalization?**\n\n**批标准化（Batch Normalization，经常简称为 BN）** 会使参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更庞大，工作效果也很好，也会使训练更容易。\n\n用和处理输入特征X同样的思路处理 **隐藏层** 的激活值 $a^{[l]}$，以加速 $W^{[l+1]}$ 和 $b^{[l+1]}$ 的训练。在实践中，经常选择标准化 $Z^{[l]}$\n\n$$\\mu = \\frac{1}{m} \\sum_i z^{(i)}$$\n$$\\sigma^2 = \\frac{1}{m} \\sum_i {(z_i - \\mu)}^2$$\n$$z_{norm}^{(i)} = \\frac{z^{(i)} - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$$\n\n其中，m 是单个 mini-batch 所包含的样本个数，ϵ 是为了防止分母为零，通常取 $10^{-8}$。\n\n这样，我们使得所有的输入 $z^{(i)}$ 均值为 0，方差为 1。但我们不想让隐藏层单元总是含有平均值 0 和方差 1，也许隐藏层单元有了不同的分布会更有意义。因此，我们计算\n\n$$\\tilde z^{(i)} = \\gamma z^{(i)}_{norm} + \\beta$$\n\n其中，γ 和 β 都是模型的学习参数，所以可以用各种梯度下降算法来更新 γ 和 β 的值，如同更新神经网络的权重一样。\n\n通过对 γ 和 β 的合理设置，可以让 $\\tilde z^{(i)}$ 的均值和方差为任意值。\n\n**设置 γ 和 β 的原因是**，如果各隐藏层的输入均值在靠近 0 的区域，即处于激活函数的线性区域，不利于训练非线性神经网络，从而得到效果较差的模型。因此，需要用 γ 和 β 对标准化后的结果做进一步处理。\n\n\n**为什么使用Batch Normalization？**\n\nBatch Normalization 效果很好的原因有以下两点：\n\n1. 通过对隐藏层各神经元的输入做类似的标准化处理，提高神经网络训练速度；\n2. 可以使前面层的权重变化对后面层造成的影响减小，整体网络更加健壮。\n\n即使输入的值改变了，由于 Batch Normalization 的作用，使得均值和方差保持不变（由 γ 和 β 决定），限制了在前层的参数更新对数值分布的影响程度，因此后层的学习变得更容易一些。Batch Normalization 减少了各层 W 和 b 之间的耦合性，让各层更加独立，实现自我训练学习的效果。\n\n另外，Batch Normalization 也**起到微弱的正则化**（regularization）效果。因为在每个 mini-batch 而非整个数据集上计算均值和方差，只由这一小部分数据估计得出的均值和方差会有一些噪声，因此最终计算出的 $\\tilde z^{(i)}$ 也有一定噪声。类似于 dropout，这种噪声会使得神经元不会再特别依赖于任何一个输入特征。\n\n因为 Batch Normalization 只有微弱的正则化效果，因此可以和 dropout 一起使用，以获得更强大的正则化效果。通过应用更大的 mini-batch 大小，可以减少噪声，从而减少这种正则化效果。\n\n最后，不要将 Batch Normalization 作为正则化的手段，而是当作加速学习的方式。正则化只是一种非期望的副作用，Batch Normalization 解决的还是反向传播过程中的梯度问题（梯度消失和爆炸）。\n\n### 卷积神经网络\n\n**用传统神经网络处理计算机视觉问题的缺点？**\n\n计算机视觉时要面临的一个挑战是数据的输入可能会非常大。例如一张 1000x1000x3 的图片，神经网络输入层的维度将高达三百万，使得网络权重 W 非常庞大。这样会造成两个后果：\n\n1. 神经网络结构复杂，数据量相对较少，容易出现过拟合；\n2. 所需内存和计算量巨大。\n\n因此，一般的神经网络很难处理蕴含着大量数据的图像。解决这一问题的方法就是使用**卷积神经网络（Convolutional Neural Network, CNN）**。\n\n**什么是图像的卷积运算？**\n\n卷积运算的求解过程是从左到右，由上到下，每次在原始图片矩阵中取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘后求和，将结果组成一个矩阵。滤波器中的值还可以设置为**参数**，通过模型训练来得到。在进行卷积运算时，我们有两种选择：\n\n* **Valid 卷积**：不填充，直接卷积。结果大小为 $(n-f+1) \\times (n-f+1)$；\n* **Same 卷积**：进行填充，并使得卷积后结果大小与输入一致，这样 $p = \\frac{f-1}{2}$。\n\n目前为止我们学习的“卷积”实际上被称为 **互相关（cross-correlation）**，而非数学意义上的卷积。真正的卷积操作在做元素乘积求和之前，要将滤波器沿水平和垂直轴翻转（相当于旋转 180 度）。因为这种翻转对一般为水平或垂直对称的滤波器影响不大，按照机器学习的惯例，我们通常不进行翻转操作，在简化代码的同时使神经网络能够正常工作。\n\n**什么是卷积步长？**\n\n卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置 **步长（Stride）** 来压缩一部分信息。\n\n步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。\n设步长为 $s$，填充长度为 $p$，输入图片大小为 $n \\times n$，滤波器大小为 $f \\times f$，则卷积后图片的尺寸为：\n\n$$\\biggl\\lfloor \\frac{n+2p-f}{s}+1   \\biggr\\rfloor \\times \\biggl\\lfloor \\frac{n+2p-f}{s}+1 \\biggr\\rfloor$$\n\n**什么是池化操作及它有什么作用？**\n\n与卷积操作类似，池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。池化层的作用是在卷积后很好地聚合了特征，通过降维来减少运算量, 缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。池化过程的特点之一是，它有一组超参数，但是并**没有参数需要学习**。池化过程的超参数包括滤波器的大小 $f$、步长 $s$，以及选用最大池化还是平均池化。而填充 $p$则很少用到。\n\n**为什么使用卷积？**\n\n相比标准神经网络，对于大量的输入数据，卷积过程有效地减少了 CNN 的参数数量，原因有以下两点：\n\n* **参数共享（Parameter sharing）**：特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。\n* **稀疏连接（Sparsity of connections）**：在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。\n\n由于 CNN 参数数量较小，所需的训练样本就相对较少，因此在一定程度上不容易发生过拟合现象。并且 CNN 比较擅长捕捉区域位置偏移。即进行物体检测时，不太受物体在图片中位置的影响，增加检测的准确性和系统的健壮性。\n","slug":"吴恩达深度学习课程总结","published":1,"updated":"2018-09-22T05:35:02.561Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ozj002m44vo8i7tp3t1"},{"title":"布雷默曼极限","date":"2018-08-05T13:38:25.000Z","mathjax":true,"_content":"\n**以Hans-Joachim Bremermann命名的 Bremermann极限是物质世界中独立系统的最大计算速度**由爱因斯坦的质能效应和海森堡测不准原理得到。\n\n$$\\frac{c^2}{h} \\approx 1.36 \\times 10^{50} bits/s\\cdot kg$$\n\n在设计加密算法时，此值很重要，因为它可用于确定加密密钥的最小大小或创建一个永远不会被暴力搜索破解的算法所需的哈希值。例如，在Bremermann极限下运行整个地球质量的计算机每秒可执行大约$10^{75}$次数学计算。如果假设只使用一个操作可以测试加密密钥，那么典型的128位密钥可以在$10^{36}$秒内被破解。但是，256位密钥（已在某些系统中使用）将需要大约两分钟才能破解。使用512位密钥会将破解时间增加到接近$10^{72}$年，而不会将加密时间增加超过常数因子（取决于所使用的加密算法）。\n","source":"_posts/布雷默曼极限.md","raw":"---\ntitle: 布雷默曼极限\ndate: 2018-08-05 21:38:25\ntags: 物理\ncategories: 计算机科学\nmathjax: true\n---\n\n**以Hans-Joachim Bremermann命名的 Bremermann极限是物质世界中独立系统的最大计算速度**由爱因斯坦的质能效应和海森堡测不准原理得到。\n\n$$\\frac{c^2}{h} \\approx 1.36 \\times 10^{50} bits/s\\cdot kg$$\n\n在设计加密算法时，此值很重要，因为它可用于确定加密密钥的最小大小或创建一个永远不会被暴力搜索破解的算法所需的哈希值。例如，在Bremermann极限下运行整个地球质量的计算机每秒可执行大约$10^{75}$次数学计算。如果假设只使用一个操作可以测试加密密钥，那么典型的128位密钥可以在$10^{36}$秒内被破解。但是，256位密钥（已在某些系统中使用）将需要大约两分钟才能破解。使用512位密钥会将破解时间增加到接近$10^{72}$年，而不会将加密时间增加超过常数因子（取决于所使用的加密算法）。\n","slug":"布雷默曼极限","published":1,"updated":"2018-08-31T03:53:16.775Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ozm002q44vouz6hti9e"},{"title":"循环神经网络","date":"2018-09-01T09:05:05.000Z","mathjax":true,"_content":"**循环神经网络(Recurrent Neural Network)** 是一类用于处理序列数据的神经网络。如自然语言，音频这类前后关联的数据。\n\n使用RNN实现的应用包括下图所示：\n![Examples-of-Sequence-Model](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-Sequence-Model.png)\n\n## 数学符号\n\n对于一个序列数据 $x$，用符号 $x^{⟨t⟩}$ 来表示这个数据中的第 $t$个元素，用 $y^{⟨t⟩}$ 来表示第 $t$ 个标签，用 $T_x$ 和 $T_y$ 来表示输入和输出的长度。对于一段音频，元素可能是其中的几帧；对于一句话，元素可能是一到多个单词。\n\n第 $i$ 个序列数据的第 $t$ 个元素用符号 $x^{(i)⟨t⟩}$，第 $t$ 个标签即为 $y^{(i)⟨t⟩}$。对应即有 $T^{(i)}_x$ 和 $T^{(i)}_y$。\n\n想要表示一个词语，需要先建立一个 **词汇表（Vocabulary**，或者叫 **字典（Dictionary**。将需要表示的所有词语变为一个列向量，可以根据字母顺序排列，然后根据单词在向量中的位置，用 **one-hot 向量（one-hot vector）** 来表示该单词的标签：将每个单词编码成一个 $R^{|V| \\times 1}$ 向量，其中 $|V|$ 是词汇表中单词的数量。一个单词在词汇表中的索引在该向量对应的元素为 1，其余元素均为 0。\n\n例如，'zebra'排在词汇表的最后一位，因此它的词向量表示为：\n\n$$w^{zebra} = \\left [ 0, 0, 0, ..., 1\\right ]^T$$\n\n## 循环神经网络模型\n\n对于序列数据，使用标准神经网络存在以下问题：\n\n* 对于不同的示例，输入和输出可能有不同的长度，因此输入层和输出层的神经元数量无法固定。\n* 从输入文本的不同位置学到的同一特征无法共享。\n* 模型中的参数太多，计算量太大。\n\n为了解决这些问题，引入 **循环神经网络（Recurrent Neural Network，RNN）**。一种循环神经网络的结构如下图所示：\n\n![Recurrent-Neural-Network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Recurrent-Neural-Network.png)\n\n当元素 $x^{⟨t⟩}$ 输入对应时间步（Time Step）的隐藏层的同时，该隐藏层也会接收来自上一时间步的隐藏层的激活值 $a^{⟨t-1⟩}$，其中 $a^{⟨0⟩}$ 一般直接初始化为零向量。一个时间步输出一个对应的预测结果 $\\hat y^{⟨t⟩}$。\n\n循环神经网络从左向右扫描数据，同时每个时间步的参数也是共享的，输入、激活、输出的参数对应为 $W_{ax}$、$W_{aa}$、$W_{ay}$。\n\n下图是一个 RNN 神经元的结构：\n\n![RNN-cell](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/RNN-cell.png)\n\n前向传播过程的公式如下：\n\n$$a^{⟨0⟩} = \\vec{0}$$\n\n$$a^{⟨t⟩} = g_1(W_{aa}a^{⟨t-1⟩} + W_{ax}x^{⟨t⟩} + b_a)$$\n\n$$\\hat y^{⟨t⟩} = g_2(W_{ya}a^{⟨t⟩} + b_y)$$\n\n激活函数 $g_1$通常选择 tanh，有时也用 ReLU；$g_2$可选 sigmoid 或 softmax，取决于需要的输出类型。\n\n为了进一步简化公式以方便运算，可以将 $W_{ax}$、$W_{aa}$**水平并列** 为一个矩阵 $W_a$，同时 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$ **堆叠** 成一个矩阵。则有：\n\n$$W_a = [W_{ax}, W_{aa}]$$\n\n$$a^{⟨t⟩} = g_1(W_a[a^{⟨t-1⟩}, x^{⟨t⟩}] + b_a)$$\n\n$$\\hat y^{⟨t⟩} = g_2(W_{y}a^{⟨t⟩} + b_y)$$\n\n### 反向传播\n\n为了计算反向传播过程，需要先定义一个损失函数。单个位置上（或者说单个时间步上）某个单词的预测值的损失函数采用**交叉熵损失函数**，如下所示：\n\n$$L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -y^{⟨t⟩}log\\hat y^{⟨t⟩} - (1 - y^{⟨t⟩})log(1-\\hat y^{⟨t⟩})$$\n\n将单个位置上的损失函数相加，得到整个序列的成本函数如下：\n\n$$J = L(\\hat y, y) = \\sum^{T_x}_{t=1} L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$\n\n循环神经网络的反向传播被称为 **通过时间反向传播（Backpropagation through time）**，因为从右向左计算的过程就像是时间倒流。\n\n### 不同结构\n\n某些情况下，输入长度和输出长度不一致。根据所需的输入及输出长度，循环神经网络可分为“一对一”、“多对一”、“多对多”等结构：\n\n![Examples-of-RNN-architectures](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-RNN-architectures.png)\n\n目前我们看到的模型的问题是，只使用了这个序列中之前的信息来做出预测，即后文没有被使用。可以通过 **双向循环神经网络（Bidirectional RNN，BRNN）** 来解决这个问题。\n\n## 语言模型\n\n**语言模型（Language Model）** 是根据语言客观事实而进行的语言抽象数学建模，能够估计某个序列中各元素出现的可能性。例如，在一个语音识别系统中，语言模型能够计算两个读音相近的句子为正确结果的概率，以此为依据作出准确判断。\n\n建立语言模型所采用的训练集是一个大型的 **语料库（Corpus）**，指数量众多的句子组成的文本。建立过程的第一步是 **标记化（Tokenize）**，即建立字典；然后将语料库中的每个词表示为对应的 one-hot 向量。另外，需要增加一个额外的标记 EOS（End of Sentence）来表示一个句子的结尾。标点符号可以忽略，也可以加入字典后用 one-hot 向量表示。\n\n对于语料库中部分特殊的、不包含在字典中的词汇，例如人名、地名，可以不必针对这些具体的词，而是在词典中加入一个 UNK（Unique Token）标记来表示。\n\n将标志化后的训练集用于训练 RNN，过程如下图所示：\n\n![language-model-RNN-example](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/language-model-RNN-example.png)\n\n在第一个时间步中，输入的 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 都是零向量，$\\hat y^{⟨1⟩}$ 是通过 softmax 预测出的字典中每个词作为第一个词出现的概率；在第二个时间步中，输入的 $x^{⟨2⟩}$ 是训练样本的标签中的第一个单词 $y^{⟨1⟩}$（即“cats”）和上一层的激活项 $a^{⟨1⟩}$，输出的 $y^{⟨2⟩}$ 表示的是通过 softmax 预测出的、单词“cats”后面出现字典中的其他每个词的条件概率。以此类推，最后就可以得到整个句子出现的概率。\n\n定义损失函数为：\n\n$$L(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -\\sum_t y_i^{⟨t⟩} log \\hat y^{⟨t⟩}$$\n\n则成本函数为：\n\n$$J = \\sum_t L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$\n\n## 采样\n\n在训练好一个语言模型后，可以通过 **采样（Sample）** 新的序列来了解这个模型中都学习到了一些什么。\n\n![Sampling](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Sampling.png)\n\n在第一个时间步输入 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 为零向量，输出预测出的字典中每个词作为第一个词出现的概率，根据 softmax 的分布进行随机采样（`np.random.choice`），将采样得到的 $\\hat y^{⟨1⟩}$ 作为第二个时间步的输入 $x^{⟨2⟩}$。以此类推，直到采样到 EOS，最后模型会自动生成一些句子，从这些句子中可以发现模型通过语料库学习到的知识。\n\n这里建立的是基于词汇构建的语言模型。根据需要也可以构建基于字符的语言模型，其优点是不必担心出现未知标识（UNK），其缺点是得到的序列过多过长，并且训练成本高昂。因此，基于词汇构建的语言模型更为常用。\n\n## RNN 的梯度消失\n\n$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$\n\n$$The\\ cats, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ were\\ full.$$\n\n对于以上两个句子，后面的动词单复数形式由前面的名词的单复数形式决定。但是 **基本的 RNN 不擅长捕获这种长期依赖关系**。究其原因，由于梯度消失，在反向传播时，后面层的输出误差很难影响到较靠前层的计算，网络很难调整靠前的计算。\n\n在反向传播时，随着层数的增多，梯度不仅可能指数型下降，也有可能指数型上升，即梯度爆炸。不过梯度爆炸比较容易发现，因为参数会急剧膨胀到数值溢出（可能显示为 NaN）。这时可以采用 **梯度修剪（Gradient Clipping）** 来解决：观察梯度向量，如果它大于某个阈值，则缩放梯度向量以保证其不会太大。相比之下，梯度消失问题更难解决。**GRU 和 LSTM 都可以作为缓解梯度消失问题的方案**。\n\n## GRU（门控循环单元）\n\n**GRU（Gated Recurrent Units, 门控循环单元）** 改善了 RNN 的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题。\n\n$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$\n\n当我们从左到右读上面这个句子时，GRU 单元有一个新的变量称为 $c$，代表 **记忆细胞（Memory Cell）**，其作用是提供记忆的能力，记住例如前文主语是单数还是复数等信息。在时间 t，记忆细胞的值 $c^{⟨t⟩}$ 等于输出的激活值 $a^{⟨t⟩}$；$\\tilde c^{⟨t⟩}$ 代表下一个 $c$ 的候选值。$Γ_u$ 代表 **更新门（Update Gate）** ，用于决定什么时候更新记忆细胞的值。以上结构的具体公式为：\n\n$$\\tilde c^{⟨t⟩} = tanh(W_c[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$\n\n$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$\n\n$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$\n\n$$a^{⟨t⟩} = c^{⟨t⟩}$$\n\n当使用 sigmoid 作为激活函数 $\\sigma$ 来得到 $Γ_u$时，$Γ_u$ 的值在 0 到 1 的范围内，且大多数时间非常接近于 0 或 1。当 $Γ_u = 1$时，$c^{⟨t⟩}$ 被更新为 $\\tilde c^{⟨t⟩}$，否则保持为 $c^{⟨t-1⟩}$。因为 $Γ_u$ 可以很接近 0，因此 $c^{⟨t⟩}$ 几乎就等于 $c^{⟨t-1⟩}$。在经过很长的序列后，$c$ 的值依然被维持，从而实现“记忆”的功能。\n\n以上实际上是简化过的 GRU 单元，但是蕴涵了 GRU 最重要的思想。完整的 GRU 单元添加了一个新的**相关门（Relevance Gate）** $Γ_r$，表示 $\\tilde c^{⟨t⟩}$ 和 $c^{⟨t⟩}$ 的相关性。因此，表达式改为如下所示：\n\n$$\\tilde c^{⟨t⟩} = tanh(W_c[Γ_r * c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$\n\n$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$\n\n$$Γ_r = \\sigma(W_r[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_r)$$\n\n$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$\n\n$$a^{⟨t⟩} = c^{⟨t⟩}$$\n\n相关论文：\n\n1. [Cho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches](https://arxiv.org/pdf/1409.1259.pdf)\n2. [Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/pdf/1412.3555.pdf)\n\n## LSTM（长短期记忆）\n\n**LSTM（Long Short Term Memory，长短期记忆）** 网络比 GRU 更加灵活和强大，它额外引入了 **遗忘门（Forget Gate）** $Γ_f$ 和 **输出门（Output Gate）** $Γ_o$。其结构图和公式如下：\n\n![LSTM](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/LSTM.png)\n\n将多个 LSTM 单元按时间次序连接起来，就得到一个 LSTM 网络。\n\n以上是简化版的 LSTM。在更为常用的版本中，几个门值不仅取决于 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$，有时也可以偷窥上一个记忆细胞输入的值 $c^{⟨t-1⟩}$，这被称为 **窥视孔连接（Peephole Connection)**。这时，和 GRU 不同，$c^{⟨t-1⟩}$ 和门值是一对一的。\n\n$c^{0}$ 常被初始化为零向量。\n\n相关论文：[Hochreiter & Schmidhuber 1997. Long short-term memory](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory)\n\n## 双向循环神经网络（BRNN）\n\n单向的循环神经网络在某一时刻的预测结果只能使用之前输入的序列信息。**双向循环神经网络（Bidirectional RNN，BRNN）** 可以在序列的任意位置使用之前和之后的数据。其工作原理是增加一个反向循环层，结构如下图所示：\n\n![BRNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/BRNN.png)\n\n因此，有\n\n$$y^{⟨t⟩} = g(W_y[\\overrightarrow a^{⟨t⟩},  \\overleftarrow a^{⟨t⟩}] + b_y)$$\n\n这个改进的方法不仅能用于基本的 RNN，也可以用于 GRU 或 LSTM。**缺点** 是需要完整的序列数据，才能预测任意位置的结果。例如构建语音识别系统，需要等待用户说完并获取整个语音表达，才能处理这段语音并进一步做语音识别。因此，实际应用会有更加复杂的模块。\n\n## 深度循环神经网络（DRNN)\n\n循环神经网络的每个时间步上也可以包含多个隐藏层，形成 **深度循环神经网络（Deep RNN)** 。结构如下图所示：\n\n![DRNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/DRNN.png)\n\n以 $a^{[2]⟨3⟩}$ 为例，有 $a^{[2]⟨3⟩} = g(W_a^{[2]}[a^{[2]⟨2⟩}, a^{[1]⟨3⟩}] + b_a^{[2]})$。\n","source":"_posts/循环神经网络.md","raw":"---\ntitle: 循环神经网络\ndate: 2018-09-01 17:05:05\ntags: RNN\ncategories: 深度学习\nmathjax: true\n---\n**循环神经网络(Recurrent Neural Network)** 是一类用于处理序列数据的神经网络。如自然语言，音频这类前后关联的数据。\n\n使用RNN实现的应用包括下图所示：\n![Examples-of-Sequence-Model](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-Sequence-Model.png)\n\n## 数学符号\n\n对于一个序列数据 $x$，用符号 $x^{⟨t⟩}$ 来表示这个数据中的第 $t$个元素，用 $y^{⟨t⟩}$ 来表示第 $t$ 个标签，用 $T_x$ 和 $T_y$ 来表示输入和输出的长度。对于一段音频，元素可能是其中的几帧；对于一句话，元素可能是一到多个单词。\n\n第 $i$ 个序列数据的第 $t$ 个元素用符号 $x^{(i)⟨t⟩}$，第 $t$ 个标签即为 $y^{(i)⟨t⟩}$。对应即有 $T^{(i)}_x$ 和 $T^{(i)}_y$。\n\n想要表示一个词语，需要先建立一个 **词汇表（Vocabulary**，或者叫 **字典（Dictionary**。将需要表示的所有词语变为一个列向量，可以根据字母顺序排列，然后根据单词在向量中的位置，用 **one-hot 向量（one-hot vector）** 来表示该单词的标签：将每个单词编码成一个 $R^{|V| \\times 1}$ 向量，其中 $|V|$ 是词汇表中单词的数量。一个单词在词汇表中的索引在该向量对应的元素为 1，其余元素均为 0。\n\n例如，'zebra'排在词汇表的最后一位，因此它的词向量表示为：\n\n$$w^{zebra} = \\left [ 0, 0, 0, ..., 1\\right ]^T$$\n\n## 循环神经网络模型\n\n对于序列数据，使用标准神经网络存在以下问题：\n\n* 对于不同的示例，输入和输出可能有不同的长度，因此输入层和输出层的神经元数量无法固定。\n* 从输入文本的不同位置学到的同一特征无法共享。\n* 模型中的参数太多，计算量太大。\n\n为了解决这些问题，引入 **循环神经网络（Recurrent Neural Network，RNN）**。一种循环神经网络的结构如下图所示：\n\n![Recurrent-Neural-Network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Recurrent-Neural-Network.png)\n\n当元素 $x^{⟨t⟩}$ 输入对应时间步（Time Step）的隐藏层的同时，该隐藏层也会接收来自上一时间步的隐藏层的激活值 $a^{⟨t-1⟩}$，其中 $a^{⟨0⟩}$ 一般直接初始化为零向量。一个时间步输出一个对应的预测结果 $\\hat y^{⟨t⟩}$。\n\n循环神经网络从左向右扫描数据，同时每个时间步的参数也是共享的，输入、激活、输出的参数对应为 $W_{ax}$、$W_{aa}$、$W_{ay}$。\n\n下图是一个 RNN 神经元的结构：\n\n![RNN-cell](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/RNN-cell.png)\n\n前向传播过程的公式如下：\n\n$$a^{⟨0⟩} = \\vec{0}$$\n\n$$a^{⟨t⟩} = g_1(W_{aa}a^{⟨t-1⟩} + W_{ax}x^{⟨t⟩} + b_a)$$\n\n$$\\hat y^{⟨t⟩} = g_2(W_{ya}a^{⟨t⟩} + b_y)$$\n\n激活函数 $g_1$通常选择 tanh，有时也用 ReLU；$g_2$可选 sigmoid 或 softmax，取决于需要的输出类型。\n\n为了进一步简化公式以方便运算，可以将 $W_{ax}$、$W_{aa}$**水平并列** 为一个矩阵 $W_a$，同时 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$ **堆叠** 成一个矩阵。则有：\n\n$$W_a = [W_{ax}, W_{aa}]$$\n\n$$a^{⟨t⟩} = g_1(W_a[a^{⟨t-1⟩}, x^{⟨t⟩}] + b_a)$$\n\n$$\\hat y^{⟨t⟩} = g_2(W_{y}a^{⟨t⟩} + b_y)$$\n\n### 反向传播\n\n为了计算反向传播过程，需要先定义一个损失函数。单个位置上（或者说单个时间步上）某个单词的预测值的损失函数采用**交叉熵损失函数**，如下所示：\n\n$$L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -y^{⟨t⟩}log\\hat y^{⟨t⟩} - (1 - y^{⟨t⟩})log(1-\\hat y^{⟨t⟩})$$\n\n将单个位置上的损失函数相加，得到整个序列的成本函数如下：\n\n$$J = L(\\hat y, y) = \\sum^{T_x}_{t=1} L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$\n\n循环神经网络的反向传播被称为 **通过时间反向传播（Backpropagation through time）**，因为从右向左计算的过程就像是时间倒流。\n\n### 不同结构\n\n某些情况下，输入长度和输出长度不一致。根据所需的输入及输出长度，循环神经网络可分为“一对一”、“多对一”、“多对多”等结构：\n\n![Examples-of-RNN-architectures](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Examples-of-RNN-architectures.png)\n\n目前我们看到的模型的问题是，只使用了这个序列中之前的信息来做出预测，即后文没有被使用。可以通过 **双向循环神经网络（Bidirectional RNN，BRNN）** 来解决这个问题。\n\n## 语言模型\n\n**语言模型（Language Model）** 是根据语言客观事实而进行的语言抽象数学建模，能够估计某个序列中各元素出现的可能性。例如，在一个语音识别系统中，语言模型能够计算两个读音相近的句子为正确结果的概率，以此为依据作出准确判断。\n\n建立语言模型所采用的训练集是一个大型的 **语料库（Corpus）**，指数量众多的句子组成的文本。建立过程的第一步是 **标记化（Tokenize）**，即建立字典；然后将语料库中的每个词表示为对应的 one-hot 向量。另外，需要增加一个额外的标记 EOS（End of Sentence）来表示一个句子的结尾。标点符号可以忽略，也可以加入字典后用 one-hot 向量表示。\n\n对于语料库中部分特殊的、不包含在字典中的词汇，例如人名、地名，可以不必针对这些具体的词，而是在词典中加入一个 UNK（Unique Token）标记来表示。\n\n将标志化后的训练集用于训练 RNN，过程如下图所示：\n\n![language-model-RNN-example](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/language-model-RNN-example.png)\n\n在第一个时间步中，输入的 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 都是零向量，$\\hat y^{⟨1⟩}$ 是通过 softmax 预测出的字典中每个词作为第一个词出现的概率；在第二个时间步中，输入的 $x^{⟨2⟩}$ 是训练样本的标签中的第一个单词 $y^{⟨1⟩}$（即“cats”）和上一层的激活项 $a^{⟨1⟩}$，输出的 $y^{⟨2⟩}$ 表示的是通过 softmax 预测出的、单词“cats”后面出现字典中的其他每个词的条件概率。以此类推，最后就可以得到整个句子出现的概率。\n\n定义损失函数为：\n\n$$L(\\hat y^{⟨t⟩}, y^{⟨t⟩}) = -\\sum_t y_i^{⟨t⟩} log \\hat y^{⟨t⟩}$$\n\n则成本函数为：\n\n$$J = \\sum_t L^{⟨t⟩}(\\hat y^{⟨t⟩}, y^{⟨t⟩})$$\n\n## 采样\n\n在训练好一个语言模型后，可以通过 **采样（Sample）** 新的序列来了解这个模型中都学习到了一些什么。\n\n![Sampling](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Sampling.png)\n\n在第一个时间步输入 $a^{⟨0⟩}$ 和 $x^{⟨1⟩}$ 为零向量，输出预测出的字典中每个词作为第一个词出现的概率，根据 softmax 的分布进行随机采样（`np.random.choice`），将采样得到的 $\\hat y^{⟨1⟩}$ 作为第二个时间步的输入 $x^{⟨2⟩}$。以此类推，直到采样到 EOS，最后模型会自动生成一些句子，从这些句子中可以发现模型通过语料库学习到的知识。\n\n这里建立的是基于词汇构建的语言模型。根据需要也可以构建基于字符的语言模型，其优点是不必担心出现未知标识（UNK），其缺点是得到的序列过多过长，并且训练成本高昂。因此，基于词汇构建的语言模型更为常用。\n\n## RNN 的梯度消失\n\n$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$\n\n$$The\\ cats, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ were\\ full.$$\n\n对于以上两个句子，后面的动词单复数形式由前面的名词的单复数形式决定。但是 **基本的 RNN 不擅长捕获这种长期依赖关系**。究其原因，由于梯度消失，在反向传播时，后面层的输出误差很难影响到较靠前层的计算，网络很难调整靠前的计算。\n\n在反向传播时，随着层数的增多，梯度不仅可能指数型下降，也有可能指数型上升，即梯度爆炸。不过梯度爆炸比较容易发现，因为参数会急剧膨胀到数值溢出（可能显示为 NaN）。这时可以采用 **梯度修剪（Gradient Clipping）** 来解决：观察梯度向量，如果它大于某个阈值，则缩放梯度向量以保证其不会太大。相比之下，梯度消失问题更难解决。**GRU 和 LSTM 都可以作为缓解梯度消失问题的方案**。\n\n## GRU（门控循环单元）\n\n**GRU（Gated Recurrent Units, 门控循环单元）** 改善了 RNN 的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题。\n\n$$The\\ cat, which\\ already\\ ate\\ a\\ bunch\\ of\\ food,\\ was\\ full.$$\n\n当我们从左到右读上面这个句子时，GRU 单元有一个新的变量称为 $c$，代表 **记忆细胞（Memory Cell）**，其作用是提供记忆的能力，记住例如前文主语是单数还是复数等信息。在时间 t，记忆细胞的值 $c^{⟨t⟩}$ 等于输出的激活值 $a^{⟨t⟩}$；$\\tilde c^{⟨t⟩}$ 代表下一个 $c$ 的候选值。$Γ_u$ 代表 **更新门（Update Gate）** ，用于决定什么时候更新记忆细胞的值。以上结构的具体公式为：\n\n$$\\tilde c^{⟨t⟩} = tanh(W_c[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$\n\n$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$\n\n$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$\n\n$$a^{⟨t⟩} = c^{⟨t⟩}$$\n\n当使用 sigmoid 作为激活函数 $\\sigma$ 来得到 $Γ_u$时，$Γ_u$ 的值在 0 到 1 的范围内，且大多数时间非常接近于 0 或 1。当 $Γ_u = 1$时，$c^{⟨t⟩}$ 被更新为 $\\tilde c^{⟨t⟩}$，否则保持为 $c^{⟨t-1⟩}$。因为 $Γ_u$ 可以很接近 0，因此 $c^{⟨t⟩}$ 几乎就等于 $c^{⟨t-1⟩}$。在经过很长的序列后，$c$ 的值依然被维持，从而实现“记忆”的功能。\n\n以上实际上是简化过的 GRU 单元，但是蕴涵了 GRU 最重要的思想。完整的 GRU 单元添加了一个新的**相关门（Relevance Gate）** $Γ_r$，表示 $\\tilde c^{⟨t⟩}$ 和 $c^{⟨t⟩}$ 的相关性。因此，表达式改为如下所示：\n\n$$\\tilde c^{⟨t⟩} = tanh(W_c[Γ_r * c^{⟨t-1⟩}, x^{⟨t⟩}] + b_c)$$\n\n$$Γ_u = \\sigma(W_u[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_u)$$\n\n$$Γ_r = \\sigma(W_r[c^{⟨t-1⟩}, x^{⟨t⟩}] + b_r)$$\n\n$$c^{⟨t⟩} = Γ_u \\times \\tilde c^{⟨t⟩} + (1 - Γ_u) \\times c^{⟨t-1⟩}$$\n\n$$a^{⟨t⟩} = c^{⟨t⟩}$$\n\n相关论文：\n\n1. [Cho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches](https://arxiv.org/pdf/1409.1259.pdf)\n2. [Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/pdf/1412.3555.pdf)\n\n## LSTM（长短期记忆）\n\n**LSTM（Long Short Term Memory，长短期记忆）** 网络比 GRU 更加灵活和强大，它额外引入了 **遗忘门（Forget Gate）** $Γ_f$ 和 **输出门（Output Gate）** $Γ_o$。其结构图和公式如下：\n\n![LSTM](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/LSTM.png)\n\n将多个 LSTM 单元按时间次序连接起来，就得到一个 LSTM 网络。\n\n以上是简化版的 LSTM。在更为常用的版本中，几个门值不仅取决于 $a^{⟨t-1⟩}$ 和 $x^{⟨t⟩}$，有时也可以偷窥上一个记忆细胞输入的值 $c^{⟨t-1⟩}$，这被称为 **窥视孔连接（Peephole Connection)**。这时，和 GRU 不同，$c^{⟨t-1⟩}$ 和门值是一对一的。\n\n$c^{0}$ 常被初始化为零向量。\n\n相关论文：[Hochreiter & Schmidhuber 1997. Long short-term memory](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory)\n\n## 双向循环神经网络（BRNN）\n\n单向的循环神经网络在某一时刻的预测结果只能使用之前输入的序列信息。**双向循环神经网络（Bidirectional RNN，BRNN）** 可以在序列的任意位置使用之前和之后的数据。其工作原理是增加一个反向循环层，结构如下图所示：\n\n![BRNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/BRNN.png)\n\n因此，有\n\n$$y^{⟨t⟩} = g(W_y[\\overrightarrow a^{⟨t⟩},  \\overleftarrow a^{⟨t⟩}] + b_y)$$\n\n这个改进的方法不仅能用于基本的 RNN，也可以用于 GRU 或 LSTM。**缺点** 是需要完整的序列数据，才能预测任意位置的结果。例如构建语音识别系统，需要等待用户说完并获取整个语音表达，才能处理这段语音并进一步做语音识别。因此，实际应用会有更加复杂的模块。\n\n## 深度循环神经网络（DRNN)\n\n循环神经网络的每个时间步上也可以包含多个隐藏层，形成 **深度循环神经网络（Deep RNN)** 。结构如下图所示：\n\n![DRNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/DRNN.png)\n\n以 $a^{[2]⟨3⟩}$ 为例，有 $a^{[2]⟨3⟩} = g(W_a^{[2]}[a^{[2]⟨2⟩}, a^{[1]⟨3⟩}] + b_a^{[2]})$。\n","slug":"循环神经网络","published":1,"updated":"2018-09-01T14:15:14.770Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ozo002t44voelyg2r65"},{"title":"恋爱领域中普遍存在的贬低倾向","date":"2018-07-19T13:03:37.000Z","_content":"\n## 心理阳痿\n\n### 症状\n\n受该障碍困扰者，力比多的活动强烈而旺盛，然而在发作时，执行性欲之器官却无法实行性行为。只有在与某些人做爱时才会失败，与其他人则不会。\n\n### 成因\n\n实际上，这是由于主体的某些心理情结尚未得到认识而产生出的抑制力。他未能克服对母亲或姐妹的乱伦固着，这一点在病因中十分显著，且普遍存在于受此障碍困扰的人身上。此外，主体在婴幼儿时期的性活动中意外获得的某些受挫印象所产生的影响力从总体上削减了理应导向女性性对象的力比多。该障碍的基础在于，在力比多的发展获得我们所谓的正常的最终形态之前，其发展历程中出现了一种抑制，而这或许也是所有神经官能障碍的基础。有两种因素的结合保证了完全正确的爱情态度，即 **情感趋向**和 **肉欲趋向**。这一发展上的抑制有两个来源：一是童年期的强烈固着，二是在反乱伦壁垒的干涉下个体在现实中遭遇了挫折。\n\n### 措施\n\n从心理上贬低性对象，而正常情况在对性对象的过高评价，在这里则会被留给了乱伦对象及其代表。一旦完成心理上的贬低，便能自由地表达性欲。\n\n----\n摘自弗洛伊德的《爱情心理学》第二章\n","source":"_posts/恋爱领域中普遍存在的贬低倾向.md","raw":"---\ntitle: 恋爱领域中普遍存在的贬低倾向\ndate: 2018-07-19 21:03:37\ntags: 爱情心理学\ncategories: 心理学\n---\n\n## 心理阳痿\n\n### 症状\n\n受该障碍困扰者，力比多的活动强烈而旺盛，然而在发作时，执行性欲之器官却无法实行性行为。只有在与某些人做爱时才会失败，与其他人则不会。\n\n### 成因\n\n实际上，这是由于主体的某些心理情结尚未得到认识而产生出的抑制力。他未能克服对母亲或姐妹的乱伦固着，这一点在病因中十分显著，且普遍存在于受此障碍困扰的人身上。此外，主体在婴幼儿时期的性活动中意外获得的某些受挫印象所产生的影响力从总体上削减了理应导向女性性对象的力比多。该障碍的基础在于，在力比多的发展获得我们所谓的正常的最终形态之前，其发展历程中出现了一种抑制，而这或许也是所有神经官能障碍的基础。有两种因素的结合保证了完全正确的爱情态度，即 **情感趋向**和 **肉欲趋向**。这一发展上的抑制有两个来源：一是童年期的强烈固着，二是在反乱伦壁垒的干涉下个体在现实中遭遇了挫折。\n\n### 措施\n\n从心理上贬低性对象，而正常情况在对性对象的过高评价，在这里则会被留给了乱伦对象及其代表。一旦完成心理上的贬低，便能自由地表达性欲。\n\n----\n摘自弗洛伊德的《爱情心理学》第二章\n","slug":"恋爱领域中普遍存在的贬低倾向","published":1,"updated":"2018-08-31T03:53:26.675Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ozs002x44vozohaqs67"},{"title":"数据划分：训练 / 验证 / 测试集","date":"2018-07-20T06:52:44.000Z","_content":"\n## 数据划分：训练 / 验证 / 测试集\n\n应用深度学习是一个典型的迭代过程。\n\n对于一个需要解决的问题的样本数据，在建立模型的过程中，数据会被划分为以下几个部分：\n\n* 训练集（train set）：用训练集对算法或模型进行**训练**过程；\n* 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行**交叉验证**，**选择出最好的模型**；\n* 测试集（test set）：最后利用测试集对模型进行测试，**获取模型运行的无偏估计**（对学习方法进行评估）。\n\n在**小数据量**的时代，如 100、1000、10000 的数据量大小，可以将数据集按照以下比例进行划分：\n\n* 无验证集的情况：70% / 30%；\n* 有验证集的情况：60% / 20% / 20%；\n\n而在如今的**大数据时代**，对于一个问题，我们拥有的数据集的规模可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。\n\n验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大到能够验证大约 2-10 种算法哪种更好，而不需要使用 20% 的数据作为验证集。如百万数据中抽取 1 万的数据作为验证集就可以了。\n\n测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中 1000 条数据足以评估单个模型的效果。\n\n* 100 万数据量：98% / 1% / 1%；\n* 超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）\n\n### 建议\n\n建议**验证集要和训练集来自于同一个分布**（数据来源一致），可以使得机器学习算法变得更快并获得更好的效果。\n\n如果不需要用**无偏估计**来评估模型的性能，则可以不需要测试集。\n\n### 补充：交叉验证（cross validation）\n\n交叉验证的基本思想是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。\n\n### 参考资料\n\n[无偏估计_百度百科](https://baike.baidu.com/item/%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1/3370664?fr=aladdin)\n","source":"_posts/数据划分.md","raw":"---\ntitle: 数据划分：训练 / 验证 / 测试集\ndate: 2018-07-20 14:52:44\ntags: 数据\ncategories: 深度学习\n---\n\n## 数据划分：训练 / 验证 / 测试集\n\n应用深度学习是一个典型的迭代过程。\n\n对于一个需要解决的问题的样本数据，在建立模型的过程中，数据会被划分为以下几个部分：\n\n* 训练集（train set）：用训练集对算法或模型进行**训练**过程；\n* 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行**交叉验证**，**选择出最好的模型**；\n* 测试集（test set）：最后利用测试集对模型进行测试，**获取模型运行的无偏估计**（对学习方法进行评估）。\n\n在**小数据量**的时代，如 100、1000、10000 的数据量大小，可以将数据集按照以下比例进行划分：\n\n* 无验证集的情况：70% / 30%；\n* 有验证集的情况：60% / 20% / 20%；\n\n而在如今的**大数据时代**，对于一个问题，我们拥有的数据集的规模可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。\n\n验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大到能够验证大约 2-10 种算法哪种更好，而不需要使用 20% 的数据作为验证集。如百万数据中抽取 1 万的数据作为验证集就可以了。\n\n测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中 1000 条数据足以评估单个模型的效果。\n\n* 100 万数据量：98% / 1% / 1%；\n* 超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）\n\n### 建议\n\n建议**验证集要和训练集来自于同一个分布**（数据来源一致），可以使得机器学习算法变得更快并获得更好的效果。\n\n如果不需要用**无偏估计**来评估模型的性能，则可以不需要测试集。\n\n### 补充：交叉验证（cross validation）\n\n交叉验证的基本思想是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。\n\n### 参考资料\n\n[无偏估计_百度百科](https://baike.baidu.com/item/%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1/3370664?fr=aladdin)\n","slug":"数据划分","published":1,"updated":"2018-08-31T03:53:47.798Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ozv003044vo93v2f1ey"},{"title":"数据的加载-预处理-可视化","date":"2018-07-21T09:33:49.000Z","_content":"## 图片操作\n\n### 把图片转换为向量\n\n```python\ndef image2vector(image):\n    \"\"\"\n    Argument:\n    image -- a numpy array of shape (length, height, depth)\n\n    Returns:\n    v -- a vector of shape (length*height*depth, 1)\n    \"\"\"\n    v = image.reshape((image.shape[0] * image.shape[1] * image.shape[2], 1))    \n    return v\n```\n### 读入图片\n\n```python\nmy_image = \"my_image.jpg\" # change this to the name of your image file\nmy_label_y = [1] # the true class of your image (1 -> cat, 0 -> non-cat)\nfname = \"images/\" + my_image\nimage = np.array(ndimage.imread(fname, flatten=False))\nmy_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))\nmy_predicted_image = predict(my_image, my_label_y, parameters)\n\nplt.imshow(image)\nprint (\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")\n```\n\n## 矩阵的正则化\n\n```python\ndef normalize(x):\n    \"\"\"\n    Implement a function that normalizes each row of the matrix x (to have unit length).\n\n    Argument:\n    x -- A numpy matrix of shape (n, m)\n\n    Returns:\n    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n    \"\"\"\n    x_norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)  # column: axis=0\n    x = x / x_norm\n    return x\n```\n\n## 猫的数据集\n\n```python\ndef load_dataset():\n    \"\"\"\n    Returns:\n    train_set_x_orig -- shape of (209, 64, 64, 3)\n    train_set_y_orig -- shape of (1, 209)\n    test_set_x_orig -- shape of (50, 64, 64, 3)\n    test_set_y_orig -- shape of (1, 50)\n    \"\"\"\n    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n\n    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n\n    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n\n    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n\n    return train_set_x_orig, train_set_y_orig, test_set_x_origtest_set_x_orig, test_set_y_orig, classes\n```\n\n### 可视化\n\n```python\nindex = 23\nplt.imshow(train_set_x_orig[index])\nprint (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")\nplt.show()\n```\n\n### 向量化\n\n```python\ntrain_x_set_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\ntest_x_set_flatten = train_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n```\n\n### 标准化\n\n```python\ntrain_x_set = train_x_set_flatten / 255\ntest_x_set = test_x_set_flatten / 255\n```\n\n## 二维数据的一般操作\n\n### 加载\n\n```python\ndef load_planar_dataset():\n    \"\"\"\n    Returns:\n    X -- a numpy array shaped (2, 400) that contains features (x1, x2)\n    Y -- a numpy array shaped (1, 400) that contains labels (0, 1)\n    \"\"\"\n    np.random.seed(1)\n    m = 400  # number of examples\n    N = int(m / 2)  # number of points per class\n    D = 2  # dimensionality\n    X = np.zeros((m, D))  # data matrix where each row is a single example\n    # labels vector (0 for red, 1 for blue)\n    Y = np.zeros((m, 1), dtype='uint8')\n    a = 4  # maximum ray of the flower\n    for j in range(2):\n        ix = range(N * j, N * (j + 1))\n        t = np.linspace(j * 3.12, (j + 1) * 3.12, N) + \\\n            np.random.randn(N) * 0.2  # theta\n        r = a * np.sin(4 * t) + np.random.randn(N) * 0.2  # radius\n        X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n        Y[ix] = j\n    X = X.T\n    Y = Y.T\n    return X, Y\n```\n\n### 可视化\n\n```python\nplt.scatter(X[0, :], X[1, :], c=Y.flatten(), s=40, cmp=plt.cm.Spectral)\nplt.show()\n```\n\n### 可视化决策边界\n\n```python\ndef plot_decision_boundary(model, X, y):\n    # Set min and max values and give it some padding\n    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n    h = 0.01\n    # Generate a grid of points with distance h between them\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    # Predict the function value for the whole grid\n    Z = model(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    # Plot the contour and training examples\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n    plt.ylabel('x2')\n    plt.xlabel('x1')\n    plt.scatter(X[0, :], X[1, :], c=y.flatten(), cmap=plt.cm.Spectral)\n```\n\n\n## Sklearn中的其他数据集\n\n```python\ndef load_extra_datasets():\n    N = 200\n    noisy_circles = sklearn.datasets.make_circles(\n        n_samples=N, factor=.5, noise=.3)\n    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n    blobs = sklearn.datasets.make_blobs(\n        n_samples=N, random_state=5, n_features=2, centers=6)\n    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(\n        mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n\n    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure\n```\n","source":"_posts/数据的加载-预处理-可视化.md","raw":"---\ntitle: 数据的加载-预处理-可视化\ndate: 2018-07-21 17:33:49\ntags: 数据\ncategories: 深度学习\n---\n## 图片操作\n\n### 把图片转换为向量\n\n```python\ndef image2vector(image):\n    \"\"\"\n    Argument:\n    image -- a numpy array of shape (length, height, depth)\n\n    Returns:\n    v -- a vector of shape (length*height*depth, 1)\n    \"\"\"\n    v = image.reshape((image.shape[0] * image.shape[1] * image.shape[2], 1))    \n    return v\n```\n### 读入图片\n\n```python\nmy_image = \"my_image.jpg\" # change this to the name of your image file\nmy_label_y = [1] # the true class of your image (1 -> cat, 0 -> non-cat)\nfname = \"images/\" + my_image\nimage = np.array(ndimage.imread(fname, flatten=False))\nmy_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))\nmy_predicted_image = predict(my_image, my_label_y, parameters)\n\nplt.imshow(image)\nprint (\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")\n```\n\n## 矩阵的正则化\n\n```python\ndef normalize(x):\n    \"\"\"\n    Implement a function that normalizes each row of the matrix x (to have unit length).\n\n    Argument:\n    x -- A numpy matrix of shape (n, m)\n\n    Returns:\n    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n    \"\"\"\n    x_norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)  # column: axis=0\n    x = x / x_norm\n    return x\n```\n\n## 猫的数据集\n\n```python\ndef load_dataset():\n    \"\"\"\n    Returns:\n    train_set_x_orig -- shape of (209, 64, 64, 3)\n    train_set_y_orig -- shape of (1, 209)\n    test_set_x_orig -- shape of (50, 64, 64, 3)\n    test_set_y_orig -- shape of (1, 50)\n    \"\"\"\n    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n\n    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n\n    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n\n    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n\n    return train_set_x_orig, train_set_y_orig, test_set_x_origtest_set_x_orig, test_set_y_orig, classes\n```\n\n### 可视化\n\n```python\nindex = 23\nplt.imshow(train_set_x_orig[index])\nprint (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")\nplt.show()\n```\n\n### 向量化\n\n```python\ntrain_x_set_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\ntest_x_set_flatten = train_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n```\n\n### 标准化\n\n```python\ntrain_x_set = train_x_set_flatten / 255\ntest_x_set = test_x_set_flatten / 255\n```\n\n## 二维数据的一般操作\n\n### 加载\n\n```python\ndef load_planar_dataset():\n    \"\"\"\n    Returns:\n    X -- a numpy array shaped (2, 400) that contains features (x1, x2)\n    Y -- a numpy array shaped (1, 400) that contains labels (0, 1)\n    \"\"\"\n    np.random.seed(1)\n    m = 400  # number of examples\n    N = int(m / 2)  # number of points per class\n    D = 2  # dimensionality\n    X = np.zeros((m, D))  # data matrix where each row is a single example\n    # labels vector (0 for red, 1 for blue)\n    Y = np.zeros((m, 1), dtype='uint8')\n    a = 4  # maximum ray of the flower\n    for j in range(2):\n        ix = range(N * j, N * (j + 1))\n        t = np.linspace(j * 3.12, (j + 1) * 3.12, N) + \\\n            np.random.randn(N) * 0.2  # theta\n        r = a * np.sin(4 * t) + np.random.randn(N) * 0.2  # radius\n        X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n        Y[ix] = j\n    X = X.T\n    Y = Y.T\n    return X, Y\n```\n\n### 可视化\n\n```python\nplt.scatter(X[0, :], X[1, :], c=Y.flatten(), s=40, cmp=plt.cm.Spectral)\nplt.show()\n```\n\n### 可视化决策边界\n\n```python\ndef plot_decision_boundary(model, X, y):\n    # Set min and max values and give it some padding\n    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n    h = 0.01\n    # Generate a grid of points with distance h between them\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    # Predict the function value for the whole grid\n    Z = model(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    # Plot the contour and training examples\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n    plt.ylabel('x2')\n    plt.xlabel('x1')\n    plt.scatter(X[0, :], X[1, :], c=y.flatten(), cmap=plt.cm.Spectral)\n```\n\n\n## Sklearn中的其他数据集\n\n```python\ndef load_extra_datasets():\n    N = 200\n    noisy_circles = sklearn.datasets.make_circles(\n        n_samples=N, factor=.5, noise=.3)\n    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n    blobs = sklearn.datasets.make_blobs(\n        n_samples=N, random_state=5, n_features=2, centers=6)\n    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(\n        mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n\n    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure\n```\n","slug":"数据的加载-预处理-可视化","published":1,"updated":"2018-08-31T03:54:02.897Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19ozz003344voew1qcddr"},{"title":"标准化输入","date":"2018-07-20T08:27:20.000Z","mathjax":true,"_content":"## 标准化输入\n\n使用标准化处理输入 X 能够有效加速收敛。\n\n### 标准化公式\n\n$$x = \\frac{x - \\mu}{\\sigma}$$\n\n其中，\n\n$$\\mu = \\frac{1}{m}\\sum^m\\_{i=1}x^{(i)}$$\n\n$$\\sigma = \\sqrt{\\frac{1}{m}\\sum^m\\_{i=1}{x^{(i)}}^2}$$\n\n（注意，课程上对应内容中的标准化公式疑似有误，将标准差写成了方差，此处进行修正）\n\n### 使用标准化的原因\n\n![why_normalize](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/why_normalize.png)\n\n有图可知，使用标准化前后，成本函数的形状有较大差别。\n\n在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。\n","source":"_posts/标准化输入.md","raw":"---\ntitle: 标准化输入\ndate: 2018-07-20 16:27:20\ntags: 优化算法\ncategories: 深度学习\nmathjax: true\n---\n## 标准化输入\n\n使用标准化处理输入 X 能够有效加速收敛。\n\n### 标准化公式\n\n$$x = \\frac{x - \\mu}{\\sigma}$$\n\n其中，\n\n$$\\mu = \\frac{1}{m}\\sum^m\\_{i=1}x^{(i)}$$\n\n$$\\sigma = \\sqrt{\\frac{1}{m}\\sum^m\\_{i=1}{x^{(i)}}^2}$$\n\n（注意，课程上对应内容中的标准化公式疑似有误，将标准差写成了方差，此处进行修正）\n\n### 使用标准化的原因\n\n![why_normalize](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/why_normalize.png)\n\n有图可知，使用标准化前后，成本函数的形状有较大差别。\n\n在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。\n","slug":"标准化输入","published":1,"updated":"2018-08-31T03:54:12.437Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p02003744vo0nsn71px"},{"title":"梯度检验","date":"2018-07-20T08:31:29.000Z","mathjax":true,"_content":"## 梯度检验（Gradient checking）\n\n### 梯度的数值逼近\n\n使用双边误差的方法去逼近导数，精度要高于单边误差。\n\n* 单边误差：\n\n![one-sided-difference](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/one-sided-difference.png)\n\n$$f'(\\theta) = \\lim\\_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta)}{\\varepsilon}$$\n\n误差：$O(\\varepsilon)$\n\n* 双边误差求导（即导数的定义）：\n\n![two-sided-difference](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/two-sided-difference.png)\n\n$$f'(\\theta) = \\lim\\_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta - \\varepsilon)}{2\\varepsilon}$$\n\n误差：$O(\\varepsilon^2)$\n\n当 ε 越小时，结果越接近真实的导数，也就是梯度值。可以使用这种方法来判断反向传播进行梯度下降时，是否出现了错误。\n\n### 梯度检验的实施\n\n#### 连接参数\n\n将 $W^{[1]}$，$b^{[1]}$，...，$W^{[L]}$，$b^{[L]}$全部连接出来，成为一个巨型向量 θ。这样，\n\n$$J(W^{[1]}, b^{[1]}, ..., W^{[L]}，b^{[L]}) = J(\\theta)$$\n\n同时，对 $dW^{[1]}$，$db^{[1]}$，...，$dW^{[L]}$，$db^{[L]}$执行同样的操作得到巨型向量 dθ，它和 θ 有同样的维度。\n\n![dictionary_to_vector](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dictionary_to_vector.png)\n\n现在，我们需要找到 dθ 和代价函数 J 的梯度的关系。\n\n#### 进行梯度检验\n\n求得一个梯度逼近值\n\n$$d\\theta_{approx}[i] ＝ \\frac{J(\\theta\\_1, \\theta\\_2, ..., \\theta\\_i+\\varepsilon, ...) - J(\\theta\\_1, \\theta\\_2, ..., \\theta\\_i-\\varepsilon, ...)}{2\\varepsilon}$$\n\n应该\n\n$$\\approx{d\\theta[i]} = \\frac{\\partial J}{\\partial \\theta_i}$$\n\n因此，我们用梯度检验值\n\n$$\\frac{||d\\theta\\_{approx} - d\\theta||\\_2}{||d\\theta\\_{approx}||\\_2+||d\\theta||\\_2}$$\n\n检验反向传播的实施是否正确。其中，\n\n$${||x||}\\_2 = \\sum^N\\_{i=1}{|x_i|}^2$$\n\n表示向量 x 的 2-范数（也称“欧几里德范数”）。\n\n如果梯度检验值和 ε 的值相近，说明神经网络的实施是正确的，否则要去检查代码是否存在 bug。\n\n### 在神经网络实施梯度检验的实用技巧和注意事项\n\n1. 不要在训练中使用梯度检验，它只用于调试（debug）。使用完毕关闭梯度检验的功能；\n2. 如果算法的梯度检验失败，要检查所有项，并试着找出 bug，即确定哪个 dθapprox[i] 与 dθ 的值相差比较大；\n3. 当成本函数包含正则项时，也需要带上正则项进行检验；\n4. 梯度检验不能与 dropout 同时使用。因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的成本函数 J。建议关闭 dropout，用梯度检验进行双重检查，确定在没有 dropout 的情况下算法正确，然后打开 dropout；\n","source":"_posts/梯度检验.md","raw":"---\ntitle: 梯度检验\ndate: 2018-07-20 16:31:29\ntags: 优化算法\ncategories: 深度学习\nmathjax: true\n---\n## 梯度检验（Gradient checking）\n\n### 梯度的数值逼近\n\n使用双边误差的方法去逼近导数，精度要高于单边误差。\n\n* 单边误差：\n\n![one-sided-difference](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/one-sided-difference.png)\n\n$$f'(\\theta) = \\lim\\_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta)}{\\varepsilon}$$\n\n误差：$O(\\varepsilon)$\n\n* 双边误差求导（即导数的定义）：\n\n![two-sided-difference](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/two-sided-difference.png)\n\n$$f'(\\theta) = \\lim\\_{\\varepsilon\\to 0} = \\frac{f(\\theta + \\varepsilon) - (\\theta - \\varepsilon)}{2\\varepsilon}$$\n\n误差：$O(\\varepsilon^2)$\n\n当 ε 越小时，结果越接近真实的导数，也就是梯度值。可以使用这种方法来判断反向传播进行梯度下降时，是否出现了错误。\n\n### 梯度检验的实施\n\n#### 连接参数\n\n将 $W^{[1]}$，$b^{[1]}$，...，$W^{[L]}$，$b^{[L]}$全部连接出来，成为一个巨型向量 θ。这样，\n\n$$J(W^{[1]}, b^{[1]}, ..., W^{[L]}，b^{[L]}) = J(\\theta)$$\n\n同时，对 $dW^{[1]}$，$db^{[1]}$，...，$dW^{[L]}$，$db^{[L]}$执行同样的操作得到巨型向量 dθ，它和 θ 有同样的维度。\n\n![dictionary_to_vector](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/dictionary_to_vector.png)\n\n现在，我们需要找到 dθ 和代价函数 J 的梯度的关系。\n\n#### 进行梯度检验\n\n求得一个梯度逼近值\n\n$$d\\theta_{approx}[i] ＝ \\frac{J(\\theta\\_1, \\theta\\_2, ..., \\theta\\_i+\\varepsilon, ...) - J(\\theta\\_1, \\theta\\_2, ..., \\theta\\_i-\\varepsilon, ...)}{2\\varepsilon}$$\n\n应该\n\n$$\\approx{d\\theta[i]} = \\frac{\\partial J}{\\partial \\theta_i}$$\n\n因此，我们用梯度检验值\n\n$$\\frac{||d\\theta\\_{approx} - d\\theta||\\_2}{||d\\theta\\_{approx}||\\_2+||d\\theta||\\_2}$$\n\n检验反向传播的实施是否正确。其中，\n\n$${||x||}\\_2 = \\sum^N\\_{i=1}{|x_i|}^2$$\n\n表示向量 x 的 2-范数（也称“欧几里德范数”）。\n\n如果梯度检验值和 ε 的值相近，说明神经网络的实施是正确的，否则要去检查代码是否存在 bug。\n\n### 在神经网络实施梯度检验的实用技巧和注意事项\n\n1. 不要在训练中使用梯度检验，它只用于调试（debug）。使用完毕关闭梯度检验的功能；\n2. 如果算法的梯度检验失败，要检查所有项，并试着找出 bug，即确定哪个 dθapprox[i] 与 dθ 的值相差比较大；\n3. 当成本函数包含正则项时，也需要带上正则项进行检验；\n4. 梯度检验不能与 dropout 同时使用。因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的成本函数 J。建议关闭 dropout，用梯度检验进行双重检查，确定在没有 dropout 的情况下算法正确，然后打开 dropout；\n","slug":"梯度检验","published":1,"updated":"2018-08-31T03:54:25.694Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p06003a44vo5dt4e90l"},{"title":"梯度消失和梯度爆炸","date":"2018-07-20T08:25:16.000Z","categroies":"深度学习","mathjax":true,"_content":"\n## 梯度消失和梯度爆炸\n\n在梯度函数上出现的以指数级递增或者递减的情况分别称为**梯度爆炸**或者**梯度消失**。\n\n假定 $g(z) = z, b^{[l]} = 0$，对于目标输出有：\n\n$$\\hat{y} = W^{[L]}W^{[L-1]}...W^{[2]}W^{[1]}X$$\n\n* 对于 $W^{[l]}$的值大于 1 的情况，激活函数的值将以指数级递增；\n* 对于 $W^{[l]}$的值小于 1 的情况，激活函数的值将以指数级递减。\n\n对于导数同理。因此，在计算梯度时，根据不同情况梯度函数会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。\n\n### 利用初始化缓解梯度消失和爆炸\n\n根据\n\n$$z={w}_1{x}\\_1+{w}\\_2{x}\\_2 + ... + {w}\\_n{x}\\_n + b$$\n\n可知，当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。\n\n为了得到较小的 wi，设置`Var(wi)=1/n`，这里称为 **Xavier initialization**。\n\n```python\nWL = np.random.randn(WL.shape[0], WL.shape[1]) * np.sqrt(1/n)\n```\n\n其中 n 是输入的神经元个数，即`WL.shape[1]`。\n\n这样，激活函数的输入 x 近似设置成均值为 0，标准方差为 1，神经元输出 z 的方差就正则化到 1 了。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。\n\n同理，也有 **He Initialization**。它和  Xavier initialization 唯一的区别是`Var(wi)=2/n`，适用于 **ReLU** 作为激活函数时。\n\n当激活函数使用 ReLU 时，`Var(wi)=2/n`；当激活函数使用 tanh 时，`Var(wi)=1/n`。\n","source":"_posts/梯度消失和梯度爆炸.md","raw":"---\ntitle: 梯度消失和梯度爆炸\ndate: 2018-07-20 16:25:16\ntags: 优化算法\ncategroies: 深度学习\nmathjax: true\n---\n\n## 梯度消失和梯度爆炸\n\n在梯度函数上出现的以指数级递增或者递减的情况分别称为**梯度爆炸**或者**梯度消失**。\n\n假定 $g(z) = z, b^{[l]} = 0$，对于目标输出有：\n\n$$\\hat{y} = W^{[L]}W^{[L-1]}...W^{[2]}W^{[1]}X$$\n\n* 对于 $W^{[l]}$的值大于 1 的情况，激活函数的值将以指数级递增；\n* 对于 $W^{[l]}$的值小于 1 的情况，激活函数的值将以指数级递减。\n\n对于导数同理。因此，在计算梯度时，根据不同情况梯度函数会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。\n\n### 利用初始化缓解梯度消失和爆炸\n\n根据\n\n$$z={w}_1{x}\\_1+{w}\\_2{x}\\_2 + ... + {w}\\_n{x}\\_n + b$$\n\n可知，当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。\n\n为了得到较小的 wi，设置`Var(wi)=1/n`，这里称为 **Xavier initialization**。\n\n```python\nWL = np.random.randn(WL.shape[0], WL.shape[1]) * np.sqrt(1/n)\n```\n\n其中 n 是输入的神经元个数，即`WL.shape[1]`。\n\n这样，激活函数的输入 x 近似设置成均值为 0，标准方差为 1，神经元输出 z 的方差就正则化到 1 了。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。\n\n同理，也有 **He Initialization**。它和  Xavier initialization 唯一的区别是`Var(wi)=2/n`，适用于 **ReLU** 作为激活函数时。\n\n当激活函数使用 ReLU 时，`Var(wi)=2/n`；当激活函数使用 tanh 时，`Var(wi)=1/n`。\n","slug":"梯度消失和梯度爆炸","published":1,"updated":"2018-08-31T03:54:36.141Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0a003e44voe1vvqnlr"},{"title":"模型估计：偏差 / 方差","date":"2018-07-20T07:56:17.000Z","_content":"## 模型估计：偏差 / 方差\n\n**“偏差-方差分解”（bias-variance decomposition）**是解释学习算法泛化性能的一种重要工具。\n\n泛化误差可分解为偏差、方差与噪声之和：\n\n* **偏差**：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了**学习算法本身的拟合能力**；\n* **方差**：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了**数据扰动所造成的影响**；\n* **噪声**：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了**学习问题本身的难度**。\n\n偏差-方差分解说明，**泛化性能**是由**学习算法的能力**、**数据的充分性**以及**学习任务本身的难度**所共同决定的。给定学习任务，为了取得好的泛化性能，则需要使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。\n\n<!-- 以上摘自周志华《机器学习》 -->\n\n在**欠拟合（underfitting）**的情况下，出现**高偏差（high bias）**的情况，即不能很好地对数据进行分类。\n\n当模型设置的太复杂时，训练集中的一些噪声没有被排除，使得模型出现**过拟合（overfitting）**的情况，在验证集上出现**高方差（high variance）**的现象。\n\n当训练出一个模型以后，如果：\n\n* 训练集的错误率较小，而验证集的错误率却较大，说明模型存在较大方差，可能出现了过拟合；\n* 训练集和开发集的错误率都较大，且两者相当，说明模型存在较大偏差，可能出现了欠拟合；\n* 训练集错误率较大，且开发集的错误率远较训练集大，说明方差和偏差都较大，模型很差；\n* 训练集和开发集的错误率都较小，且两者的相差也较小，说明方差和偏差都较小，这个模型效果比较好。\n\n偏差和方差的权衡问题对于模型来说十分重要。\n\n最优误差通常也称为“贝叶斯误差”。\n\n### 应对方法\n\n存在高偏差：\n\n* 扩大网络规模，如添加隐藏层或隐藏单元数目；\n* 寻找合适的网络架构，使用更大的 NN 结构；\n* 花费更长时间训练。\n\n存在高方差：\n\n* 获取更多的数据；\n* 正则化（regularization）；\n* 寻找更合适的网络结构。\n\n不断尝试，直到找到低偏差、低方差的框架。\n\n在深度学习的早期阶段，没有太多方法能做到只减少偏差或方差而不影响到另外一方。而在大数据时代，深度学习对监督式学习大有裨益，使得我们不用像以前一样太过关注如何平衡偏差和方差的权衡问题，通过以上方法可以在不增加某一方的前提下减少另一方的值。\n","source":"_posts/模型估计.md","raw":"---\ntitle: 模型估计：偏差 / 方差\ndate: 2018-07-20 15:56:17\ntags: 模型估计\ncategories: 深度学习\n---\n## 模型估计：偏差 / 方差\n\n**“偏差-方差分解”（bias-variance decomposition）**是解释学习算法泛化性能的一种重要工具。\n\n泛化误差可分解为偏差、方差与噪声之和：\n\n* **偏差**：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了**学习算法本身的拟合能力**；\n* **方差**：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了**数据扰动所造成的影响**；\n* **噪声**：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了**学习问题本身的难度**。\n\n偏差-方差分解说明，**泛化性能**是由**学习算法的能力**、**数据的充分性**以及**学习任务本身的难度**所共同决定的。给定学习任务，为了取得好的泛化性能，则需要使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。\n\n<!-- 以上摘自周志华《机器学习》 -->\n\n在**欠拟合（underfitting）**的情况下，出现**高偏差（high bias）**的情况，即不能很好地对数据进行分类。\n\n当模型设置的太复杂时，训练集中的一些噪声没有被排除，使得模型出现**过拟合（overfitting）**的情况，在验证集上出现**高方差（high variance）**的现象。\n\n当训练出一个模型以后，如果：\n\n* 训练集的错误率较小，而验证集的错误率却较大，说明模型存在较大方差，可能出现了过拟合；\n* 训练集和开发集的错误率都较大，且两者相当，说明模型存在较大偏差，可能出现了欠拟合；\n* 训练集错误率较大，且开发集的错误率远较训练集大，说明方差和偏差都较大，模型很差；\n* 训练集和开发集的错误率都较小，且两者的相差也较小，说明方差和偏差都较小，这个模型效果比较好。\n\n偏差和方差的权衡问题对于模型来说十分重要。\n\n最优误差通常也称为“贝叶斯误差”。\n\n### 应对方法\n\n存在高偏差：\n\n* 扩大网络规模，如添加隐藏层或隐藏单元数目；\n* 寻找合适的网络架构，使用更大的 NN 结构；\n* 花费更长时间训练。\n\n存在高方差：\n\n* 获取更多的数据；\n* 正则化（regularization）；\n* 寻找更合适的网络结构。\n\n不断尝试，直到找到低偏差、低方差的框架。\n\n在深度学习的早期阶段，没有太多方法能做到只减少偏差或方差而不影响到另外一方。而在大数据时代，深度学习对监督式学习大有裨益，使得我们不用像以前一样太过关注如何平衡偏差和方差的权衡问题，通过以上方法可以在不增加某一方的前提下减少另一方的值。\n","slug":"模型估计","published":1,"updated":"2018-08-31T03:54:44.876Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0d003i44vo9iqj3rhi"},{"title":"正则化（regularization）","date":"2018-07-20T07:58:06.000Z","mathjax":true,"_content":"## 正则化（regularization）\n\n**正则化**是在成本函数中加入一个正则化项，惩罚模型的复杂度。正则化可以用于解决高方差的问题。\n\n### Logistic 回归中的正则化\n\n对于 Logistic 回归，加入 L2 正则化（也称“L2 范数”）的成本函数：\n\n$$J(w,b) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}{||w||}^2\\_2$$\n\n* L2 正则化：\n\n$$\\frac{\\lambda}{2m}{||w||}^2\\_2 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n\\_x}w^2\\_j = \\frac{\\lambda}{2m}w^Tw$$\n\n* L1 正则化：\n\n$$\\frac{\\lambda}{2m}{||w||}\\_1 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n\\_x}{|w\\_j|}$$\n\n其中，λ 为**正则化因子**，是**超参数**。\n\n由于 L1 正则化最后得到 w 向量中将存在大量的 0，使模型变得稀疏化，因此 L2 正则化更加常用。\n\n**注意**，`lambda`在 Python 中属于保留字，所以在编程的时候，用`lambd`代替这里的正则化因子。\n\n### 神经网络中的正则化\n\n对于神经网络，加入正则化的成本函数：\n\n$$J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum_{l=1}^L{||w^{[l]}||}^2_F$$\n\n因为 w 的大小为 ($n^{[l−1]}$, $n^{[l]}$)，因此\n\n$${||w^{[l]}||}^2\\_F = \\sum^{n^{[l-1]}}\\_{i=1}\\sum^{n^{[l]}}\\_{j=1}(w^{[l]}\\_{ij})^2$$\n\n```python\nL2_regularization_cost = 1./m * lambd/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)))\ncost = cross_entropy_cost + L2_regularization_cost\n```\n\n该矩阵范数被称为**弗罗贝尼乌斯范数（Frobenius Norm）**，所以神经网络中的正则化项被称为弗罗贝尼乌斯范数矩阵。\n\n#### 权重衰减（Weight decay）\n\n**在加入正则化项后，梯度变为**（反向传播要按这个计算）：\n\n$$dW^{[l]}= \\frac{\\partial L}{\\partial w^{[l]}} +\\frac{\\lambda}{m}W^{[l]}$$\n\n```python\ndW = 1./m * np.dot(dZ, A_prev.T) + lambd / m * W\n```\n\n代入梯度更新公式：\n\n$$W^{[l]} := W^{[l]}-\\alpha dW^{[l]}$$\n\n可得：\n\n$$W^{[l]} := W^{[l]} - \\alpha [\\frac{\\partial L}{\\partial w^{[l]}} + \\frac{\\lambda}{m}W^{[l]}]$$\n\n$$= W^{[l]} - \\alpha \\frac{\\lambda}{m}W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n\n$$= (1 - \\frac{\\alpha\\lambda}{m})W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n\n其中，因为 $1 - \\frac{\\alpha\\lambda}{m}<1$，会给原来的 $W^{[l]}$一个衰减的参数，因此 L2 正则化项也被称为**权重衰减（Weight Decay）**。\n\n### 正则化可以减小过拟合的原因\n\n#### 直观解释\n\n正则化因子设置的足够大的情况下，为了使成本函数最小化，权重矩阵 W 就会被设置为接近于 0 的值，**直观上**相当于消除了很多神经元的影响，那么大的神经网络就会变成一个较小的网络。当然，实际上隐藏层的神经元依然存在，但是其影响减弱了，便不会导致过拟合。\n\n#### 数学解释\n\n假设神经元中使用的激活函数为`g(z) = tanh(z)`（sigmoid 同理）。\n\n![regularization_prevent_overfitting](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/regularization_prevent_overfitting.png)\n\n在加入正则化项后，当 λ  增大，导致 $W^{[l]}$减小，$Z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$便会减小。由上图可知，在 z 较小（接近于 0）的区域里，`tanh(z)`函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，因此不会发生过拟合。\n\n#### 其他解释\n\n在权值 $w^{[L]}$变小之下，输入样本 X 随机的变化不会对神经网络模造成过大的影响，神经网络受局部噪音的影响的可能性变小。这就是正则化能够降低模型方差的原因。\n","source":"_posts/正则化.md","raw":"---\ntitle: 正则化（regularization）\ndate: 2018-07-20 15:58:06\ntags: 正则化\ncategories: 深度学习\nmathjax: true\n---\n## 正则化（regularization）\n\n**正则化**是在成本函数中加入一个正则化项，惩罚模型的复杂度。正则化可以用于解决高方差的问题。\n\n### Logistic 回归中的正则化\n\n对于 Logistic 回归，加入 L2 正则化（也称“L2 范数”）的成本函数：\n\n$$J(w,b) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}{||w||}^2\\_2$$\n\n* L2 正则化：\n\n$$\\frac{\\lambda}{2m}{||w||}^2\\_2 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n\\_x}w^2\\_j = \\frac{\\lambda}{2m}w^Tw$$\n\n* L1 正则化：\n\n$$\\frac{\\lambda}{2m}{||w||}\\_1 = \\frac{\\lambda}{2m}\\sum_{j=1}^{n\\_x}{|w\\_j|}$$\n\n其中，λ 为**正则化因子**，是**超参数**。\n\n由于 L1 正则化最后得到 w 向量中将存在大量的 0，使模型变得稀疏化，因此 L2 正则化更加常用。\n\n**注意**，`lambda`在 Python 中属于保留字，所以在编程的时候，用`lambd`代替这里的正则化因子。\n\n### 神经网络中的正则化\n\n对于神经网络，加入正则化的成本函数：\n\n$$J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum_{l=1}^L{||w^{[l]}||}^2_F$$\n\n因为 w 的大小为 ($n^{[l−1]}$, $n^{[l]}$)，因此\n\n$${||w^{[l]}||}^2\\_F = \\sum^{n^{[l-1]}}\\_{i=1}\\sum^{n^{[l]}}\\_{j=1}(w^{[l]}\\_{ij})^2$$\n\n```python\nL2_regularization_cost = 1./m * lambd/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)))\ncost = cross_entropy_cost + L2_regularization_cost\n```\n\n该矩阵范数被称为**弗罗贝尼乌斯范数（Frobenius Norm）**，所以神经网络中的正则化项被称为弗罗贝尼乌斯范数矩阵。\n\n#### 权重衰减（Weight decay）\n\n**在加入正则化项后，梯度变为**（反向传播要按这个计算）：\n\n$$dW^{[l]}= \\frac{\\partial L}{\\partial w^{[l]}} +\\frac{\\lambda}{m}W^{[l]}$$\n\n```python\ndW = 1./m * np.dot(dZ, A_prev.T) + lambd / m * W\n```\n\n代入梯度更新公式：\n\n$$W^{[l]} := W^{[l]}-\\alpha dW^{[l]}$$\n\n可得：\n\n$$W^{[l]} := W^{[l]} - \\alpha [\\frac{\\partial L}{\\partial w^{[l]}} + \\frac{\\lambda}{m}W^{[l]}]$$\n\n$$= W^{[l]} - \\alpha \\frac{\\lambda}{m}W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n\n$$= (1 - \\frac{\\alpha\\lambda}{m})W^{[l]} - \\alpha \\frac{\\partial L}{\\partial w^{[l]}}$$\n\n其中，因为 $1 - \\frac{\\alpha\\lambda}{m}<1$，会给原来的 $W^{[l]}$一个衰减的参数，因此 L2 正则化项也被称为**权重衰减（Weight Decay）**。\n\n### 正则化可以减小过拟合的原因\n\n#### 直观解释\n\n正则化因子设置的足够大的情况下，为了使成本函数最小化，权重矩阵 W 就会被设置为接近于 0 的值，**直观上**相当于消除了很多神经元的影响，那么大的神经网络就会变成一个较小的网络。当然，实际上隐藏层的神经元依然存在，但是其影响减弱了，便不会导致过拟合。\n\n#### 数学解释\n\n假设神经元中使用的激活函数为`g(z) = tanh(z)`（sigmoid 同理）。\n\n![regularization_prevent_overfitting](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/regularization_prevent_overfitting.png)\n\n在加入正则化项后，当 λ  增大，导致 $W^{[l]}$减小，$Z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$便会减小。由上图可知，在 z 较小（接近于 0）的区域里，`tanh(z)`函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，因此不会发生过拟合。\n\n#### 其他解释\n\n在权值 $w^{[L]}$变小之下，输入样本 X 随机的变化不会对神经网络模造成过大的影响，神经网络受局部噪音的影响的可能性变小。这就是正则化能够降低模型方差的原因。\n","slug":"正则化","published":1,"updated":"2018-08-31T03:54:49.461Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0f003l44vo9k25g0er"},{"title":"深度卷积神经网络:实例探究","date":"2018-08-26T09:33:47.000Z","mathjax":true,"_content":"## 经典卷积网络\n\n### LeNet-5\n\n![LeNet-5](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/LeNet-5.png)\n\n特点：\n\n* LeNet-5 针对灰度图像而训练，因此输入图片的通道数为 1。\n* 该模型总共包含了约 6 万个参数，远少于标准神经网络所需。\n* 典型的 LeNet-5 结构包含卷积层（CONV layer），池化层（POOL layer）和全连接层（FC layer），排列顺序一般为 CONV layer->POOL layer->CONV layer->POOL layer->FC layer->FC layer->OUTPUT layer。一个或多个卷积层后面跟着一个池化层的模式至今仍十分常用。\n* 当 LeNet-5模型被提出时，其池化层使用的是平均池化，而且各层激活函数一般选用 Sigmoid 和 tanh。现在，我们可以根据需要，做出改进，使用最大池化并选用 ReLU 作为激活函数。\n\n相关论文：[LeCun et.al., 1998. Gradient-based learning applied to document recognition](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791&tag=1)。\n\n### AlexNet\n\n![AlexNet](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/AlexNet.png)\n\n特点：\n\n* AlexNet 模型与 LeNet-5 模型类似，但是更复杂，包含约 6000 万个参数。另外，AlexNet 模型使用了 ReLU 函数。\n* 当用于训练图像和数据集时，AlexNet 能够处理非常相似的基本构造模块，这些模块往往包含大量的隐藏单元或数据。\n\n相关论文：[Krizhevsky et al.,2012. ImageNet classification with deep convolutional neural networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。这是一篇易于理解并且影响巨大的论文，计算机视觉群体自此开始重视深度学习。\n\n### VGG\n\n![VGG](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/VGG.png)\n\n特点：\n\n* VGG 又称 VGG-16 网络，“16”指网络中包含 16 个卷积层和全连接层。\n* 超参数较少，只需要专注于构建卷积层。\n* 结构不复杂且规整，在每一组卷积层进行滤波器翻倍操作。\n* VGG 需要训练的特征数量巨大，包含多达约 1.38 亿个参数。\n\n相关论文：[Simonvan & Zisserman 2015. Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556.pdf)。\n\n## 残差网络\n\n因为存在梯度消失和梯度爆炸问题，网络越深，就越难以训练成功。**残差网络（Residual Networks，简称为 ResNets）** 可以有效解决这个问题。\n\n![Residual-block](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-block.jpg)\n\n上图的结构被称为 **残差块（Residual block**。 通过 **捷径（Short cut，或者称跳远连接，Skip connections）** 可以将 $a^{[l]}$ 添加到第二个 ReLU 过程中，直接建立 $a^{[l]}$ 与 $a^{[l+2]}$ 之间的隔层联系。表达式如下：\n\n$$z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$$\n\n$$a^{[l+1]} = g(z^{[l+1]})$$\n\n$$z^{[l+2]} = W^{[l+2]}a^{[l+1]} + b^{[l+2]}$$\n\n$$a^{[l+2]} = g(z^{[l+2]} + a^{[l]})$$\n\n构建一个残差网络就是将许多残差块堆积在一起，形成一个深度网络。\n\n![Residual-Network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-Network.jpg)\n\n为了便于区分，在 ResNets 的论文[He et al., 2015. Deep residual networks for image recognition](https://arxiv.org/pdf/1512.03385.pdf)中，非残差网络被称为 **普通网络（Plain Network）**。 将它变为残差网络的方法是加上所有的跳远连接。\n\n在理论上，随着网络深度的增加，性能应该越来越好。但实际上，对于一个普通网络，随着神经网络层数增加，训练错误会先减少，然后开始增多。但残差网络的训练效果显示，即使网络再深，其在训练集上的表现也会越来越好。\n\n![ResNet-Training-Error](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Training-Error.jpg)\n\n残差网络有助于解决梯度消失和梯度爆炸问题，使得在训练更深的网络的同时，又能保证良好的性能。\n\n### 残差网络有效的原因\n\n假设有一个大型神经网络，其输入为 $X$，输出为 $a^{[l]}$。给这个神经网络额外增加两层，输出为 $a^{[l+2]}$。将这两层看作一个具有跳远连接的残差块。为了方便说明，假设整个网络中都选用 ReLU 作为激活函数，因此输出的所有激活值都大于等于 0。\n\n![Why-do-residual-networks-work](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Why-do-residual-networks-work.jpg)\n\n则有：\n\n$$\n\\begin{equation}\n\\begin{split}\n a^{[l+2]} &= g(z^{[l+2]}+a^{[l]})\n     \\\\\\ &= g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})\n\\end{split}\n\\end{equation}\n$$\n\n当发生梯度消失时，$W^{[l+2]}\\approx0$，$b^{[l+2]}\\approx0$，则有：\n\n$$a^{[l+2]} = g(a^{[l]}) = ReLU(a^{[l]}) = a^{[l]}$$\n\n因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。\n\n注意，如果 $a^{[l]}$ 与 $a^{[l+2]}$ 的维度不同，需要引入矩阵 $W\\_s$ 与 $a^{[l]}$ 相乘，使得二者的维度相匹配。参数矩阵 $W\\_s$ 既可以通过模型训练得到，也可以作为固定值，仅使 $a^{[l]}$ 截断或者补零。\n\n![ResNet-Paper](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Paper.png)\n\n上图是论文提供的 CNN 中 ResNet 的一个典型结构。卷积层通常使用 Same 卷积以保持维度相同，而不同类型层之间的连接（例如卷积层和池化层），如果维度不同，则需要引入矩阵 $W_s$。\n\n## 1x1 卷积\n\n1x1 卷积（1x1 convolution，或称为 Network in Network）指滤波器的尺寸为 1。当通道数为 1 时，1x1 卷积意味着卷积操作等同于乘积操作。\n\n![1x1-Conv-1](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-1.png)\n\n而当通道数更多时，1x1 卷积的作用实际上类似全连接层的神经网络结构，从而降低（或升高，取决于滤波器组数）数据的维度。\n\n池化能压缩数据的高度（$n_H$）及宽度（$n_W$），而 1×1 卷积能压缩数据的通道数（$n_C$）。在如下图所示的例子中，用 32 个大小为 1×1×192 的滤波器进行卷积，就能使原先数据包含的 192 个通道压缩为 32 个。\n\n![1x1-Conv-2](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-2.png)\n\n虽然论文[Lin et al., 2013. Network in network](https://arxiv.org/pdf/1312.4400.pdf)中关于架构的详细内容并没有得到广泛应用，但是 1x1 卷积的理念十分有影响力，许多神经网络架构（包括 Inception 网络）都受到它的影响。\n\n## Inception 网络\n\n在之前的卷积网络中，我们只能选择单一尺寸和类型的滤波器。而 **Inception 网络的作用**即是代替人工来确定卷积层中的滤波器尺寸与类型，或者确定是否需要创建卷积层或池化层。\n\n![Motivation-for-inception-network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Motivation-for-inception-network.jpg)\n\n如图，Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。\n\n相关论文：[Szegedy et al., 2014, Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842.pdf)\n\n### 计算成本问题\n\n在提升性能的同时，Inception 网络有着较大的计算成本。下图是一个例子：\n\n![The-problem-of-computational-cost](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/The-problem-of-computational-cost.png)\n\n图中有 32 个滤波器，每个滤波器的大小为 5x5x192。输出大小为 28x28x32，所以需要计算 28x28x32 个数字，对于每个数，都要执行 5x5x192 次乘法运算。加法运算次数与乘法运算次数近似相等。因此，可以看作这一层的计算量为 28x28x32x5x5x192 = 1.2亿。\n\n为了解决计算量大的问题，可以引入 1x1 卷积来减少其计算量。\n\n![Using-1x1-convolution](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Using-1x1-convolution.png)\n\n对于同一个例子，我们使用 1x1 卷积把输入数据从 192 个通道减少到 16 个通道，然后对这个较小层运行 5x5 卷积，得到最终输出。这个 1x1 的卷积层通常被称作**瓶颈层（Bottleneck layer）**。\n\n改进后的计算量为 28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。\n\n只要合理构建瓶颈层，就可以既显著缩小计算规模，又不会降低网络性能。\n\n### 完整的 Inception 网络\n\n![Inception-module](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-module.jpg)\n\n上图是引入 1x1 卷积后的 Inception 模块。值得注意的是，为了将所有的输出组合起来，红色的池化层使用 Same 类型的填充（padding）来池化使得输出的宽高不变，通道数也不变。\n\n多个 Inception 模块组成一个完整的 Inception 网络（被称为 GoogLeNet，以向 LeNet 致敬），如下图所示：\n\n![Inception-network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-network.jpg)\n\n注意黑色椭圆圈出的隐藏层，这些分支都是 Softmax 的输出层，可以用来参与特征的计算及结果预测，起到调整并防止发生过拟合的效果。\n\n经过研究者们的不断发展，Inception 模型的 V2、V3、V4 以及引入残差网络的版本被提出，这些变体都基于 Inception V1 版本的基础思想上。顺便一提，Inception 模型的名字来自电影《盗梦空间》。\n\n## 使用开源的实现方案\n\n很多神经网络复杂细致，并充斥着参数调节的细节问题，因而很难仅通过阅读论文来重现他人的成果。想要搭建一个同样的神经网络，查看开源的实现方案会快很多。\n\n## 迁移学习\n\n在“搭建机器学习项目”课程中，[迁移学习](http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Structuring_Machine_Learning_Projects/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89?id=%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0)已经被提到过。计算机视觉是一个经常用到迁移学习的领域。在搭建计算机视觉的应用时，相比于从头训练权重，下载别人已经训练好的网络结构的权重，用其做**预训练**，然后转换到自己感兴趣的任务上，有助于加速开发。\n\n对于已训练好的卷积神经网络，可以将所有层都看作是**冻结的**，只需要训练与你的 Softmax 层有关的参数即可。大多数深度学习框架都允许用户指定是否训练特定层的权重。\n\n而冻结的层由于不需要改变和训练，可以看作一个固定函数。可以将这个固定函数存入硬盘，以便后续使用，而不必每次再使用训练集进行训练了。\n\n上述的做法适用于你只有一个较小的数据集。如果你有一个更大的数据集，应该冻结更少的层，然后训练后面的层。越多的数据意味着冻结越少的层，训练更多的层。如果有一个极大的数据集，你可以将开源的网络和它的权重整个当作初始化（代替随机初始化），然后训练整个网络。\n\n## 数据扩增\n\n计算机视觉领域的应用都需要大量的数据。当数据不够时，**数据扩增（Data Augmentation）**就有帮助。常用的数据扩增包括镜像翻转、随机裁剪、色彩转换。\n\n其中，色彩转换是对图片的 RGB 通道数值进行随意增加或者减少，改变图片色调。另外，**PCA 颜色增强**指更有针对性地对图片的 RGB 通道进行主成分分析（Principles Components Analysis，PCA），对主要的通道颜色进行增加或减少，可以采用高斯扰动做法来增加有效的样本数量。具体的 PCA 颜色增强做法可以查阅 AlexNet 的相关论文或者开源代码。\n\n在构建大型神经网络的时候，数据扩增和模型训练可以由两个或多个不同的线程并行来实现。\n\n## 计算机视觉现状\n\n通常，学习算法有两种知识来源：\n\n* 被标记的数据\n* 手工工程\n\n**手工工程（Hand-engineering，又称 hacks）** 指精心设计的特性、网络体系结构或是系统的其他组件。手工工程是一项非常重要也比较困难的工作。在数据量不多的情况下，手工工程是获得良好表现的最佳方式。正因为数据量不能满足需要，历史上计算机视觉领域更多地依赖于手工工程。近几年数据量急剧增加，因此手工工程量大幅减少。\n\n另外，在模型研究或者竞赛方面，有一些方法能够有助于提升神经网络模型的性能：\n\n* 集成（Ensembling）：独立地训练几个神经网络，并平均输出它们的输出\n* Multi-crop at test time：将数据扩增应用到测试集，对结果进行平均\n\n但是由于这些方法计算和内存成本较大，一般不适用于构建实际的生产项目。\n","source":"_posts/深度卷积神经网络-实例探究.md","raw":"---\ntitle: 深度卷积神经网络:实例探究\ndate: 2018-08-26 17:33:47\ntags: CNN\ncategories: 深度学习\nmathjax: true\n---\n## 经典卷积网络\n\n### LeNet-5\n\n![LeNet-5](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/LeNet-5.png)\n\n特点：\n\n* LeNet-5 针对灰度图像而训练，因此输入图片的通道数为 1。\n* 该模型总共包含了约 6 万个参数，远少于标准神经网络所需。\n* 典型的 LeNet-5 结构包含卷积层（CONV layer），池化层（POOL layer）和全连接层（FC layer），排列顺序一般为 CONV layer->POOL layer->CONV layer->POOL layer->FC layer->FC layer->OUTPUT layer。一个或多个卷积层后面跟着一个池化层的模式至今仍十分常用。\n* 当 LeNet-5模型被提出时，其池化层使用的是平均池化，而且各层激活函数一般选用 Sigmoid 和 tanh。现在，我们可以根据需要，做出改进，使用最大池化并选用 ReLU 作为激活函数。\n\n相关论文：[LeCun et.al., 1998. Gradient-based learning applied to document recognition](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791&tag=1)。\n\n### AlexNet\n\n![AlexNet](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/AlexNet.png)\n\n特点：\n\n* AlexNet 模型与 LeNet-5 模型类似，但是更复杂，包含约 6000 万个参数。另外，AlexNet 模型使用了 ReLU 函数。\n* 当用于训练图像和数据集时，AlexNet 能够处理非常相似的基本构造模块，这些模块往往包含大量的隐藏单元或数据。\n\n相关论文：[Krizhevsky et al.,2012. ImageNet classification with deep convolutional neural networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。这是一篇易于理解并且影响巨大的论文，计算机视觉群体自此开始重视深度学习。\n\n### VGG\n\n![VGG](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/VGG.png)\n\n特点：\n\n* VGG 又称 VGG-16 网络，“16”指网络中包含 16 个卷积层和全连接层。\n* 超参数较少，只需要专注于构建卷积层。\n* 结构不复杂且规整，在每一组卷积层进行滤波器翻倍操作。\n* VGG 需要训练的特征数量巨大，包含多达约 1.38 亿个参数。\n\n相关论文：[Simonvan & Zisserman 2015. Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556.pdf)。\n\n## 残差网络\n\n因为存在梯度消失和梯度爆炸问题，网络越深，就越难以训练成功。**残差网络（Residual Networks，简称为 ResNets）** 可以有效解决这个问题。\n\n![Residual-block](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-block.jpg)\n\n上图的结构被称为 **残差块（Residual block**。 通过 **捷径（Short cut，或者称跳远连接，Skip connections）** 可以将 $a^{[l]}$ 添加到第二个 ReLU 过程中，直接建立 $a^{[l]}$ 与 $a^{[l+2]}$ 之间的隔层联系。表达式如下：\n\n$$z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]}$$\n\n$$a^{[l+1]} = g(z^{[l+1]})$$\n\n$$z^{[l+2]} = W^{[l+2]}a^{[l+1]} + b^{[l+2]}$$\n\n$$a^{[l+2]} = g(z^{[l+2]} + a^{[l]})$$\n\n构建一个残差网络就是将许多残差块堆积在一起，形成一个深度网络。\n\n![Residual-Network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Residual-Network.jpg)\n\n为了便于区分，在 ResNets 的论文[He et al., 2015. Deep residual networks for image recognition](https://arxiv.org/pdf/1512.03385.pdf)中，非残差网络被称为 **普通网络（Plain Network）**。 将它变为残差网络的方法是加上所有的跳远连接。\n\n在理论上，随着网络深度的增加，性能应该越来越好。但实际上，对于一个普通网络，随着神经网络层数增加，训练错误会先减少，然后开始增多。但残差网络的训练效果显示，即使网络再深，其在训练集上的表现也会越来越好。\n\n![ResNet-Training-Error](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Training-Error.jpg)\n\n残差网络有助于解决梯度消失和梯度爆炸问题，使得在训练更深的网络的同时，又能保证良好的性能。\n\n### 残差网络有效的原因\n\n假设有一个大型神经网络，其输入为 $X$，输出为 $a^{[l]}$。给这个神经网络额外增加两层，输出为 $a^{[l+2]}$。将这两层看作一个具有跳远连接的残差块。为了方便说明，假设整个网络中都选用 ReLU 作为激活函数，因此输出的所有激活值都大于等于 0。\n\n![Why-do-residual-networks-work](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Why-do-residual-networks-work.jpg)\n\n则有：\n\n$$\n\\begin{equation}\n\\begin{split}\n a^{[l+2]} &= g(z^{[l+2]}+a^{[l]})\n     \\\\\\ &= g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})\n\\end{split}\n\\end{equation}\n$$\n\n当发生梯度消失时，$W^{[l+2]}\\approx0$，$b^{[l+2]}\\approx0$，则有：\n\n$$a^{[l+2]} = g(a^{[l]}) = ReLU(a^{[l]}) = a^{[l]}$$\n\n因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。\n\n注意，如果 $a^{[l]}$ 与 $a^{[l+2]}$ 的维度不同，需要引入矩阵 $W\\_s$ 与 $a^{[l]}$ 相乘，使得二者的维度相匹配。参数矩阵 $W\\_s$ 既可以通过模型训练得到，也可以作为固定值，仅使 $a^{[l]}$ 截断或者补零。\n\n![ResNet-Paper](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/ResNet-Paper.png)\n\n上图是论文提供的 CNN 中 ResNet 的一个典型结构。卷积层通常使用 Same 卷积以保持维度相同，而不同类型层之间的连接（例如卷积层和池化层），如果维度不同，则需要引入矩阵 $W_s$。\n\n## 1x1 卷积\n\n1x1 卷积（1x1 convolution，或称为 Network in Network）指滤波器的尺寸为 1。当通道数为 1 时，1x1 卷积意味着卷积操作等同于乘积操作。\n\n![1x1-Conv-1](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-1.png)\n\n而当通道数更多时，1x1 卷积的作用实际上类似全连接层的神经网络结构，从而降低（或升高，取决于滤波器组数）数据的维度。\n\n池化能压缩数据的高度（$n_H$）及宽度（$n_W$），而 1×1 卷积能压缩数据的通道数（$n_C$）。在如下图所示的例子中，用 32 个大小为 1×1×192 的滤波器进行卷积，就能使原先数据包含的 192 个通道压缩为 32 个。\n\n![1x1-Conv-2](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/1x1-Conv-2.png)\n\n虽然论文[Lin et al., 2013. Network in network](https://arxiv.org/pdf/1312.4400.pdf)中关于架构的详细内容并没有得到广泛应用，但是 1x1 卷积的理念十分有影响力，许多神经网络架构（包括 Inception 网络）都受到它的影响。\n\n## Inception 网络\n\n在之前的卷积网络中，我们只能选择单一尺寸和类型的滤波器。而 **Inception 网络的作用**即是代替人工来确定卷积层中的滤波器尺寸与类型，或者确定是否需要创建卷积层或池化层。\n\n![Motivation-for-inception-network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Motivation-for-inception-network.jpg)\n\n如图，Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。\n\n相关论文：[Szegedy et al., 2014, Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842.pdf)\n\n### 计算成本问题\n\n在提升性能的同时，Inception 网络有着较大的计算成本。下图是一个例子：\n\n![The-problem-of-computational-cost](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/The-problem-of-computational-cost.png)\n\n图中有 32 个滤波器，每个滤波器的大小为 5x5x192。输出大小为 28x28x32，所以需要计算 28x28x32 个数字，对于每个数，都要执行 5x5x192 次乘法运算。加法运算次数与乘法运算次数近似相等。因此，可以看作这一层的计算量为 28x28x32x5x5x192 = 1.2亿。\n\n为了解决计算量大的问题，可以引入 1x1 卷积来减少其计算量。\n\n![Using-1x1-convolution](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Using-1x1-convolution.png)\n\n对于同一个例子，我们使用 1x1 卷积把输入数据从 192 个通道减少到 16 个通道，然后对这个较小层运行 5x5 卷积，得到最终输出。这个 1x1 的卷积层通常被称作**瓶颈层（Bottleneck layer）**。\n\n改进后的计算量为 28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。\n\n只要合理构建瓶颈层，就可以既显著缩小计算规模，又不会降低网络性能。\n\n### 完整的 Inception 网络\n\n![Inception-module](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-module.jpg)\n\n上图是引入 1x1 卷积后的 Inception 模块。值得注意的是，为了将所有的输出组合起来，红色的池化层使用 Same 类型的填充（padding）来池化使得输出的宽高不变，通道数也不变。\n\n多个 Inception 模块组成一个完整的 Inception 网络（被称为 GoogLeNet，以向 LeNet 致敬），如下图所示：\n\n![Inception-network](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Inception-network.jpg)\n\n注意黑色椭圆圈出的隐藏层，这些分支都是 Softmax 的输出层，可以用来参与特征的计算及结果预测，起到调整并防止发生过拟合的效果。\n\n经过研究者们的不断发展，Inception 模型的 V2、V3、V4 以及引入残差网络的版本被提出，这些变体都基于 Inception V1 版本的基础思想上。顺便一提，Inception 模型的名字来自电影《盗梦空间》。\n\n## 使用开源的实现方案\n\n很多神经网络复杂细致，并充斥着参数调节的细节问题，因而很难仅通过阅读论文来重现他人的成果。想要搭建一个同样的神经网络，查看开源的实现方案会快很多。\n\n## 迁移学习\n\n在“搭建机器学习项目”课程中，[迁移学习](http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Structuring_Machine_Learning_Projects/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89?id=%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0)已经被提到过。计算机视觉是一个经常用到迁移学习的领域。在搭建计算机视觉的应用时，相比于从头训练权重，下载别人已经训练好的网络结构的权重，用其做**预训练**，然后转换到自己感兴趣的任务上，有助于加速开发。\n\n对于已训练好的卷积神经网络，可以将所有层都看作是**冻结的**，只需要训练与你的 Softmax 层有关的参数即可。大多数深度学习框架都允许用户指定是否训练特定层的权重。\n\n而冻结的层由于不需要改变和训练，可以看作一个固定函数。可以将这个固定函数存入硬盘，以便后续使用，而不必每次再使用训练集进行训练了。\n\n上述的做法适用于你只有一个较小的数据集。如果你有一个更大的数据集，应该冻结更少的层，然后训练后面的层。越多的数据意味着冻结越少的层，训练更多的层。如果有一个极大的数据集，你可以将开源的网络和它的权重整个当作初始化（代替随机初始化），然后训练整个网络。\n\n## 数据扩增\n\n计算机视觉领域的应用都需要大量的数据。当数据不够时，**数据扩增（Data Augmentation）**就有帮助。常用的数据扩增包括镜像翻转、随机裁剪、色彩转换。\n\n其中，色彩转换是对图片的 RGB 通道数值进行随意增加或者减少，改变图片色调。另外，**PCA 颜色增强**指更有针对性地对图片的 RGB 通道进行主成分分析（Principles Components Analysis，PCA），对主要的通道颜色进行增加或减少，可以采用高斯扰动做法来增加有效的样本数量。具体的 PCA 颜色增强做法可以查阅 AlexNet 的相关论文或者开源代码。\n\n在构建大型神经网络的时候，数据扩增和模型训练可以由两个或多个不同的线程并行来实现。\n\n## 计算机视觉现状\n\n通常，学习算法有两种知识来源：\n\n* 被标记的数据\n* 手工工程\n\n**手工工程（Hand-engineering，又称 hacks）** 指精心设计的特性、网络体系结构或是系统的其他组件。手工工程是一项非常重要也比较困难的工作。在数据量不多的情况下，手工工程是获得良好表现的最佳方式。正因为数据量不能满足需要，历史上计算机视觉领域更多地依赖于手工工程。近几年数据量急剧增加，因此手工工程量大幅减少。\n\n另外，在模型研究或者竞赛方面，有一些方法能够有助于提升神经网络模型的性能：\n\n* 集成（Ensembling）：独立地训练几个神经网络，并平均输出它们的输出\n* Multi-crop at test time：将数据扩增应用到测试集，对结果进行平均\n\n但是由于这些方法计算和内存成本较大，一般不适用于构建实际的生产项目。\n","slug":"深度卷积神经网络-实例探究","published":1,"updated":"2018-08-26T09:48:38.084Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0j003p44vosmkpyw4b"},{"title":"深度学习中的优化算法","date":"2018-08-04T05:26:01.000Z","mathjax":true,"_content":"深度学习难以在大数据领域发挥最大效果的一个原因是，在巨大的数据集基础上进行训练速度很慢。而优化算法能够帮助快速训练模型，大大提高效率。\n\n## batch 梯度下降法\n\n**batch 梯度下降法**（批梯度下降法，我们之前一直使用的梯度下降法）是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。\n\n对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，处理速度就会比较慢。\n\n但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为 **mini-batch**。\n\n## Mini-Batch 梯度下降法\n\n**Mini-Batch 梯度下降法**（小批量梯度下降法）每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。\n\n使用 batch 梯度下降法，对整个训练集的一次遍历只能做一个梯度下降；而使用 Mini-Batch 梯度下降法，对整个训练集的一次遍历（称为一个 epoch）能做 mini-batch 个数个梯度下降。之后，可以一直遍历训练集，直到最后收敛到一个合适的精度。\n\nbatch 梯度下降法和 Mini-batch 梯度下降法代价函数的变化趋势如下：\n\n![training-with-mini-batch-gradient-descent](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/training-with-mini-batch-gradient-descent.png)\n\n### batch 的不同大小（size）带来的影响\n\n* mini-batch 的大小为 1，即是**随机梯度下降法（stochastic gradient descent）**，每个样本都是独立的 mini-batch；\n* mini-batch 的大小为 m（数据集大小），即是 batch 梯度下降法；\n\n![choosing-mini-batch-size](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/choosing-mini-batch-size.png)\n\n* batch 梯度下降法：\n    * 对所有 m 个训练样本执行一次梯度下降，**每一次迭代时间较长，训练过程慢**； \n    * 相对噪声低一些，幅度也大一些；\n    * 成本函数总是向减小的方向下降。\n\n* 随机梯度下降法：\n    * 对每一个训练样本执行一次梯度下降，训练速度快，但**丢失了向量化带来的计算加速**；\n    * 有很多噪声，减小学习率可以适当；\n    * 成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。\n\n因此，选择一个`1 < size < m`的合适的大小进行 Mini-batch 梯度下降，可以实现快速学习，也应用了向量化带来的好处，且成本函数的下降处于前两者之间。\n\n### mini-batch 大小的选择\n\n* 如果训练样本的大小比较小，如 $m \\lt 2000$ 时，选择 batch 梯度下降法；\n* 如果训练样本的大小比较大，选择 Mini-Batch 梯度下降法。为了和计算机的信息存储方式相适应，代码在 mini-batch 大小为 2 的幂次时运行要快一些。典型的大小为 $2^6$、$2^7$、...、$2^9$；\n* mini-batch 的大小要符合 CPU/GPU 内存。\n\nmini-batch 的大小也是一个重要的超变量，需要根据经验快速尝试，找到能够最有效地减少成本函数的值。\n\n### 获得 mini-batch 的步骤\n\n1. 将数据集打乱；\n2. 按照既定的大小分割数据集；\n\n其中打乱数据集的代码：\n\n```py\nm = X.shape[1] \npermutation = list(np.random.permutation(m))\nshuffled_X = X[:, permutation]\nshuffled_Y = Y[:, permutation].reshape((1,m))\n```\n\n`np.random.permutation`与`np.random.shuffle`有两处不同：\n\n1. 如果传给`permutation`一个矩阵，它会返回一个洗牌后的矩阵副本；而`shuffle`只是对一个矩阵进行洗牌，没有返回值。\n2. 如果传入一个整数，它会返回一个洗牌后的`arange`。\n\n### 符号表示\n\n* 使用上角小括号 i 表示训练集里的值，$x^{(i)}$ 是第 i 个训练样本；\n* 使用上角中括号 l 表示神经网络的层数，$z^{[l]}$ 表示神经网络中第 l 层的 z 值；\n* 现在引入大括号 t 来代表不同的 mini-batch，因此有 $X^{t}$、$Y^{t}$。\n\n## 指数平均加权\n\n**指数加权平均（Exponentially Weight Average）**是一种常用的序列数据处理方式，计算公式为：\n\n$$\nS\\_t = \n\\begin{cases} \nY\\_1, &t = 1 \\\\\\\\ \n\\beta S\\_{t-1} + (1-\\beta)Y_t, &t > 1 \n\\end{cases}\n$$\n\n其中 $Y\\_t$ 为 t 下的实际值，$S\\_t$ 为 t 下加权平均后的值，β 为权重值。\n\n指数加权平均数在统计学中被称为“指数加权移动平均值”。\n\n![Exponentially-weight-average](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Exponentially-weight-average.png)\n\n给定一个时间序列，例如伦敦一年每天的气温值，图中蓝色的点代表真实数据。对于一个即时的气温值，取权重值 β 为 0.9，根据求得的值可以得到图中的红色曲线，它反映了气温变化的大致趋势。\n\n当取权重值 β=0.98 时，可以得到图中更为平滑的绿色曲线。而当取权重值 β=0.5 时，得到图中噪点更多的黄色曲线。**β 越大相当于求取平均利用的天数越多**，曲线自然就会越平滑而且越滞后。\n\n### 理解指数平均加权\n\n当 β 为 0.9 时，\n\n$$v\\_{100} = 0.9v\\_{99} + 0.1 \\theta\\_{100}$$\n\n$$v\\_{99} = 0.9v\\_{98} + 0.1 \\theta\\_{99}$$\n\n$$v\\_{98} = 0.9v\\_{97} + 0.1 \\theta\\_{98}$$\n$$...$$\n\n展开：\n\n$$v\\_{100} = 0.1 \\theta\\_{100} + 0.1 \\* 0.9 \\theta\\_{99} + 0.1 \\* {(0.9)}^2 \\theta\\_{98} + ...$$\n\n其中 θi 指第 i 天的实际数据。所有 θ 前面的系数（不包括 0.1）相加起来为 1 或者接近于 1，这些系数被称作**偏差修正（Bias Correction）**。\n\n根据函数极限的一条定理：\n\n$$\\lim\\_{\\beta\\to 0}(1 - \\beta)^\\frac{1}{\\beta} = \\frac{1}{e} \\approx 0.368$$\n\n当 β 为 0.9 时，可以当作把过去 10 天的气温指数加权平均作为当日的气温，因为 10 天后权重已经下降到了当天的 1/3 左右。同理，当 β 为 0.98 时，可以把过去 50 天的气温指数加权平均作为当日的气温。\n\n因此，在计算当前时刻的平均值时，只需要前一天的平均值和当前时刻的值。\n\n$$v\\_t = \\beta v\\_{t-1} + (1 - \\beta)\\theta_t$$\n\n考虑到代码，只需要不断更新 v 即可：\n\n$$v := \\beta v + (1 - \\beta)\\theta_t$$\n<!--此处应有公式的实现代码-->\n\n指数平均加权并**不是最精准**的计算平均数的方法，你可以直接计算过去 10 天或 50 天的平均值来得到更好的估计，但缺点是保存数据需要占用更多内存，执行更加复杂，计算成本更加高昂。\n\n指数加权平均数公式的好处之一在于它只需要一行代码，且占用极少内存，因此**效率极高，且节省成本**。\n\n### 指数平均加权的偏差修正\n\n我们通常有\n\n$$v\\_0 = 0$$\n$$v\\_1 = 0.98v\\_0 + 0.02\\theta\\_1$$\n\n因此，$v\\_1$ 仅为第一个数据的 0.02（或者说 1-β），显然不准确。往后递推同理。\n\n因此，我们修改公式为\n\n$$v\\_t = \\frac{\\beta v\\_{t-1} + (1 - \\beta)\\theta_t}{1-\\beta^t}$$\n\n随着 t 的增大，β 的 t 次方趋近于 0。因此当 t 很大的时候，偏差修正几乎没有作用，但是在前期学习可以帮助更好的预测数据。在实际过程中，一般会忽略前期偏差的影响。\n\n## 动量梯度下降法\n\n**动量梯度下降（Gradient Descent with Momentum）**是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：\n\nfor l = 1, .. , L：\n\n$$v\\_{dW^{[l]}} = \\beta v\\_{dW^{[l]}} + (1 - \\beta) dW^{[l]}$$\n$$v\\_{db^{[l]}} = \\beta v\\_{db^{[l]}} + (1 - \\beta) db^{[l]}$$\n$$W^{[l]} := W^{[l]} - \\alpha v\\_{dW^{[l]}}$$\n$$b^{[l]} := b^{[l]} - \\alpha v\\_{db^{[l]}}$$\n\n其中，将动量衰减参数 β 设置为 0.9 是超参数的一个常见且效果不错的选择。当 β 被设置为 0 时，显然就成了 batch 梯度下降法。\n\n![Gradient-Descent-with-Momentum](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Gradient-Descent-with-Momentum.png)\n\n进行一般的梯度下降将会得到图中的蓝色曲线，由于存在上下波动，减缓了梯度下降的速度，因此只能使用一个较小的学习率进行迭代。如果用较大的学习率，结果可能会像紫色曲线一样偏离函数的范围。\n\n而使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色的曲线。\n\n当前后梯度方向一致时，动量梯度下降能够加速学习；而前后梯度方向不一致时，动量梯度下降能够抑制震荡。\n\n另外，在 10 次迭代之后，移动平均已经不再是一个具有偏差的预测。因此实际在使用梯度下降法或者动量梯度下降法时，不会同时进行偏差修正。\n\n### 动量梯度下降法的形象解释\n\n将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v\\_{dw}$、$v\\_{db}$ 相当于速度。\n\n小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。\n\n## RMSProp 算法\n\n**RMSProp（Root Mean Square Prop，均方根支）**算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为（省略了 l）：\n\n$$s\\_{dw} = \\beta s\\_{dw} + (1 - \\beta)(dw)^2$$\n$$s\\_{db} = \\beta s\\_{db} + (1 - \\beta)(db)^2$$\n$$w := w - \\alpha \\frac{dw}{\\sqrt{s\\_{dw} + \\epsilon}}$$\n$$b := b - \\alpha \\frac{db}{\\sqrt{s\\_{db} + \\epsilon}}$$\n\n其中，ϵ 是一个实际操作时加上的较小数（例如10^-8），为了防止分母太小而导致的数值不稳定。\n\n当 dw 或 db 较大时，$(dw)^2$、$(db)^2$会较大，进而 $s\\_{dw}$、$s\\_{db}$也会较大，最终使得\n\n$$\\frac{dw}{\\sqrt{s\\_{dw} + \\epsilon}}$$\n\n和\n\n$$\\frac{db}{\\sqrt{s\\_{db} + \\epsilon}}$$\n\n较小，从而减小某些维度梯度更新波动较大的情况，使下降速度变得更快。\n\n![RMSProp](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/RMSProp.png)\n\nRMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。并且，它和 Adam 优化算法已被证明适用于不同的深度学习网络结构。\n\n注意，β 也是一个超参数。\n\n## Adam 优化算法\n\n**Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）**基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。具体过程如下（省略了 l）：\n\n首先进行初始化：\n\n$$v\\_{dW} = 0, s\\_{dW} = 0, v\\_{db} = 0, s\\_{db} = 0$$\n\n用每一个 mini-batch 计算 dW、db，第 t 次迭代时：\n\n$$v\\_{dW} = \\beta\\_1 v\\_{dW} + (1 - \\beta\\_1) dW$$\n$$v\\_{db} = \\beta\\_1 v\\_{db} + (1 - \\beta\\_1) db$$\n$$s\\_{dW} = \\beta\\_2 s\\_{dW} + (1 - \\beta\\_2) (dW)^2$$\n$$s\\_{db} = \\beta\\_2 s\\_{db} + (1 - \\beta\\_2) (db)^2$$\n\n一般使用 Adam 算法时需要计算偏差修正：\n\n$$v^{corrected}\\_{dW} = \\frac{v\\_{dW}}{1-{\\beta\\_1}^t}$$\n$$v^{corrected}\\_{db} = \\frac{v\\_{db}}{1-{\\beta\\_1}^t}$$\n$$s^{corrected}\\_{dW} = \\frac{s\\_{dW}}{1-{\\beta\\_2}^t}$$\n$$s^{corrected}\\_{db} = \\frac{s\\_{db}}{1-{\\beta\\_2}^t}$$\n\n所以，更新 W、b 时有：\n\n$$W := W - \\alpha \\frac{v^{corrected}\\_{dW}}{\\sqrt{s^{corrected}\\_{dW} + \\epsilon}}$$\n\n$$b := b - \\alpha \\frac{v^{corrected}\\_{db}}{\\sqrt{s^{corrected}\\_{db}} + \\epsilon}$$\n\n（可以看到 Andrew 在这里 ϵ 没有写到平方根里去，和他在 RMSProp 中写的不太一样。考虑到 ϵ 所起的作用，我感觉影响不大）\n\n### 超参数的选择\n\nAdam 优化算法有很多的超参数，其中\n\n* 学习率 α：需要尝试一系列的值，来寻找比较合适的；\n* β1：常用的缺省值为 0.9；\n* β2：Adam 算法的作者建议为 0.999；\n* ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；\n\nβ1、β2、ϵ 通常不需要调试。\n\n## 学习率衰减\n\n如果设置一个固定的学习率 α，在最小值点附近，由于不同的 batch 中存在一定的噪声，因此不会精确收敛，而是始终在最小值周围一个较大的范围内波动。\n\n而如果随着时间慢慢减少学习率 α 的大小，在初期 α 较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小 α 的值，即减小步长，有助于算法的收敛，更容易接近最优解。\n\n最常用的学习率衰减方法：\n\n$$\\alpha = \\frac{1}{1 + decay\\\\\\_rate \\* epoch\\\\\\_num} \\* \\alpha\\_0$$\n\n其中，`decay_rate`为衰减率（超参数），`epoch_num`为将所有的训练样本完整过一遍的次数。\n\n* 指数衰减：\n\n$$\\alpha = 0.95^{epoch\\\\\\_num} \\* \\alpha\\_0$$\n\n* 其他：\n\n$$\\alpha = \\frac{k}{\\sqrt{epoch\\\\\\_num}} \\* \\alpha\\_0$$\n\n* 离散下降\n\n对于较小的模型，也有人会在训练时根据进度手动调小学习率。\n\n## 局部最优问题\n\n![saddle](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/saddle.png)\n\n**鞍点（saddle）**是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。\n\n结论：\n\n* 在训练较大的神经网络、存在大量参数，并且成本函数被定义在较高的维度空间时，困在极差的局部最优中是不大可能的；\n* 鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。\n","source":"_posts/深度学习中的优化算法.md","raw":"---\ntitle: 深度学习中的优化算法\ndate: 2018-08-04 13:26:01\ntags: 优化算法\ncategories: 深度学习\nmathjax: true\n---\n深度学习难以在大数据领域发挥最大效果的一个原因是，在巨大的数据集基础上进行训练速度很慢。而优化算法能够帮助快速训练模型，大大提高效率。\n\n## batch 梯度下降法\n\n**batch 梯度下降法**（批梯度下降法，我们之前一直使用的梯度下降法）是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。\n\n对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，处理速度就会比较慢。\n\n但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为 **mini-batch**。\n\n## Mini-Batch 梯度下降法\n\n**Mini-Batch 梯度下降法**（小批量梯度下降法）每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。\n\n使用 batch 梯度下降法，对整个训练集的一次遍历只能做一个梯度下降；而使用 Mini-Batch 梯度下降法，对整个训练集的一次遍历（称为一个 epoch）能做 mini-batch 个数个梯度下降。之后，可以一直遍历训练集，直到最后收敛到一个合适的精度。\n\nbatch 梯度下降法和 Mini-batch 梯度下降法代价函数的变化趋势如下：\n\n![training-with-mini-batch-gradient-descent](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/training-with-mini-batch-gradient-descent.png)\n\n### batch 的不同大小（size）带来的影响\n\n* mini-batch 的大小为 1，即是**随机梯度下降法（stochastic gradient descent）**，每个样本都是独立的 mini-batch；\n* mini-batch 的大小为 m（数据集大小），即是 batch 梯度下降法；\n\n![choosing-mini-batch-size](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/choosing-mini-batch-size.png)\n\n* batch 梯度下降法：\n    * 对所有 m 个训练样本执行一次梯度下降，**每一次迭代时间较长，训练过程慢**； \n    * 相对噪声低一些，幅度也大一些；\n    * 成本函数总是向减小的方向下降。\n\n* 随机梯度下降法：\n    * 对每一个训练样本执行一次梯度下降，训练速度快，但**丢失了向量化带来的计算加速**；\n    * 有很多噪声，减小学习率可以适当；\n    * 成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。\n\n因此，选择一个`1 < size < m`的合适的大小进行 Mini-batch 梯度下降，可以实现快速学习，也应用了向量化带来的好处，且成本函数的下降处于前两者之间。\n\n### mini-batch 大小的选择\n\n* 如果训练样本的大小比较小，如 $m \\lt 2000$ 时，选择 batch 梯度下降法；\n* 如果训练样本的大小比较大，选择 Mini-Batch 梯度下降法。为了和计算机的信息存储方式相适应，代码在 mini-batch 大小为 2 的幂次时运行要快一些。典型的大小为 $2^6$、$2^7$、...、$2^9$；\n* mini-batch 的大小要符合 CPU/GPU 内存。\n\nmini-batch 的大小也是一个重要的超变量，需要根据经验快速尝试，找到能够最有效地减少成本函数的值。\n\n### 获得 mini-batch 的步骤\n\n1. 将数据集打乱；\n2. 按照既定的大小分割数据集；\n\n其中打乱数据集的代码：\n\n```py\nm = X.shape[1] \npermutation = list(np.random.permutation(m))\nshuffled_X = X[:, permutation]\nshuffled_Y = Y[:, permutation].reshape((1,m))\n```\n\n`np.random.permutation`与`np.random.shuffle`有两处不同：\n\n1. 如果传给`permutation`一个矩阵，它会返回一个洗牌后的矩阵副本；而`shuffle`只是对一个矩阵进行洗牌，没有返回值。\n2. 如果传入一个整数，它会返回一个洗牌后的`arange`。\n\n### 符号表示\n\n* 使用上角小括号 i 表示训练集里的值，$x^{(i)}$ 是第 i 个训练样本；\n* 使用上角中括号 l 表示神经网络的层数，$z^{[l]}$ 表示神经网络中第 l 层的 z 值；\n* 现在引入大括号 t 来代表不同的 mini-batch，因此有 $X^{t}$、$Y^{t}$。\n\n## 指数平均加权\n\n**指数加权平均（Exponentially Weight Average）**是一种常用的序列数据处理方式，计算公式为：\n\n$$\nS\\_t = \n\\begin{cases} \nY\\_1, &t = 1 \\\\\\\\ \n\\beta S\\_{t-1} + (1-\\beta)Y_t, &t > 1 \n\\end{cases}\n$$\n\n其中 $Y\\_t$ 为 t 下的实际值，$S\\_t$ 为 t 下加权平均后的值，β 为权重值。\n\n指数加权平均数在统计学中被称为“指数加权移动平均值”。\n\n![Exponentially-weight-average](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Exponentially-weight-average.png)\n\n给定一个时间序列，例如伦敦一年每天的气温值，图中蓝色的点代表真实数据。对于一个即时的气温值，取权重值 β 为 0.9，根据求得的值可以得到图中的红色曲线，它反映了气温变化的大致趋势。\n\n当取权重值 β=0.98 时，可以得到图中更为平滑的绿色曲线。而当取权重值 β=0.5 时，得到图中噪点更多的黄色曲线。**β 越大相当于求取平均利用的天数越多**，曲线自然就会越平滑而且越滞后。\n\n### 理解指数平均加权\n\n当 β 为 0.9 时，\n\n$$v\\_{100} = 0.9v\\_{99} + 0.1 \\theta\\_{100}$$\n\n$$v\\_{99} = 0.9v\\_{98} + 0.1 \\theta\\_{99}$$\n\n$$v\\_{98} = 0.9v\\_{97} + 0.1 \\theta\\_{98}$$\n$$...$$\n\n展开：\n\n$$v\\_{100} = 0.1 \\theta\\_{100} + 0.1 \\* 0.9 \\theta\\_{99} + 0.1 \\* {(0.9)}^2 \\theta\\_{98} + ...$$\n\n其中 θi 指第 i 天的实际数据。所有 θ 前面的系数（不包括 0.1）相加起来为 1 或者接近于 1，这些系数被称作**偏差修正（Bias Correction）**。\n\n根据函数极限的一条定理：\n\n$$\\lim\\_{\\beta\\to 0}(1 - \\beta)^\\frac{1}{\\beta} = \\frac{1}{e} \\approx 0.368$$\n\n当 β 为 0.9 时，可以当作把过去 10 天的气温指数加权平均作为当日的气温，因为 10 天后权重已经下降到了当天的 1/3 左右。同理，当 β 为 0.98 时，可以把过去 50 天的气温指数加权平均作为当日的气温。\n\n因此，在计算当前时刻的平均值时，只需要前一天的平均值和当前时刻的值。\n\n$$v\\_t = \\beta v\\_{t-1} + (1 - \\beta)\\theta_t$$\n\n考虑到代码，只需要不断更新 v 即可：\n\n$$v := \\beta v + (1 - \\beta)\\theta_t$$\n<!--此处应有公式的实现代码-->\n\n指数平均加权并**不是最精准**的计算平均数的方法，你可以直接计算过去 10 天或 50 天的平均值来得到更好的估计，但缺点是保存数据需要占用更多内存，执行更加复杂，计算成本更加高昂。\n\n指数加权平均数公式的好处之一在于它只需要一行代码，且占用极少内存，因此**效率极高，且节省成本**。\n\n### 指数平均加权的偏差修正\n\n我们通常有\n\n$$v\\_0 = 0$$\n$$v\\_1 = 0.98v\\_0 + 0.02\\theta\\_1$$\n\n因此，$v\\_1$ 仅为第一个数据的 0.02（或者说 1-β），显然不准确。往后递推同理。\n\n因此，我们修改公式为\n\n$$v\\_t = \\frac{\\beta v\\_{t-1} + (1 - \\beta)\\theta_t}{1-\\beta^t}$$\n\n随着 t 的增大，β 的 t 次方趋近于 0。因此当 t 很大的时候，偏差修正几乎没有作用，但是在前期学习可以帮助更好的预测数据。在实际过程中，一般会忽略前期偏差的影响。\n\n## 动量梯度下降法\n\n**动量梯度下降（Gradient Descent with Momentum）**是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：\n\nfor l = 1, .. , L：\n\n$$v\\_{dW^{[l]}} = \\beta v\\_{dW^{[l]}} + (1 - \\beta) dW^{[l]}$$\n$$v\\_{db^{[l]}} = \\beta v\\_{db^{[l]}} + (1 - \\beta) db^{[l]}$$\n$$W^{[l]} := W^{[l]} - \\alpha v\\_{dW^{[l]}}$$\n$$b^{[l]} := b^{[l]} - \\alpha v\\_{db^{[l]}}$$\n\n其中，将动量衰减参数 β 设置为 0.9 是超参数的一个常见且效果不错的选择。当 β 被设置为 0 时，显然就成了 batch 梯度下降法。\n\n![Gradient-Descent-with-Momentum](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/Gradient-Descent-with-Momentum.png)\n\n进行一般的梯度下降将会得到图中的蓝色曲线，由于存在上下波动，减缓了梯度下降的速度，因此只能使用一个较小的学习率进行迭代。如果用较大的学习率，结果可能会像紫色曲线一样偏离函数的范围。\n\n而使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色的曲线。\n\n当前后梯度方向一致时，动量梯度下降能够加速学习；而前后梯度方向不一致时，动量梯度下降能够抑制震荡。\n\n另外，在 10 次迭代之后，移动平均已经不再是一个具有偏差的预测。因此实际在使用梯度下降法或者动量梯度下降法时，不会同时进行偏差修正。\n\n### 动量梯度下降法的形象解释\n\n将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v\\_{dw}$、$v\\_{db}$ 相当于速度。\n\n小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。\n\n## RMSProp 算法\n\n**RMSProp（Root Mean Square Prop，均方根支）**算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为（省略了 l）：\n\n$$s\\_{dw} = \\beta s\\_{dw} + (1 - \\beta)(dw)^2$$\n$$s\\_{db} = \\beta s\\_{db} + (1 - \\beta)(db)^2$$\n$$w := w - \\alpha \\frac{dw}{\\sqrt{s\\_{dw} + \\epsilon}}$$\n$$b := b - \\alpha \\frac{db}{\\sqrt{s\\_{db} + \\epsilon}}$$\n\n其中，ϵ 是一个实际操作时加上的较小数（例如10^-8），为了防止分母太小而导致的数值不稳定。\n\n当 dw 或 db 较大时，$(dw)^2$、$(db)^2$会较大，进而 $s\\_{dw}$、$s\\_{db}$也会较大，最终使得\n\n$$\\frac{dw}{\\sqrt{s\\_{dw} + \\epsilon}}$$\n\n和\n\n$$\\frac{db}{\\sqrt{s\\_{db} + \\epsilon}}$$\n\n较小，从而减小某些维度梯度更新波动较大的情况，使下降速度变得更快。\n\n![RMSProp](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/RMSProp.png)\n\nRMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。并且，它和 Adam 优化算法已被证明适用于不同的深度学习网络结构。\n\n注意，β 也是一个超参数。\n\n## Adam 优化算法\n\n**Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）**基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。具体过程如下（省略了 l）：\n\n首先进行初始化：\n\n$$v\\_{dW} = 0, s\\_{dW} = 0, v\\_{db} = 0, s\\_{db} = 0$$\n\n用每一个 mini-batch 计算 dW、db，第 t 次迭代时：\n\n$$v\\_{dW} = \\beta\\_1 v\\_{dW} + (1 - \\beta\\_1) dW$$\n$$v\\_{db} = \\beta\\_1 v\\_{db} + (1 - \\beta\\_1) db$$\n$$s\\_{dW} = \\beta\\_2 s\\_{dW} + (1 - \\beta\\_2) (dW)^2$$\n$$s\\_{db} = \\beta\\_2 s\\_{db} + (1 - \\beta\\_2) (db)^2$$\n\n一般使用 Adam 算法时需要计算偏差修正：\n\n$$v^{corrected}\\_{dW} = \\frac{v\\_{dW}}{1-{\\beta\\_1}^t}$$\n$$v^{corrected}\\_{db} = \\frac{v\\_{db}}{1-{\\beta\\_1}^t}$$\n$$s^{corrected}\\_{dW} = \\frac{s\\_{dW}}{1-{\\beta\\_2}^t}$$\n$$s^{corrected}\\_{db} = \\frac{s\\_{db}}{1-{\\beta\\_2}^t}$$\n\n所以，更新 W、b 时有：\n\n$$W := W - \\alpha \\frac{v^{corrected}\\_{dW}}{\\sqrt{s^{corrected}\\_{dW} + \\epsilon}}$$\n\n$$b := b - \\alpha \\frac{v^{corrected}\\_{db}}{\\sqrt{s^{corrected}\\_{db}} + \\epsilon}$$\n\n（可以看到 Andrew 在这里 ϵ 没有写到平方根里去，和他在 RMSProp 中写的不太一样。考虑到 ϵ 所起的作用，我感觉影响不大）\n\n### 超参数的选择\n\nAdam 优化算法有很多的超参数，其中\n\n* 学习率 α：需要尝试一系列的值，来寻找比较合适的；\n* β1：常用的缺省值为 0.9；\n* β2：Adam 算法的作者建议为 0.999；\n* ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；\n\nβ1、β2、ϵ 通常不需要调试。\n\n## 学习率衰减\n\n如果设置一个固定的学习率 α，在最小值点附近，由于不同的 batch 中存在一定的噪声，因此不会精确收敛，而是始终在最小值周围一个较大的范围内波动。\n\n而如果随着时间慢慢减少学习率 α 的大小，在初期 α 较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小 α 的值，即减小步长，有助于算法的收敛，更容易接近最优解。\n\n最常用的学习率衰减方法：\n\n$$\\alpha = \\frac{1}{1 + decay\\\\\\_rate \\* epoch\\\\\\_num} \\* \\alpha\\_0$$\n\n其中，`decay_rate`为衰减率（超参数），`epoch_num`为将所有的训练样本完整过一遍的次数。\n\n* 指数衰减：\n\n$$\\alpha = 0.95^{epoch\\\\\\_num} \\* \\alpha\\_0$$\n\n* 其他：\n\n$$\\alpha = \\frac{k}{\\sqrt{epoch\\\\\\_num}} \\* \\alpha\\_0$$\n\n* 离散下降\n\n对于较小的模型，也有人会在训练时根据进度手动调小学习率。\n\n## 局部最优问题\n\n![saddle](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/saddle.png)\n\n**鞍点（saddle）**是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。\n\n结论：\n\n* 在训练较大的神经网络、存在大量参数，并且成本函数被定义在较高的维度空间时，困在极差的局部最优中是不大可能的；\n* 鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。\n","slug":"深度学习中的优化算法","published":1,"updated":"2018-08-19T01:59:35.807Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0m003s44vosh0343gd"},{"title":"男人的对象选择中的一种特殊类型","date":"2018-07-19T10:15:03.000Z","_content":"\n首先我将描述一种对象选择类型--选择的主体是男人--特点是设定一系列的“恋爱的必要条件”。\n\n1. 在这些恋爱的先决条件中，有一条是通行的：只要你在一个人身上发现了它，就能在他身上找到这个类型的其他特点。这个先决条件就是得有 **“受到伤害的第三方”；也就是说，这类男人永远不会选择没有归属的女人--如未婚少女或心无所系的已婚妇女--他只会选择已被其他男人占有的女人，这个其他男人可以是丈夫、未婚夫或朋友。** 这个先决条件的作用十分强大，以至于只要一个女人不属于某个男人，那么在对象选择中，她就会遭到该类型的男人的忽视或拒绝；而一旦她与另一个男人确立了关系，就会立刻成为该类男人发泄激情的对象。\n2. 第二个先决条件或许不像第一条那样，在该类型的每个男人身上都能找到，不过它也同样引人瞩目。第二条就是，**名声无可指责的纯洁女人永远无法成为被选择的对象，只有在性方面声名狼藉、忠诚度和可信度都受到怀疑的女人才能激起该类男人的兴趣。** 不过他们选择的范围也相当大，从并不厌恶调情、略有丑闻的已婚女子到性生活淫乱的妓女或深谙爱情艺术的熟女，不一而足。\n\n现在让我们审视一番这种类型的人的不同特征：所爱之女人必须有所归属并像个妓女；他对这样的女人评价极高；他有体验嫉妒的需要；他对这样的女人忠贞不二，而又可与多个女人更替地保持和谐之爱；他有拯救女人的强烈愿望。表面看来，这很难来自同一根源。然而，精神分析关于这种人生活史的探讨却可以轻松地找到这种单一根源。这种人对象选择的奇怪条件及示爱的单一方式，与正常人的爱具有相同的心理根源。**它们源于对母亲柔情的婴儿固着，其表现乃是这种固着的结果。**\n\n---\n\n摘自弗洛伊德的《爱情心理学》第一章\n","source":"_posts/男人的对象选择中的一种特殊类型.md","raw":"---\ntitle: 男人的对象选择中的一种特殊类型\ndate: 2018-07-19 18:15:03\ntags: 爱情心理学\ncategories: 心理学\n---\n\n首先我将描述一种对象选择类型--选择的主体是男人--特点是设定一系列的“恋爱的必要条件”。\n\n1. 在这些恋爱的先决条件中，有一条是通行的：只要你在一个人身上发现了它，就能在他身上找到这个类型的其他特点。这个先决条件就是得有 **“受到伤害的第三方”；也就是说，这类男人永远不会选择没有归属的女人--如未婚少女或心无所系的已婚妇女--他只会选择已被其他男人占有的女人，这个其他男人可以是丈夫、未婚夫或朋友。** 这个先决条件的作用十分强大，以至于只要一个女人不属于某个男人，那么在对象选择中，她就会遭到该类型的男人的忽视或拒绝；而一旦她与另一个男人确立了关系，就会立刻成为该类男人发泄激情的对象。\n2. 第二个先决条件或许不像第一条那样，在该类型的每个男人身上都能找到，不过它也同样引人瞩目。第二条就是，**名声无可指责的纯洁女人永远无法成为被选择的对象，只有在性方面声名狼藉、忠诚度和可信度都受到怀疑的女人才能激起该类男人的兴趣。** 不过他们选择的范围也相当大，从并不厌恶调情、略有丑闻的已婚女子到性生活淫乱的妓女或深谙爱情艺术的熟女，不一而足。\n\n现在让我们审视一番这种类型的人的不同特征：所爱之女人必须有所归属并像个妓女；他对这样的女人评价极高；他有体验嫉妒的需要；他对这样的女人忠贞不二，而又可与多个女人更替地保持和谐之爱；他有拯救女人的强烈愿望。表面看来，这很难来自同一根源。然而，精神分析关于这种人生活史的探讨却可以轻松地找到这种单一根源。这种人对象选择的奇怪条件及示爱的单一方式，与正常人的爱具有相同的心理根源。**它们源于对母亲柔情的婴儿固着，其表现乃是这种固着的结果。**\n\n---\n\n摘自弗洛伊德的《爱情心理学》第一章\n","slug":"男人的对象选择中的一种特殊类型","published":1,"updated":"2018-08-31T03:55:01.946Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0o003w44vot9j1u3ot"},{"title":"目标检测","date":"2018-09-02T12:06:02.000Z","mathjax":true,"_content":"\n目标检测是计算机视觉领域中一个新兴的应用方向，其任务是对输入图像进行分类的同时，检测图像中是否包含某些目标，并对他们准确定位并标识。\n\n## 目标定位\n\n定位分类问题不仅要求判断出图片中物体的种类，还要在图片中标记出它的具体位置，用 **边框（Bounding Box，或者称包围盒）** 把物体圈起来。一般来说，定位分类问题通常只有一个较大的对象位于图片中间位置；而在目标检测问题中，图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象。\n\n为了定位图片中汽车的位置，可以让神经网络多输出 4 个数字，标记为 $b_x$、$b_y$、$b_h$、$b_w$。将图片左上角标记为 (0, 0)，右下角标记为 (1, 1)，则有：\n\n* 红色方框的中心点：($b_x$，$b_y$)\n* 边界框的高度：$b_h$\n* 边界框的宽度：$b_w$\n\n因此，训练集不仅包含对象分类标签，还包含表示边界框的四个数字。定义目标标签 Y 如下：\n\n$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n则有：\n\n$$P_c=1, Y = \\left[\\begin{matrix}1, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n其中，$c_n$表示存在第 $n$ 个种类的概率；如果 $P_c=0$，表示没有检测到目标，则输出标签后面的 7 个参数都是无效的，可以忽略（用 ? 来表示）。\n\n$$P_c=0, Y = \\left[\\begin{matrix}0, ?, ?, ?, ?, ?, ?, ?\\end{matrix}\\right]^T$$\n\n损失函数可以表示为 $L(\\hat y, y)$，如果使用平方误差形式，对于不同的 $P_c$有不同的损失函数（注意下标 $i$指标签的第 $i$个值）：\n\n1. $P_c=1$，即$y_1=1$：\n\n    $L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2$\n\n2. $P_c=0$，即$y_1=0$：\n\n    $L(\\hat y,y)=(\\hat y_1-y_1)^2$\n\n除了使用平方误差，也可以使用逻辑回归损失函数，类标签 $c_1,c_2,c_3$ 也可以通过 softmax 输出。相比较而言，平方误差已经能够取得比较好的效果。\n\n## 特征点检测\n\n神经网络可以像标识目标的中心点位置那样，通过输出图片上的特征点，来实现对目标特征的识别。在标签中，这些特征点以多个二维坐标的形式表示。\n\n通过检测人脸特征点可以进行情绪分类与判断，或者应用于 AR 领域等等。也可以透过检测姿态特征点来进行人体姿态检测。\n\n## 目标检测\n\n想要实现目标检测，可以采用 **基于滑动窗口的目标检测（Sliding Windows Detection）** 算法。该算法的步骤如下：\n\n1. 训练集上搜集相应的各种目标图片和非目标图片，样本图片要求尺寸较小，相应目标居于图片中心位置并基本占据整张图片。\n2. 使用训练集构建 CNN 模型，使得模型有较高的识别率。\n3. 选择大小适宜的窗口与合适的固定步幅，对测试图片进行从左到右、从上倒下的滑动遍历。每个窗口区域使用已经训练好的 CNN 模型进行识别判断。\n4. 可以选择更大的窗口，然后重复第三步的操作。\n\n![Sliding-windows-detection](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Sliding-windows-detection.png)\n\n滑动窗口目标检测的 **优点** 是原理简单，且不需要人为选定目标区域；**缺点** 是需要人为直观设定滑动窗口的大小和步幅。滑动窗口过小或过大，步幅过大均会降低目标检测的正确率。另外，每次滑动都要进行一次 CNN 网络计算，如果滑动窗口和步幅较小，计算成本往往很大。\n\n所以，滑动窗口目标检测算法虽然简单，但是性能不佳，效率较低。\n\n## 基于卷积的滑动窗口实现\n\n相比从较大图片多次截取，在卷积层上应用滑动窗口目标检测算法可以提高运行速度。所要做的仅是将全连接层换成卷积层，即使用与上一层尺寸一致的滤波器进行卷积运算。\n\n![Convolution-implementation-of-sliding-windows](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Convolution-implementation-of-sliding-windows.png)\n\n如图，对于 16x16x3 的图片，步长为 2，CNN 网络得到的输出层为 2x2x4。其中，2x2 表示共有 4 个窗口结果。对于更复杂的 28x28x3 的图片，得到的输出层为 8x8x4，共 64 个窗口结果。最大池化层的宽高和步长相等。\n\n运行速度提高的原理：在滑动窗口的过程中，需要重复进行 CNN 正向计算。因此，不需要将输入图片分割成多个子集，分别执行向前传播，而是将它们作为一张图片输入给卷积网络进行一次 CNN 正向计算。这样，公共区域的计算可以共享，以降低运算成本。\n\n相关论文：[Sermanet et al., 2014. OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks](https://arxiv.org/pdf/1312.6229.pdf)\n\n## 边框预测\n\n在上述算法中，边框的位置可能无法完美覆盖目标，或者大小不合适，或者最准确的边框并非正方形，而是长方形。\n\n**YOLO（You Only Look Once）算法** 可以用于得到更精确的边框。YOLO 算法将原始图片划分为 n×n 网格，并将目标定位一节中提到的图像分类和目标定位算法，逐一应用在每个网格中，每个网格都有标签如：\n\n$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n若某个目标的中点落在某个网格，则该网格负责检测该对象。\n\n![Bounding-Box-Predictions](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Bounding-Box-Predictions.png)\n\n如上面的示例中，如果将输入的图片划分为 3×3 的网格、需要检测的目标有 3 类，则每一网格部分图片的标签会是一个 8 维的列矩阵，最终输出的就是大小为 3×3×8 的结果。要得到这个结果，就要训练一个输入大小为 100×100×3，输出大小为 3×3×8 的 CNN。在实践中，可能使用更为精细的 19×19 网格，则两个目标的中点在同一个网格的概率更小。\n\nYOLO 算法的优点：\n\n1. 和图像分类和目标定位算法类似，显式输出边框坐标和大小，不会受到滑窗分类器的步长大小限制。\n2. 仍然只进行一次 CNN 正向计算，效率很高，甚至可以达到实时识别。\n\n如何编码边框 $b_x$、$b_y$、$b_h$、$b_w$？YOLO 算法设 $b_x$、$b_y$、$b_h$、$b_w$ 的值是相对于网格长的比例。则 $b_x$、$b_y$ 在 0 到 1 之间，而 $b_h$、$b_w$ 可以大于 1。当然，也有其他参数化的形式，且效果可能更好。这里只是给出一个通用的表示方法。\n\n相关论文：[Redmon et al., 2015. You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf)。\n\n## 交互比\n\n**交互比（IoU, Intersection Over Union）** 函数用于评价对象检测算法，它计算预测边框和实际边框交集（I）与并集（U）之比：\n\n$$IoU = \\frac{I}{U}$$\n\nIoU 的值在 0～1 之间，且越接近 1 表示目标的定位越准确。IoU 大于等于 0.5 时，一般可以认为预测边框是正确的，当然也可以更加严格地要求一个更高的阈值。\n\n## 非极大值抑制\n\nYOLO 算法中，可能有很多网格检测到同一目标。**非极大值抑制（Non-max Suppression）** 会通过清理检测结果，找到每个目标中点所位于的网格，确保算法对每个目标只检测一次。\n\n进行非极大值抑制的步骤如下：\n\n1. 将包含目标中心坐标的可信度 $P_c$ 小于阈值（例如 0.6）的网格丢弃；\n2. 选取拥有最大 $P_c$ 的网格；\n3. 分别计算该网格和其他所有网格的 IoU，将 IoU 超过预设阈值的网格丢弃；\n4. 重复第 2~3 步，直到不存在未处理的网格。\n\n上述步骤适用于单类别目标检测。进行多个类别目标检测时，对于每个类别，应该单独做一次非极大值抑制。\n\n## Anchor Boxes\n\n到目前为止，我们讨论的情况都是一个网格只检测一个对象。如果要将算法运用在多目标检测上，需要用到 Anchor Boxes。一个网格的标签中将包含多个 Anchor Box，相当于存在多个用以标识不同目标的边框。\n\n![Overlapping-objects](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Overlapping-objects.png)\n\n在上图示例中，我们希望同时检测人和汽车。因此，每个网格的的标签中含有两个 Anchor Box。输出的标签结果大小从 3×3×8 变为 3×3×16。若两个 $P_c$ 都大于预设阈值，则说明检测到了两个目标。\n\n在单目标检测中，图像中的目标被分配给了包含该目标中点的那个网格；引入 Anchor Box 进行多目标检测时，图像中的目标则被分配到了包含该目标中点的那个网格以及具有最高 IoU 值的该网格的 Anchor Box。\n\nAnchor Boxes 也有局限性，对于同一网格有三个及以上目标，或者两个目标的 Anchor Box 高度重合的情况处理不好。\n\nAnchor Box 的形状一般通过人工选取。高级一点的方法是用 k-means 将两类对象形状聚类，选择最具代表性的 Anchor Box。\n\n## R-CNN\n\n前面介绍的滑动窗口目标检测算法对一些明显没有目标的区域也进行了扫描，这降低了算法的运行效率。为了解决这个问题，**R-CNN（Region CNN，带区域的 CNN）** 被提出。通过对输入图片运行 **图像分割算法**，在不同的色块上找出 **候选区域（Region Proposal）**，就只需要在这些区域上运行分类器。\n\n![R-CNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/R-CNN.png)\n\nR-CNN 的缺点是运行速度很慢，所以有一系列后续研究工作改进。例如 Fast R-CNN（与基于卷积的滑动窗口实现相似，但得到候选区域的聚类步骤依然很慢）、Faster R-CNN（使用卷积对图片进行分割）。不过大多数时候还是比 YOLO 算法慢。\n\n相关论文：\n\n* R-CNN：[Girshik et al., 2013. Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf)\n* Fast R-CNN：[Girshik, 2015. Fast R-CNN](https://arxiv.org/pdf/1504.08083.pdf)\n* Faster R-CNN：[Ren et al., 2016. Faster R-CNN: Towards real-time object detection with region proposal networks](https://arxiv.org/pdf/1506.01497v3.pdf)\n","source":"_posts/目标检测.md","raw":"---\ntitle: 目标检测\ndate: 2018-09-02 20:06:02\ntags: 计算机视觉\ncategories: 深度学习\nmathjax: true\n---\n\n目标检测是计算机视觉领域中一个新兴的应用方向，其任务是对输入图像进行分类的同时，检测图像中是否包含某些目标，并对他们准确定位并标识。\n\n## 目标定位\n\n定位分类问题不仅要求判断出图片中物体的种类，还要在图片中标记出它的具体位置，用 **边框（Bounding Box，或者称包围盒）** 把物体圈起来。一般来说，定位分类问题通常只有一个较大的对象位于图片中间位置；而在目标检测问题中，图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象。\n\n为了定位图片中汽车的位置，可以让神经网络多输出 4 个数字，标记为 $b_x$、$b_y$、$b_h$、$b_w$。将图片左上角标记为 (0, 0)，右下角标记为 (1, 1)，则有：\n\n* 红色方框的中心点：($b_x$，$b_y$)\n* 边界框的高度：$b_h$\n* 边界框的宽度：$b_w$\n\n因此，训练集不仅包含对象分类标签，还包含表示边界框的四个数字。定义目标标签 Y 如下：\n\n$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n则有：\n\n$$P_c=1, Y = \\left[\\begin{matrix}1, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n其中，$c_n$表示存在第 $n$ 个种类的概率；如果 $P_c=0$，表示没有检测到目标，则输出标签后面的 7 个参数都是无效的，可以忽略（用 ? 来表示）。\n\n$$P_c=0, Y = \\left[\\begin{matrix}0, ?, ?, ?, ?, ?, ?, ?\\end{matrix}\\right]^T$$\n\n损失函数可以表示为 $L(\\hat y, y)$，如果使用平方误差形式，对于不同的 $P_c$有不同的损失函数（注意下标 $i$指标签的第 $i$个值）：\n\n1. $P_c=1$，即$y_1=1$：\n\n    $L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2$\n\n2. $P_c=0$，即$y_1=0$：\n\n    $L(\\hat y,y)=(\\hat y_1-y_1)^2$\n\n除了使用平方误差，也可以使用逻辑回归损失函数，类标签 $c_1,c_2,c_3$ 也可以通过 softmax 输出。相比较而言，平方误差已经能够取得比较好的效果。\n\n## 特征点检测\n\n神经网络可以像标识目标的中心点位置那样，通过输出图片上的特征点，来实现对目标特征的识别。在标签中，这些特征点以多个二维坐标的形式表示。\n\n通过检测人脸特征点可以进行情绪分类与判断，或者应用于 AR 领域等等。也可以透过检测姿态特征点来进行人体姿态检测。\n\n## 目标检测\n\n想要实现目标检测，可以采用 **基于滑动窗口的目标检测（Sliding Windows Detection）** 算法。该算法的步骤如下：\n\n1. 训练集上搜集相应的各种目标图片和非目标图片，样本图片要求尺寸较小，相应目标居于图片中心位置并基本占据整张图片。\n2. 使用训练集构建 CNN 模型，使得模型有较高的识别率。\n3. 选择大小适宜的窗口与合适的固定步幅，对测试图片进行从左到右、从上倒下的滑动遍历。每个窗口区域使用已经训练好的 CNN 模型进行识别判断。\n4. 可以选择更大的窗口，然后重复第三步的操作。\n\n![Sliding-windows-detection](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Sliding-windows-detection.png)\n\n滑动窗口目标检测的 **优点** 是原理简单，且不需要人为选定目标区域；**缺点** 是需要人为直观设定滑动窗口的大小和步幅。滑动窗口过小或过大，步幅过大均会降低目标检测的正确率。另外，每次滑动都要进行一次 CNN 网络计算，如果滑动窗口和步幅较小，计算成本往往很大。\n\n所以，滑动窗口目标检测算法虽然简单，但是性能不佳，效率较低。\n\n## 基于卷积的滑动窗口实现\n\n相比从较大图片多次截取，在卷积层上应用滑动窗口目标检测算法可以提高运行速度。所要做的仅是将全连接层换成卷积层，即使用与上一层尺寸一致的滤波器进行卷积运算。\n\n![Convolution-implementation-of-sliding-windows](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Convolution-implementation-of-sliding-windows.png)\n\n如图，对于 16x16x3 的图片，步长为 2，CNN 网络得到的输出层为 2x2x4。其中，2x2 表示共有 4 个窗口结果。对于更复杂的 28x28x3 的图片，得到的输出层为 8x8x4，共 64 个窗口结果。最大池化层的宽高和步长相等。\n\n运行速度提高的原理：在滑动窗口的过程中，需要重复进行 CNN 正向计算。因此，不需要将输入图片分割成多个子集，分别执行向前传播，而是将它们作为一张图片输入给卷积网络进行一次 CNN 正向计算。这样，公共区域的计算可以共享，以降低运算成本。\n\n相关论文：[Sermanet et al., 2014. OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks](https://arxiv.org/pdf/1312.6229.pdf)\n\n## 边框预测\n\n在上述算法中，边框的位置可能无法完美覆盖目标，或者大小不合适，或者最准确的边框并非正方形，而是长方形。\n\n**YOLO（You Only Look Once）算法** 可以用于得到更精确的边框。YOLO 算法将原始图片划分为 n×n 网格，并将目标定位一节中提到的图像分类和目标定位算法，逐一应用在每个网格中，每个网格都有标签如：\n\n$$\\left[\\begin{matrix}P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3\\end{matrix}\\right]^T$$\n\n若某个目标的中点落在某个网格，则该网格负责检测该对象。\n\n![Bounding-Box-Predictions](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Bounding-Box-Predictions.png)\n\n如上面的示例中，如果将输入的图片划分为 3×3 的网格、需要检测的目标有 3 类，则每一网格部分图片的标签会是一个 8 维的列矩阵，最终输出的就是大小为 3×3×8 的结果。要得到这个结果，就要训练一个输入大小为 100×100×3，输出大小为 3×3×8 的 CNN。在实践中，可能使用更为精细的 19×19 网格，则两个目标的中点在同一个网格的概率更小。\n\nYOLO 算法的优点：\n\n1. 和图像分类和目标定位算法类似，显式输出边框坐标和大小，不会受到滑窗分类器的步长大小限制。\n2. 仍然只进行一次 CNN 正向计算，效率很高，甚至可以达到实时识别。\n\n如何编码边框 $b_x$、$b_y$、$b_h$、$b_w$？YOLO 算法设 $b_x$、$b_y$、$b_h$、$b_w$ 的值是相对于网格长的比例。则 $b_x$、$b_y$ 在 0 到 1 之间，而 $b_h$、$b_w$ 可以大于 1。当然，也有其他参数化的形式，且效果可能更好。这里只是给出一个通用的表示方法。\n\n相关论文：[Redmon et al., 2015. You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf)。\n\n## 交互比\n\n**交互比（IoU, Intersection Over Union）** 函数用于评价对象检测算法，它计算预测边框和实际边框交集（I）与并集（U）之比：\n\n$$IoU = \\frac{I}{U}$$\n\nIoU 的值在 0～1 之间，且越接近 1 表示目标的定位越准确。IoU 大于等于 0.5 时，一般可以认为预测边框是正确的，当然也可以更加严格地要求一个更高的阈值。\n\n## 非极大值抑制\n\nYOLO 算法中，可能有很多网格检测到同一目标。**非极大值抑制（Non-max Suppression）** 会通过清理检测结果，找到每个目标中点所位于的网格，确保算法对每个目标只检测一次。\n\n进行非极大值抑制的步骤如下：\n\n1. 将包含目标中心坐标的可信度 $P_c$ 小于阈值（例如 0.6）的网格丢弃；\n2. 选取拥有最大 $P_c$ 的网格；\n3. 分别计算该网格和其他所有网格的 IoU，将 IoU 超过预设阈值的网格丢弃；\n4. 重复第 2~3 步，直到不存在未处理的网格。\n\n上述步骤适用于单类别目标检测。进行多个类别目标检测时，对于每个类别，应该单独做一次非极大值抑制。\n\n## Anchor Boxes\n\n到目前为止，我们讨论的情况都是一个网格只检测一个对象。如果要将算法运用在多目标检测上，需要用到 Anchor Boxes。一个网格的标签中将包含多个 Anchor Box，相当于存在多个用以标识不同目标的边框。\n\n![Overlapping-objects](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Overlapping-objects.png)\n\n在上图示例中，我们希望同时检测人和汽车。因此，每个网格的的标签中含有两个 Anchor Box。输出的标签结果大小从 3×3×8 变为 3×3×16。若两个 $P_c$ 都大于预设阈值，则说明检测到了两个目标。\n\n在单目标检测中，图像中的目标被分配给了包含该目标中点的那个网格；引入 Anchor Box 进行多目标检测时，图像中的目标则被分配到了包含该目标中点的那个网格以及具有最高 IoU 值的该网格的 Anchor Box。\n\nAnchor Boxes 也有局限性，对于同一网格有三个及以上目标，或者两个目标的 Anchor Box 高度重合的情况处理不好。\n\nAnchor Box 的形状一般通过人工选取。高级一点的方法是用 k-means 将两类对象形状聚类，选择最具代表性的 Anchor Box。\n\n## R-CNN\n\n前面介绍的滑动窗口目标检测算法对一些明显没有目标的区域也进行了扫描，这降低了算法的运行效率。为了解决这个问题，**R-CNN（Region CNN，带区域的 CNN）** 被提出。通过对输入图片运行 **图像分割算法**，在不同的色块上找出 **候选区域（Region Proposal）**，就只需要在这些区域上运行分类器。\n\n![R-CNN](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/R-CNN.png)\n\nR-CNN 的缺点是运行速度很慢，所以有一系列后续研究工作改进。例如 Fast R-CNN（与基于卷积的滑动窗口实现相似，但得到候选区域的聚类步骤依然很慢）、Faster R-CNN（使用卷积对图片进行分割）。不过大多数时候还是比 YOLO 算法慢。\n\n相关论文：\n\n* R-CNN：[Girshik et al., 2013. Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf)\n* Fast R-CNN：[Girshik, 2015. Fast R-CNN](https://arxiv.org/pdf/1504.08083.pdf)\n* Faster R-CNN：[Ren et al., 2016. Faster R-CNN: Towards real-time object detection with region proposal networks](https://arxiv.org/pdf/1506.01497v3.pdf)\n","slug":"目标检测","published":1,"updated":"2018-09-02T13:13:55.997Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0q003z44vo31xwfjhg"},{"title":"矩阵链乘法","date":"2018-09-01T14:12:29.000Z","mathjax":true,"_content":"### 问题描述\n\n给定一个n个矩阵的序列（矩阵链）$<A_1, A_2, ..., A_n>$, 为了计算它们的乘积 $A_1A_2...A_n$，可以先用括号明确它们的计算次序，然后利用标准的矩阵相乘算法进行计算。\n\n我们称有如下性质的矩阵乘积链为完全括号化的：它是单一矩阵，或者是两个完全括号化的矩阵乘积链的积，且以外加括号。如 $((A_1A_2)(A_3A_4))$.\n\n对矩阵链加括号的方式会对乘积运算的代价产生巨大影响。矩阵链乘法问题可描述如下：**给定n个矩阵的链 $<A_1, A_2, ..., A_n>$ ，矩阵 $A_i$ 的规模为 $p_{i-1} \\times p_i$, 求完全括号化方案，使得计算乘积 $A_1A_2...A_n$ 所需标量乘法次数最少。**\n\n### 计算括号化方案的数量\n\n令 $P(n)$ 表示n个矩阵的链可供选择的括号化方案的数量。则：\n$$P(n) = \\begin{cases} 1, \\qquad where \\quad n = 1 \\\\ \\sum_{k=1}^{n-1} P(k)P(n - k)\\quad where \\quad n \\ge 2\\end{cases}$$\n\n### 应用动态规划方法\n\n对矩阵链乘法问题，我们可以将对所有 $i \\le i \\le j \\le n$ 确定 $A_1A_2...A_n$ 的最小代价括号化方案作为子问题。令 $m[i,j]$ 表示计算矩阵 $A_{i,j}$ 所需要标量乘法次数的最小值，那么原问题的最优解--计算 $A_{1...n}$ 所需要的最低代价就是 $m[1, n]$.\n$$m[i, j] = \\begin{cases}0 \\qquad i = j\\\\ min_{i \\le k \\lt j} \\{m[i, k] + m[k+1, j] + p_{i-1}p_kp_j\\} \\qquad i < j\\end{cases}$$\n\n为得到最优括号化方案，我们用 $s[i, j]$ 保存 $A_1A_2...A_n$ 最优括号化方案的分割点k\n\n### 代码实现\n\n```python\ndef matrix_chain_order(p):\n    \"\"\"\n    p: 假定矩阵A_i的规模是(p_{i-1}, p_i), p是矩阵链规模的序列\n    \"\"\"\n    n = len(p) - 1\n    # m[i, j]表示计算矩阵A_{i..j} i,j = {1...n}所需的标量乘法次数的最小值\n    m = [[j for j in range(n + 1)] for i in range(n + 1)]\n    # s[i, j]表示A_{i..j} i = {1, n-1}, j={2, n}最优括号化方案的分割点位置\n    s = [[j for j in range(n + 1)] for i in range(n)]\n    for i in range(n + 1):\n        m[i][i] = 0\n    for l in range(2, n + 1):\n        for i in range(1, n - l + 2):\n            j = i + l - 1\n            m[i][j] = float('inf')\n            for k in range(i, j):\n                q = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j]\n                if q < m[i][j]:\n                    m[i][j] = q\n                    s[i][j] = k\n    return m, s\n\ndef print_optimal_solution(s, i, j):\n    global optimal_solution\n    if i == j:\n        optimal_solution.append(\"A\" + str(i))\n    else:\n        optimal_solution.append('(')\n        print_optimal_solution(s, i, s[i][j])\n        print_optimal_solution(s, s[i][j] + 1, j)\n        optimal_solution.append(')')\n\n\nif __name__ == '__main__':\n    optimal_solution = []\n    p = [5, 10, 3, 12, 5, 50, 6]\n    m, s = matrix_chain_order(p)\n    print_optimal_solution(s, 1, 6)\n    print('optimal: ', m[1][6])\n    print(''.join(optimal_solution))\n```\n","source":"_posts/矩阵链乘法.md","raw":"---\ntitle: 矩阵链乘法\ndate: 2018-09-01 22:12:29\ntags: 动态规划\ncategories: 算法导论\nmathjax: true\n---\n### 问题描述\n\n给定一个n个矩阵的序列（矩阵链）$<A_1, A_2, ..., A_n>$, 为了计算它们的乘积 $A_1A_2...A_n$，可以先用括号明确它们的计算次序，然后利用标准的矩阵相乘算法进行计算。\n\n我们称有如下性质的矩阵乘积链为完全括号化的：它是单一矩阵，或者是两个完全括号化的矩阵乘积链的积，且以外加括号。如 $((A_1A_2)(A_3A_4))$.\n\n对矩阵链加括号的方式会对乘积运算的代价产生巨大影响。矩阵链乘法问题可描述如下：**给定n个矩阵的链 $<A_1, A_2, ..., A_n>$ ，矩阵 $A_i$ 的规模为 $p_{i-1} \\times p_i$, 求完全括号化方案，使得计算乘积 $A_1A_2...A_n$ 所需标量乘法次数最少。**\n\n### 计算括号化方案的数量\n\n令 $P(n)$ 表示n个矩阵的链可供选择的括号化方案的数量。则：\n$$P(n) = \\begin{cases} 1, \\qquad where \\quad n = 1 \\\\ \\sum_{k=1}^{n-1} P(k)P(n - k)\\quad where \\quad n \\ge 2\\end{cases}$$\n\n### 应用动态规划方法\n\n对矩阵链乘法问题，我们可以将对所有 $i \\le i \\le j \\le n$ 确定 $A_1A_2...A_n$ 的最小代价括号化方案作为子问题。令 $m[i,j]$ 表示计算矩阵 $A_{i,j}$ 所需要标量乘法次数的最小值，那么原问题的最优解--计算 $A_{1...n}$ 所需要的最低代价就是 $m[1, n]$.\n$$m[i, j] = \\begin{cases}0 \\qquad i = j\\\\ min_{i \\le k \\lt j} \\{m[i, k] + m[k+1, j] + p_{i-1}p_kp_j\\} \\qquad i < j\\end{cases}$$\n\n为得到最优括号化方案，我们用 $s[i, j]$ 保存 $A_1A_2...A_n$ 最优括号化方案的分割点k\n\n### 代码实现\n\n```python\ndef matrix_chain_order(p):\n    \"\"\"\n    p: 假定矩阵A_i的规模是(p_{i-1}, p_i), p是矩阵链规模的序列\n    \"\"\"\n    n = len(p) - 1\n    # m[i, j]表示计算矩阵A_{i..j} i,j = {1...n}所需的标量乘法次数的最小值\n    m = [[j for j in range(n + 1)] for i in range(n + 1)]\n    # s[i, j]表示A_{i..j} i = {1, n-1}, j={2, n}最优括号化方案的分割点位置\n    s = [[j for j in range(n + 1)] for i in range(n)]\n    for i in range(n + 1):\n        m[i][i] = 0\n    for l in range(2, n + 1):\n        for i in range(1, n - l + 2):\n            j = i + l - 1\n            m[i][j] = float('inf')\n            for k in range(i, j):\n                q = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j]\n                if q < m[i][j]:\n                    m[i][j] = q\n                    s[i][j] = k\n    return m, s\n\ndef print_optimal_solution(s, i, j):\n    global optimal_solution\n    if i == j:\n        optimal_solution.append(\"A\" + str(i))\n    else:\n        optimal_solution.append('(')\n        print_optimal_solution(s, i, s[i][j])\n        print_optimal_solution(s, s[i][j] + 1, j)\n        optimal_solution.append(')')\n\n\nif __name__ == '__main__':\n    optimal_solution = []\n    p = [5, 10, 3, 12, 5, 50, 6]\n    m, s = matrix_chain_order(p)\n    print_optimal_solution(s, 1, 6)\n    print('optimal: ', m[1][6])\n    print(''.join(optimal_solution))\n```\n","slug":"矩阵链乘法","published":1,"updated":"2018-09-02T01:38:46.520Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0s004244vof8eo0cqc"},{"title":"短诗三首","date":"2018-07-19T02:25:47.000Z","_content":"\n### 确认过眼神\n\n```\n它，睁开朦胧的双眼\n看见天空\n穿着蓝色的裙子\n在微风中跳舞\n红了脸\n害羞地躲到云朵中\n\n它，热烈地燃烧\n想带给天空温暖\n却抵挡不了黑夜的到来\n黑夜一无所有\n却能给天空安慰\n\n它，裹在云朵中哭泣\n眼泪在泥土上溅起水花\n弄脏了天空的裙子\n又停止哭泣\n给天空画上了美丽的彩虹\n```\n\n### 1900\n```\n冬天来了\n你迫不及待地等待夏天\n夏天来了\n你还活在死寂的冬天\n```\n\n### 远方的山\n```\n有些情\n像远方的山\n不知所起，亦不知所终\n隔着呼啸的海浪\n任心被激打\n激打出沉默的浪花\n何不做那海燕\n到山那边歇歇脚\n```\n","source":"_posts/短诗三首.md","raw":"---\ntitle: 短诗三首\ndate: 2018-07-19 10:25:47\ntags: 现代诗\ncategories: 文学\n---\n\n### 确认过眼神\n\n```\n它，睁开朦胧的双眼\n看见天空\n穿着蓝色的裙子\n在微风中跳舞\n红了脸\n害羞地躲到云朵中\n\n它，热烈地燃烧\n想带给天空温暖\n却抵挡不了黑夜的到来\n黑夜一无所有\n却能给天空安慰\n\n它，裹在云朵中哭泣\n眼泪在泥土上溅起水花\n弄脏了天空的裙子\n又停止哭泣\n给天空画上了美丽的彩虹\n```\n\n### 1900\n```\n冬天来了\n你迫不及待地等待夏天\n夏天来了\n你还活在死寂的冬天\n```\n\n### 远方的山\n```\n有些情\n像远方的山\n不知所起，亦不知所终\n隔着呼啸的海浪\n任心被激打\n激打出沉默的浪花\n何不做那海燕\n到山那边歇歇脚\n```\n","slug":"短诗三首","published":1,"updated":"2018-08-31T03:55:08.779Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0v004644vouv85bkgg"},{"title":"神经网络中的通用函数代码","date":"2018-07-21T08:58:55.000Z","_content":"\n## 激活函数\n\n### Sigmoid\n\n```python\ndef sigmoid(Z):\n    \"\"\"\n    Implements the sigmoid activation in numpy\n\n    Arguments:\n    Z -- numpy array of any shape\n\n    Returns:\n    A -- output of sigmoid(z), same shape as Z\n    cache -- returns Z as well, useful during backpropagation\n    \"\"\"\n    A = 1 / (1 + np.exp(-Z))\n    cache = Z\n    return A, cache\n\ndef sigmoid_backward(dA, cache):\n    \"\"\"\n    Implement the backward propagation for a single SIGMOID unit.\n\n    Arguments:\n    dA -- post-activation gradient, of any shape\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    s = 1 / (1 + np.exp(-Z))\n    dZ = dA * s * (1 - s)\n    assert (dZ.shape == Z.shape)\n    return dZ\n```\n\n### Relu\n\n```python\ndef relu(Z):\n    \"\"\"\n    Implement the RELU function.\n\n    Arguments:\n    Z -- Output of the linear layer, of any shape\n\n    Returns:\n    A -- Post-activation parameter, of the same shape as Z\n    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    A = np.maximum(0, Z)\n    assert(A.shape == Z.shape)\n    cache = Z\n    return A, cache\n\ndef relu_backward(dA, cache):\n    \"\"\"\n    Implement the backward propagation for a single RELU unit.\n\n    Arguments:\n    dA -- post-activation gradient, of any shape\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    dZ = np.array(dA, copy=True)  # just converting dz to a correct object.\n    # When z <= 0, you should set dz to 0 as well.\n    dZ[Z <= 0] = 0\n    assert (dZ.shape == Z.shape)\n    return dZ\n```\n\n## 代价函数\n\n### 交叉熵\n\n```python\ndef compute_cost(AL, Y):\n    \"\"\"\n    Implement the cost function\n\n    Arguments:\n    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n\n    Returns:\n    cost -- cross-entropy cost\n    \"\"\"\n    m = Y.shape[1]\n    # Compute loss from aL and y.\n    cost = -1 / m * np.sum(np.dot(Y, np.log(AL).T) + np.dot(1 - Y, np.log(1 - AL).T))\n    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n    assert(cost.shape == ())\n    return cost\n```\n\n### L1 and L2 Loss\n\n```python\ndef L1(yhat, y):\n    \"\"\"\n    Arguments:\n    yhat -- vector of size m (predicted labels)\n    y -- vector of size m (true labels)\n\n    Returns:\n    loss -- the value of the L1 loss function defined above\n    \"\"\"\n    loss = np.sum(abs(yhat - y))\n    return loss\n\ndef L2(yhat, y):\n    \"\"\"\n    Arguments:\n    yhat -- vector of size m (predicted labels)\n    y -- vector of size m (true labels)\n\n    Returns:\n    loss -- the value of the L2 loss function defined above\n    \"\"\"\n    loss = np.sum((y - yhat) ** 2)\n    return loss\n```\n\n## 线性函数\n\n```python\ndef linear_forward(A, W, b):\n    \"\"\"\n    Implement the linear part of a layer's forward propagation.\n\n    Arguments:\n    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n\n    Returns:\n    Z -- the input of the activation function, also called pre-activation parameter\n    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    Z = np.dot(W, A) + b\n    assert(Z.shape == (W.shape[0], A.shape[1]))\n    cache = (A, W, b)\n    return Z, cache\n\ndef linear_backward(dZ, cache):\n    \"\"\"\n    Implement the linear portion of backward propagation for a single layer (layer l)\n\n    Arguments:\n    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    A_prev, W, b = cache\n    m = A_prev.shape[1]\n    dW = 1 / m * np.dot(dZ, A_prev.T)\n    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n    dA_prev = np.dot(W.T, dZ)\n    assert (dA_prev.shape == A_prev.shape)\n    assert (dW.shape == W.shape)\n    assert (db.shape == b.shape)\n    return dA_prev, dW, db\n```\n\n## 线性到激活层\n\n```python\ndef linear_activation_forward(A_prev, W, b, activation):\n    \"\"\"\n    Implement the forward propagation for the LINEAR->ACTIVATION layer\n\n    Arguments:\n    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n\n    Returns:\n    A -- the output of the activation function, also called the post-activation value\n    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n             stored for computing the backward pass efficiently\n    \"\"\"\n    if activation == \"sigmoid\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = sigmoid(Z)\n    elif activation == \"relu\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = relu(Z)\n    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n    cache = (linear_cache, activation_cache)\n    return A, cache\n\ndef linear_activation_backward(dA, cache, activation):\n    \"\"\"\n    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n\n    Arguments:\n    dA -- post-activation gradient for current layer l\n    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    linear_cache, activation_cache = cache\n    if activation == \"relu\":\n        dZ = relu_backward(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    elif activation == \"sigmoid\":\n        dZ = sigmoid_backward(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    return dA_prev, dW, db\n```\n\n## L层前馈网络\n\n```python\ndef L_model_forward(X, parameters):\n    \"\"\"\n    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n\n    Arguments:\n    X -- data, numpy array of shape (input size, number of examples)\n    parameters -- output of initialize_parameters_deep()\n\n    Returns:\n    AL -- last post-activation value\n    caches -- list of caches containing:\n                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n    \"\"\"\n    caches = []\n    A = X\n    L = len(parameters) // 2                  # number of layers in the neural network\n    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n    for l in range(1, L):\n        A_prev = A\n        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n        caches.append(cache)\n    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")    # 注意这里是 A\n    caches.append(cache)\n    assert(AL.shape == (1, X.shape[1]))\n    return AL, caches\n\ndef L_model_backward(AL, Y, caches):\n    \"\"\"\n    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n\n    Arguments:\n    AL -- probability vector, output of the forward propagation (L_model_forward())\n    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n    caches -- list of caches containing:\n                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n\n    Returns:\n    grads -- A dictionary with the gradients\n             grads[\"dA\" + str(l)] = ...\n             grads[\"dW\" + str(l)] = ...\n             grads[\"db\" + str(l)] = ...\n    \"\"\"\n    grads = {}\n    L = len(caches)  # the number of layers\n    # m = AL.shape[1]\n    Y = Y.reshape(AL.shape)  # after this line, Y is the same shape as AL\n    # Initializing the backpropagation\n    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n    # Lth layer (SIGMOID -> LINEAR) gradients.\n    current_cache = caches[L - 1]\n    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, 'sigmoid')\n    for l in reversed(range(L - 1)):\n        # lth layer: (RELU -> LINEAR) gradients.\n        current_cache = caches[l]\n        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], caches[l], 'relu')\n        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n        grads[\"dW\" + str(l + 1)] = dW_temp\n        grads[\"db\" + str(l + 1)] = db_temp\n    return grads\n```\n\n## 参数初始化\n\n```python\ndef initialize_parameters_deep(layer_dims):\n    \"\"\"\n    Arguments:\n    layer_dims -- python array (list) containing the dimensions of each layer in our network\n\n    Returns:\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n                    bl -- bias vector of shape (layer_dims[l], 1)\n    \"\"\"\n    np.random.seed(3)\n    parameters = {}\n    L = len(layer_dims)            # number of layers in the network\n    for l in range(1, L):\n        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * np.sqrt(2 / layer_dims[l - 1])  # He initialization\n        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n    return parameters\n```\n\n## 参数更新（梯度下降）\n\n```python\ndef update_parameters(parameters, grads, learning_rate):\n    \"\"\"\n    Update parameters using gradient descent\n\n    Arguments:\n    parameters -- python dictionary containing your parameters\n    grads -- python dictionary containing your gradients, output of L_model_backward\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters\n                  parameters[\"W\" + str(l)] = ...\n                  parameters[\"b\" + str(l)] = ...\n    \"\"\"\n    L = len(parameters) // 2  # number of layers in the neural network\n    # Update rule for each parameter. Use a for loop.\n    for l in range(L):\n        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n    return parameters\n```\n\n## 训练模型\n\n```python\ndef L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False):  # lr was 0.009\n    \"\"\"\n    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n\n    Arguments:\n    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    costs = []                         # keep track of cost\n    # Parameters initialization.\n    parameters = initialize_parameters_deep(layers_dims)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n        AL, caches = L_model_forward(X, parameters)\n        # Compute cost.\n        cost = compute_cost(AL, Y)\n        # Backward propagation.\n        grads = L_model_backward(AL, Y, caches)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads, learning_rate=0.0075)\n        # Print the cost every 100 training example\n        if print_cost and i % 100 == 0:\n            print(\"Cost after iteration %i: %f\" % (i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)\n    # plot the cost\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Learning rate =\" + str(learning_rate))\n    plt.show()\n    return parameters\n```\n\n## 预测\n\n```python\ndef predict(X, y, parameters):\n    \"\"\"\n    This function is used to predict the results of a  L-layer neural network.\n\n    Arguments:\n    X -- data set of examples you would like to label\n    parameters -- parameters of the trained model\n\n    Returns:\n    p -- predictions for the given dataset X\n    \"\"\"\n    m = X.shape[1]\n    p = np.zeros((1, m))\n    # Forward propagation\n    probas, caches = L_model_forward(X, parameters)\n    # convert probas to 0/1 predictions\n    for i in range(0, probas.shape[1]):\n        if probas[0, i] > 0.5:\n            p[0, i] = 1\n        else:\n            p[0, i] = 0\n    print(\"Accuracy: \" + str(np.sum((p == y) / m)))\n    return p\n```\n","source":"_posts/神经网络中的通用函数代码.md","raw":"---\ntitle: 神经网络中的通用函数代码\ndate: 2018-07-21 16:58:55\ntags: 神经网络\ncategories: 深度学习\n---\n\n## 激活函数\n\n### Sigmoid\n\n```python\ndef sigmoid(Z):\n    \"\"\"\n    Implements the sigmoid activation in numpy\n\n    Arguments:\n    Z -- numpy array of any shape\n\n    Returns:\n    A -- output of sigmoid(z), same shape as Z\n    cache -- returns Z as well, useful during backpropagation\n    \"\"\"\n    A = 1 / (1 + np.exp(-Z))\n    cache = Z\n    return A, cache\n\ndef sigmoid_backward(dA, cache):\n    \"\"\"\n    Implement the backward propagation for a single SIGMOID unit.\n\n    Arguments:\n    dA -- post-activation gradient, of any shape\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    s = 1 / (1 + np.exp(-Z))\n    dZ = dA * s * (1 - s)\n    assert (dZ.shape == Z.shape)\n    return dZ\n```\n\n### Relu\n\n```python\ndef relu(Z):\n    \"\"\"\n    Implement the RELU function.\n\n    Arguments:\n    Z -- Output of the linear layer, of any shape\n\n    Returns:\n    A -- Post-activation parameter, of the same shape as Z\n    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    A = np.maximum(0, Z)\n    assert(A.shape == Z.shape)\n    cache = Z\n    return A, cache\n\ndef relu_backward(dA, cache):\n    \"\"\"\n    Implement the backward propagation for a single RELU unit.\n\n    Arguments:\n    dA -- post-activation gradient, of any shape\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    dZ = np.array(dA, copy=True)  # just converting dz to a correct object.\n    # When z <= 0, you should set dz to 0 as well.\n    dZ[Z <= 0] = 0\n    assert (dZ.shape == Z.shape)\n    return dZ\n```\n\n## 代价函数\n\n### 交叉熵\n\n```python\ndef compute_cost(AL, Y):\n    \"\"\"\n    Implement the cost function\n\n    Arguments:\n    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n\n    Returns:\n    cost -- cross-entropy cost\n    \"\"\"\n    m = Y.shape[1]\n    # Compute loss from aL and y.\n    cost = -1 / m * np.sum(np.dot(Y, np.log(AL).T) + np.dot(1 - Y, np.log(1 - AL).T))\n    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n    assert(cost.shape == ())\n    return cost\n```\n\n### L1 and L2 Loss\n\n```python\ndef L1(yhat, y):\n    \"\"\"\n    Arguments:\n    yhat -- vector of size m (predicted labels)\n    y -- vector of size m (true labels)\n\n    Returns:\n    loss -- the value of the L1 loss function defined above\n    \"\"\"\n    loss = np.sum(abs(yhat - y))\n    return loss\n\ndef L2(yhat, y):\n    \"\"\"\n    Arguments:\n    yhat -- vector of size m (predicted labels)\n    y -- vector of size m (true labels)\n\n    Returns:\n    loss -- the value of the L2 loss function defined above\n    \"\"\"\n    loss = np.sum((y - yhat) ** 2)\n    return loss\n```\n\n## 线性函数\n\n```python\ndef linear_forward(A, W, b):\n    \"\"\"\n    Implement the linear part of a layer's forward propagation.\n\n    Arguments:\n    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n\n    Returns:\n    Z -- the input of the activation function, also called pre-activation parameter\n    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    Z = np.dot(W, A) + b\n    assert(Z.shape == (W.shape[0], A.shape[1]))\n    cache = (A, W, b)\n    return Z, cache\n\ndef linear_backward(dZ, cache):\n    \"\"\"\n    Implement the linear portion of backward propagation for a single layer (layer l)\n\n    Arguments:\n    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    A_prev, W, b = cache\n    m = A_prev.shape[1]\n    dW = 1 / m * np.dot(dZ, A_prev.T)\n    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n    dA_prev = np.dot(W.T, dZ)\n    assert (dA_prev.shape == A_prev.shape)\n    assert (dW.shape == W.shape)\n    assert (db.shape == b.shape)\n    return dA_prev, dW, db\n```\n\n## 线性到激活层\n\n```python\ndef linear_activation_forward(A_prev, W, b, activation):\n    \"\"\"\n    Implement the forward propagation for the LINEAR->ACTIVATION layer\n\n    Arguments:\n    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n\n    Returns:\n    A -- the output of the activation function, also called the post-activation value\n    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n             stored for computing the backward pass efficiently\n    \"\"\"\n    if activation == \"sigmoid\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = sigmoid(Z)\n    elif activation == \"relu\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = relu(Z)\n    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n    cache = (linear_cache, activation_cache)\n    return A, cache\n\ndef linear_activation_backward(dA, cache, activation):\n    \"\"\"\n    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n\n    Arguments:\n    dA -- post-activation gradient for current layer l\n    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    linear_cache, activation_cache = cache\n    if activation == \"relu\":\n        dZ = relu_backward(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    elif activation == \"sigmoid\":\n        dZ = sigmoid_backward(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    return dA_prev, dW, db\n```\n\n## L层前馈网络\n\n```python\ndef L_model_forward(X, parameters):\n    \"\"\"\n    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n\n    Arguments:\n    X -- data, numpy array of shape (input size, number of examples)\n    parameters -- output of initialize_parameters_deep()\n\n    Returns:\n    AL -- last post-activation value\n    caches -- list of caches containing:\n                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n    \"\"\"\n    caches = []\n    A = X\n    L = len(parameters) // 2                  # number of layers in the neural network\n    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n    for l in range(1, L):\n        A_prev = A\n        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n        caches.append(cache)\n    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")    # 注意这里是 A\n    caches.append(cache)\n    assert(AL.shape == (1, X.shape[1]))\n    return AL, caches\n\ndef L_model_backward(AL, Y, caches):\n    \"\"\"\n    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n\n    Arguments:\n    AL -- probability vector, output of the forward propagation (L_model_forward())\n    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n    caches -- list of caches containing:\n                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n\n    Returns:\n    grads -- A dictionary with the gradients\n             grads[\"dA\" + str(l)] = ...\n             grads[\"dW\" + str(l)] = ...\n             grads[\"db\" + str(l)] = ...\n    \"\"\"\n    grads = {}\n    L = len(caches)  # the number of layers\n    # m = AL.shape[1]\n    Y = Y.reshape(AL.shape)  # after this line, Y is the same shape as AL\n    # Initializing the backpropagation\n    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n    # Lth layer (SIGMOID -> LINEAR) gradients.\n    current_cache = caches[L - 1]\n    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, 'sigmoid')\n    for l in reversed(range(L - 1)):\n        # lth layer: (RELU -> LINEAR) gradients.\n        current_cache = caches[l]\n        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], caches[l], 'relu')\n        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n        grads[\"dW\" + str(l + 1)] = dW_temp\n        grads[\"db\" + str(l + 1)] = db_temp\n    return grads\n```\n\n## 参数初始化\n\n```python\ndef initialize_parameters_deep(layer_dims):\n    \"\"\"\n    Arguments:\n    layer_dims -- python array (list) containing the dimensions of each layer in our network\n\n    Returns:\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n                    bl -- bias vector of shape (layer_dims[l], 1)\n    \"\"\"\n    np.random.seed(3)\n    parameters = {}\n    L = len(layer_dims)            # number of layers in the network\n    for l in range(1, L):\n        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * np.sqrt(2 / layer_dims[l - 1])  # He initialization\n        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n    return parameters\n```\n\n## 参数更新（梯度下降）\n\n```python\ndef update_parameters(parameters, grads, learning_rate):\n    \"\"\"\n    Update parameters using gradient descent\n\n    Arguments:\n    parameters -- python dictionary containing your parameters\n    grads -- python dictionary containing your gradients, output of L_model_backward\n\n    Returns:\n    parameters -- python dictionary containing your updated parameters\n                  parameters[\"W\" + str(l)] = ...\n                  parameters[\"b\" + str(l)] = ...\n    \"\"\"\n    L = len(parameters) // 2  # number of layers in the neural network\n    # Update rule for each parameter. Use a for loop.\n    for l in range(L):\n        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n    return parameters\n```\n\n## 训练模型\n\n```python\ndef L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False):  # lr was 0.009\n    \"\"\"\n    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n\n    Arguments:\n    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    costs = []                         # keep track of cost\n    # Parameters initialization.\n    parameters = initialize_parameters_deep(layers_dims)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n        AL, caches = L_model_forward(X, parameters)\n        # Compute cost.\n        cost = compute_cost(AL, Y)\n        # Backward propagation.\n        grads = L_model_backward(AL, Y, caches)\n        # Update parameters.\n        parameters = update_parameters(parameters, grads, learning_rate=0.0075)\n        # Print the cost every 100 training example\n        if print_cost and i % 100 == 0:\n            print(\"Cost after iteration %i: %f\" % (i, cost))\n        if print_cost and i % 100 == 0:\n            costs.append(cost)\n    # plot the cost\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Learning rate =\" + str(learning_rate))\n    plt.show()\n    return parameters\n```\n\n## 预测\n\n```python\ndef predict(X, y, parameters):\n    \"\"\"\n    This function is used to predict the results of a  L-layer neural network.\n\n    Arguments:\n    X -- data set of examples you would like to label\n    parameters -- parameters of the trained model\n\n    Returns:\n    p -- predictions for the given dataset X\n    \"\"\"\n    m = X.shape[1]\n    p = np.zeros((1, m))\n    # Forward propagation\n    probas, caches = L_model_forward(X, parameters)\n    # convert probas to 0/1 predictions\n    for i in range(0, probas.shape[1]):\n        if probas[0, i] > 0.5:\n            p[0, i] = 1\n        else:\n            p[0, i] = 0\n    print(\"Accuracy: \" + str(np.sum((p == y) / m)))\n    return p\n```\n","slug":"神经网络中的通用函数代码","published":1,"updated":"2018-08-31T03:55:23.326Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p0x004944vomff8o4xr"},{"title":"神经风格迁移","date":"2018-09-04T06:25:53.000Z","mathjax":true,"_content":"**神经风格迁移（Neural style transfer）** 将参考风格图像的风格“迁移”到另外一张内容图像中，生成具有其特色的图像。\n\n![Neural-style-transfer](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Neural-style-transfer.png)\n\n### 深度卷积网络在学什么？\n\n想要理解如何实现神经风格转换，首先要理解在输入图像数据后，一个深度卷积网络从中都学到了些什么。我们借助可视化来做到这一点。\n\n![Visualizing-deep-layers](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Visualizing-deep-layers.png)\n\n我们通过遍历所有的训练样本，找出使该层激活函数输出最大的 9 块图像区域。可以看出，浅层的隐藏层通常检测出的是原始图像的边缘、颜色、阴影等简单信息。随着层数的增加，隐藏单元能捕捉的区域更大，学习到的特征也由从边缘到纹理再到具体物体，变得更加复杂。\n\n相关论文：[Zeiler and Fergus., 2013, Visualizing and understanding convolutional networks](https://arxiv.org/pdf/1311.2901.pdf)\n\n### 代价函数\n\n神经风格迁移生成图片 G 的代价函数如下：\n\n$$J(G) = \\alpha \\cdot J_{content}(C, G) + \\beta \\cdot J_{style}(S, G)$$\n\n其中，$\\alpha$、$\\beta$ 是用于控制相似度比重的超参数。\n\n神经风格迁移的算法步骤如下：\n\n1. 随机生成图片 G 的所有像素点；\n2. 使用梯度下降算法使代价函数最小化，以不断修正 G 的所有像素点。\n\n相关论文：[Gatys al., 2015. A neural algorithm of artistic style](https://arxiv.org/pdf/1508.06576v2.pdf)\n\n#### 内容代价函数\n\n上述代价函数包含一个内容代价部分和风格代价部分。我们先来讨论内容代价函数 $J_{content}(C, G)$，它表示内容图片 C 和生成图片 G 之间的相似度。\n\n$J_{content}(C, G)$ 的计算过程如下：\n\n* 使用一个预训练好的 CNN（例如 VGG）；\n* 选择一个隐藏层 $l$ 来计算内容代价。$l$ 太小则内容图片和生成图片像素级别相似，$l$ 太大则可能只有具体物体级别的相似。因此，$l$ 一般选一个中间层；\n* 设 $a^{(C)[l]}$、$a^{(G)[l]}$ 为 C 和 G 在 $l$ 层的激活，则有：\n\n$$J_{content}(C, G) = \\frac{1}{2}||(a^{(C)[l]} - a^{(G)[l]})||^2$$\n\n$a^{(C)[l]}$ 和 $a^{(G)[l]}$ 越相似，则 $J_{content}(C, G)$ 越小。\n\n#### 风格代价函数\n\n![Intuition-about-style-of-an-image](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Intuition-about-style-of-an-image.png)\n\n每个通道提取图片的特征不同，比如标为红色的通道提取的是图片的垂直纹理特征，标为黄色的通道提取的是图片的橙色背景特征。那么计算这两个通道的相关性，相关性的大小，即表示原始图片既包含了垂直纹理也包含了该橙色背景的可能性大小。通过 CNN，**“风格”被定义为同一个隐藏层不同通道之间激活值的相关系数，因其反映了原始图片特征间的相互关系。**\n\n对于风格图像 S，选定网络中的第 $l$ 层，则相关系数以一个 gram 矩阵的形式表示：\n\n$$G^{(S)[l]}_{kk'} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}\\_W}\\_{j=1} a^{(S)[l]}\\_{ijk} a^{(S)[l]}_{ijk'}$$\n\n其中，$i$ 和 $j$ 为第 $l$ 层的高度和宽度；$k$ 和 $k'$ 为选定的通道，其范围为 $1$ 到 $n_C^{[l]}$；$a^{(S)[l]}_{ijk}$ 为激活。\n\n同理，对于生成图像 G，有：\n\n$$G^{(G)[l]}_{kk'} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}\\_W}\\_{j=1} a^{(G)[l]}\\_{ijk} a^{(G)[l]}_{ijk'}$$\n\n因此，第 $l$ 层的风格代价函数为：\n\n$$J^{[l]}_{style}(S, G) = \\frac{1}{(2n^{[l]}_Hn^{[l]}\\_Wn^{[l]}_C)^2} \\sum_k \\sum_{k'}(G^{(S)[l]}\\_{kk'} - G^{(G)[l]}_{kk'})^2$$\n\n如果对各层都使用风格代价函数，效果会更好。因此有：\n\n$$J_{style}(S, G) = \\sum_l \\lambda^{[l]} J^{[l]}_{style}(S, G)$$\n\n其中，$lambda$ 是用于设置不同层所占权重的超参数。\n","source":"_posts/神经风格迁移.md","raw":"---\ntitle: 神经风格迁移\ndate: 2018-09-04 14:25:53\ntags: 计算机视觉\ncategories: 深度学习\nmathjax: true\n---\n**神经风格迁移（Neural style transfer）** 将参考风格图像的风格“迁移”到另外一张内容图像中，生成具有其特色的图像。\n\n![Neural-style-transfer](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Neural-style-transfer.png)\n\n### 深度卷积网络在学什么？\n\n想要理解如何实现神经风格转换，首先要理解在输入图像数据后，一个深度卷积网络从中都学到了些什么。我们借助可视化来做到这一点。\n\n![Visualizing-deep-layers](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Visualizing-deep-layers.png)\n\n我们通过遍历所有的训练样本，找出使该层激活函数输出最大的 9 块图像区域。可以看出，浅层的隐藏层通常检测出的是原始图像的边缘、颜色、阴影等简单信息。随着层数的增加，隐藏单元能捕捉的区域更大，学习到的特征也由从边缘到纹理再到具体物体，变得更加复杂。\n\n相关论文：[Zeiler and Fergus., 2013, Visualizing and understanding convolutional networks](https://arxiv.org/pdf/1311.2901.pdf)\n\n### 代价函数\n\n神经风格迁移生成图片 G 的代价函数如下：\n\n$$J(G) = \\alpha \\cdot J_{content}(C, G) + \\beta \\cdot J_{style}(S, G)$$\n\n其中，$\\alpha$、$\\beta$ 是用于控制相似度比重的超参数。\n\n神经风格迁移的算法步骤如下：\n\n1. 随机生成图片 G 的所有像素点；\n2. 使用梯度下降算法使代价函数最小化，以不断修正 G 的所有像素点。\n\n相关论文：[Gatys al., 2015. A neural algorithm of artistic style](https://arxiv.org/pdf/1508.06576v2.pdf)\n\n#### 内容代价函数\n\n上述代价函数包含一个内容代价部分和风格代价部分。我们先来讨论内容代价函数 $J_{content}(C, G)$，它表示内容图片 C 和生成图片 G 之间的相似度。\n\n$J_{content}(C, G)$ 的计算过程如下：\n\n* 使用一个预训练好的 CNN（例如 VGG）；\n* 选择一个隐藏层 $l$ 来计算内容代价。$l$ 太小则内容图片和生成图片像素级别相似，$l$ 太大则可能只有具体物体级别的相似。因此，$l$ 一般选一个中间层；\n* 设 $a^{(C)[l]}$、$a^{(G)[l]}$ 为 C 和 G 在 $l$ 层的激活，则有：\n\n$$J_{content}(C, G) = \\frac{1}{2}||(a^{(C)[l]} - a^{(G)[l]})||^2$$\n\n$a^{(C)[l]}$ 和 $a^{(G)[l]}$ 越相似，则 $J_{content}(C, G)$ 越小。\n\n#### 风格代价函数\n\n![Intuition-about-style-of-an-image](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Convolutional_Neural_Networks/Intuition-about-style-of-an-image.png)\n\n每个通道提取图片的特征不同，比如标为红色的通道提取的是图片的垂直纹理特征，标为黄色的通道提取的是图片的橙色背景特征。那么计算这两个通道的相关性，相关性的大小，即表示原始图片既包含了垂直纹理也包含了该橙色背景的可能性大小。通过 CNN，**“风格”被定义为同一个隐藏层不同通道之间激活值的相关系数，因其反映了原始图片特征间的相互关系。**\n\n对于风格图像 S，选定网络中的第 $l$ 层，则相关系数以一个 gram 矩阵的形式表示：\n\n$$G^{(S)[l]}_{kk'} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}\\_W}\\_{j=1} a^{(S)[l]}\\_{ijk} a^{(S)[l]}_{ijk'}$$\n\n其中，$i$ 和 $j$ 为第 $l$ 层的高度和宽度；$k$ 和 $k'$ 为选定的通道，其范围为 $1$ 到 $n_C^{[l]}$；$a^{(S)[l]}_{ijk}$ 为激活。\n\n同理，对于生成图像 G，有：\n\n$$G^{(G)[l]}_{kk'} = \\sum^{n^{[l]}_H}_{i=1} \\sum^{n^{[l]}\\_W}\\_{j=1} a^{(G)[l]}\\_{ijk} a^{(G)[l]}_{ijk'}$$\n\n因此，第 $l$ 层的风格代价函数为：\n\n$$J^{[l]}_{style}(S, G) = \\frac{1}{(2n^{[l]}_Hn^{[l]}\\_Wn^{[l]}_C)^2} \\sum_k \\sum_{k'}(G^{(S)[l]}\\_{kk'} - G^{(G)[l]}_{kk'})^2$$\n\n如果对各层都使用风格代价函数，效果会更好。因此有：\n\n$$J_{style}(S, G) = \\sum_l \\lambda^{[l]} J^{[l]}_{style}(S, G)$$\n\n其中，$lambda$ 是用于设置不同层所占权重的超参数。\n","slug":"神经风格迁移","published":1,"updated":"2018-09-05T11:51:36.557Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p11004d44voxrbe4eyt"},{"title":"贞洁禁忌","date":"2018-07-21T07:31:50.000Z","_content":"## 现象\n\n**处女不能将贞洁保留给新郎或未来的伴侣，习俗上要求新郎避开使处女失贞这一行为。**史实记载在澳大利亚的Dieri部落,女孩到青春期破处是普遍的习俗。\n\n## 解释\n\n### 对血的恐惧\n\n贞洁禁忌与普遍存在的月经禁忌有关。面对每月流血这一令人迷惑的现象，原始人无法把它与施虐观点相连，而被解释为某种鬼怪咬了女孩。\n\n### 对新事物的恐惧\n\n正如精神分析理论所研究的焦虑神经症一样，原始人也长期受到潜在忧虑的影响。在不同寻常的场合，这种忧虑尤其强烈，包括遇到新事物或预料之外的情况、无法理解或神秘之事。这也是各种仪式的根源，后来被宗教广泛采用。威胁焦虑者的危险只会在他自己期待中生动上演，而非在真实的危险情境中。因此，婚姻中首行性事之前做些预防措施十分重要。\n\n### 贞洁禁忌是整个性生活的一部分\n\n不仅与女人的第一次性交是禁忌，而且性交总体上就是个禁忌。在多数情况下，原始人的性生活被各种禁止强有力地约束着，并不像在文明社会中已达到的较高水平。当原始人从事重要活动，如出发探索周围环境，狩猎或参加战役时，就必须远离自己的妻子，尤其不能与她性交。\n\n只要原始人设立禁忌，就意味着惧怕事物，不容争议的是，所有回避女人的规定都表达了对女人整体的恐惧。或许这种恐惧建立在男女不同的事实上，即女人永远都无法令人理解、神秘且陌生，因此明显地与男人敌对。男人害怕受女性气质的感染，害怕变得像女人一样脆弱无能。性交的效果--卸载紧张、引发身体疲软--或许是男人惧怕女人的原型。\n\n## 结论\n\n在文明社会中，“失贞”不仅会长久地把女性束缚在男性身上，还会从女性身上释放出对男性的敌意反应。女性对男性的敌意反应可以采取病态形式，并常常表现为婚后对性生活的抑制，同时，我们也可以把第二段婚姻比第一段婚姻更美满的原因归结于此。\n\n十分有趣的是，精神分析家还会遇到这样的女人：她们心中同时存在着归属于敌意两种冲动，而且着两种冲动彼此间的联系十分紧密。她们可能看起来完全离开了丈夫，但心里还会受到丈夫的影响。当她试图爱上别的男人时，前任的形象就会冒出来干扰，对她的新爱情产生抑制效果。分析表明，这类女人确实还与前任有联结，尽管这不是一种情感联结。她们之所以离不开前任，是因为自己还没有完成复仇计划。\n","source":"_posts/贞洁禁忌.md","raw":"---\ntitle: 贞洁禁忌\ndate: 2018-07-21 15:31:50\ntags: 爱情心理学\ncategories: 心理学\n---\n## 现象\n\n**处女不能将贞洁保留给新郎或未来的伴侣，习俗上要求新郎避开使处女失贞这一行为。**史实记载在澳大利亚的Dieri部落,女孩到青春期破处是普遍的习俗。\n\n## 解释\n\n### 对血的恐惧\n\n贞洁禁忌与普遍存在的月经禁忌有关。面对每月流血这一令人迷惑的现象，原始人无法把它与施虐观点相连，而被解释为某种鬼怪咬了女孩。\n\n### 对新事物的恐惧\n\n正如精神分析理论所研究的焦虑神经症一样，原始人也长期受到潜在忧虑的影响。在不同寻常的场合，这种忧虑尤其强烈，包括遇到新事物或预料之外的情况、无法理解或神秘之事。这也是各种仪式的根源，后来被宗教广泛采用。威胁焦虑者的危险只会在他自己期待中生动上演，而非在真实的危险情境中。因此，婚姻中首行性事之前做些预防措施十分重要。\n\n### 贞洁禁忌是整个性生活的一部分\n\n不仅与女人的第一次性交是禁忌，而且性交总体上就是个禁忌。在多数情况下，原始人的性生活被各种禁止强有力地约束着，并不像在文明社会中已达到的较高水平。当原始人从事重要活动，如出发探索周围环境，狩猎或参加战役时，就必须远离自己的妻子，尤其不能与她性交。\n\n只要原始人设立禁忌，就意味着惧怕事物，不容争议的是，所有回避女人的规定都表达了对女人整体的恐惧。或许这种恐惧建立在男女不同的事实上，即女人永远都无法令人理解、神秘且陌生，因此明显地与男人敌对。男人害怕受女性气质的感染，害怕变得像女人一样脆弱无能。性交的效果--卸载紧张、引发身体疲软--或许是男人惧怕女人的原型。\n\n## 结论\n\n在文明社会中，“失贞”不仅会长久地把女性束缚在男性身上，还会从女性身上释放出对男性的敌意反应。女性对男性的敌意反应可以采取病态形式，并常常表现为婚后对性生活的抑制，同时，我们也可以把第二段婚姻比第一段婚姻更美满的原因归结于此。\n\n十分有趣的是，精神分析家还会遇到这样的女人：她们心中同时存在着归属于敌意两种冲动，而且着两种冲动彼此间的联系十分紧密。她们可能看起来完全离开了丈夫，但心里还会受到丈夫的影响。当她试图爱上别的男人时，前任的形象就会冒出来干扰，对她的新爱情产生抑制效果。分析表明，这类女人确实还与前任有联结，尽管这不是一种情感联结。她们之所以离不开前任，是因为自己还没有完成复仇计划。\n","slug":"贞洁禁忌","published":1,"updated":"2018-08-31T03:55:27.511Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmd19p14004g44voqavdyqmj"}],"PostAsset":[],"PostCategory":[{"post_id":"cjmd19ow1000144voegorubd0","category_id":"cjmd19owd000444vogeysilf2","_id":"cjmd19ox1000e44vo3e9t2myn"},{"post_id":"cjmd19owv000c44vok75ao4za","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19oxk000k44vogpvjhlgi"},{"post_id":"cjmd19ow9000344voc93n9d4y","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19oxq000o44vo8dabucy8"},{"post_id":"cjmd19ox9000h44voba7cemgi","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19oxu000r44vo6wd4jx6k"},{"post_id":"cjmd19owg000644vok5gflb02","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19oxy000w44vow56htklj"},{"post_id":"cjmd19oxn000n44vom138wkku","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19oy1000z44vo8iws76ro"},{"post_id":"cjmd19owk000744von0qfgscn","category_id":"cjmd19oxl000l44vol4y8hx8h","_id":"cjmd19oy3001244vop6a9ov3c"},{"post_id":"cjmd19oxx000v44vosmftr0cq","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19oy9001644vonw3d4e37"},{"post_id":"cjmd19owp000844vo31q1h3r6","category_id":"cjmd19oxl000l44vol4y8hx8h","_id":"cjmd19oyf001944vonmmehmrq"},{"post_id":"cjmd19oxz000y44vo638yoqrh","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19oyh001c44vo895yrufc"},{"post_id":"cjmd19owy000d44vo2ekzhm18","category_id":"cjmd19oy1001044vojxxpvfc6","_id":"cjmd19oyj001f44vo6jeucja5"},{"post_id":"cjmd19oy6001544vofj349hkm","category_id":"cjmd19oy1001044vojxxpvfc6","_id":"cjmd19oym001k44voontom1n8"},{"post_id":"cjmd19oyc001844voacobmjjr","category_id":"cjmd19owd000444vogeysilf2","_id":"cjmd19oyo001n44voo2tokqvu"},{"post_id":"cjmd19oxe000j44voo24ekut5","category_id":"cjmd19oyb001744voubntz5se","_id":"cjmd19oyr001s44vo1x7r2k0d"},{"post_id":"cjmd19oyi001e44voop6urdgo","category_id":"cjmd19owd000444vogeysilf2","_id":"cjmd19oyt001v44voob1msb1x"},{"post_id":"cjmd19oxr000q44vom7pkorvt","category_id":"cjmd19oyj001g44vopclruv8h","_id":"cjmd19oyx001z44vozuwxze0d"},{"post_id":"cjmd19oy2001144vo0njy7dc6","category_id":"cjmd19oyp001p44votm8ru9f6","_id":"cjmd19oz2002444vowd9wauml"},{"post_id":"cjmd19oyv001y44vob5alyo8u","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19oz9002844vof2jqfhkg"},{"post_id":"cjmd19oyg001b44vo4utvm089","category_id":"cjmd19oyp001p44votm8ru9f6","_id":"cjmd19ozc002c44vor4pw4jd5"},{"post_id":"cjmd19oz3002544vo5tpqfit3","category_id":"cjmd19oyj001g44vopclruv8h","_id":"cjmd19ozf002g44voa9zudls2"},{"post_id":"cjmd19oyl001j44vo7ch7isvx","category_id":"cjmd19oz1002344vo5ffaysbn","_id":"cjmd19ozi002k44vock1s8jd3"},{"post_id":"cjmd19oz8002744vonb7bs9jr","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19ozk002n44voinezlpn3"},{"post_id":"cjmd19ozb002b44vofv6fsirp","category_id":"cjmd19oyj001g44vopclruv8h","_id":"cjmd19ozn002r44vo18pehh9b"},{"post_id":"cjmd19oyn001m44vo39nls8l9","category_id":"cjmd19oz1002344vo5ffaysbn","_id":"cjmd19ozq002u44vow9ka4z1d"},{"post_id":"cjmd19ozh002j44vonw60neyw","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19ozt002y44voxp7lbvja"},{"post_id":"cjmd19oyq001r44vo73bfobfy","category_id":"cjmd19oz1002344vo5ffaysbn","_id":"cjmd19ozx003144voxrsx9mmx"},{"post_id":"cjmd19ozj002m44vo8i7tp3t1","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p00003444voit6k8jz9"},{"post_id":"cjmd19ozo002t44voelyg2r65","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p03003844vom0vo1ldw"},{"post_id":"cjmd19oys001u44voq4j1b3f3","category_id":"cjmd19ozm002p44vo2n672n3c","_id":"cjmd19p08003b44voxe8hxtjq"},{"post_id":"cjmd19ozv003044vo93v2f1ey","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p0b003f44vo1jpdv95u"},{"post_id":"cjmd19oyz002244vo1te5lr90","category_id":"cjmd19ozu002z44vo4fdkn895","_id":"cjmd19p0e003j44vo2hsffbmh"},{"post_id":"cjmd19ozz003344voew1qcddr","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p0h003m44vo410urdvu"},{"post_id":"cjmd19p02003744vo0nsn71px","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p0l003q44vogu89l02v"},{"post_id":"cjmd19ozm002q44vouz6hti9e","category_id":"cjmd19p01003644vo8gf6wnb0","_id":"cjmd19p0n003t44vouo5mrca4"},{"post_id":"cjmd19p06003a44vo5dt4e90l","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p0p003x44vo73g7hzsj"},{"post_id":"cjmd19ozs002x44vozohaqs67","category_id":"cjmd19p09003d44vo9u4y80tv","_id":"cjmd19p0r004044voj73nim72"},{"post_id":"cjmd19p0d003i44vo9iqj3rhi","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p0t004344von78873ut"},{"post_id":"cjmd19p0f003l44vo9k25g0er","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p0w004744vojyjf23qe"},{"post_id":"cjmd19p0j003p44vosmkpyw4b","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p0z004a44voquxeda5f"},{"post_id":"cjmd19p0m003s44vosh0343gd","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p12004e44vorlohr10t"},{"post_id":"cjmd19p0o003w44vot9j1u3ot","category_id":"cjmd19p09003d44vo9u4y80tv","_id":"cjmd19p15004h44vo8jh4srrb"},{"post_id":"cjmd19p0q003z44vo31xwfjhg","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p19004k44voydft1nqx"},{"post_id":"cjmd19p0s004244vof8eo0cqc","category_id":"cjmd19oyj001g44vopclruv8h","_id":"cjmd19p1a004m44vo3mh7a263"},{"post_id":"cjmd19p0v004644vouv85bkgg","category_id":"cjmd19ozm002p44vo2n672n3c","_id":"cjmd19p1b004o44vow5ao8bro"},{"post_id":"cjmd19p0x004944vomff8o4xr","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p1b004q44vo9bytkngm"},{"post_id":"cjmd19p11004d44voxrbe4eyt","category_id":"cjmd19ows000944voo7aqq6lh","_id":"cjmd19p1c004r44vok435prvh"},{"post_id":"cjmd19p14004g44voqavdyqmj","category_id":"cjmd19p09003d44vo9u4y80tv","_id":"cjmd19p1d004u44vowlj4ls45"}],"PostTag":[{"post_id":"cjmd19ow1000144voegorubd0","tag_id":"cjmd19owf000544voq8ochafg","_id":"cjmd19owv000b44voafaxy79e"},{"post_id":"cjmd19ow9000344voc93n9d4y","tag_id":"cjmd19owt000a44vo8mynh4wk","_id":"cjmd19oxc000i44vofgy3o9ww"},{"post_id":"cjmd19owg000644vok5gflb02","tag_id":"cjmd19ox2000g44vokgzf8rzy","_id":"cjmd19oxq000p44vokwoujayf"},{"post_id":"cjmd19oxn000n44vom138wkku","tag_id":"cjmd19owt000a44vo8mynh4wk","_id":"cjmd19oxw000t44voei5f8uzv"},{"post_id":"cjmd19owk000744von0qfgscn","tag_id":"cjmd19oxm000m44vo0if6ap0i","_id":"cjmd19oxz000x44vopla580gt"},{"post_id":"cjmd19owp000844vo31q1h3r6","tag_id":"cjmd19oxx000u44vod093e7ad","_id":"cjmd19oy5001444voglmsdunp"},{"post_id":"cjmd19owv000c44vok75ao4za","tag_id":"cjmd19oy4001344votiyjkka1","_id":"cjmd19oyh001d44voargpz3sm"},{"post_id":"cjmd19oyc001844voacobmjjr","tag_id":"cjmd19owf000544voq8ochafg","_id":"cjmd19oyk001h44voynoau9bb"},{"post_id":"cjmd19oyg001b44vo4utvm089","tag_id":"cjmd19owf000544voq8ochafg","_id":"cjmd19oym001l44vojdxvjlp2"},{"post_id":"cjmd19owy000d44vo2ekzhm18","tag_id":"cjmd19oyf001a44vo17sjfowy","_id":"cjmd19oyp001o44vondqou4yf"},{"post_id":"cjmd19oyi001e44voop6urdgo","tag_id":"cjmd19owf000544voq8ochafg","_id":"cjmd19oyr001t44vo5q7h6tk6"},{"post_id":"cjmd19ox9000h44voba7cemgi","tag_id":"cjmd19oyk001i44vowor07gcx","_id":"cjmd19oyt001w44voisf6kozn"},{"post_id":"cjmd19oxe000j44voo24ekut5","tag_id":"cjmd19oyq001q44vol7x4lj8j","_id":"cjmd19oyz002144voy3njl3z5"},{"post_id":"cjmd19oxr000q44vom7pkorvt","tag_id":"cjmd19oyx002044voc53igkw9","_id":"cjmd19oza002944voh2kdysct"},{"post_id":"cjmd19oz8002744vonb7bs9jr","tag_id":"cjmd19oy4001344votiyjkka1","_id":"cjmd19ozd002e44vozvn6jn4f"},{"post_id":"cjmd19oxx000v44vosmftr0cq","tag_id":"cjmd19oz6002644vos5qjy691","_id":"cjmd19ozg002h44voy2sx44gx"},{"post_id":"cjmd19oxz000y44vo638yoqrh","tag_id":"cjmd19ozd002d44vo23ko4vh9","_id":"cjmd19ozl002o44vo7fjrm7j1"},{"post_id":"cjmd19ozh002j44vonw60neyw","tag_id":"cjmd19oyk001i44vowor07gcx","_id":"cjmd19ozo002s44vo4jvyercj"},{"post_id":"cjmd19oy2001144vo0njy7dc6","tag_id":"cjmd19ozj002l44voayybk50u","_id":"cjmd19ozs002w44vo4434e75g"},{"post_id":"cjmd19oyl001j44vo7ch7isvx","tag_id":"cjmd19ozr002v44vo2ixna5bo","_id":"cjmd19p00003544von8hr0e33"},{"post_id":"cjmd19oyn001m44vo39nls8l9","tag_id":"cjmd19ozr002v44vo2ixna5bo","_id":"cjmd19p08003c44vonjscahei"},{"post_id":"cjmd19p02003744vo0nsn71px","tag_id":"cjmd19oy4001344votiyjkka1","_id":"cjmd19p0b003g44voie2mh6c9"},{"post_id":"cjmd19p06003a44vo5dt4e90l","tag_id":"cjmd19oy4001344votiyjkka1","_id":"cjmd19p0e003k44vo936w7dmc"},{"post_id":"cjmd19oyq001r44vo73bfobfy","tag_id":"cjmd19ozr002v44vo2ixna5bo","_id":"cjmd19p0h003n44vo0rjcbizg"},{"post_id":"cjmd19p0a003e44voe1vvqnlr","tag_id":"cjmd19oy4001344votiyjkka1","_id":"cjmd19p0l003r44vowljxl1rw"},{"post_id":"cjmd19oys001u44voq4j1b3f3","tag_id":"cjmd19p0c003h44vo4fn5mxpu","_id":"cjmd19p0n003u44vo1i97vgok"},{"post_id":"cjmd19p0j003p44vosmkpyw4b","tag_id":"cjmd19oyk001i44vowor07gcx","_id":"cjmd19p0q003y44vohnhmiwf8"},{"post_id":"cjmd19oyv001y44vob5alyo8u","tag_id":"cjmd19p0i003o44vodytaw9il","_id":"cjmd19p0s004144voc9lo3cbt"},{"post_id":"cjmd19p0m003s44vosh0343gd","tag_id":"cjmd19oy4001344votiyjkka1","_id":"cjmd19p0u004544vor9n2erbh"},{"post_id":"cjmd19p0q003z44vo31xwfjhg","tag_id":"cjmd19p0i003o44vodytaw9il","_id":"cjmd19p0w004844vo9we5uu6s"},{"post_id":"cjmd19oyz002244vo1te5lr90","tag_id":"cjmd19p0o003v44vo36pvazab","_id":"cjmd19p0z004b44vokiv0k939"},{"post_id":"cjmd19oz3002544vo5tpqfit3","tag_id":"cjmd19p0t004444voztkn26en","_id":"cjmd19p13004f44vo5pfg1gtm"},{"post_id":"cjmd19p11004d44voxrbe4eyt","tag_id":"cjmd19p0i003o44vodytaw9il","_id":"cjmd19p18004j44vo3k8ypc2m"},{"post_id":"cjmd19ozb002b44vofv6fsirp","tag_id":"cjmd19p10004c44vo4joxfd69","_id":"cjmd19p19004l44vojii7e9f8"},{"post_id":"cjmd19oze002f44voxyihp0rl","tag_id":"cjmd19p17004i44vodnbgswbo","_id":"cjmd19p1b004p44vo0pkjyp03"},{"post_id":"cjmd19ozj002m44vo8i7tp3t1","tag_id":"cjmd19p1a004n44vocwvwf5gw","_id":"cjmd19p1d004t44vosrt4rqqo"},{"post_id":"cjmd19ozm002q44vouz6hti9e","tag_id":"cjmd19p1c004s44vo6ynnkod2","_id":"cjmd19p1f004w44von5oumt03"},{"post_id":"cjmd19ozo002t44voelyg2r65","tag_id":"cjmd19p1e004v44vokayjrvn5","_id":"cjmd19p1i004y44vobsr6cpn3"},{"post_id":"cjmd19ozs002x44vozohaqs67","tag_id":"cjmd19p1g004x44vo9x3tjkhn","_id":"cjmd19p1l005044vogthr7dkl"},{"post_id":"cjmd19ozv003044vo93v2f1ey","tag_id":"cjmd19p1j004z44vov8bw5gdm","_id":"cjmd19p1o005244vo3c8b2n30"},{"post_id":"cjmd19ozz003344voew1qcddr","tag_id":"cjmd19p1j004z44vov8bw5gdm","_id":"cjmd19p1r005444vol54y076b"},{"post_id":"cjmd19p0d003i44vo9iqj3rhi","tag_id":"cjmd19p1p005344votxrhfgq0","_id":"cjmd19p1v005644vo8u8yyqzo"},{"post_id":"cjmd19p0f003l44vo9k25g0er","tag_id":"cjmd19p1s005544vo3pqdiv78","_id":"cjmd19p1y005844vofkfzkmvs"},{"post_id":"cjmd19p0o003w44vot9j1u3ot","tag_id":"cjmd19p1g004x44vo9x3tjkhn","_id":"cjmd19p20005a44vou50ft2ft"},{"post_id":"cjmd19p0s004244vof8eo0cqc","tag_id":"cjmd19p10004c44vo4joxfd69","_id":"cjmd19p21005c44vov58wf7c0"},{"post_id":"cjmd19p0v004644vouv85bkgg","tag_id":"cjmd19p20005b44vomi01y3h8","_id":"cjmd19p23005e44vox0ihfhta"},{"post_id":"cjmd19p0x004944vomff8o4xr","tag_id":"cjmd19p22005d44vourh5ws30","_id":"cjmd19p26005g44vo2j97jaio"},{"post_id":"cjmd19p14004g44voqavdyqmj","tag_id":"cjmd19p1g004x44vo9x3tjkhn","_id":"cjmd19p28005h44voimgvwgpc"}],"Tag":[{"name":"python","_id":"cjmd19owf000544voq8ochafg"},{"name":"数据集","_id":"cjmd19owt000a44vo8mynh4wk"},{"name":"DNN","_id":"cjmd19ox2000g44vokgzf8rzy"},{"name":"进化算法","_id":"cjmd19oxm000m44vo0if6ap0i"},{"name":"遗传算法","_id":"cjmd19oxx000u44vod093e7ad"},{"name":"优化算法","_id":"cjmd19oy4001344votiyjkka1"},{"name":"hexo","_id":"cjmd19oyf001a44vo17sjfowy"},{"name":"CNN","_id":"cjmd19oyk001i44vowor07gcx"},{"name":"回归","_id":"cjmd19oyq001q44vol7x4lj8j"},{"name":"Permutation","_id":"cjmd19oyx002044voc53igkw9"},{"name":"CNN, VGG","_id":"cjmd19oz6002644vos5qjy691"},{"name":"dropout","_id":"cjmd19ozd002d44vo23ko4vh9"},{"name":"git","_id":"cjmd19ozj002l44voayybk50u"},{"name":"tensorflow_python_API","_id":"cjmd19ozr002v44vo2ixna5bo"},{"name":"路遥","_id":"cjmd19p0c003h44vo4fn5mxpu"},{"name":"计算机视觉","_id":"cjmd19p0i003o44vodytaw9il"},{"name":"信息简史","_id":"cjmd19p0o003v44vo36pvazab"},{"name":"分治策略","_id":"cjmd19p0t004444voztkn26en"},{"name":"动态规划","_id":"cjmd19p10004c44vo4joxfd69"},{"name":"策略游戏","_id":"cjmd19p17004i44vodnbgswbo"},{"name":"总结","_id":"cjmd19p1a004n44vocwvwf5gw"},{"name":"物理","_id":"cjmd19p1c004s44vo6ynnkod2"},{"name":"RNN","_id":"cjmd19p1e004v44vokayjrvn5"},{"name":"爱情心理学","_id":"cjmd19p1g004x44vo9x3tjkhn"},{"name":"数据","_id":"cjmd19p1j004z44vov8bw5gdm"},{"name":"模型估计","_id":"cjmd19p1p005344votxrhfgq0"},{"name":"正则化","_id":"cjmd19p1s005544vo3pqdiv78"},{"name":"现代诗","_id":"cjmd19p20005b44vomi01y3h8"},{"name":"神经网络","_id":"cjmd19p22005d44vourh5ws30"}]}}