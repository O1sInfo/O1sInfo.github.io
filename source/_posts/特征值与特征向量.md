---
title: 特征值与特征向量
date: 2018-09-23 15:34:27
tags: 线性代数
categories: 机器学习
---

## 特征向量(eigenvector)与特征值(eigenvalue)

$\mathbf A$为$n \times n$矩阵，对非零向量 $\vec x$, 若存在某个数量 $\lambda$. 使得 $\mathbf Ax = \lambda x$ 则称 $\vec x$ 为 $\mathbf A$ 的 **特征向量**. 如果方程有非平凡解，则数量 $\lambda$ 为 $\mathbf A$ 的 **特征值**。

$\lambda$ 是 $\mathbf A$ 的特征值当且仅当方程(1)有非平凡解，即 $(\mathbf A - \lambda \mathbf I)$ 不可逆。
$$(\mathbf A - \lambda \mathbf I)\vec x = \mathbf 0 \tag{1}$$

(1)所有解的集合恰好是矩阵 $(\mathbf A - \lambda \mathbf I)$ 的零空间，所以这个集合是 $\mathbf R^n$ 的子空间，我们将它称为 $\mathbf A$ 的对应于 $\lambda$ 的 **特征空间(eigenspace)**。

定理一： 三角矩阵的特征值为其主对角线上的元素。

定理二：若 $\vec v_1, ... \vec v_r$ 为 $n \times n$ 矩阵 $\mathbf A$ 的对应于不同特征值 $\lambda_1, ..., \lambda_r$ 的特征向量，则集合 $\{\vec v_1, ... \vec v_r\}$ 线性无关。

## 特征向量和差分方程

$$\vec x_{k+1} = \mathbf A\vec x_k \qquad k=(0,1,2...) \tag{2}$$

如果 $\mathbf A$ 为 $n \times n$ 矩阵，则(2)是 $\mathbf R^n$ 中序列的一个递归描述。它的一个解是{$\vec x_k$}的一个显示表示。构造(2)的解最简单的方法是取一个特征向量 $\vec x_0$ 以及对应的特征值 $\lambda$, 令
$$\vec x_k = \lambda^k \vec x_0 \qquad k=(1,2,..)$$
该序列即为(2)的解。因为：
$$\mathbf A\vec x_k = \mathbf A(\lambda^k \vec x_0) = \lambda^k(\mathbf A\vec x_0)\\ = \lambda^k(\lambda\vec x_0) = \lambda^{k+1}\vec x_0 = \vec x_{k+1}$$


## 特征方程

数量 $\lambda$ 是 $\mathbf A$ 的特征值当 $\lambda$ 满足特征方程：
$$det(\mathbf A - \lambda \mathbf I) = 0 \tag{3}$$

### 相似

设$A$和$B$是$n*n$矩阵，如果存在一个可逆矩阵P使得$P^{-1}AP = B$, 或等价地$A=P^{-1}BP$, 则称$A$相似于$B$, 令$Q=P^{-1}$, 则$Q^{-1}BQ = A$, 所以$B$也相似于$A$. 我们简称$A$和$B$相似。将$A$转换为$P^{-1}AP$称为相似变换。

定理4：如果$n*n$矩阵$A$和$B$相似，则他们有相同的特征多项式，从而有相同的特征值。

## 对角化

定理5：可对角化定理

$n*n$矩阵$A$可对角化当且仅当$A$有$n$个线性无关的特征向量。事实上，$A=PDP^{-1}$, 其中$D$为对角矩阵，当且仅当$P$的列向量是$A$的$n$个线性无关的特征向量，此时$D$的对角线元素是$A$的特征值，并且它们分别对应于$P$的特征向量。

换言之，$A$可对角化当且仅当$A$有足够多的特征向量可以构成$R^n$的一组基，这样的一组基称为**特征向量基**.
