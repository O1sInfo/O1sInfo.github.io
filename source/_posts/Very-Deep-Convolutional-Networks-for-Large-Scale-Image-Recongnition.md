---
title: Very Deep Convolutional Networks for Large-Scale Image Recongnition
date: 2018-08-31 10:08:37
tags: CNN, VGG
categories: 深度学习
mathjax: true
---
## 概述

这是一篇由牛津大学视觉几何组(VGG)2015年发表在ICLR上的论文。该论文中，他们主要研究了卷积网络深度对大尺度图像识别精度的影响。主要的贡献是，对使用同一小卷积核但深度不同的网络性能的完整评估，当把深度加到16-19层时，它相对于先前技术在性能上有了很大改善。文中的网络架构被称为 **VGG**, 它也在ImageNet Challenge 2014上取得了定位第一，分类第二的好成绩。

## 网络配置

所有的网络使用相同的卷积池化操作只是深度不同。使用'SAME'卷积, 卷积核大小均为 $3 \times 3$ , 步长为1. 使用最大池化, 池化单元大小均为 $2 \times 2$, 步长为2. 卷积核个数(通道数)从64开始以2倍增长直到512. 每层卷积层的非线性函数为ReLU. 最后三个全连接层的大小分别为4096, 4096, 1000.

![](/images/vgg_architecture.PNG)

亮点：**使用3个堆叠的3\*3卷积而不是采样像alexnet中的7\*7卷积.**

理由：在3个堆叠的卷积层中都包含了ReLU非线性单元，这使决策函数更具有分辨力；其次减少了参数，相比于7\*7的卷积需要参数( $7 \times7 C^2$ ), 3个3\*3卷积层需要更少的参数( $3\times 3 \times 3 C^2$ )

## 分类任务的训练和测试

### 训练阶段

利用带动量的小批量梯度下降法优化多项逻辑回归目标。$batch size=256, momentum=0.9, L2=5*10^{-4}, dropout=0.5, learning\_rate=0.01$
先训练小网络A, 再将训练后A的权重给其他网络初始化, 其他还未初始化的层，权重使用均值为0方差为0.01的正态分布初始化，偏差初始化为0.
在每个SGD迭代过程，对每幅输入图像进行随机裁剪到固定大小224\*224.

训练图像的大小(S: 是经过各向同性调整后的最小边长)：

方法一：单尺度训练，固定S=256/S=384. 先用S=256训练，将参数保留然后再用S=384进行微调(学习率下降到0.001)。

方法二：多尺度训练，S从[256, 512]中随机取值，先用S=384训练再将其参数保留用多尺度方法训练。

### 测试阶段

给一个测试图像，先将其进行各向同性调整到预定义的最小尺寸Q. 将全连接层转换为卷积层(第一个全连接层变为7\*7的卷积层，第二，三个全连接层变为1\*1的卷积层，核的大小均与之前全连接层的单元数相等)。将整个未裁剪的图像应用在整个卷积网络上。结果是一个类的得分映射，通道数等于类数，以及一个可变的空间分辨率，取决于输入的图像大小。最后，为了获得图像的类分数的固定大小向量，类分数被进行空间平均（一个类的得分为该通道上像素的平均值）。还能通过水平翻转的方式来增强测试集。

亮点：**测试时将全连接层转换为卷积层。**

理由：在测试时不需要生成多个裁剪的图像重复进行计算。对输入图像的大小没有限制。

## 分类任务的评估

该数据集包含1000个类的图像，并分为三组:训练(130万张图像)、验证(50K图像)和测试(100K带有提示标签的图像)。

### 单尺度评估(Q不变)

$对于固定的S, Q=S; 对于 S \in [S_{min}, S_{max}], Q = 0.5(S_{min} + S_{max})$
![](/images/vgg_performance_1.PNG)

### 多尺度评估(Q变化)

$对于固定的S, Q=\{S-32, S, S+32\}; 对于 S \in [S_{min}, S_{max}], Q = \{S_{min}, 0.5(S_{min} + S_{max}), S_{max}\}$
![](/images/vgg_performance_2.PNG)

### Multi-crop 评估(S变化)

![](/images/vgg_performance_3.PNG)
