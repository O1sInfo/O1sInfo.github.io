---
title: ImageNet Classification wih Deep Convolutional Neural Network
date: 2018-08-28 15:07:25
tags: CNN
categories: 深度学习
mathjax: true
---
这是一篇由Alex Krizhevsky, Ilya Sutskever, Geoffrey E.Hinton发表在NIPS上的[Paper](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)。该论文中提出了一种新型网络架构即 **AlexNet**.

## AlexNet

AlexNet首次在大规模图像数据集实现了深层卷积神经网络结构，点燃了深度学习应用在计算机视觉领域的这把火。其在 *ImageNet LSVRC-2012* $^{[1]}$ 目标识别竞赛的 *top-5 error* $^{[2]}$ 为15.3%，同期第二名仅为26.2%，碾压其他传统的hand-craft 特征方法，使得计算机视觉从业者从繁重的特征工程中解脱出来，转向思考能够从数据中自动提取需要的特征，做到数据驱动。

### 数据集

对原始高清图像进行下采样得到固定的256\*256的图像。具体方法是，给一个矩形图像，先调整短边长度为256然后裁剪出中间部分256\*256的图片。最后按RGB像素值减去训练集中所有图像的均值图像像素。

### 架构

![](/images/alexnet_architecture.PNG)

第二、第四和第五卷积层的内核只连接到位于同一GPU上的前一层内核映射。第三个卷积层的内核连接到第二层的所有内核映射。完全连接层的神经元与前一层的所有神经元连接。局部响应归一化接在第一，第二个卷积层后面。最大池化层跟随着局部响应层和第五个卷积层。

#### ReLU Nonlinearity

标准的神经元模型输出是sigmoid, tanh这些的函数。用梯度下降训练时在训练时间上，这些饱和非线性函数比非饱和非线性函数需要的时间要多得多。相比于tanh单元，深度卷积网络使用ReLU训练得更快。

#### 在多个GPU上训练

当前的gpu特别适合于cross-gpu并行化，因为它们能够直接从彼此的内存中读取和写入，而无需通过主机内存。并行化方案实际上是将一半的内核(或神经元)放在每个GPU上，还有一个额外的技巧:GPU只在特定层进行通信。这个方案使top-1和top-5的错误率分别降低了1.7%和1.2%。

#### 局部响应归一化

$$b^{i}\_{x, y} = a^{i}\_{x, y} / (k + \alpha \sum_{j = max(0, i - n/2)}^{min(N - 1, i + n/2)} (a^{i}_{x, y})^2)^{\beta}$$

$a^{i}\_{x, y}$ 是应用卷积(包括非线性单元)操作后第i个通道位于(x, y)的值, $b^{i}\_{x, y}$ 是应用局部响应归一化后的同一位置上值。常数$k, n, \alpha, \beta$ 是超参数。这里设置为$k = 2, n = 5, \alpha=10^{-4}, \beta=0.75$

来源于生物学上的概念: **侧抑制**, 指被激化的神经元抑制相邻神经元的现象。这使得响应比较大的值相对更大，提高了模型的泛化能力。这个方案使top-1和top-5的错误率分别降低了1.4%和1.2%。

#### 重叠池化

CNNs中的池化层汇总了同一核映射中相邻神经元群的输出。传统的池化，相邻池单元不会重叠，即步长$s=z$ 池化单元大小。如果$s < z$则得到重叠的池化。在整个网络中使用$s = 2, z=3$。这个方案使top-1和top-5的错误率分别降低了0.4%和0.3%。

### 降低过拟合

#### 数据增强

关于图像数据最简单也最常用的降低过拟合的方法是通过保留标签对图像进行简单变换的方法人为地扩大数据集。

第一种形式是：将图像进行水平翻转。通过从256\*256的图像中随机抽取227\*227的块，还有它们的水平翻转，用这些图像去训练网络。在测试时，通过抽取测试图像的四个角落和中间227\*227的块，以及它们的水平翻转，一共10个块来输入进网络，最后以它们的平均值作为预测结果。

第二种形式是：改变RGB通道的强度。具体来说，在整个训练集中对RGB像素值集执行PCA。对于每个训练图像，添加已找到的主成分的倍数。与对应的特征值成正比的大小乘以均值为0和标准差为0.1的高斯随机变量。

对每个像素值 $I\_{xy} = [I^{R}\_{xy}, I^{G}\_{xy}, I^{B}\_{xy}]^T$ 加上以下数量：
$$[p_1, p_2, p_3][\alpha_1 \lambda_1, \alpha_2 \lambda_2, \alpha_3 \lambda_3]^T$$
$p_i, \lambda_i$ 分别是RGB像素协方差矩阵的第i个特征向量和特征值, $\alpha_i$ 是随机变量，每个 $\alpha_i$ 只一个训练图像的一个像素。这个方案使top-1降低了1%。

#### Dropout

以一定概率使神经元的输出置为0。这种技术减少了神经元复杂的协同适应，因为神经元不能依赖于特定的其他神经元的存在。因此，它不得不学习更健壮的特性，这些特性与其他神经元的许多不同随机子集一起使用。

### 注解

[1]: ImageNet数据集大约包含2.2万种不同种类的1500万张高清图像。年度的图像识别竞赛**the ImageNet Large-Scale Visual Recognition Challenge
(ILSVRC)** 从2010开始举行。 ILSVRC 使用大约1000种类每类1000张图片的数据集。

[2]: the top-5 错误率是：测试图像的预测结果前五位不包含真实标签的比例。

[3]: The model result in ILSVRC-2010

![](/images/alexnet_ilsvrc.PNG)
