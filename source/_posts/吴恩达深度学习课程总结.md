---
title: 吴恩达深度学习课程总结
date: 2018-09-22 11:43:27
tags: 总结
categories: 深度学习
---
吴恩达深度学习课程学习心得

这门课程由五个章节组成，分别是：
* 神经网络和深度学习
* 超参数调试，正则化和优化算法
* 结构化机器学习项目
* 卷积神经网络
* 自然语言处理：构建序列模型

### 神经网络和深度学习

**什么是神经网络？**

人工神经网络的研究在一定程度上受到生物学的启发，因为人的学习系统是由相互连接的神经元组成的异常复杂的网络。而人工神经网络与此大体相似，它是由一系列简单的神经元相互密集连接构成的，它尝试去发现信息处理过程中的数学表示。在大多数神经网络的实现中，神经元之间的信号是实值，每一个神经元的输出是它的所有输入信号强度和的非线性函数。连接神经元的边通常有一个权重，在学习过程中不断调整它。这个权重可以影响神经元之间传递的信号强度。神经元还可能有一个阈值来控制信号的传递。简而言之它是一个通用的函数逼近机器。


**结构化数据和非结构化数据的区别？**

- 结构化数据：由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范。

- 非结构化数据：数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维逻辑表来表现的数据。包括所有格式的办公文档、文本、图片、XML, HTML、各类报表、图像和音频/视频信息等等。


**What is Logistic Regression?**

logistic回归是监督学习中用在当输出数据是0或1时的一个学习算法。它的目标是最小化预测和真实标签之间的误差。

**损失函数与代价函数的区别？**

损失函数：用于衡量预测结果与真实结果之间的误差。在单个训练样本中定义。
代价函数：衡量学习到的模型在全体样本上的表现。

**什么是全连接网络的前向传播过程和反向传播过程？**

forward propagation:
$$Z^{[l]} = {W^{[l]}}A^{[l-1]} + b^{[l]}$$
$$A^{[l]} = g(Z^{[l]})$$

backward propagation:
$$Denotion: dA^{[l]} = \frac{\partial J}{\partial A^{[l]}}\\dZ^{[l]} = dA^{[l]} * g'(Z^{[l]})\\dW^{[l]} = \frac{1}{m}dZ^{[l]}\cdot {A^{[l]}}^T\\db^{[l]} = \frac{1}{m}np.sum(dZ^{[l]}, axis=1, keepdim=True)\\dA^{[l-1]} = {W^{[l]}}^T\cdot dZ^{[l]}$$


向量化实现：$A^{[l-1]}: (n_{l-1}, m)\\W^{[l]}: (n_{l}, n_{l-1})\\b^{[l]}: (n_l, 1)\\Z^{[l]}: (n_l, m)\\A^{[l]}: (n_l, m)$

**有哪些激活函数？**

- sigmoid
    $$\sigma(z) = \frac{1}{1 + e^{-z}} $$
- tanh
    $$tanh(z) = \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}$$
- relu
    $$relu(z) = max(z, 0)$$
- leaky
    $$leakyRelu(z) = max(0.01z, 0)

**参数和超参数的区别？**

- 参数：是我们在过程中想要模型学习到的信息

- 超参数：为控制参数的输出值的一些网络信息（需要人经验判断）。超参数的改变会导致最终得到的参数。


### 超参数调试，正则化和优化算法

**训练集/验证集/测试集该怎么划分？**

* 训练集（train set）：用训练集对算法或模型进行 **训练** 过程；
* 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行**交叉验证**，**选择出最好的模型**；
* 测试集（test set）：最后利用测试集对模型进行测试，**获取模型运行的无偏估计**（对学习方法进行评估）。

* 对小数据量数据集，如 100、1000、10000 的数据量大小。无验证集的情况：70% / 30%；有验证集的情况：60% / 20% / 20%；

* 对于大数据量数据集： 100 万数据量：98% / 1% / 1%；超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）

**验证集要和训练集来自于同一个分布**（数据来源一致），如果不需要用**无偏估计**来评估模型的性能，则可以不需要测试集。


**什么是偏差，方差，噪声？**

* **偏差**：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了**学习算法本身的拟合能力**
* **方差**：度量了同样大小的训练集的变动导致的学习性能的变化，即刻画了**数据扰动所造成的影响**
* **噪声**：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了**学习问题本身的难度**

* 训练集的错误率较小，而验证集的错误率却较大，说明模型存在较大方差，可能出现了过拟合；
* 训练集和测试集的错误率都较大，且两者相当，说明模型存在较大偏差，可能出现了欠拟合；
* 训练集错误率较大，且测试集的错误率远较训练集大，说明方差和偏差都较大，模型很差；
* 训练集和测试集的错误率都较小，且两者的相差也较小，说明方差和偏差都较小，这个模型效果比较好。

**如何应对高偏差和高方差？**

存在高偏差：**扩大网络规模，寻找合适的网络架构，训练更多次**

存在高方差：**获取更多的数据，正则化，寻找更合适的网络架构**

**什么是正则化？**

正则化是在代价函数中加入一个正则化项，惩罚模型的复杂度，可用于解决高方差问题。
* L2 正则化：
$$\frac{\lambda}{2m}{||w||}^2_2 = \frac{\lambda}{2m}\sum_{j=1}^{n_x}w^2_j = \frac{\lambda}{2m}w^Tw$$

* L1 正则化：
$$\frac{\lambda}{2m}{||w||}_1 = \frac{\lambda}{2m}\sum_{j=1}^{n_x}{|w_j|}$$

**神经网络中的正则化如何表示？**

对于神经网络，加入正则化的成本函数：

$$J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^L{||w^{[l]}||}^2_F$$

因为 $w^{[l]}$ 的大小为 ($n^{[l−1]}$, $n^{[l]}$)，因此

$${||w^{[l]}||}^2_F = \sum^{n^{[l-1]}}_{i=1}\sum^{n^{[l]}}_{j=1}(w^{[l]}_{ij})^2$$

该矩阵范数被称为 **弗罗贝尼乌斯范数（Frobenius Norm）**，所以神经网络中的正则化项被称为弗罗贝尼乌斯范数矩阵。

对权重的影响：
$$dW^{[l]}= \frac{\partial L}{\partial w^{[l]}} +\frac{\lambda}{m}W^{[l]}$$
$$W^{[l]} := W^{[l]} - \alpha [\frac{\partial L}{\partial w^{[l]}} + \frac{\lambda}{m}W^{[l]}]$$
$$= (1 - \frac{\alpha\lambda}{m})W^{[l]} - \alpha \frac{\partial L}{\partial w^{[l]}}$$
其中，因为 $1 - \frac{\alpha\lambda}{m}<1$，会给原来的 $W^{[l]}$ 一个衰减的参数，因此 L2 正则化项也被称为**权重衰减（Weight Decay）**

**什么是dropout正则化？**

**dropout(随机失活)**：是在神经网络的隐藏层为每个神经元结点设置一个随机消除的概率。对于单个神经元，其工作是接收输入并产生一些有意义的输出。但是加入了 dropout 后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征，即不会给任何一个输入特征设置太大的权重。因此，通过传播过程，dropout 将产生和 L2 正则化相同的**收缩权重**的效果。

**dropout的缺点，该怎么训练它？**

dropout 的一大是**成本函数无法被明确定义**。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将`keep_prob`全部设置为 1.0 后运行代码，确保 $J(w, b)$ 函数单调递减，再打开 dropout。

**还有什么其他的正则化方法？**

* 数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。
* 早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，在两者开始发生较大偏差时及时停止迭代，避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。

**如何对输入做正则化处理？**

使用正则化输入能够有效加速收敛。正则化公式：
$$x = \frac{x - \mu}{\sigma}$$
$$\mu = \frac{1}{m}\sum^m_{i=1}x^{(i)}$$
$$\sigma = \sqrt{\frac{1}{m}\sum^m_{i=1}x^{{(i)}^2}}$$

在不使用正则化的代价函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了正则化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。

**什么是梯度消失和梯度爆炸？**

在梯度函数上出现的以指数级递增或递减的情况分别是**梯度爆炸**和**梯度消失**

**如何利用初始化缓解梯度消失和梯度爆炸？**

根据
$$z={w}_1{x}_1+{w}_2{x}_2 + ... + {w}_n{x}_n + b$$
可知，当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。
为了得到较小的 wi，设置`Var(wi)=1/n`，这里称为 **Xavier initialization**。同理，也有 **He Initialization**。它和  Xavier initialization 唯一的区别是`Var(wi)=2/n`，适用于 **ReLU** 作为激活函数时。
当激活函数使用 ReLU 时，`Var(wi)=2/n`；当激活函数使用 tanh 时，`Var(wi)=1/n`。

**batch/mini-batch/stochastic gradient descent三者区别？**

* **Batch GD**: 是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。成本函数总是向减小的方向下降。
* **Mini-Batch GD**: 每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。成本函数带振荡地向减小的方向下降。
* **Stochastic GD**: 即mini-batch的size为1， 对每一个训练样本执行一次梯度下降，训练速度快，但丢失了向量化带来的计算加速。成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。

**什么是指数加权平均？**

**指数加权平均（Exponentially Weight Average）** 是一种常用的序列数据处理方式，计算公式为：

$$S_t = \begin{cases} Y_1, &t = 1 \\ \beta S_{t-1} + (1-\beta)Y_t, &t > 1 \end{cases}$$

其中 $Y_t$ 为 t 下的实际值，$S_t$ 为 t 下加权平均后的值，β 为权重值。
由极限定理：
$${\lim_{\beta\to 0}}(1 - \beta)^{\frac{1}{\beta}} = \frac{1}{e} \approx 0.368$$
可知，指数加权平均相当于平均了前 $\frac{1}{1-\beta}$ 天的数据。

**什么是动量梯度下降法？**

**动量梯度下降（Gradient Descent with Momentum）** 是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：

$$v_{dW^{[l]}} = \beta v_{dW^{[l]}} + (1 - \beta) dW^{[l]}$$
$$v_{db^{[l]}} = \beta v_{db^{[l]}} + (1 - \beta) db^{[l]}$$
$$W^{[l]} := W^{[l]} - \alpha v_{dW^{[l]}}$$
$$b^{[l]} := b^{[l]} - \alpha v_{db^{[l]}}$$

通常 $\beta = 0.9$ 将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v_{dw}$、$v_{db}$ 相当于速度。
小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。

**什么是RMSProp算法？**

**RMSProp（Root Mean Square Prop，均方根支）** 算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为：

$$s_{dw} = \beta s_{dw} + (1 - \beta)(dw)^2$$
$$s_{db} = \beta s_{db} + (1 - \beta)(db)^2$$
$$w := w - \alpha \frac{dw}{\sqrt{s_{dw} + \epsilon}}$$
$$b := b - \alpha \frac{db}{\sqrt{s_{db} + \epsilon}}$$

其中，ϵ 是一个实际操作时加上的较小数（例如10^-8），为了防止分母太小而导致的数值不稳定。RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。

**什么是Adam算法？**

**Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）** 基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。具体过程如下：

首先进行初始化：

$$v_{dW} = 0, s_{dW} = 0, v_{db} = 0, s_{db} = 0$$

用每一个 mini-batch 计算 dW、db，第 t 次迭代时：

$$v_{dW} = \beta_1 v_{dW} + (1 - \beta_1) dW$$
$$v_{db} = \beta_1 v_{db} + (1 - \beta_1) db$$
$$s_{dW} = \beta_2 s_{dW} + (1 - \beta_2) {(dW)}^2$$
$$s_{db} = \beta_2 s_{db} + (1 - \beta_2) {(db)}^2$$

一般使用 Adam 算法时需要计算偏差修正：

$$v^{corrected}_{dW} = \frac{v_{dW}}{1-{\beta_1}^t}$$
$$v^{corrected}_{db} = \frac{v_{db}}{1-{\beta_1}^t}$$
$$s^{corrected}_{dW} = \frac{s_{dW}}{1-{\beta_2}^t}$$
$$s^{corrected}_{db} = \frac{s_{db}}{1-{\beta_2}^t}$$

所以，更新 W、b 时有：

$$W := W - \alpha \frac{v^{corrected}_{dW}}{{\sqrt{s^{corrected}_{dW}} + \epsilon}}$$

$$b := b - \alpha \frac{v^{corrected}_{db}}{{\sqrt{s^{corrected}_{db}} + \epsilon}}$$

Adam 优化算法有很多的超参数，其中

* 学习率 α：需要尝试一系列的值，来寻找比较合适的；
* β1：常用的缺省值为 0.9；
* β2：Adam 算法的作者建议为 0.999；
* ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；

**为什么要使用学习率衰减？**

如果设置一个固定的学习率 α，在最小值点附近，由于不同的 batch 中存在一定的噪声，因此不会精确收敛，而是始终在最小值周围一个较大的范围内波动。
而如果随着时间慢慢减少学习率 α 的大小，在初期 α 较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小 α 的值，即减小步长，有助于算法的收敛，更容易接近最优解。

最常用的学习率衰减方法：
$$\alpha = \frac{1}{1 + decay\_rate \times epoch\_num} \times \alpha_0$$

其中，`decay_rate`为衰减率（超参数），`epoch_num`为将所有的训练样本完整过一遍的次数。

**为什么神经网络不容易陷入局部最优问题以及鞍点对学习的影响？**

![saddle](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/saddle.png)

**鞍点（saddle）** 是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。

鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。

**如何调试超参数？**

* **随机选择** 点（而非均匀选取），用这些点实验超参数的效果。这样做的原因是我们提前很难知道超参数的重要程度，可以通过选择更多值来进行更多实验；
* 由粗糙到精细：聚焦效果不错的点组成的小区域，在其中更密集地取值，以此类推；

**什么是Batch Normalization?**

**批标准化（Batch Normalization，经常简称为 BN）** 会使参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更庞大，工作效果也很好，也会使训练更容易。

用和处理输入特征X同样的思路处理 **隐藏层** 的激活值 $a^{[l]}$，以加速 $W^{[l+1]}$ 和 $b^{[l+1]}$ 的训练。在实践中，经常选择标准化 $Z^{[l]}$

$$\mu = \frac{1}{m} \sum_i z^{(i)}$$
$$\sigma^2 = \frac{1}{m} \sum_i {(z_i - \mu)}^2$$
$$z_{norm}^{(i)} = \frac{z^{(i)} - \mu}{\sqrt{\sigma^2 + \epsilon}}$$

其中，m 是单个 mini-batch 所包含的样本个数，ϵ 是为了防止分母为零，通常取 $10^{-8}$。

这样，我们使得所有的输入 $z^{(i)}$ 均值为 0，方差为 1。但我们不想让隐藏层单元总是含有平均值 0 和方差 1，也许隐藏层单元有了不同的分布会更有意义。因此，我们计算

$$\tilde z^{(i)} = \gamma z^{(i)}_{norm} + \beta$$

其中，γ 和 β 都是模型的学习参数，所以可以用各种梯度下降算法来更新 γ 和 β 的值，如同更新神经网络的权重一样。

通过对 γ 和 β 的合理设置，可以让 $\tilde z^{(i)}$ 的均值和方差为任意值。

**设置 γ 和 β 的原因是**，如果各隐藏层的输入均值在靠近 0 的区域，即处于激活函数的线性区域，不利于训练非线性神经网络，从而得到效果较差的模型。因此，需要用 γ 和 β 对标准化后的结果做进一步处理。


**为什么使用Batch Normalization？**

Batch Normalization 效果很好的原因有以下两点：

1. 通过对隐藏层各神经元的输入做类似的标准化处理，提高神经网络训练速度；
2. 可以使前面层的权重变化对后面层造成的影响减小，整体网络更加健壮。

即使输入的值改变了，由于 Batch Normalization 的作用，使得均值和方差保持不变（由 γ 和 β 决定），限制了在前层的参数更新对数值分布的影响程度，因此后层的学习变得更容易一些。Batch Normalization 减少了各层 W 和 b 之间的耦合性，让各层更加独立，实现自我训练学习的效果。

另外，Batch Normalization 也**起到微弱的正则化**（regularization）效果。因为在每个 mini-batch 而非整个数据集上计算均值和方差，只由这一小部分数据估计得出的均值和方差会有一些噪声，因此最终计算出的 $\tilde z^{(i)}$ 也有一定噪声。类似于 dropout，这种噪声会使得神经元不会再特别依赖于任何一个输入特征。

因为 Batch Normalization 只有微弱的正则化效果，因此可以和 dropout 一起使用，以获得更强大的正则化效果。通过应用更大的 mini-batch 大小，可以减少噪声，从而减少这种正则化效果。

最后，不要将 Batch Normalization 作为正则化的手段，而是当作加速学习的方式。正则化只是一种非期望的副作用，Batch Normalization 解决的还是反向传播过程中的梯度问题（梯度消失和爆炸）。

### 卷积神经网络

**用传统神经网络处理计算机视觉问题的缺点？**

计算机视觉时要面临的一个挑战是数据的输入可能会非常大。例如一张 1000x1000x3 的图片，神经网络输入层的维度将高达三百万，使得网络权重 W 非常庞大。这样会造成两个后果：

1. 神经网络结构复杂，数据量相对较少，容易出现过拟合；
2. 所需内存和计算量巨大。

因此，一般的神经网络很难处理蕴含着大量数据的图像。解决这一问题的方法就是使用**卷积神经网络（Convolutional Neural Network, CNN）**。

**什么是图像的卷积运算？**

卷积运算的求解过程是从左到右，由上到下，每次在原始图片矩阵中取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘后求和，将结果组成一个矩阵。滤波器中的值还可以设置为**参数**，通过模型训练来得到。在进行卷积运算时，我们有两种选择：

* **Valid 卷积**：不填充，直接卷积。结果大小为 $(n-f+1) \times (n-f+1)$；
* **Same 卷积**：进行填充，并使得卷积后结果大小与输入一致，这样 $p = \frac{f-1}{2}$。

目前为止我们学习的“卷积”实际上被称为 **互相关（cross-correlation）**，而非数学意义上的卷积。真正的卷积操作在做元素乘积求和之前，要将滤波器沿水平和垂直轴翻转（相当于旋转 180 度）。因为这种翻转对一般为水平或垂直对称的滤波器影响不大，按照机器学习的惯例，我们通常不进行翻转操作，在简化代码的同时使神经网络能够正常工作。

**什么是卷积步长？**

卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置 **步长（Stride）** 来压缩一部分信息。

步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。
设步长为 $s$，填充长度为 $p$，输入图片大小为 $n \times n$，滤波器大小为 $f \times f$，则卷积后图片的尺寸为：

$$\biggl\lfloor \frac{n+2p-f}{s}+1   \biggr\rfloor \times \biggl\lfloor \frac{n+2p-f}{s}+1 \biggr\rfloor$$

**什么是池化操作及它有什么作用？**

与卷积操作类似，池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。池化层的作用是在卷积后很好地聚合了特征，通过降维来减少运算量, 缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。池化过程的特点之一是，它有一组超参数，但是并**没有参数需要学习**。池化过程的超参数包括滤波器的大小 $f$、步长 $s$，以及选用最大池化还是平均池化。而填充 $p$则很少用到。

**为什么使用卷积？**

相比标准神经网络，对于大量的输入数据，卷积过程有效地减少了 CNN 的参数数量，原因有以下两点：

* **参数共享（Parameter sharing）**：特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。
* **稀疏连接（Sparsity of connections）**：在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。

由于 CNN 参数数量较小，所需的训练样本就相对较少，因此在一定程度上不容易发生过拟合现象。并且 CNN 比较擅长捕捉区域位置偏移。即进行物体检测时，不太受物体在图片中位置的影响，增加检测的准确性和系统的健壮性。
